{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp traceability.unsupervised.eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis for Software Traceability [EDA]\n",
    "> Adapted from CodeSearchNet Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "pd.set_option('max_colwidth',300)\n",
    "from pprint import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "columns_long_list = ['repo', 'path', 'url', 'code', \n",
    "                     'code_tokens', 'docstring', 'docstring_tokens', \n",
    "                     'language', 'partition']\n",
    "\n",
    "columns_short_list = ['code_tokens', 'docstring_tokens', \n",
    "                      'language', 'partition']\n",
    "\n",
    "'''\n",
    "Load a list of jsonl.gz files into a pandas DataFrame.\n",
    "\n",
    "param 1: the list of files to put into the DataFrame\n",
    "returns: the pandas DataFrame\n",
    "'''\n",
    "def jsonl_list_to_dataframe(file_list, columns=columns_long_list):\n",
    "    return pd.concat([pd.read_json(f, \n",
    "                                   orient='records', \n",
    "                                   compression='gzip',\n",
    "                                   lines=True)[columns] \n",
    "                      for f in file_list], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "'''\n",
    "param 1: The code to check if its a valid register\n",
    "returns: boolean true if the code is a string, false if it is not\n",
    "'''\n",
    "def valid_register(code):\n",
    "    '''print(code)\n",
    "    print(type(code))'''\n",
    "    return type(code) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "'''\n",
    "Checks if a column in a Pandas DataFrame is comprised of strings\n",
    "param 1: Pandas DataFrame to check\n",
    "param 2: Column within the dataframe to check\n",
    "returns:  the boolean values for each datum in the column\n",
    "'''\n",
    "def get_valid_code_df(code_df, column):\n",
    "    return code_df[code_df[column].apply(valid_register)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastprogress\n",
      "  Downloading fastprogress-1.0.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy in /Users/willkinney/opt/anaconda3/lib/python3.8/site-packages (from fastprogress) (1.18.5)\n",
      "Installing collected packages: fastprogress\n",
      "Successfully installed fastprogress-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastprogress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# Imports\n",
    "import dit\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sentencepiece as sp\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from scipy.stats import sem, t\n",
    "from statistics import mean, median, stdev\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# ds4se\n",
    "from ds4se.mgmnt.prep.bpe import *\n",
    "from ds4se.exp.info import *\n",
    "from ds4se.desc.stats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from ds4se.desc.metrics import *\n",
    "from ds4se.desc.metrics.java import *\n",
    "import lizard\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "'''\n",
    "Adds mccabe metrics to a column of a DataFram\n",
    "param 1: the DataFrame to modify\n",
    "param 2: the columnn to modify\n",
    "returns: the modified dataframe\n",
    "'''\n",
    "def add_method_mccabe_metrics_to_code_df(src_code_df, code_column):\n",
    "    \"\"\"Computes method level McAbe metrics and adds it as columns in the specified dataframe\"\"\"\n",
    "    #result_df = src_code_df.copy()\n",
    "    cyclomatic_complexity = []\n",
    "    nloc = []\n",
    "    parameter_count = []\n",
    "    method_name = []\n",
    "    token_count = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for index, row in src_code_df.iterrows():\n",
    "        #print('index{}'.format(index))\n",
    "        #print('type:{}'.format(type(row[code_column])))\n",
    "        metrics = lizard.analyze_file.analyze_source_code('java_file.java', row[code_column])\n",
    "        metrics_obj = metrics.function_list\n",
    "\n",
    "        valid_indices.append(index)\n",
    "        cyclomatic_complexity.append(metrics_obj[0].cyclomatic_complexity)\n",
    "        nloc.append(metrics_obj[0].nloc)\n",
    "        parameter_count.append(metrics_obj[0].parameter_count)\n",
    "        method_name.append(metrics_obj[0].name)\n",
    "        token_count.append(metrics_obj[0].token_count)\n",
    "    \n",
    "    src_code_df['cyclomatic_complexity'] = cyclomatic_complexity\n",
    "    src_code_df['nloc'] = nloc\n",
    "    src_code_df['parameter_count'] = parameter_count\n",
    "    src_code_df['method_name'] = method_name\n",
    "    src_code_df['token_count'] = token_count\n",
    "    \n",
    "    return src_code_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "'''\n",
    "Generates a heatmap\n",
    "param 1: x values of data to map\n",
    "param 2: y values of data to map\n",
    "param 3: kwargs\n",
    "'''\n",
    "def heatmap(x, y, **kwargs):\n",
    "    if 'color' in kwargs:\n",
    "        color = kwargs['color']\n",
    "    else:\n",
    "        color = [1]*len(x)\n",
    "\n",
    "    if 'palette' in kwargs:\n",
    "        palette = kwargs['palette']\n",
    "        n_colors = len(palette)\n",
    "    else:\n",
    "        n_colors = 256 # Use 256 colors for the diverging color palette\n",
    "        palette = sns.color_palette(\"Blues\", n_colors) \n",
    "\n",
    "    if 'color_range' in kwargs:\n",
    "        color_min, color_max = kwargs['color_range']\n",
    "    else:\n",
    "        color_min, color_max = min(color), max(color) # Range of values that will be mapped to the palette, i.e. min and max possible correlation\n",
    "\n",
    "    def value_to_color(val):\n",
    "        if color_min == color_max:\n",
    "            return palette[-1]\n",
    "        else:\n",
    "            val_position = float((val - color_min)) / (color_max - color_min) # position of value in the input range, relative to the length of the input range\n",
    "            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "            ind = int(val_position * (n_colors - 1)) # target index in the color palette\n",
    "            return palette[ind]\n",
    "\n",
    "    if 'size' in kwargs:\n",
    "        size = kwargs['size']\n",
    "    else:\n",
    "        size = [1]*len(x)\n",
    "\n",
    "    if 'size_range' in kwargs:\n",
    "        size_min, size_max = kwargs['size_range'][0], kwargs['size_range'][1]\n",
    "    else:\n",
    "        size_min, size_max = min(size), max(size)\n",
    "\n",
    "    size_scale = kwargs.get('size_scale', 500)\n",
    "\n",
    "    def value_to_size(val):\n",
    "        if size_min == size_max:\n",
    "            return 1 * size_scale\n",
    "        else:\n",
    "            val_position = (val - size_min) * 0.99 / (size_max - size_min) + 0.01 # position of value in the input range, relative to the length of the input range\n",
    "            val_position = min(max(val_position, 0), 1) # bound the position betwen 0 and 1\n",
    "            return val_position * size_scale\n",
    "    if 'x_order' in kwargs: \n",
    "        x_names = [t for t in kwargs['x_order']]\n",
    "    else:\n",
    "        x_names = [t for t in sorted(set([v for v in x]))]\n",
    "    x_to_num = {p[1]:p[0] for p in enumerate(x_names)}\n",
    "\n",
    "    if 'y_order' in kwargs: \n",
    "        y_names = [t for t in kwargs['y_order']]\n",
    "    else:\n",
    "        y_names = [t for t in sorted(set([v for v in y]))]\n",
    "    y_to_num = {p[1]:p[0] for p in enumerate(y_names)}\n",
    "\n",
    "    plot_grid = plt.GridSpec(1, 15, hspace=0.2, wspace=0.1) # Setup a 1x10 grid\n",
    "    ax = plt.subplot(plot_grid[:,:-1]) # Use the left 14/15ths of the grid for the main plot\n",
    "\n",
    "    marker = kwargs.get('marker', 's')\n",
    "\n",
    "    kwargs_pass_on = {k:v for k,v in kwargs.items() if k not in [\n",
    "         'color', 'palette', 'color_range', 'size', 'size_range', 'size_scale', 'marker', 'x_order', 'y_order', 'xlabel', 'ylabel'\n",
    "    ]}\n",
    "\n",
    "    ax.scatter(\n",
    "        x=[x_to_num[v] for v in x],\n",
    "        y=[y_to_num[v] for v in y],\n",
    "        marker=marker,\n",
    "        s=[value_to_size(v) for v in size], \n",
    "        c=[value_to_color(v) for v in color],\n",
    "        **kwargs_pass_on\n",
    "    )\n",
    "    ax.set_xticks([v for k,v in x_to_num.items()])\n",
    "    ax.set_xticklabels([k for k in x_to_num], rotation=45, horizontalalignment='right')\n",
    "    ax.set_yticks([v for k,v in y_to_num.items()])\n",
    "    ax.set_yticklabels([k for k in y_to_num])\n",
    "\n",
    "    ax.grid(False, 'major')\n",
    "    ax.grid(True, 'minor')\n",
    "    ax.set_xticks([t + 0.5 for t in ax.get_xticks()], minor=True)\n",
    "    ax.set_yticks([t + 0.5 for t in ax.get_yticks()], minor=True)\n",
    "\n",
    "    ax.set_xlim([-0.5, max([v for v in x_to_num.values()]) + 0.5])\n",
    "    ax.set_ylim([-0.5, max([v for v in y_to_num.values()]) + 0.5])\n",
    "    ax.set_facecolor('#F1F1F1')\n",
    "\n",
    "    ax.set_xlabel(kwargs.get('xlabel', ''))\n",
    "    ax.set_ylabel(kwargs.get('ylabel', ''))\n",
    "\n",
    "    # Add color legend on the right side of the plot\n",
    "    if color_min < color_max:\n",
    "        ax = plt.subplot(plot_grid[:,-1]) # Use the rightmost column of the plot\n",
    "\n",
    "        col_x = [0]*len(palette) # Fixed x coordinate for the bars\n",
    "        bar_y=np.linspace(color_min, color_max, n_colors) # y coordinates for each of the n_colors bars\n",
    "\n",
    "        bar_height = bar_y[1] - bar_y[0]\n",
    "        ax.barh(\n",
    "            y=bar_y,\n",
    "            width=[5]*len(palette), # Make bars 5 units wide\n",
    "            left=col_x, # Make bars start at 0\n",
    "            height=bar_height,\n",
    "            color=palette,\n",
    "            linewidth=0\n",
    "        )\n",
    "        ax.set_xlim(1, 2) # Bars are going from 0 to 5, so lets crop the plot somewhere in the middle\n",
    "        ax.grid(False) # Hide grid\n",
    "        ax.set_facecolor('white') # Make background white\n",
    "        ax.set_xticks([]) # Remove horizontal ticks\n",
    "        ax.set_yticks(np.linspace(min(bar_y), max(bar_y), 3)) # Show vertical ticks for min, middle and max\n",
    "        ax.yaxis.tick_right() # Show vertical ticks on the right \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "'''\n",
    "Generates a correlation matrix plot\n",
    "param 1: the data to generate the plot from\n",
    "param 2: the size of the plot\n",
    "param 3: the marker\n",
    "'''\n",
    "def corrplot(data, size_scale=500, marker='s'):\n",
    "    corr = pd.melt(data.reset_index(), id_vars='index').replace(np.nan, 0)\n",
    "    corr.columns = ['x', 'y', 'value']\n",
    "    heatmap(\n",
    "        corr['x'], corr['y'],\n",
    "        color=corr['value'], color_range=[-1, 1],\n",
    "        palette=sns.diverging_palette(20, 220, n=256),\n",
    "        size=corr['value'].abs(), size_range=[0,1],\n",
    "        marker=marker,\n",
    "        x_order=data.columns,\n",
    "        y_order=data.columns[::-1],\n",
    "        size_scale=size_scale\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
