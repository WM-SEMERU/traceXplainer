{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp infoxplainer.causality.eval.traceability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Methods for Software Traceability: Causality\n",
    "> This module is dedicated to evaluate word2vec/doc2vec or any neural unsupervised approaches on traceability datasets by using the theory of information transmission.\n",
    "> Implementing Causalit Analysis\n",
    "> Author: @danaderp Feb 2021\n",
    "\n",
    "Software Traceability is analyzed in three classes of tasks ways: description, prediction, and causal inference. \n",
    "\n",
    "## Causal Inference\n",
    "### Causality Analysis of Traceability Distance\n",
    "\n",
    "### Causality Analysis of Information Transmission\n",
    "\n",
    "Check out this methods for causality [links](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6074945/#:~:text=G%20methods%20include%20inverse%20probability,assumptions%20than%20standard%20regression%20methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Science Causal Inference Task\n",
    "Counterfactual prediction is using data to predict certain features of the world if the world had been different, as is required in causal inference applications. An example of causal inference is the estimation of the mortality rate that would have been observed if all individuals in a study population had received screening for colorectal cancer vs. if they had not received screening. The analytics employed for causal inference range from elementary calculations in randomized experiments with no loss to follow-up and perfect adherence (e.g., the difference in mortality rates between the screened and the unscreened) to complex implementations of g- methods in observational studies with treatment-confounder feedback (e.g., the plug-in g- formula).11 Note that, contrary to some computer scientists’ belief, “causal inference” and “reinforcement learning” are not synonyms. Reinforcement learning is a technique that, in some simple settings, leads to sound causal inference. However, reinforcement learning is inapplicable in complex causal settings, as we discuss below. Also, note that statistical inference is often required in all three tasks. For example, one might want to add 95% confidence intervals around descriptive, predictive, or causal estimates involving samples of target populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
