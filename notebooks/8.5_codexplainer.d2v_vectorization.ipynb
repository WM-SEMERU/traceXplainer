{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp codexplainer.d2v_vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import os\n",
    "import sentencepiece as spm\n",
    "\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Optional\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from ds4se.mgmnt.prep.bpe_tokenization import HFTokenizer, SPTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d2v_vectorization\n",
    "\n",
    "> Use doc2vec models to get distributed representation (embedding vectors) for source code\n",
    "\n",
    "> @Alvaro 15 April 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "\n",
    "Doc2Vec model is not trained, just loaded and used through gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# utils\n",
    "def check_file_existence(path) -> bool:\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        logging.error('Provided file cannot be found.')\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def configure_dirs(base_path: str, config_name: str, dataset_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs configuration of directories for storing vectors\n",
    "    :param base_path:\n",
    "    :param config_name:\n",
    "    :param dataset_name:\n",
    "    \n",
    "    :return: Full configuration path\n",
    "    \"\"\"\n",
    "    base_path = Path(base_path)\n",
    "    base_path.mkdir(exist_ok=True)\n",
    "\n",
    "    full_path = base_path / config_name\n",
    "    full_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    full_path = full_path / dataset_name\n",
    "    full_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    return str(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizer class is defined abstract in order to provide alternatives for tokenization (SentencePiece and HuggingFace's Tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Doc2VecVectorizer(ABC):\n",
    "    def __init__(self, tkzr_path:str, d2v_path: str, tokenizer: Optional[Any]=None):\n",
    "        \"\"\"\n",
    "        Default constructor for Vectorizer class\n",
    "        \"\"\"\n",
    "        self.tkzr_path = tkzr_path\n",
    "        self.d2v_path = d2v_path\n",
    "        \n",
    "        self._load_doc2vec_model(d2v_path)\n",
    "        if tokenizer is None:\n",
    "            self._load_tokenizer_model(self.tkzr_path)\n",
    "        else:\n",
    "            self.tokenizer = tokenizer\n",
    "        \n",
    "    def tokenize_df(self, df: pd.DataFrame, code_column: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Performs tokenization of a Dataframe\n",
    "        \n",
    "        :param df: DataFrame containing code\n",
    "        :param code_column: Str indicating column name of code data\n",
    "        \n",
    "        :return: Tokenized DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.tokenizer.tokenize_df(df, code_column)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _load_tokenizer_model(self, model_path: str):\n",
    "        pass\n",
    "    \n",
    "    def _load_doc2vec_model(self, model_path: str):\n",
    "        \"\"\"\n",
    "        :param model_path: Path to the model file\n",
    "        :return: Gensim Doc2Vec model (corresponding to the loaded model)\n",
    "        \"\"\"\n",
    "        if not check_file_existence(model_path):\n",
    "            msg = 'Doc2vec model could no be loaded'\n",
    "            logging.error('Doc2vec model could no be loaded')\n",
    "            raise Exception(msg)\n",
    "        \n",
    "        model = gensim.models.Doc2Vec.load(model_path)\n",
    "        self.d2v_model = model    \n",
    "        \n",
    "    def infer_d2v(self, df: pd.DataFrame, tokenized_column: str, out_path: str,\n",
    "                  config_name: str, sample_set_name: str,\n",
    "                  perform_tokenization: Optional[bool]=False,\n",
    "                  steps: Optional[int]=200) -> tuple:\n",
    "        \"\"\"\n",
    "        Performs vectorization via Doc2Vec model \n",
    "        :param df: Pandas DataFrame containing source code\n",
    "        :param tokenized_column: Column name of the column corresponding to source code tokenized\n",
    "                                 with the appropriate implementation\n",
    "        :param out_path: String indicating the base location for storing vectors\n",
    "        :param config_name: String indicating the model from which the samples came from\n",
    "        :param sample_set_name: String indicating the base name for identifying the set of\n",
    "                                 samples being processed\n",
    "        :param perform_tokenization: Bool indicating whether tokenization is required or not\n",
    "                                     (input df is previously tokenized or not)\n",
    "        :param steps: Steps for the doc2vec infere\n",
    "        :return: Tuple containing (idx of the input DF, obtained vectors)\n",
    "        \"\"\"\n",
    "        \n",
    "        tokenized_df = df.copy()\n",
    "        \n",
    "        if perform_tokenization:\n",
    "            tokenized_df[tokenized_column] = self.tokenizer.tokenize_df(tokenized_df, 'code')\n",
    "        \n",
    "        inferred_vecs = np.array([self.d2v_model.infer_vector(tok_snippet, steps=200) \\\n",
    "                                  for tok_snippet in tokenized_df[tokenized_column].values])\n",
    "        \n",
    "        indices = np.array(df.index)\n",
    "        \n",
    "        dest_path = configure_dirs(out_path, config_name, sample_set_name)\n",
    "        \n",
    "        now = datetime.now()\n",
    "        ts = str(datetime.timestamp(now))\n",
    "        \n",
    "        file_name = f\"{dest_path}/{self.tok_name}-{ts}\"\n",
    "        \n",
    "        np.save(f\"{file_name}-idx\", indices)\n",
    "        np.save(f\"{file_name}-ft_vecs\", inferred_vecs)\n",
    "        \n",
    "        return indices, inferred_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Doc2VecVectorizerSP(Doc2VecVectorizer):\n",
    "    \"\"\"\n",
    "    Class to perform vectorization via Doc2Vec model\n",
    "    leveraging SentencePiece to tokenizer sequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, sp_path: str, d2v_path: str, tokenizer: Optional[Any]=None):\n",
    "        \"\"\"\n",
    "        :param sp_path: Path to the SentencePiece saved model\n",
    "        :param d2v_path: Path to the Doc2Vec saved model\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(sp_path, d2v_path, tokenizer)\n",
    "        self.tok_name = \"sp\"\n",
    "    \n",
    "    def _load_tokenizer_model(self, model_path: str):\n",
    "        \"\"\"\n",
    "        Loads the sentence piece model stored in the specified path \n",
    "        :param model_path: Path to the model file\n",
    "        :return: SentencePieceProcessor object (corresponding to loaded model)\n",
    "        \"\"\"\n",
    "        if not check_file_existence(model_path):\n",
    "            msg = 'Sentence piece model could no be loaded'\n",
    "            logging.error(msg)\n",
    "            raise Exception(msg)\n",
    "        \n",
    "        sp_processor = spm.SentencePieceProcessor()\n",
    "        sp_processor.load(model_path)\n",
    "        self.tokenizer = sp_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Doc2VecVectorizerHF(Doc2VecVectorizer):\n",
    "    \"\"\"\n",
    "    Class to perform vectorization via Doc2Vec model\n",
    "    leveraging HF's Tokenizer\n",
    "    \"\"\"\n",
    "    def __init__(self, tkzr_path: str, d2v_path: str, tokenizer: Optional[Any]=None):\n",
    "        \"\"\"\n",
    "        :param tkzr_path: Path to the HF Tokenizer saved model\n",
    "        :param d2v_path: Path to the Doc2Vec saved model\n",
    "        \"\"\"\n",
    "        super().__init__(tkzr_path, d2v_path, tokenizer)\n",
    "        self.tok_name = \"hf\"\n",
    "        \n",
    "    def _load_tokenizer_model(self, path: str) -> Tokenizer:\n",
    "        \"\"\"\n",
    "        Function to load a saved HuggingFace tokenizer\n",
    "\n",
    "        :param path: Path containing the tokenizer file\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if not check_file_existence(path):\n",
    "            msg = 'HuggingFace tokenizer could no be loaded.'\n",
    "            logging.error(msg)\n",
    "            raise Exception(msg)\n",
    "        \n",
    "        self.tokenizer = Tokenizer.from_file(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Searchnet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_df = pd.read_csv(\"/tf/main/dvc-ds4se/code/searchnet/[codesearchnet-java-1597073966.81902].csv\",  header=0, index_col=0, sep='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>partition</th>\n",
       "      <th>bpe32k</th>\n",
       "      <th>code_len</th>\n",
       "      <th>bpe32_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/internal/observers/...</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>protected final void fastPathOrderedEmit(U val...</td>\n",
       "      <td>['protected', 'final', 'void', 'fastPathOrdere...</td>\n",
       "      <td>Makes sure the fast-path emits in order.\\n@par...</td>\n",
       "      <td>['Makes', 'sure', 'the', 'fast', '-', 'path', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁protected', '▁final', '▁void', '▁fast', 'Pa...</td>\n",
       "      <td>134</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@CheckReturnValue\\n    @NonNull\\n    @Schedule...</td>\n",
       "      <td>['@', 'CheckReturnValue', '@', 'NonNull', '@',...</td>\n",
       "      <td>Mirrors the one ObservableSource in an Iterabl...</td>\n",
       "      <td>['Mirrors', 'the', 'one', 'ObservableSource', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'CheckReturnValue', '▁', '@', 'NonN...</td>\n",
       "      <td>63</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@SuppressWarnings(\"unchecked\")\\n    @CheckRetu...</td>\n",
       "      <td>['@', 'SuppressWarnings', '(', '\"unchecked\"', ...</td>\n",
       "      <td>Mirrors the one ObservableSource in an array o...</td>\n",
       "      <td>['Mirrors', 'the', 'one', 'ObservableSource', ...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'SuppressWarnings', '(\"', 'unchecke...</td>\n",
       "      <td>107</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@SuppressWarnings({ \"unchecked\", \"rawtypes\" })...</td>\n",
       "      <td>['@', 'SuppressWarnings', '(', '{', '\"unchecke...</td>\n",
       "      <td>Concatenates elements of each ObservableSource...</td>\n",
       "      <td>['Concatenates', 'elements', 'of', 'each', 'Ob...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...</td>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ReactiveX/RxJava</td>\n",
       "      <td>src/main/java/io/reactivex/Observable.java</td>\n",
       "      <td>https://github.com/ReactiveX/RxJava/blob/ac841...</td>\n",
       "      <td>@SuppressWarnings({ \"unchecked\", \"rawtypes\" })...</td>\n",
       "      <td>['@', 'SuppressWarnings', '(', '{', '\"unchecke...</td>\n",
       "      <td>Returns an Observable that emits the items emi...</td>\n",
       "      <td>['Returns', 'an', 'Observable', 'that', 'emits...</td>\n",
       "      <td>java</td>\n",
       "      <td>test</td>\n",
       "      <td>['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...</td>\n",
       "      <td>91</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               repo                                               path  \\\n",
       "0  ReactiveX/RxJava  src/main/java/io/reactivex/internal/observers/...   \n",
       "1  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "2  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "3  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "4  ReactiveX/RxJava         src/main/java/io/reactivex/Observable.java   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "1  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "2  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "3  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "4  https://github.com/ReactiveX/RxJava/blob/ac841...   \n",
       "\n",
       "                                                code  \\\n",
       "0  protected final void fastPathOrderedEmit(U val...   \n",
       "1  @CheckReturnValue\\n    @NonNull\\n    @Schedule...   \n",
       "2  @SuppressWarnings(\"unchecked\")\\n    @CheckRetu...   \n",
       "3  @SuppressWarnings({ \"unchecked\", \"rawtypes\" })...   \n",
       "4  @SuppressWarnings({ \"unchecked\", \"rawtypes\" })...   \n",
       "\n",
       "                                         code_tokens  \\\n",
       "0  ['protected', 'final', 'void', 'fastPathOrdere...   \n",
       "1  ['@', 'CheckReturnValue', '@', 'NonNull', '@',...   \n",
       "2  ['@', 'SuppressWarnings', '(', '\"unchecked\"', ...   \n",
       "3  ['@', 'SuppressWarnings', '(', '{', '\"unchecke...   \n",
       "4  ['@', 'SuppressWarnings', '(', '{', '\"unchecke...   \n",
       "\n",
       "                                           docstring  \\\n",
       "0  Makes sure the fast-path emits in order.\\n@par...   \n",
       "1  Mirrors the one ObservableSource in an Iterabl...   \n",
       "2  Mirrors the one ObservableSource in an array o...   \n",
       "3  Concatenates elements of each ObservableSource...   \n",
       "4  Returns an Observable that emits the items emi...   \n",
       "\n",
       "                                    docstring_tokens language partition  \\\n",
       "0  ['Makes', 'sure', 'the', 'fast', '-', 'path', ...     java      test   \n",
       "1  ['Mirrors', 'the', 'one', 'ObservableSource', ...     java      test   \n",
       "2  ['Mirrors', 'the', 'one', 'ObservableSource', ...     java      test   \n",
       "3  ['Concatenates', 'elements', 'of', 'each', 'Ob...     java      test   \n",
       "4  ['Returns', 'an', 'Observable', 'that', 'emits...     java      test   \n",
       "\n",
       "                                              bpe32k  code_len  bpe32_len  \n",
       "0  ['▁protected', '▁final', '▁void', '▁fast', 'Pa...       134        138  \n",
       "1  ['▁', '@', 'CheckReturnValue', '▁', '@', 'NonN...        63         71  \n",
       "2  ['▁', '@', 'SuppressWarnings', '(\"', 'unchecke...       107        109  \n",
       "3  ['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...        79         83  \n",
       "4  ['▁', '@', 'SuppressWarnings', '({', '▁\"', 'un...        91        112  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "java_samples = java_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>partition</th>\n",
       "      <th>bpe32k</th>\n",
       "      <th>code_len</th>\n",
       "      <th>bpe32_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14702</th>\n",
       "      <td>wildfly/wildfly-core</td>\n",
       "      <td>controller/src/main/java/org/jboss/as/controll...</td>\n",
       "      <td>https://github.com/wildfly/wildfly-core/blob/c...</td>\n",
       "      <td>@Override\\n    public void validateParameter(S...</td>\n",
       "      <td>['@', 'Override', 'public', 'void', 'validateP...</td>\n",
       "      <td>{@inheritDoc}</td>\n",
       "      <td>['{']</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁', '@', 'Override', '▁public', '▁void', '▁v...</td>\n",
       "      <td>78</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29105</th>\n",
       "      <td>cloudant/java-cloudant</td>\n",
       "      <td>cloudant-client/src/main/java/com/cloudant/cli...</td>\n",
       "      <td>https://github.com/cloudant/java-cloudant/blob...</td>\n",
       "      <td>public InputStream find(String id, String rev)...</td>\n",
       "      <td>['public', 'InputStream', 'find', '(', 'String...</td>\n",
       "      <td>Finds the document with the specified document...</td>\n",
       "      <td>['Finds', 'the', 'document', 'with', 'the', 's...</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁public', '▁InputStream', '▁find', '(', 'Str...</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18440</th>\n",
       "      <td>ops4j/org.ops4j.pax.logging</td>\n",
       "      <td>pax-logging-service/src/main/java/org/apache/l...</td>\n",
       "      <td>https://github.com/ops4j/org.ops4j.pax.logging...</td>\n",
       "      <td>public void close() {\\n    /**\\n     * Set clo...</td>\n",
       "      <td>['public', 'void', 'close', '(', ')', '{', '/*...</td>\n",
       "      <td>Close this &lt;code&gt;AsyncAppender&lt;/code&gt; by inter...</td>\n",
       "      <td>['Close', 'this', '&lt;code', '&gt;', 'AsyncAppender...</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁public', '▁void', '▁close', '()', '▁{', '▁/...</td>\n",
       "      <td>78</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>reactor/reactor-core</td>\n",
       "      <td>reactor-core/src/main/java/reactor/core/publis...</td>\n",
       "      <td>https://github.com/reactor/reactor-core/blob/d...</td>\n",
       "      <td>public final Mono&lt;T&gt; doAfterTerminate(Runnable...</td>\n",
       "      <td>['public', 'final', 'Mono', '&lt;', 'T', '&gt;', 'do...</td>\n",
       "      <td>Add behavior (side-effect) triggered after the...</td>\n",
       "      <td>['Add', 'behavior', '(', 'side', '-', 'effect'...</td>\n",
       "      <td>java</td>\n",
       "      <td>valid</td>\n",
       "      <td>['▁public', '▁final', '▁Mon', 'o', '&lt;', 'T', '...</td>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>OpenLiberty/open-liberty</td>\n",
       "      <td>dev/com.ibm.ws.messaging.runtime/src/com/ibm/w...</td>\n",
       "      <td>https://github.com/OpenLiberty/open-liberty/bl...</td>\n",
       "      <td>@Override\\n    public void attachLocalPtoPLoca...</td>\n",
       "      <td>['@', 'Override', 'public', 'void', 'attachLoc...</td>\n",
       "      <td>Method attachLocalPtoPLocalisation\\n\\n&lt;p&gt; Atta...</td>\n",
       "      <td>['Method', 'attachLocalPtoPLocalisation']</td>\n",
       "      <td>java</td>\n",
       "      <td>train</td>\n",
       "      <td>['▁', '@', 'Override', '▁public', '▁void', '▁a...</td>\n",
       "      <td>114</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              repo  \\\n",
       "14702         wildfly/wildfly-core   \n",
       "29105       cloudant/java-cloudant   \n",
       "18440  ops4j/org.ops4j.pax.logging   \n",
       "1869          reactor/reactor-core   \n",
       "3541      OpenLiberty/open-liberty   \n",
       "\n",
       "                                                    path  \\\n",
       "14702  controller/src/main/java/org/jboss/as/controll...   \n",
       "29105  cloudant-client/src/main/java/com/cloudant/cli...   \n",
       "18440  pax-logging-service/src/main/java/org/apache/l...   \n",
       "1869   reactor-core/src/main/java/reactor/core/publis...   \n",
       "3541   dev/com.ibm.ws.messaging.runtime/src/com/ibm/w...   \n",
       "\n",
       "                                                     url  \\\n",
       "14702  https://github.com/wildfly/wildfly-core/blob/c...   \n",
       "29105  https://github.com/cloudant/java-cloudant/blob...   \n",
       "18440  https://github.com/ops4j/org.ops4j.pax.logging...   \n",
       "1869   https://github.com/reactor/reactor-core/blob/d...   \n",
       "3541   https://github.com/OpenLiberty/open-liberty/bl...   \n",
       "\n",
       "                                                    code  \\\n",
       "14702  @Override\\n    public void validateParameter(S...   \n",
       "29105  public InputStream find(String id, String rev)...   \n",
       "18440  public void close() {\\n    /**\\n     * Set clo...   \n",
       "1869   public final Mono<T> doAfterTerminate(Runnable...   \n",
       "3541   @Override\\n    public void attachLocalPtoPLoca...   \n",
       "\n",
       "                                             code_tokens  \\\n",
       "14702  ['@', 'Override', 'public', 'void', 'validateP...   \n",
       "29105  ['public', 'InputStream', 'find', '(', 'String...   \n",
       "18440  ['public', 'void', 'close', '(', ')', '{', '/*...   \n",
       "1869   ['public', 'final', 'Mono', '<', 'T', '>', 'do...   \n",
       "3541   ['@', 'Override', 'public', 'void', 'attachLoc...   \n",
       "\n",
       "                                               docstring  \\\n",
       "14702                                      {@inheritDoc}   \n",
       "29105  Finds the document with the specified document...   \n",
       "18440  Close this <code>AsyncAppender</code> by inter...   \n",
       "1869   Add behavior (side-effect) triggered after the...   \n",
       "3541   Method attachLocalPtoPLocalisation\\n\\n<p> Atta...   \n",
       "\n",
       "                                        docstring_tokens language partition  \\\n",
       "14702                                              ['{']     java     train   \n",
       "29105  ['Finds', 'the', 'document', 'with', 'the', 's...     java     train   \n",
       "18440  ['Close', 'this', '<code', '>', 'AsyncAppender...     java     train   \n",
       "1869   ['Add', 'behavior', '(', 'side', '-', 'effect'...     java     valid   \n",
       "3541           ['Method', 'attachLocalPtoPLocalisation']     java     train   \n",
       "\n",
       "                                                  bpe32k  code_len  bpe32_len  \n",
       "14702  ['▁', '@', 'Override', '▁public', '▁void', '▁v...        78         86  \n",
       "29105  ['▁public', '▁InputStream', '▁find', '(', 'Str...        22         23  \n",
       "18440  ['▁public', '▁void', '▁close', '()', '▁{', '▁/...        78        115  \n",
       "1869   ['▁public', '▁final', '▁Mon', 'o', '<', 'T', '...        38         50  \n",
       "3541   ['▁', '@', 'Override', '▁public', '▁void', '▁a...       114        222  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "java_samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14702, 29105, 18440,  1869,  3541,  4346,  7034,  7423, 22602,\n",
       "       14870])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(java_samples.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"bpe32k_path\": \"/tf/main/dvc-ds4se/models/bpe/sentencepiece/deprecated/java_bpe_32k.model\",\n",
    "    \"doc2vec_java_path\": \"/tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\",\n",
    "    \"hf_tokenizer\": \"/tf/main/nbs/tokenizer.json\",\n",
    "    \"vectors_storage_path\": \"/tf/main/dvc-ds4se/results/d2v_vectors\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure directories to store obtained vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test vectorization with Doc2Vec (based on SentencePiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_tokenizer = SPTokenizer(params['bpe32k_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-25 17:53:24,968 : INFO : loading Doc2Vec object from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n",
      "2021-05-25 17:53:25,538 : INFO : loading vocabulary recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.vocabulary.* with mmap=None\n",
      "2021-05-25 17:53:25,539 : INFO : loading trainables recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.trainables.* with mmap=None\n",
      "2021-05-25 17:53:25,539 : INFO : loading wv recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.wv.* with mmap=None\n",
      "2021-05-25 17:53:25,540 : INFO : loading docvecs recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.* with mmap=None\n",
      "2021-05-25 17:53:25,541 : INFO : loading vectors_docs from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.vectors_docs.npy with mmap=None\n",
      "2021-05-25 17:53:25,768 : INFO : loaded /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n"
     ]
    }
   ],
   "source": [
    "vectorizer = Doc2VecVectorizerSP(params['bpe32k_path'], params[\"doc2vec_java_path\"], tokenizer=sp_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = vectorizer.tokenize_df(java_samples, 'code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411      [▁public, ▁void, ▁each, Row, (, String, ▁sql, ...\n",
       "1698     [▁private, ▁static, ▁int, ▁get, Block, Length,...\n",
       "20430    [▁public, ▁static, ▁void, ▁incr, Compute, Spec...\n",
       "25303    [▁public, ▁void, ▁info, (, User, Feed, back, E...\n",
       "4869     [▁protected, ▁Reliability, ▁getRe, liability, ...\n",
       "6272     [▁public, ▁static, ▁String, ▁message, Mo, ved,...\n",
       "22668    [▁public, ▁List, <, Form, >, ▁getAll, By, Logg...\n",
       "5547     [▁@, Worker, Thread, ▁public, ▁long, ▁insert, ...\n",
       "19835    [▁@, XmlElementDecl, (, namespace, ▁=, ▁\", htt...\n",
       "5232     [▁public, ▁void, ▁pairs, Matching, (, final, ▁...\n",
       "Name: code, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, vectors = vectorizer.infer_d2v(java_samples, 'bpe32k-tokens', params[\"vectors_storage_path\"],\n",
    "                                        \"human_trn\", \"10-sample-20052021\", perform_tokenization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  411,  1698, 20430, 25303,  4869,  6272, 22668,  5547, 19835,\n",
       "        5232])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07038781, -0.58109975, -0.9463178 , ..., -2.1921134 ,\n",
       "        -1.7908362 ,  0.71608573],\n",
       "       [ 0.5599993 ,  0.7043637 , -0.43915233, ...,  0.483188  ,\n",
       "        -0.4529718 ,  0.28490466],\n",
       "       [ 0.08634362,  0.06870021,  0.11204075, ..., -1.0273234 ,\n",
       "         0.50954473,  0.4812691 ],\n",
       "       ...,\n",
       "       [-1.6385366 ,  0.26093784,  0.58297956, ..., -0.2630522 ,\n",
       "        -1.3928666 , -1.9163388 ],\n",
       "       [ 1.0110482 , -0.27105835, -0.2851525 , ..., -0.5329149 ,\n",
       "        -0.7664558 , -0.67246526],\n",
       "       [ 0.31932476,  1.1802573 , -0.26099774, ..., -0.74102426,\n",
       "        -0.9270507 ,  0.55426735]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Test vectorization with Doc2Vec (based on HuggingFace's Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_tokenizer = HFTokenizer(params['hf_tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-25 17:57:17,865 : INFO : loading Doc2Vec object from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n",
      "2021-05-25 17:57:18,469 : INFO : loading vocabulary recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.vocabulary.* with mmap=None\n",
      "2021-05-25 17:57:18,470 : INFO : loading trainables recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.trainables.* with mmap=None\n",
      "2021-05-25 17:57:18,471 : INFO : loading wv recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.wv.* with mmap=None\n",
      "2021-05-25 17:57:18,472 : INFO : loading docvecs recursively from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.* with mmap=None\n",
      "2021-05-25 17:57:18,473 : INFO : loading vectors_docs from /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model.docvecs.vectors_docs.npy with mmap=None\n",
      "2021-05-25 17:57:18,701 : INFO : loaded /tf/main/dvc-ds4se/models/pv/bpe8k/[doc2vec-Java-PVDBOW-500-20E-8k-1594569414.336389].model\n"
     ]
    }
   ],
   "source": [
    "hf_vectorizer = Doc2VecVectorizerHF(params['hf_tokenizer'], params[\"doc2vec_java_path\n",
    "                                                                   \"], tokenizer=hf_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = hf_vectorizer.tokenize_df(java_samples, 'code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14702    [@, Override, Ċ, ĠĠĠ, Ġp, ublic, Ġ, void, Ġval...\n",
       "29105    [public, ĠInputStream, Ġfind, (, String, Ġid, ...\n",
       "18440    [public, Ġ, void, Ġclose, (, ), Ġ, {, Ċ, ĠĠĠ, ...\n",
       "1869     [public, Ġ, final, ĠMon, o, <, T, >, Ġ, do, Af...\n",
       "3541     [@, Override, Ċ, ĠĠĠ, Ġp, ublic, Ġ, void, Ġatt...\n",
       "4346     [@, NonNull, Ċ, ĠĠĠ, Ġp, ublic, Ġstat, ic, ĠSt...\n",
       "7034     [@, Override, Ċ, ĠĠĠ, Ġp, ublic, ĠGet, Inte, g...\n",
       "7423     [public, ĠProperty, Definition, [, ], ĠgetProp...\n",
       "22602    [private, ĠInteger, Vector, ĠgetS, em, ant, ic...\n",
       "14870    [public, Ġstat, ic, ĠPath, Address, Ġtrans, fo...\n",
       "Name: code, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, vectors = hf_vectorizer.infer_d2v(java_samples, 'bpe-hf-tokens', params[\"vectors_storage_path\"],\n",
    "                                        \"human_trn\", \"10-sample-20052021\", perform_tokenization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14702, 29105, 18440,  1869,  3541,  4346,  7034,  7423, 22602,\n",
       "       14870])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.4170451e-01,  1.5865822e+00, -1.5674361e-03, ...,\n",
       "        -1.5819024e+00,  5.6919813e-01, -8.9502269e-01],\n",
       "       [-6.8043721e-01, -2.6820338e-01,  3.9857324e-02, ...,\n",
       "        -4.6697325e-01, -2.4018152e-01, -1.2825546e-02],\n",
       "       [-9.2789513e-01,  2.2848961e+00,  4.6906880e-01, ...,\n",
       "        -1.4570843e+00,  4.1882795e-01,  2.0528805e+00],\n",
       "       ...,\n",
       "       [-4.0173218e-01, -5.2009028e-01, -7.1974285e-02, ...,\n",
       "         1.7002009e-01, -3.4709036e-01,  2.7916936e-02],\n",
       "       [-1.2270563e+00,  2.2932885e+00,  1.0075219e+00, ...,\n",
       "        -1.7897085e+00,  9.4967000e-02,  3.8890353e-01],\n",
       "       [-4.5752251e-01,  1.7355688e+00,  7.0712149e-01, ...,\n",
       "        -9.3595511e-01, -3.8285625e-01,  2.4485412e+00]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Export code as module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 0.0_mgmnt.prep.i.ipynb.\n",
      "Converted 0.1_mgmnt.prep.conv.ipynb.\n",
      "Converted 0.3_mgmnt.prep.bpe.ipynb.\n",
      "Converted 0.6_mgmnt.prep.nltk.ipynb.\n",
      "Converted 0.7_mgmnt.prep.files_mgmnt.ipynb.\n",
      "Converted 0.8_mgmnt.prep.bpe_tokenization.ipynb.\n",
      "Converted 1.0_exp.i.ipynb.\n",
      "Converted 1.1_exp.info-[inspect].ipynb.\n",
      "Converted 1.1_exp.info.ipynb.\n",
      "Converted 1.2_exp.csnc.ipynb.\n",
      "Converted 1.2_exp.gen.code.ipynb.\n",
      "Converted 1.3_exp.csnc_python.ipynb.\n",
      "Converted 10.0_utils.clusterization.ipynb.\n",
      "Converted 10.1_utils.visualization.ipynb.\n",
      "Converted 2.0_repr.codebert.ipynb.\n",
      "Converted 2.0_repr.i.ipynb.\n",
      "Converted 2.1_repr.codeberta.ipynb.\n",
      "Converted 2.1_repr.roberta.train.ipynb.\n",
      "Converted 2.2_repr.roberta.eval.ipynb.\n",
      "Converted 2.3_repr.word2vec.train.ipynb.\n",
      "Converted 2.6_repr.word2vec.eval.ipynb.\n",
      "Converted 2.7_repr.distmetrics.ipynb.\n",
      "Converted 2.8_repr.sentence_transformers.ipynb.\n",
      "Converted 3.1_mining.unsupervised.traceability.eda.ipynb.\n",
      "Converted 3.2_mining.unsupervised.eda.traceability.d2v.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "h\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "Converted 3.2_mining.unsupervised.mutual_information.traceability.approach.sacp-w2v.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "h\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "e\n",
      "This cell doesn't have an export destination and was ignored:\n",
      "E\n",
      "Converted 3.2_mining.unsupervised.mutual_information.traceability.approach.sacp.w2v.ipynb.\n",
      "Converted 3.2_mutual_information_theory.eval.ipynb.\n",
      "Converted 3.4_facade.ipynb.\n",
      "Converted 4.0_mining.ir.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.d2v.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp4.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp5.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v-exp6.ipynb.\n",
      "Converted 5.0_experiment.mining.ir.unsupervised.w2v.ipynb.\n",
      "Converted 6.0_desc.stats.ipynb.\n",
      "Converted 6.0_eval.mining.ir.unsupervised.x2v.ipynb.\n",
      "Converted 6.1_desc.metrics.java.ipynb.\n",
      "Converted 6.1_desc.metrics.main.ipynb.\n",
      "Converted 6.1_desc.metrics.se.ipynb.\n",
      "Converted 6.2_desc.metrics.java.ipynb.\n",
      "Converted 6.2_desc.metrics.main.ipynb.\n",
      "Converted 7.0_inf.i.ipynb.\n",
      "Converted 7.1_inf.bayesian.ipynb.\n",
      "Converted 7.2_inf.causal.ipynb.\n",
      "Converted 7.3_statistical_analysis.ipynb.\n",
      "Converted 8.0_interpretability.i.ipynb.\n",
      "Converted 8.1_interpretability.error_checker.ipynb.\n",
      "Converted 8.2_interpretability.metrics_python.ipynb.\n",
      "Converted 8.3_interpretability.metrics_java.ipynb.\n",
      "Converted 8.4_interpretability.metrics_example.ipynb.\n",
      "Converted 8.5_interpretability.d2v_vectorization.ipynb.\n",
      "Converted 8.6_interpretability.prototypes_criticisms.ipynb.\n",
      "Converted 8.7_interpretability.info_theory_processing.ipynb.\n",
      "Converted 9.0_ds.causality.eval.traceability.ipynb.\n",
      "Converted 9.0_ds.description.eval.traceability.ipynb.\n",
      "Converted 9.0_ds.prediction.eval.traceability.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
