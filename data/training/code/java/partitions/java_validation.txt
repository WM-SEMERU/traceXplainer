public List<Node> select(final String query) {		Collection<List<CssSelector>> selectorsCollection = CSSelly.parse(query);		return select(selectorsCollection);	}
public List<Node> select(final Collection<List<CssSelector>> selectorsCollection) {		List<Node> results = new ArrayList<>();		for (List<CssSelector> selectors : selectorsCollection) {			processSelectors(results, selectors);		}		return results;	}
protected void processSelectors(final List<Node> results, final List<CssSelector> selectors) {		List<Node> selectedNodes = select(rootNode, selectors);		for (Node selectedNode : selectedNodes) {			if (!results.contains(selectedNode)) {				results.add(selectedNode);			}		}	}
public Node selectFirst(final String query) {		List<Node> selectedNodes = select(query);		if (selectedNodes.isEmpty()) {			return null;		}		return selectedNodes.get(0);	}
public List<Node> select(final NodeFilter nodeFilter) {		List<Node> nodes = new ArrayList<>();		walk(rootNode, nodeFilter, nodes);		return nodes;	}
public Node selectFirst(final NodeFilter nodeFilter) {		List<Node> selectedNodes = select(nodeFilter);		if (selectedNodes.isEmpty()) {			return null;		}		return selectedNodes.get(0);	}
protected void walk(final Node rootNode, final NodeFilter nodeFilter, final List<Node> result) {		int childCount = rootNode.getChildNodesCount();		for (int i = 0; i < childCount; i++) {			Node node = rootNode.getChild(i);			if (nodeFilter.accept(node)) {				result.add(node);			}			walk(node, nodeFilter, result);		}	}
protected void walkDescendantsIteratively(final LinkedList<Node> nodes, final CssSelector cssSelector, final List<Node> result) {		while (!nodes.isEmpty()) {			Node node = nodes.removeFirst();			selectAndAdd(node, cssSelector, result);			// append children in walking order to be processed right after this node			int childCount = node.getChildNodesCount();			for (int i = childCount - 1; i >= 0; i--) {				nodes.addFirst(node.getChild(i));			}		}	}
protected void walk(final Node rootNode, final CssSelector cssSelector, final List<Node> result) {		// previous combinator determines the behavior		CssSelector previousCssSelector = cssSelector.getPrevCssSelector();		Combinator combinator = previousCssSelector != null ?				previousCssSelector.getCombinator() :				Combinator.DESCENDANT;		switch (combinator) {			case DESCENDANT:				LinkedList<Node> nodes = new LinkedList<>();				int childCount = rootNode.getChildNodesCount();				for (int i = 0; i < childCount; i++) {					nodes.add(rootNode.getChild(i));					// recursive//					selectAndAdd(node, cssSelector, result);//					walk(node, cssSelector, result);				}				walkDescendantsIteratively(nodes, cssSelector, result);				break;			case CHILD:				childCount = rootNode.getChildNodesCount();				for (int i = 0; i < childCount; i++) {					Node node = rootNode.getChild(i);					selectAndAdd(node, cssSelector, result);				}				break;			case ADJACENT_SIBLING:				Node node = rootNode.getNextSiblingElement();				if (node != null) {					selectAndAdd(node, cssSelector, result);				}				break;			case GENERAL_SIBLING:				node = rootNode;				while (true) {					node = node.getNextSiblingElement();					if (node == null) {						break;					}					selectAndAdd(node, cssSelector, result);				}				break;		}	}
protected void selectAndAdd(final Node node, final CssSelector cssSelector, final List<Node> result) {		// ignore all nodes that are not elements		if (node.getNodeType() != Node.NodeType.ELEMENT) {			return;		}		boolean matched = cssSelector.accept(node);		if (matched) {			// check for duplicates			if (result.contains(node)) {				return;			}			// no duplicate found, add it to the results			result.add(node);		}	}
protected boolean filter(final List<Node> currentResults, final Node node, final CssSelector cssSelector, final int index) {		return cssSelector.accept(currentResults, node, index);	}
private static char [] zzUnpackCMap(final String packed) {    char [] map = new char[0x110000];    int i = 0;  /* index in packed string  */    int j = 0;  /* index in unpacked array */    while (i < 128) {      int  count = packed.charAt(i++);      char value = packed.charAt(i++);      do map[j++] = value; while (--count > 0);    }    return map;  }
private boolean zzRefill() {    if (zzBuffer == null) {      zzBuffer = zzChars;      zzEndRead += zzChars.length;      return false;    }    return true;  }
public int yylex() throws java.io.IOException {    int zzInput;    int zzAction;    // cached fields:    int zzCurrentPosL;    int zzMarkedPosL;    int zzEndReadL = zzEndRead;    char [] zzBufferL = zzBuffer;    char [] zzCMapL = ZZ_CMAP;    int [] zzTransL = ZZ_TRANS;    int [] zzRowMapL = ZZ_ROWMAP;    int [] zzAttrL = ZZ_ATTRIBUTE;    while (true) {      zzMarkedPosL = zzMarkedPos;      yychar+= zzMarkedPosL-zzStartRead;      zzAction = -1;      zzCurrentPosL = zzCurrentPos = zzStartRead = zzMarkedPosL;      zzState = ZZ_LEXSTATE[zzLexicalState];      // set up zzAction for empty match case:      int zzAttributes = zzAttrL[zzState];      if ( (zzAttributes & 1) == 1 ) {        zzAction = zzState;      }      zzForAction: {        while (true) {          if (zzCurrentPosL < zzEndReadL) {            zzInput = Character.codePointAt(zzBufferL, zzCurrentPosL, zzEndReadL);            zzCurrentPosL += Character.charCount(zzInput);          }          else if (zzAtEOF) {            zzInput = YYEOF;            break zzForAction;          }          else {            // store back cached positions            zzCurrentPos  = zzCurrentPosL;            zzMarkedPos   = zzMarkedPosL;            boolean eof = zzRefill();            // get translated positions and possibly new buffer            zzCurrentPosL  = zzCurrentPos;            zzMarkedPosL   = zzMarkedPos;            zzBufferL      = zzBuffer;            zzEndReadL     = zzEndRead;            if (eof) {              zzInput = YYEOF;              break zzForAction;            }            else {              zzInput = Character.codePointAt(zzBufferL, zzCurrentPosL, zzEndReadL);              zzCurrentPosL += Character.charCount(zzInput);            }          }          int zzNext = zzTransL[ zzRowMapL[zzState] + zzCMapL[zzInput] ];          if (zzNext == -1) break zzForAction;          zzState = zzNext;          zzAttributes = zzAttrL[zzState];          if ( (zzAttributes & 1) == 1 ) {            zzAction = zzState;            zzMarkedPosL = zzCurrentPosL;            if ( (zzAttributes & 8) == 8 ) break zzForAction;          }        }      }      // store back cached position      zzMarkedPos = zzMarkedPosL;      if (zzInput == YYEOF && zzStartRead == zzCurrentPos) {        zzAtEOF = true;            zzDoEOF();          { return 0; }      }      else {        switch (zzAction < 0 ? zzAction : ZZ_ACTION[zzAction]) {          case 1:             { cssSelector.setCombinator(Combinator.DESCENDANT); stateReset();            }          case 20: break;          case 2:             { cssSelector = new CssSelector(yytext()); selectors.add(cssSelector); stateSelector();            }          case 21: break;          case 3:             { cssSelector = new CssSelector(); selectors.add(cssSelector); yypushback(1); stateSelector();            }          case 22: break;          case 4:             { /* ignore whitespaces */            }          case 23: break;          case 5:             { cssSelector = new CssSelector(); selectors.add(cssSelector); stateSelector();            }          case 24: break;          case 6:             { throw new CSSellyException("Illegal character <"+ yytext() +">.", yystate(), line(), column());            }          case 25: break;          case 7:             { yypushback(1); stateCombinator();            }          case 26: break;          case 8:             { stateAttr();            }          case 27: break;          case 9:             { cssSelector.addAttributeSelector(yytext());            }          case 28: break;          case 10:             { stateSelector();            }          case 29: break;          case 11:             { throw new CSSellyException("Invalid combinator <"+ yytext() +">.", yystate(), line(), column());            }          case 30: break;          case 12:             { cssSelector.setCombinator(Combinator.GENERAL_SIBLING); stateReset();            }          case 31: break;          case 13:             { cssSelector.setCombinator(Combinator.CHILD); stateReset();            }          case 32: break;          case 14:             { cssSelector.setCombinator(Combinator.ADJACENT_SIBLING); stateReset();            }          case 33: break;          case 15:             { cssSelector.addPseudoFunctionSelector(pseudoFnName, yytext(0, 1)); stateSelector();            }          case 34: break;          case 16:             { cssSelector.addClassSelector(yytext(1));            }          case 35: break;          case 17:             { cssSelector.addIdSelector(yytext(1));            }          case 36: break;          case 18:             { cssSelector.addPseudoClassSelector(yytext( yycharat(1) == ':' ? 2 : 1 ));            }          case 37: break;          case 19:             { pseudoFnName = yytext(yycharat(1) == ':' ? 2 : 1,1); statePseudoFn();            }          case 38: break;          default:            zzScanError(ZZ_NO_MATCH);        }      }    }  }
public <T> PageData<T> page(PageRequest pageRequest, final String sql, final Map params, final String[] sortColumns, final Class[] target) {		if (pageRequest == null) {			pageRequest = getDefaultPageRequest();		}		// check sort		String sortColumName = null;		boolean ascending = true;		int sort = pageRequest.getSort();		if (sort != 0) {			ascending = sort > 0;			if (!ascending) {				sort = -sort;			}			int index = sort - 1;			if (index >= sortColumns.length) {				index = 1;			}			sortColumName = sortColumns[index];		}		// page		int page = pageRequest.getPage();		int pageSize = pageRequest.getSize();		PageData<T> pageData = page(sql, params, page, pageSize, sortColumName, ascending, target);		// fix the out-of-bounds		if (pageData.getItems().isEmpty() && pageData.currentPage != 0) {			if (pageData.currentPage != page) {				// out of bounds				int newPage = pageData.getCurrentPage();				pageData = page(sql, params, newPage, pageSize, sortColumName, ascending, target);			}		}		return pageData;	}
protected <T> PageData<T> page(String sql, final Map params, final int page, final int pageSize, final String sortColumnName, final boolean ascending, final Class[] target) {		if (sortColumnName != null) {			sql = buildOrderSql(sql, sortColumnName, ascending);		}		int from = (page - 1) * pageSize;		String pageSql = buildPageSql(sql, from, pageSize);		DbSqlBuilder dbsql = sql(pageSql);		DbOomQuery query = query(dbsql);		query.setMaxRows(pageSize);		query.setFetchSize(pageSize);		query.setMap(params);		List<T> list = query.list(pageSize, target);		query.close();		String countSql = buildCountSql(sql);		dbsql = sql(countSql);		query = query(dbsql);		query.setMap(params);		long count = query.executeCount();		query.close();		return new PageData<>(page, (int) count, pageSize, list);	}
protected String removeSelect(String sql) {		int ndx = StringUtil.indexOfIgnoreCase(sql, "select");		if (ndx != -1) {			sql = sql.substring(ndx + 6);	// select.length()		}		return sql;	}
protected String removeToFrom(String sql) {		int from = 0;		int fromCount = 1;		int selectCount = 0;		int lastNdx = 0;		while (true) {			int ndx = StringUtil.indexOfIgnoreCase(sql, "from", from);			if (ndx == -1) {				break;			}			// count selects in left part			String left = sql.substring(lastNdx, ndx);			selectCount += StringUtil.countIgnoreCase(left, "select");			if (fromCount >= selectCount) {				sql = sql.substring(ndx);				break;			}			// find next 'from'			lastNdx = ndx;			from = ndx + 4;			fromCount++;		}		return sql;	}
protected String removeLastOrderBy(String sql) {		int ndx = StringUtil.lastIndexOfIgnoreCase(sql, "order by");		if (ndx != -1) {			int ndx2 = sql.lastIndexOf(sql, ')');			if (ndx > ndx2) {				sql = sql.substring(0, ndx);			}		}		return sql;	}
public static String decode(final String html) {		int ndx = html.indexOf('&');		if (ndx == -1) {			return html;		}		StringBuilder result = new StringBuilder(html.length());		int lastIndex = 0;		int len = html.length();mainloop:		while (ndx != -1) {			result.append(html.substring(lastIndex, ndx));			lastIndex = ndx;			while (html.charAt(lastIndex) != ';') {				lastIndex++;				if (lastIndex == len) {					lastIndex = ndx;					break mainloop;				}			}			if (html.charAt(ndx + 1) == '#') {				// decimal/hex				char c = html.charAt(ndx + 2);				int radix;				if ((c == 'x') || (c == 'X')) {					radix = 16;					ndx += 3;				} else {					radix = 10;					ndx += 2;				}				String number = html.substring(ndx, lastIndex);				int i = Integer.parseInt(number, radix);				result.append((char) i);				lastIndex++;			} else {				// token				String encodeToken = html.substring(ndx + 1, lastIndex);				char[] replacement = ENTITY_MAP.get(encodeToken);				if (replacement == null) {					result.append('&');					lastIndex = ndx + 1;				} else {					result.append(replacement);					lastIndex++;				}			}			ndx = html.indexOf('&', lastIndex);		}		result.append(html.substring(lastIndex));		return result.toString();	}
public static String detectName(final char[] input, int ndx) {		final Ptr ptr = new Ptr();		int firstIndex = 0;		int lastIndex = ENTITY_NAMES.length - 1;		int len = input.length;		char[] lastName = null;		final BinarySearchBase binarySearch = new BinarySearchBase() {			@Override			protected int compare(final int index) {				char[] name = ENTITY_NAMES[index];				if (ptr.offset >= name.length) {					return -1;				}				return name[ptr.offset] - ptr.c;			}		};		while (true) {			ptr.c = input[ndx];			if (!CharUtil.isAlphaOrDigit(ptr.c)) {				return lastName != null ? new String(lastName) : null;			}			firstIndex = binarySearch.findFirst(firstIndex, lastIndex);			if (firstIndex < 0) {				return lastName != null ? new String(lastName) : null;			}			char[] element = ENTITY_NAMES[firstIndex];			if (element.length == ptr.offset + 1) {				// total match, remember position, continue for finding the longer name				lastName = ENTITY_NAMES[firstIndex];			}			lastIndex = binarySearch.findLast(firstIndex, lastIndex);			if (firstIndex == lastIndex) {				// only one element found, check the rest				for (int i = ptr.offset; i < element.length; i++) {					if (element[i] != input[ndx]) {						return lastName != null ? new String(lastName) : null;					}					ndx++;				}				return new String(element);			}			ptr.offset++;			ndx++;			if (ndx == len) {				return lastName != null ? new String(lastName) : null;			}		}	}
@Override	protected void defineParameter(final StringBuilder query, final String name, final Object value, DbEntityColumnDescriptor dec) {		if (dec == null) {			dec = templateData.lastColumnDec;		}		super.defineParameter(query, name, value, dec);	}
@Override	protected String buildOrderSql(String sql, final String column, final boolean ascending) {		sql += " order by " + column;		if (!ascending) {			sql += " desc";		}		return sql;	}
@Override	protected String buildPageSql(String sql, final int from, final int pageSize) {		sql = removeSelect(sql);		return "select LIMIT " + from + ' ' + pageSize + sql;	}
@Override	protected String buildCountSql(String sql) {		sql = removeToFrom(sql);		sql = removeLastOrderBy(sql);		return "select count(*) " + sql;	}
private void resolveColumnsAndProperties(final Class type) {		PropertyDescriptor[] allProperties = ClassIntrospector.get().lookup(type).getAllPropertyDescriptors();		List<DbEntityColumnDescriptor> decList = new ArrayList<>(allProperties.length);		int idcount = 0;		HashSet<String> names = new HashSet<>(allProperties.length);		for (PropertyDescriptor propertyDescriptor : allProperties) {			DbEntityColumnDescriptor dec =					DbMetaUtil.resolveColumnDescriptors(this, propertyDescriptor, isAnnotated, columnNamingStrategy);			if (dec != null) {				if (!names.add(dec.getColumnName())) {					throw new DbOomException("Duplicate column name: " + dec.getColumnName());				}				decList.add(dec);				if (dec.isId) {					idcount++;				}			}		}		if (decList.isEmpty()) {			throw new DbOomException("No column mappings in entity: " + type);		}		columnDescriptors = decList.toArray(new DbEntityColumnDescriptor[0]);		Arrays.sort(columnDescriptors);		// extract ids from sorted list		if (idcount > 0) {			idColumnDescriptors = new DbEntityColumnDescriptor[idcount];			idcount = 0;			for (DbEntityColumnDescriptor dec : columnDescriptors) {				if (dec.isId) {					idColumnDescriptors[idcount++] = dec;				}			}		}	}
public DbEntityColumnDescriptor findByColumnName(final String columnName) {		if (columnName == null) {			return null;		}		init();		for (DbEntityColumnDescriptor columnDescriptor : columnDescriptors) {			if (columnDescriptor.columnName.equalsIgnoreCase(columnName)) {				return columnDescriptor;			}		}		return null;	}
public DbEntityColumnDescriptor findByPropertyName(final String propertyName) {		if (propertyName == null) {			return null;		}		init();		for (DbEntityColumnDescriptor columnDescriptor : columnDescriptors) {			if (columnDescriptor.propertyName.equals(propertyName)) {				return columnDescriptor;			}		}		return null;	}
public String getPropertyName(final String columnName) {		DbEntityColumnDescriptor dec = findByColumnName(columnName);		return dec == null ? null : dec.propertyName;	}
public String getColumnName(final String propertyName) {		DbEntityColumnDescriptor dec = findByPropertyName(propertyName);		return dec == null ? null : dec.columnName;	}
public Object getIdValue(final E object) {		final String propertyName = getIdPropertyName();		return BeanUtil.declared.getProperty(object, propertyName);	}
public void setIdValue(final E object, final Object value) {		final String propertyName = getIdPropertyName();		BeanUtil.declared.setProperty(object, propertyName, value);	}
public String getKeyValue(final E object) {		Object idValue = getIdValue(object);		String idValueString = idValue == null ?  StringPool.NULL : idValue.toString();		return type.getName().concat(StringPool.COLON).concat(idValueString);	}
public StringBand append(String s) {		if (s == null) {			s = StringPool.NULL;		}		if (index >= array.length) {			expandCapacity();		}		array[index++] = s;		length += s.length();				return this;	}
public void setIndex(final int newIndex) {		if (newIndex < 0) {			throw new ArrayIndexOutOfBoundsException(newIndex);		}		if (newIndex > array.length) {			String[] newArray = new String[newIndex];			System.arraycopy(array, 0, newArray, 0, index);			array = newArray;		}		if (newIndex > index) {			for (int i = index; i < newIndex; i++) {				array[i] = StringPool.EMPTY;			}		} else if (newIndex < index) {			for (int i = newIndex; i < index; i++) {				array[i] = null;			}		}		index = newIndex;		length = calculateLength();	}
public char charAt(final int pos) {		int len = 0;		for (int i = 0; i < index; i++) {			int newlen = len + array[i].length();			if (pos < newlen) {				return array[i].charAt(pos - len);			}			len = newlen;		}		throw new IllegalArgumentException("Invalid char index");	}
protected void expandCapacity() {		String[] newArray = new String[array.length << 1];		System.arraycopy(array, 0, newArray, 0, index);		array = newArray;	}
protected int calculateLength() {		int len = 0;		for (int i = 0; i < index; i++) {			len += array[i].length();		}		return len;	}
public Object lookupValue(final PetiteContainer petiteContainer, final BeanDefinition targetBeanDefinition, final BeanDefinition refBeanDefinition) {		Scope targetScope = targetBeanDefinition.scope;		Scope refBeanScope = refBeanDefinition.scope;		boolean detectMixedScopes = petiteContainer.config().isDetectMixedScopes();		boolean wireScopedProxy = petiteContainer.config().isWireScopedProxy();		// when target scope is null then all beans can be injected into it		// similar to prototype scope		if (targetScope != null && !targetScope.accept(refBeanScope)) {			if (!wireScopedProxy) {				if (detectMixedScopes) {					throw new PetiteException(createMixingMessage(targetBeanDefinition, refBeanDefinition));				}				return null;			}			if (detectMixedScopes) {				if (log.isWarnEnabled()) {					log.warn(createMixingMessage(targetBeanDefinition, refBeanDefinition));				}			} else {				if (log.isDebugEnabled()) {					log.debug(createMixingMessage(targetBeanDefinition, refBeanDefinition));				}			}			String scopedProxyBeanName = refBeanDefinition.name;			Object proxy = proxies.get(scopedProxyBeanName);			if (proxy == null) {				proxy = createScopedProxyBean(petiteContainer, refBeanDefinition);				proxies.put(scopedProxyBeanName, proxy);			}			return proxy;		}		return null;	}
protected String createMixingMessage(final BeanDefinition targetBeanDefinition, final BeanDefinition refBeanDefinition) {		return "Scopes mixing detected: " +				refBeanDefinition.name + "@" + refBeanDefinition.scope.getClass().getSimpleName() + " -> " +				targetBeanDefinition.name + "@" + targetBeanDefinition.scope.getClass().getSimpleName();	}
protected Object createScopedProxyBean(final PetiteContainer petiteContainer, final BeanDefinition refBeanDefinition) {		Class beanType = refBeanDefinition.type;		Class proxyClass = proxyClasses.get(beanType);		if (proxyClass == null) {			// create proxy class only once			if (refBeanDefinition instanceof ProxettaBeanDefinition) {				// special case, double proxy!				ProxettaBeanDefinition pbd =					(ProxettaBeanDefinition) refBeanDefinition;				ProxyProxetta proxetta = Proxetta.proxyProxetta().withAspects(ArraysUtil.insert(pbd.proxyAspects, aspect, 0));				proxetta.setClassNameSuffix("$ScopedProxy");				proxetta.setVariableClassName(true);				ProxyProxettaFactory builder = proxetta.proxy().setTarget(pbd.originalTarget);				proxyClass = builder.define();				proxyClasses.put(beanType, proxyClass);			}			else {				ProxyProxetta proxetta = Proxetta.proxyProxetta().withAspect(aspect);				proxetta.setClassNameSuffix("$ScopedProxy");				proxetta.setVariableClassName(true);				ProxyProxettaFactory builder = proxetta.proxy().setTarget(beanType);				proxyClass = builder.define();				proxyClasses.put(beanType, proxyClass);			}		}		Object proxy;		try {			proxy = ClassUtil.newInstance(proxyClass);			Field field = proxyClass.getField("$__petiteContainer$0");			field.set(proxy, petiteContainer);			field = proxyClass.getField("$__name$0");			field.set(proxy, refBeanDefinition.name);		} catch (Exception ex) {			throw new PetiteException(ex);		}		return proxy;	}
protected void prepareStepDirection(final boolean autoDirection, final boolean checkDirection) {		if (step == 0) {			step = (start <= end) ? 1 : -1;			return;		}		if (autoDirection) {			if (step < 0) {				throw new IllegalArgumentException("Step value can't be negative: " + step);			}			if (start > end) {				step = -step;			}			return;		}		if (checkDirection) {			if (start < end) {				if (step < 0) {					throw new IllegalArgumentException("Negative step value for increasing loop");				}				return;			}			if (start > end) {				if (step > 0) {					throw new IllegalArgumentException("Positive step value for decreasing loop");				}			}		}	}
protected void loopBody() throws JspException {		JspFragment body = getJspBody();		if (body == null) {			return;		}		LoopIterator loopIterator = new LoopIterator(start, end, step, modulus);		if (status != null) {			getJspContext().setAttribute(status, loopIterator);		}		while (loopIterator.next()) {			TagUtil.invokeBody(body);		}		if (status != null) {			getJspContext().removeAttribute(status);		}	}
protected void init() {		File[] filesArray = dir.listFiles();		filesCount = 0;		if (filesArray != null) {			filesCount = filesArray.length;			for (File file : filesArray) {				if (!acceptFile(file)) {					continue;				}				map.put(file, new MutableLong(file.lastModified()));			}		}	}
protected boolean acceptFile(final File file) {		if (!file.isFile()) {			return false;			// ignore non-files		}		String fileName = file.getName();		if (ignoreDotFiles) {			if (fileName.startsWith(StringPool.DOT)) {				return false;        // ignore hidden files			}		}		if (patterns == null) {			return true;		}		return Wildcard.matchOne(fileName, patterns) != -1;	}
public DirWatcher useWatchFile(final String name) {		watchFile = new File(dir, name);		if (!watchFile.isFile() || !watchFile.exists()) {			try {				FileUtil.touch(watchFile);			} catch (IOException ioex) {				throw new DirWatcherException("Invalid watch file: " + name, ioex);			}		}		watchFileLastAccessTime = watchFile.lastModified();		return this;	}
public void start(final long pollingInterval) {		if (timer == null) {			if (!startBlank) {				init();			}			timer = new Timer(true);			timer.schedule(new WatchTask(), 0, pollingInterval);		}	}
protected void onChange(final DirWatcherEvent.Type type, final File file) {		listeners.accept(new DirWatcherEvent(type, file));	}
public void add(final Enumeration<T> enumeration) {		if (allEnumerations.contains(enumeration)) {			throw new IllegalArgumentException("Duplicate enumeration");		}		allEnumerations.add(enumeration);	}
public boolean hasMoreElements() {		if (currentEnumeration == -1) {			currentEnumeration = 0;		}		for (int i = currentEnumeration; i < allEnumerations.size(); i++) {			Enumeration enumeration = allEnumerations.get(i);			if (enumeration.hasMoreElements()) {				currentEnumeration = i;				return true;			}		}		return false;	}
protected double[] convertValueToArray(final Object value) {		if (value instanceof Collection) {			final Collection collection = (Collection) value;			final double[] target = new double[collection.size()];			int i = 0;			for (final Object element : collection) {				target[i] = convertType(element);				i++;			}			return target;		}		if (value instanceof Iterable) {			final Iterable iterable = (Iterable) value;			final ArrayList<Double> doubleArrayList = new ArrayList<>();			for (final Object element : iterable) {				final double convertedValue = convertType(element);				doubleArrayList.add(Double.valueOf(convertedValue));			}			final double[] array = new double[doubleArrayList.size()];			for (int i = 0; i < doubleArrayList.size(); i++) {				final Double d = doubleArrayList.get(i);				array[i] = d.doubleValue();			}			return array;		}		if (value instanceof CharSequence) {			final String[] strings = StringUtil.splitc(value.toString(), ArrayConverter.NUMBER_DELIMITERS);			return convertArrayToArray(strings);		}		// everything else:		return convertToSingleElementArray(value);	}
int computeFieldInfoSize() {    // The access_flags, name_index, descriptor_index and attributes_count fields use 8 bytes.    int size = 8;    // For ease of reference, we use here the same attribute order as in Section 4.7 of the JVMS.    if (constantValueIndex != 0) {      // ConstantValue attributes always use 8 bytes.      symbolTable.addConstantUtf8(Constants.CONSTANT_VALUE);      size += 8;    }    // Before Java 1.5, synthetic fields are represented with a Synthetic attribute.    if ((accessFlags & Opcodes.ACC_SYNTHETIC) != 0        && symbolTable.getMajorVersion() < Opcodes.V1_5) {      // Synthetic attributes always use 6 bytes.      symbolTable.addConstantUtf8(Constants.SYNTHETIC);      size += 6;    }    if (signatureIndex != 0) {      // Signature attributes always use 8 bytes.      symbolTable.addConstantUtf8(Constants.SIGNATURE);      size += 8;    }    // ACC_DEPRECATED is ASM specific, the ClassFile format uses a Deprecated attribute instead.    if ((accessFlags & Opcodes.ACC_DEPRECATED) != 0) {      // Deprecated attributes always use 6 bytes.      symbolTable.addConstantUtf8(Constants.DEPRECATED);      size += 6;    }    if (lastRuntimeVisibleAnnotation != null) {      size +=          lastRuntimeVisibleAnnotation.computeAnnotationsSize(              Constants.RUNTIME_VISIBLE_ANNOTATIONS);    }    if (lastRuntimeInvisibleAnnotation != null) {      size +=          lastRuntimeInvisibleAnnotation.computeAnnotationsSize(              Constants.RUNTIME_INVISIBLE_ANNOTATIONS);    }    if (lastRuntimeVisibleTypeAnnotation != null) {      size +=          lastRuntimeVisibleTypeAnnotation.computeAnnotationsSize(              Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS);    }    if (lastRuntimeInvisibleTypeAnnotation != null) {      size +=          lastRuntimeInvisibleTypeAnnotation.computeAnnotationsSize(              Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS);    }    if (firstAttribute != null) {      size += firstAttribute.computeAttributesSize(symbolTable);    }    return size;  }
void putFieldInfo(final ByteVector output) {    boolean useSyntheticAttribute = symbolTable.getMajorVersion() < Opcodes.V1_5;    // Put the access_flags, name_index and descriptor_index fields.    int mask = useSyntheticAttribute ? Opcodes.ACC_SYNTHETIC : 0;    output.putShort(accessFlags & ~mask).putShort(nameIndex).putShort(descriptorIndex);    // Compute and put the attributes_count field.    // For ease of reference, we use here the same attribute order as in Section 4.7 of the JVMS.    int attributesCount = 0;    if (constantValueIndex != 0) {      ++attributesCount;    }    if ((accessFlags & Opcodes.ACC_SYNTHETIC) != 0 && useSyntheticAttribute) {      ++attributesCount;    }    if (signatureIndex != 0) {      ++attributesCount;    }    if ((accessFlags & Opcodes.ACC_DEPRECATED) != 0) {      ++attributesCount;    }    if (lastRuntimeVisibleAnnotation != null) {      ++attributesCount;    }    if (lastRuntimeInvisibleAnnotation != null) {      ++attributesCount;    }    if (lastRuntimeVisibleTypeAnnotation != null) {      ++attributesCount;    }    if (lastRuntimeInvisibleTypeAnnotation != null) {      ++attributesCount;    }    if (firstAttribute != null) {      attributesCount += firstAttribute.getAttributeCount();    }    output.putShort(attributesCount);    // Put the field_info attributes.    // For ease of reference, we use here the same attribute order as in Section 4.7 of the JVMS.    if (constantValueIndex != 0) {      output          .putShort(symbolTable.addConstantUtf8(Constants.CONSTANT_VALUE))          .putInt(2)          .putShort(constantValueIndex);    }    if ((accessFlags & Opcodes.ACC_SYNTHETIC) != 0 && useSyntheticAttribute) {      output.putShort(symbolTable.addConstantUtf8(Constants.SYNTHETIC)).putInt(0);    }    if (signatureIndex != 0) {      output          .putShort(symbolTable.addConstantUtf8(Constants.SIGNATURE))          .putInt(2)          .putShort(signatureIndex);    }    if ((accessFlags & Opcodes.ACC_DEPRECATED) != 0) {      output.putShort(symbolTable.addConstantUtf8(Constants.DEPRECATED)).putInt(0);    }    if (lastRuntimeVisibleAnnotation != null) {      lastRuntimeVisibleAnnotation.putAnnotations(          symbolTable.addConstantUtf8(Constants.RUNTIME_VISIBLE_ANNOTATIONS), output);    }    if (lastRuntimeInvisibleAnnotation != null) {      lastRuntimeInvisibleAnnotation.putAnnotations(          symbolTable.addConstantUtf8(Constants.RUNTIME_INVISIBLE_ANNOTATIONS), output);    }    if (lastRuntimeVisibleTypeAnnotation != null) {      lastRuntimeVisibleTypeAnnotation.putAnnotations(          symbolTable.addConstantUtf8(Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS), output);    }    if (lastRuntimeInvisibleTypeAnnotation != null) {      lastRuntimeInvisibleTypeAnnotation.putAnnotations(          symbolTable.addConstantUtf8(Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS), output);    }    if (firstAttribute != null) {      firstAttribute.putAttributes(symbolTable, output);    }  }
public boolean match(final float ieVersion, String expression) {		expression = StringUtil.removeChars(expression, "()");		expression = expression.substring(3);		String[] andChunks = StringUtil.splitc(expression, '&');		boolean valid = true;		for (String andChunk : andChunks) {			String[] orChunks = StringUtil.splitc(andChunk, '|');			boolean innerValid = false;			for (String orChunk : orChunks) {				orChunk = orChunk.trim();				if (orChunk.startsWith("IE ")) {					String value = orChunk.substring(3);					float number = Float.parseFloat(value);					if (versionToCompare(ieVersion, number) == number) {						innerValid = true;						break;					}					continue;				}				if (orChunk.startsWith("!IE ")) {					String value = orChunk.substring(4);					float number = Float.parseFloat(value);					if (versionToCompare(ieVersion, number) != number) {						innerValid = true;						break;					}					continue;				}				if (orChunk.startsWith("lt IE ")) {					String value = orChunk.substring(6);					float number = Float.parseFloat(value);					if (ieVersion < number) {						innerValid = true;						break;					}					continue;				}				if (orChunk.startsWith("lte IE ")) {					String value = orChunk.substring(7);					float number = Float.parseFloat(value);					if (versionToCompare(ieVersion, number) <= number) {						innerValid = true;						break;					}					continue;				}				if (orChunk.startsWith("gt IE ")) {					String value = orChunk.substring(6);					float number = Float.parseFloat(value);					if (versionToCompare(ieVersion, number) > number) {						innerValid = true;						break;					}					continue;				}				if (orChunk.startsWith("gte IE ")) {					String value = orChunk.substring(7);					float number = Float.parseFloat(value);					if (ieVersion >= number) {						innerValid = true;						break;					}					continue;				}			}			valid = valid && innerValid;		}		return valid;	}
public FastByteBuffer append(final FastByteBuffer buff) {		if (buff.offset == 0) {			return this;		}		append(buff.buffer, 0, buff.offset);		return this;	}
public static Target ofValue(final Object value, final ScopeData scopeData) {		return new Target(value, null, scopeData, null, VALUE_INSTANCE_CREATOR);	}
public static Target ofMethodParam(final MethodParam methodParam, final Object object) {		return new Target(object, methodParam.type(), methodParam.scopeData(), methodParam.mapperFunction(), VALUE_INSTANCE_CREATOR);	}
public static Target ofMethodParam(final MethodParam methodParam, final Function<Class, Object> valueInstanceCreator) {		return new Target(null, methodParam.type(), methodParam.scopeData(), methodParam.mapperFunction(), valueInstanceCreator);	}
public void writeValue(final InjectionPoint injectionPoint, final Object propertyValue, final boolean silent) {		writeValue(injectionPoint.targetName(), propertyValue, silent);	}
public void decorate(final Writer writer, final char[] pageContent, final char[] decoraContent) throws IOException {		DecoraTag[] decoraTags = parseDecorator(decoraContent);		parsePage(pageContent, decoraTags);		writeDecoratedPage(writer, decoraContent, pageContent, decoraTags);	}
protected DecoraTag[] parseDecorator(final char[] decoraContent) {		LagartoParser lagartoParser = new LagartoParser(decoraContent);		lagartoParser.getConfig().setEnableRawTextModes(false);		DecoratorTagVisitor visitor = new DecoratorTagVisitor();		lagartoParser.parse(visitor);		return visitor.getDecoraTags();	}
protected void parsePage(final char[] pageContent, final DecoraTag[] decoraTags) {		LagartoParser lagartoParser = new LagartoParser(pageContent);		PageRegionExtractor writer = new PageRegionExtractor(decoraTags);		lagartoParser.parse(writer);	}
protected void writeDecoratedPage(final Writer out, final char[] decoratorContent, final char[] pageContent, final DecoraTag[] decoraTags) throws IOException {		int ndx = 0;		for (DecoraTag decoraTag : decoraTags) {			// [1] just copy content before the Decora tag			int decoratorLen = decoraTag.getStartIndex() - ndx;			if (decoratorLen <= 0) {				continue;			}			out.write(decoratorContent, ndx, decoratorLen);			ndx = decoraTag.getEndIndex();			// [2] now write region at the place of Decora tag			int regionLen = decoraTag.getRegionLength();			if (regionLen == 0) {				if (decoraTag.hasDefaultValue()) {					out.write(decoratorContent, decoraTag.getDefaultValueStart(), decoraTag.getDefaultValueLength());				}			} else {				writeRegion(out, pageContent, decoraTag, decoraTags);			}		}		// write remaining content		out.write(decoratorContent, ndx, decoratorContent.length - ndx);	}
protected void writeRegion(final Writer out, final char[] pageContent, final DecoraTag decoraTag, final DecoraTag[] decoraTags) throws IOException {		int regionStart = decoraTag.getRegionStart();		int regionLen = decoraTag.getRegionLength();		int regionEnd = regionStart + regionLen;		for (DecoraTag innerDecoraTag : decoraTags) {			if (decoraTag == innerDecoraTag) {				continue;			}			if (decoraTag.isRegionUndefined()) {				continue;			}			if (innerDecoraTag.isInsideOtherTagRegion(decoraTag)) {				// write everything from region start to the inner Decora tag				out.write(pageContent, regionStart, innerDecoraTag.getRegionTagStart() - regionStart);				regionStart = innerDecoraTag.getRegionTagEnd();			}		}		// write remaining content of the region		out.write(pageContent, regionStart, regionEnd - regionStart);	}
public boolean isBlank() {		if (blank == null) {			blank = Boolean.valueOf(StringUtil.isBlank(nodeValue));		}		return blank.booleanValue();	}
public void start() throws IOException {		serverSocket = new ServerSocket(listenPort, socketBacklog);		serverSocket.setReuseAddress(true);		executorService = Executors.newFixedThreadPool(threadPoolSize);		running = true;		while (running) {			Socket socket = serverSocket.accept();			socket.setKeepAlive(false);			executorService.execute(onSocketConnection(socket));		}		executorService.shutdown();	}
protected int[] convertValueToArray(final Object value) {		if (value instanceof Collection) {			final Collection collection = (Collection) value;			final int[] target = new int[collection.size()];			int i = 0;			for (final Object element : collection) {				target[i] = convertType(element);				i++;			}			return target;		}		if (value instanceof Iterable) {			final Iterable iterable = (Iterable) value;			final FastIntBuffer fastIntBuffer = new FastIntBuffer();			for (final Object element : iterable) {				final int convertedValue = convertType(element);				fastIntBuffer.append(convertedValue);			}			return fastIntBuffer.toArray();		}		if (value instanceof CharSequence) {			final String[] strings = StringUtil.splitc(value.toString(), ArrayConverter.NUMBER_DELIMITERS);			return convertArrayToArray(strings);		}		// everything else:		return convertToSingleElementArray(value);	}
public static ProcessResult run(final Process process) throws InterruptedException {		final ByteArrayOutputStream baos = new ByteArrayOutputStream();		final StreamGobbler outputGobbler = new StreamGobbler(process.getInputStream(), baos, OUTPUT_PREFIX);		final StreamGobbler errorGobbler = new StreamGobbler(process.getErrorStream(), baos, ERROR_PREFIX);		outputGobbler.start();		errorGobbler.start();		final int result = process.waitFor();		outputGobbler.waitFor();		errorGobbler.waitFor();		return new ProcessResult(result, baos.toString());	}
@Override	protected IMAPSSLStore getStore(final Session session) {		SimpleAuthenticator simpleAuthenticator = (SimpleAuthenticator) authenticator;		final URLName url;		if (simpleAuthenticator == null) {			url = new URLName(				PROTOCOL_IMAP,				host, port,				StringPool.EMPTY, null, null);		}		else {			final PasswordAuthentication pa = simpleAuthenticator.getPasswordAuthentication();			url = new URLName(				PROTOCOL_IMAP,				host, port,				StringPool.EMPTY,				pa.getUserName(), pa.getPassword());		}		return new IMAPSSLStore(session, url);	}
public boolean matches(final Path path) {		int exprNdx = 0;		int pathNdx = 0;		int pathLen = path.length();		int exprLen = expression.length;		while (pathNdx < pathLen) {			CharSequence current = path.get(pathNdx);			if (exprNdx < exprLen && expression[exprNdx].equals(STAR)) {				exprNdx++;			}			else if (exprNdx < exprLen && expression[exprNdx].contentEquals(current)) {				pathNdx++;				exprNdx++;			}			else if (exprNdx - 1 >= 0 && expression[exprNdx - 1].equals(STAR)) {				pathNdx++;			}			else {				return false;			}		}		if (exprNdx > 0 && expression[exprNdx - 1].equals(STAR)) {			return pathNdx >= pathLen && exprNdx >= exprLen;		}		else {			return pathLen != 0 &&					pathNdx >= pathLen &&					(included || exprNdx >= exprLen);		}	}
public ServletOutputStream createOutputStream() throws IOException {		GzipResponseStream gzstream = new GzipResponseStream(origResponse);		gzstream.setBuffer(threshold);		return gzstream;	}
@Override	public boolean isValid(final ValidationConstraintContext vcc, final Object value) {		if (value == null) {			return true;		}		vcc.validateWithin(targetValidationContext, value);		return true;	}
@Override	public URL get(final ResultSet rs, final int index, final int dbSqlType) throws SQLException {		return rs.getURL(index);	}
@Override	public void set(final PreparedStatement st, final int index, final URL value, final int dbSqlType) throws SQLException {		st.setURL(index, value);	}
@Override	public void process(final StringBuilder out) {		final DbEntityDescriptor ded;		if (tableRef != null) {			ded = lookupTableRef(tableRef);			final String tableName = resolveTable(tableRef, ded);			out.append(tableName);		} else {			ded = findColumnRef(columnRef);		}		if (onlyId) {			if (tableRef != null) {				out.append('.');			}			out.append(ded.getIdColumnName());		} else if (columnRef != null) {			DbEntityColumnDescriptor dec = ded.findByPropertyName(columnRef);			templateData.lastColumnDec = dec;			if (dec == null) {				throw new DbSqlBuilderException("Invalid column reference: [" + tableRef + '.' + columnRef + "]");			}			if (tableRef != null) {				out.append('.');			}			out.append(dec.getColumnNameForQuery());		}	}
@Override	public void init(final TemplateData templateData) {		super.init(templateData);		if (hint != null) {			templateData.incrementHintsCount();		}	}
protected void appendAlias(final StringBuilder query, final DbEntityDescriptor ded, final DbEntityColumnDescriptor dec) {		final ColumnAliasType columnAliasType = templateData.getColumnAliasType();		if (columnAliasType == null || columnAliasType == ColumnAliasType.TABLE_REFERENCE) {			final String tableName = ded.getTableName();			final String columnName = dec.getColumnNameForQuery();			templateData.registerColumnDataForTableRef(tableRef, tableName);			query.append(tableRef).append(columnAliasSeparator).append(columnName);		} else		if (columnAliasType == ColumnAliasType.COLUMN_CODE) {			final String tableName = ded.getTableName();			final String columnName = dec.getColumnName();			final String code = templateData.registerColumnDataForColumnCode(tableName, columnName);			query.append(code);		} else		if (columnAliasType == ColumnAliasType.TABLE_NAME) {			final String tableName = ded.getTableNameForQuery();			final String columnName = dec.getColumnNameForQuery();			query.append(tableName).append(columnAliasSeparator).append(columnName);		}	}
protected void appendColumnName(final StringBuilder query, final DbEntityDescriptor ded, final DbEntityColumnDescriptor dec) {		query.append(resolveTable(tableRef, ded)).append('.').append(dec.getColumnName());				if (templateData.getColumnAliasType() != null) {     // create column aliases			query.append(AS);			switch (templateData.getColumnAliasType()) {				case TABLE_NAME: {					final String tableName = ded.getTableNameForQuery();					query.append(tableName).append(columnAliasSeparator).append(dec.getColumnNameForQuery());					break;				}				case TABLE_REFERENCE: {					final String tableName = ded.getTableName();					templateData.registerColumnDataForTableRef(tableRef, tableName);					query.append(tableRef).append(columnAliasSeparator).append(dec.getColumnNameForQuery());					break;				}				case COLUMN_CODE: {					final String tableName = ded.getTableName();					final String code = templateData.registerColumnDataForColumnCode(tableName, dec.getColumnName());					query.append(code);					break;				}			}		}	}
protected void addRule(final D ruleDefinition, final boolean include) {		if (rules == null) {			rules = new ArrayList<>();		}		if (include) {			includesCount++;		} else {			excludesCount++;		}		Rule<R> newRule = new Rule<>(makeRule(ruleDefinition), include);		if (rules.contains(newRule)) {			return;		}		rules.add(newRule);	}
public boolean match(final V value, final boolean blacklist) {		if (rules == null) {			return blacklist;		}		boolean include = blacklist;		if (include) {			include = processExcludes(value, true);			include = processIncludes(value, include);		}		else {			include = processIncludes(value, false);			include = processExcludes(value, include);		}		return include;	}
public boolean apply(final V value, final boolean blacklist, boolean flag) {		if (rules == null) {			return flag;		}		if (blacklist) {			flag = processExcludes(value, flag);			flag = processIncludes(value, flag);		}		else {			flag = processIncludes(value, flag);			flag = processExcludes(value, flag);		}		return flag;	}
protected boolean processIncludes(final V value, boolean include) {		if (includesCount > 0) {			if (!include) {				for (Rule<R> rule : rules) {					if (!rule.include) {						continue;					}					if (inExRuleMatcher.accept(value, rule.value, true)) {						include = true;						break;					}				}			}		}		return include;	}
protected boolean processExcludes(final V value, boolean include) {		if (excludesCount > 0) {			if (include) {				for (Rule<R> rule : rules) {					if (rule.include) {						continue;					}					if (inExRuleMatcher.accept(value, rule.value, false)) {						include = false;						break;					}				}			}		}		return include;	}
@Override	public boolean accept(final V value, final R rule, final boolean include) {		return value.equals(rule);	}
public String getPseudoClassName() {		String name = getClass().getSimpleName().toLowerCase();		name = name.replace('_', '-');		return name;	}
@Override	public boolean add(final E o) {		int idx = 0;		if (!isEmpty()) {			idx = findInsertionPoint(o);		}		super.add(idx, o);		return true;	}
@Override	public boolean addAll(final Collection<? extends E> c) {		Iterator<? extends E> i = c.iterator();		boolean changed = false;		while (i.hasNext()) {			boolean ret = add(i.next());			if (!changed) {				changed = ret;			}		}		return changed;	}
protected int findInsertionPoint(final E o, int low, int high) {		while (low <= high) {			int mid = (low + high) >>> 1;			int delta = compare(get(mid), o);			if (delta > 0) {				high = mid - 1;			} else {				low = mid + 1;			}		}		return low;	}
private org.apache.logging.log4j.Level jodd2log4j2(final Logger.Level level) {		switch (level) {			case TRACE: return org.apache.logging.log4j.Level.TRACE;			case DEBUG: return org.apache.logging.log4j.Level.DEBUG;			case INFO:	return org.apache.logging.log4j.Level.INFO;			case WARN:	return org.apache.logging.log4j.Level.WARN;			case ERROR:	return org.apache.logging.log4j.Level.ERROR;			default:				throw new IllegalArgumentException();		}	}
public boolean accept(final Node node) {		if (!node.hasAttribute(name)) {			return false;		}		if (value == null) {		// just detect if attribute exist			return true;		}		String nodeValue = node.getAttribute(name);		if (nodeValue == null) {			return false;		}				return match.compare(nodeValue, value);	}
public void registerAnnotation(final Class<? extends Annotation> annotationType) {		final ActionConfiguredBy actionConfiguredBy = annotationType.getAnnotation(ActionConfiguredBy.class);		if (actionConfiguredBy == null) {			throw new MadvocException("Action annotation is missing it's " + ActionConfiguredBy.class.getSimpleName() + " configuration.");		}		bindAnnotationConfig(annotationType, actionConfiguredBy.value());	}
public void bindAnnotationConfig(final Class<? extends Annotation> annotationType, final Class<? extends ActionConfig> actionConfigClass) {		final ActionConfig actionConfig = registerNewActionConfiguration(actionConfigClass);		actionConfigs.put(annotationType, actionConfig);		for (final AnnotationParser annotationParser : annotationParsers) {			if (annotationType.equals(annotationParser.getAnnotationType())) {				// parser already exists				return;			}		}		annotationParsers = ArraysUtil.append(annotationParsers, new AnnotationParser(annotationType, Action.class));	}
protected ActionConfig registerNewActionConfiguration(final Class<? extends ActionConfig> actionConfigClass) {		final ActionConfig newActionConfig = createActionConfig(actionConfigClass);		actionConfigs.put(actionConfigClass, newActionConfig);		return newActionConfig;	}
public ActionConfig lookup(final Class actionTypeOrAnnotationType) {		final ActionConfig actionConfig = actionConfigs.get(actionTypeOrAnnotationType);		if (actionConfig == null) {			throw new MadvocException("ActionConfiguration not registered:" + actionTypeOrAnnotationType.getName());		}		return actionConfig;	}
public <T extends ActionConfig> void with(final Class<T> actionConfigType, final Consumer<T> actionConfigConsumer) {		final T actionConfig = (T) lookup(actionConfigType);		actionConfigConsumer.accept(actionConfig);	}
public boolean hasActionAnnotationOn(final AnnotatedElement annotatedElement) {		for (final AnnotationParser annotationParser : annotationParsers) {			if (annotationParser.hasAnnotationOn(annotatedElement)) {				return true;			}		}		return false;	}
protected static void setupSystemMailProperties() {		System.setProperty("mail.mime.encodefilename", Boolean.valueOf(Defaults.mailMimeEncodefilename).toString());		System.setProperty("mail.mime.decodefilename", Boolean.valueOf(Defaults.mailMimeDecodefilename).toString());	}
public void validateWithin(final ValidationContext vctx, final Object value) {		vtor.validate(vctx, value, name);	}
protected boolean isOneOfTableElements(final Element element) {		String elementName = element.getNodeName().toLowerCase();		return StringUtil.equalsOne(elementName, TABLE_ELEMENTS) != -1;	}
protected boolean isTableElement(final Node node) {		if (node.getNodeType() != Node.NodeType.ELEMENT) {			return false;		}		String elementName = node.getNodeName().toLowerCase();		return elementName.equals("table");	}
protected boolean isParentNodeOneOfFosterTableElements(final Node parentNode) {		if (parentNode == null) {			return false;		}		if (parentNode.getNodeName() == null) {			return false;		}		String nodeName = parentNode.getNodeName().toLowerCase();		return StringUtil.equalsOne(nodeName, FOSTER_TABLE_ELEMENTS) != -1;	}
protected Element findLastTable(final Node node) {		Node tableNode = node;		while (tableNode != null) {			if (tableNode.getNodeType() == Node.NodeType.ELEMENT) {				String tableNodeName = tableNode.getNodeName().toLowerCase();				if (tableNodeName.equals("table")) {					break;				}			}			tableNode = tableNode.getParentNode();		}		return (Element) tableNode;	}
protected boolean findFosterNodes(final Node node) {		boolean isTable = false;		if (!lastTables.isEmpty()) {			// if inside table			if (node.getNodeType() == Node.NodeType.TEXT) {				String value = node.getNodeValue();				if (!StringUtil.isBlank(value)) {					if (isParentNodeOneOfFosterTableElements(node.getParentNode())) {						fosterTexts.add((Text) node);					}				}			}		}		if (node.getNodeType() == Node.NodeType.ELEMENT) {			Element element = (Element) node;			isTable = isTableElement(node);			if (isTable) {				// if node is a table, add it to the stack-of-last-tables				lastTables.add(element);			} else {				// otherwise...				// ...if inside the table				if (!lastTables.isEmpty()) {					// check this and parent					Node parentNode = node.getParentNode();					if (							isParentNodeOneOfFosterTableElements(parentNode) &&							!isOneOfTableElements(element)							) {						String elementNodeName = element.getNodeName().toLowerCase();						if (elementNodeName.equals("form")) {							if (element.getChildNodesCount() > 0) {								// if form element, take all its child nodes								// and add after the from element								Node[] formChildNodes = element.getChildNodes();								parentNode.insertAfter(formChildNodes, element);								return false;							} else {								// empty form element, leave it where it is								return true;							}						}						if (elementNodeName.equals("input")) {							String inputType = element.getAttribute("type");							if (inputType.equals("hidden")) {								// input hidden elements remains as they are								return true;							}						}						// foster element found, remember it to process it later						fosterElements.add(element);					}				} else {					// ...if not inside the table, just keep going				}			}		}		allchilds:		while (true) {			int childs = node.getChildNodesCount();			for (int i = 0; i < childs; i++) {				Node childNode = node.getChild(i);				boolean done = findFosterNodes(childNode);				if (!done) {					continue allchilds;				}			}			break;		}		if (isTable) {			// remove last element			int size = lastTables.size();			if (size > 0) {				lastTables.remove(size - 1);	// no array copy occurs when the last element is removed			}		}		return true;	}
protected void fixElements() {		for (Element fosterElement : fosterElements) {			// find parent table			Element lastTable = findLastTable(fosterElement);			Node fosterElementParent = fosterElement.getParentNode();			// filter our foster element			Node[] fosterChilds = fosterElement.getChildNodes();			for (Node fosterChild : fosterChilds) {				if (fosterChild.getNodeType() == Node.NodeType.ELEMENT) {					if (isOneOfTableElements((Element) fosterChild)) {						// move all child table elements outside						// the foster element						fosterChild.detachFromParent();						fosterElementParent.insertBefore(fosterChild, fosterElement);					}				}			}			// finally, move foster element above the table			fosterElement.detachFromParent();			lastTable.getParentNode().insertBefore(fosterElement, lastTable);		}	}
@Override	protected int pruneCache() {		if (!isPruneExpiredActive()) {			return 0;		}        int count = 0;		Iterator<CacheObject<K,V>> values = cacheMap.values().iterator();		while (values.hasNext()) {			CacheObject<K,V> co = values.next();			if (co.isExpired()) {				values.remove();				onRemove(co.key, co.cachedObject);				count++;			}		}		return count;	}
protected Map<String, BeanData> registerSessionBeans(final HttpSession httpSession) {	    SessionBeans sessionBeans = new SessionBeans();		httpSession.setAttribute(SESSION_BEANS_NAME, sessionBeans);		return sessionBeans.getBeanMap();	}
@SuppressWarnings("unchecked")	protected Map<String, BeanData> getSessionMap(final HttpSession session) {		SessionBeans sessionBeans = (SessionBeans) session.getAttribute(SESSION_BEANS_NAME);		if (sessionBeans == null) {			return null;		}		return sessionBeans.getBeanMap();	}
protected HttpSession getCurrentHttpSession() {		HttpServletRequest request = RequestContextListener.getRequest();		if (request == null) {			throw new PetiteException("No HTTP request bound to the current thread. Is RequestContextListener registered?");		}		return request.getSession();	}
public void init(String name, final String superName, final String suffix, final String reqProxyClassName) {		int lastSlash = name.lastIndexOf('/');		this.targetPackage = lastSlash == -1 ? StringPool.EMPTY : name.substring(0, lastSlash).replace('/', '.');		this.targetClassname = name.substring(lastSlash + 1);		this.nextSupername = superName;		this.superName = name;		// create proxy name		if (reqProxyClassName != null) {			if (reqProxyClassName.startsWith(DOT)) {				name = name.substring(0, lastSlash) + '/' + reqProxyClassName.substring(1);			} else if (reqProxyClassName.endsWith(DOT)) {				name = reqProxyClassName.replace('.', '/') + this.targetClassname;			} else {				name = reqProxyClassName.replace('.', '/');			}		}		// add optional suffix		if (suffix != null) {			name += suffix;		}		this.thisReference = name;		this.superReference = this.superName;	}
void addAdviceClinitMethod(final String name) {		if (adviceClinits == null) {			adviceClinits = new ArrayList<>();		}		adviceClinits.add(name);	}
void addAdviceInitMethod(final String name) {		if (adviceInits == null) {			adviceInits = new ArrayList<>();		}		adviceInits.add(name);	}
@Override	public Byte get(final ResultSet rs, final int index, final int dbSqlType) throws SQLException {		return Byte.valueOf(rs.getByte(index));	}
@Override	public void set(final PreparedStatement st, final int index, final Byte value, final int dbSqlType) throws SQLException {		st.setByte(index, value.byteValue());	}
public String processLink(final String src) {		if (newAction) {			if (bundleId == null) {				bundleId = bundlesManager.registerNewBundleId();				bundleId += '.' + bundleContentType;			}			sources.add(src);		}		if (firstScriptTag) {			// this is the first tag, change the url to point to the bundle			firstScriptTag = false;			return buildStaplerUrl();		} else {			// ignore all other script tags			return null;		}	}
public void end() {		if (newAction) {			bundleId = bundlesManager.registerBundle(contextPath, actionPath, bundleId, bundleContentType, sources);		}	}
public char[] replaceBundleId(final char[] content) {		if (strategy == ACTION_MANAGED || bundleId == null) {			return content;		}		int index = ArraysUtil.indexOf(content, bundleIdMark);		if (index == -1) {			return content;		}		char[] bundleIdChars = bundleId.toCharArray();		char[] result = new char[content.length - bundleIdMark.length + bundleIdChars.length];		System.arraycopy(content, 0, result, 0, index);		System.arraycopy(bundleIdChars, 0, result, index, bundleIdChars.length);		System.arraycopy(content, index + bundleIdMark.length, result, index + bundleIdChars.length, content.length - bundleIdMark.length - index);		return result;	}
public static void convert(final Writer writer, final Properties properties) throws IOException {		convert(writer, properties, Collections.emptyMap());	}
public static void convert(final Writer writer, final Properties properties, final Map<String, Properties> profiles)			throws IOException {		final PropertiesToProps toProps = new PropertiesToProps();		toProps.convertToWriter(writer, properties, profiles);	}
public void parse(final String in) {		ParseState state = ParseState.TEXT;		ParseState stateOnEscape = null;		boolean insideSection = false;		String currentSection = null;		String key = null;		Operator operator = Operator.ASSIGN;		final StringBuilder sb = new StringBuilder();		final int len = in.length();		int ndx = 0;		while (ndx < len) {			final char c = in.charAt(ndx);			ndx++;			if (state == ParseState.COMMENT) {				// comment, skip to the end of the line				if (c == '\r') {					if ((ndx < len) && (in.charAt(ndx) == '\n')) {						ndx++;					}					state = ParseState.TEXT;				}				else if (c == '\n') {					state = ParseState.TEXT;				}			} else if (state == ParseState.ESCAPE) {				state = stateOnEscape;  //ParseState.VALUE;				switch (c) {					case '\r':						if ((ndx < len) && (in.charAt(ndx) == '\n')) {							ndx++;						}					case '\n':						// need to go 1 step back in order to escape						// the current line ending in the follow-up state						ndx--;						state = ParseState.ESCAPE_NEWLINE;						break;					// encode UTF character					case 'u':						int value = 0;						for (int i = 0; i < 4; i++) {							final char hexChar = in.charAt(ndx++);							if (CharUtil.isDigit(hexChar)) {								value = (value << 4) + hexChar - '0';							} else if (hexChar >= 'a' && hexChar <= 'f') {								value = (value << 4) + 10 + hexChar - 'a';							} else if (hexChar >= 'A' && hexChar <= 'F') {								value = (value << 4) + 10 + hexChar - 'A';							} else {								throw new IllegalArgumentException("Malformed \\uXXXX encoding.");							}						}						sb.append((char) value);						break;					case 't':						sb.append('\t');						break;					case 'n':						sb.append('\n');						break;					case 'r':						sb.append('\r');						break;					case 'f':						sb.append('\f');						break;					default:						sb.append(c);				}			} else if (state == ParseState.TEXT) {				switch (c) {					case '\\':						// escape char, take the next char as is						stateOnEscape = state;						state = ParseState.ESCAPE;						break;					// start section					case '[':						if (sb.length() > 0) {							if (StringUtil.isNotBlank(sb)) {								sb.append(c);								// previous string is not blank, hence it's not the section								break;							}						}						sb.setLength(0);						insideSection = true;						break;					// end section					case ']':						if (insideSection) {							currentSection = sb.toString().trim();							sb.setLength(0);							insideSection = false;							if (currentSection.length() == 0) {								currentSection = null;							}						} else {							sb.append(c);						}						break;					case '#':					case ';':						state = ParseState.COMMENT;						break;					// copy operator					case '<':						if (ndx == len || in.charAt(ndx) != '=') {							sb.append(c);							break;						}						operator = Operator.COPY;						//ndx++;						continue;					// assignment operator					case '+':						if (ndx == len || in.charAt(ndx) != '=') {							sb.append(c);							break;						}						operator = Operator.QUICK_APPEND;						//ndx++;						continue;					case '=':					case ':':						if (key == null) {							key = sb.toString().trim();							sb.setLength(0);						} else {							sb.append(c);						}						state = ParseState.VALUE;						break;					case '\r':					case '\n':						add(currentSection, key, sb, true, operator);						sb.setLength(0);						key = null;						operator = Operator.ASSIGN;						break;					case ' ':					case '\t':						// ignore whitespaces						break;					default:						sb.append(c);				}			} else {				switch (c) {					case '\\':						// escape char, take the next char as is						stateOnEscape = state;						state = ParseState.ESCAPE;						break;					case '\r':						if ((ndx < len) && (in.charAt(ndx) == '\n')) {							ndx++;						}					case '\n':						if (state == ParseState.ESCAPE_NEWLINE) {							sb.append(escapeNewLineValue);							if (!ignorePrefixWhitespacesOnNewLine) {								state = ParseState.VALUE;							}						} else {							add(currentSection, key, sb, true, operator);							sb.setLength(0);							key = null;							operator = Operator.ASSIGN;							// end of value, continue to text							state = ParseState.TEXT;						}						break;					case ' ':					case '\t':						if (state == ParseState.ESCAPE_NEWLINE) {							break;						}					default:						sb.append(c);						state = ParseState.VALUE;						if (multilineValues) {							if (sb.length() == 3) {								// check for ''' beginning								if (sb.toString().equals("'''")) {									sb.setLength(0);									int endIndex = in.indexOf("'''", ndx);									if (endIndex == -1) {										endIndex = in.length();									}									sb.append(in, ndx, endIndex);									// append									add(currentSection, key, sb, false, operator);									sb.setLength(0);									key = null;									operator = Operator.ASSIGN;									// end of value, continue to text									state = ParseState.TEXT;									ndx = endIndex + 3;								}							}						}				}			}		}		if (key != null) {			add(currentSection, key, sb, true, operator);		}	}
protected void add(			final String section, final String key,			final StringBuilder value, final boolean trim, final Operator operator) {		// ignore lines without : or =		if (key == null) {			return;		}		String fullKey = key;		if (section != null) {			if (fullKey.length() != 0) {				fullKey = section + '.' + fullKey;			} else {				fullKey = section;			}		}		String v = value.toString();		if (trim) {			if (valueTrimLeft && valueTrimRight) {				v = v.trim();			} else if (valueTrimLeft) {				v = StringUtil.trimLeft(v);			} else {				v = StringUtil.trimRight(v);			}		}		if (v.length() == 0 && skipEmptyProps) {			return;		}		extractProfilesAndAdd(fullKey, v, operator);	}
protected void extractProfilesAndAdd(final String key, final String value, final Operator operator) {		String fullKey = key;		int ndx = fullKey.indexOf(PROFILE_LEFT);		if (ndx == -1) {			justAdd(fullKey, value, null, operator);			return;		}		// extract profiles		ArrayList<String> keyProfiles = new ArrayList<>();		while (true) {			ndx = fullKey.indexOf(PROFILE_LEFT);			if (ndx == -1) {				break;			}			final int len = fullKey.length();			int ndx2 = fullKey.indexOf(PROFILE_RIGHT, ndx + 1);			if (ndx2 == -1) {				ndx2 = len;			}			// remember profile			final String profile = fullKey.substring(ndx + 1, ndx2);			keyProfiles.add(profile);			// extract profile from key			ndx2++;			final String right = (ndx2 == len) ? StringPool.EMPTY : fullKey.substring(ndx2);			fullKey = fullKey.substring(0, ndx) + right;		}		if (fullKey.startsWith(StringPool.DOT)) {			// check for special case when only profile is defined in section			fullKey = fullKey.substring(1);		}		// add value to extracted profiles		justAdd(fullKey, value, keyProfiles, operator);	}
protected void justAdd(final String key, final String value, final ArrayList<String> keyProfiles, final Operator operator) {		if (operator == Operator.COPY) {			HashMap<String,Object> target = new HashMap<>();			String[] profiles = null;			if (keyProfiles != null) {				profiles = keyProfiles.toArray(new String[0]);			}			String[] sources = StringUtil.splitc(value, ',');			for (String source : sources) {				source = source.trim();				// try to extract profile for parsing				String[] lookupProfiles = profiles;				String lookupProfilesString = null;				int leftIndex = source.indexOf('<');				if (leftIndex != -1) {					int rightIndex = source.indexOf('>');					lookupProfilesString = source.substring(leftIndex + 1, rightIndex);					source = source.substring(0, leftIndex).concat(source.substring(rightIndex + 1));					lookupProfiles = StringUtil.splitc(lookupProfilesString, ',');					StringUtil.trimAll(lookupProfiles);				}				String[] wildcards = new String[] {source + ".*"};				propsData.extract(target, lookupProfiles, wildcards, null);				for (Map.Entry<String, Object> entry : target.entrySet()) {					String entryKey = entry.getKey();					String suffix = entryKey.substring(source.length());					String newKey = key + suffix;					String newValue = "${" + entryKey;					if (lookupProfilesString != null) {						newValue += "<" + lookupProfilesString + ">";					}					newValue += "}";					if (profiles == null) {						propsData.putBaseProperty(newKey, newValue, false);					} else {						for (final String p : profiles) {							propsData.putProfileProperty(newKey, newValue, p, false);						}					}				}			}			return;		}		boolean append = operator == Operator.QUICK_APPEND;		if (keyProfiles == null) {			propsData.putBaseProperty(key, value, append);			return;		}		for (final String p : keyProfiles) {			propsData.putProfileProperty(key, value, p, append);		}	}
@Override	public int compareTo(final MutableShort other) {		return value < other.value ? -1 : (value == other.value ? 0 : 1);	}
public static String typedesc2ClassName(final String desc) {		String className = desc;		switch (desc.charAt(0)) {			case 'B':			case 'C':			case 'D':			case 'F':			case 'I':			case 'J':			case 'S':			case 'Z':			case 'V':				if (desc.length() != 1) {					throw new IllegalArgumentException(INVALID_BASE_TYPE + desc);				}				break;			case 'L':				className = className.substring(1, className.length() - 1); break;			case '[':				// uses less-known feature of class loaders for loading array types				// using bytecode-like signatures.				className = className.replace('/', '.');				break;			default: throw new IllegalArgumentException(INVALID_TYPE_DESCRIPTION + desc);		}		return className;	}
public static String typeref2Name(final String desc) {		if (desc.charAt(0) != TYPE_REFERENCE) {			throw new IllegalArgumentException(INVALID_TYPE_DESCRIPTION + desc);		}		String name = desc.substring(1, desc.length() - 1);		return name.replace('/', '.');	}
public static String typedescToSignature(final String desc, final MutableInteger from) {		int fromIndex = from.get();		from.value++;	// default usage for most cases		switch (desc.charAt(fromIndex)) {			case 'B': return "byte";			case 'C': return "char";			case 'D': return "double";			case 'F': return "float";			case 'I': return "int";			case 'J': return "long";			case 'S': return "short";			case 'Z': return "boolean";			case 'V': return "void";			case 'L':				int index = desc.indexOf(';', fromIndex);				if (index < 0) {					throw new IllegalArgumentException(INVALID_TYPE_DESCRIPTION + desc);				}				from.set(index + 1);				String str = desc.substring(fromIndex + 1, index);				return str.replace('/', '.');			case 'T':				return desc.substring(from.value);			case '[':				StringBuilder brackets = new StringBuilder();				int n = fromIndex;				while (desc.charAt(n) == '[') {	// count opening brackets					brackets.append("[]");					n++;				}				from.value = n;				String type = typedescToSignature(desc, from);	// the rest of the string denotes a `<field_type>'				return type + brackets;			default:				if (from.value == 0) {					throw new IllegalArgumentException(INVALID_TYPE_DESCRIPTION + desc);				}				// generics!				return desc.substring(from.value);		}	}
public static String typeToTyperef(final Class type) {		if (!type.isArray()) {			if (!type.isPrimitive()) {				return 'L' + typeToSignature(type) + ';';			}			if (type == int.class) {				return "I";			}			if (type == long.class) {				return "J";			}			if (type == boolean.class) {				return "Z";			}			if (type == double.class) {				return "D";			}			if (type == float.class) {				return "F";			}			if (type == short.class) {				return "S";			}			if (type == void.class) {				return "V";			}			if (type == byte.class) {				return "B";			}			if (type == char.class) {				return "C";			}		}		return type.getName();	}
public static void intValue(final MethodVisitor mv) {		mv.visitTypeInsn(CHECKCAST, SIGNATURE_JAVA_LANG_INTEGER);		mv.visitMethodInsn(INVOKEVIRTUAL, SIGNATURE_JAVA_LANG_INTEGER, "intValue", "()I", false);	}
public static void longValue(final MethodVisitor mv) {		mv.visitTypeInsn(CHECKCAST, SIGNATURE_JAVA_LANG_LONG);		mv.visitMethodInsn(INVOKEVIRTUAL, SIGNATURE_JAVA_LANG_LONG, "longValue", "()J", false);	}
public static void floatValue(final MethodVisitor mv) {		mv.visitTypeInsn(CHECKCAST, SIGNATURE_JAVA_LANG_FLOAT);		mv.visitMethodInsn(INVOKEVIRTUAL, SIGNATURE_JAVA_LANG_FLOAT, "floatValue", "()F", false);	}
public static void doubleValue(final MethodVisitor mv) {		mv.visitTypeInsn(CHECKCAST, SIGNATURE_JAVA_LANG_DOUBLE);		mv.visitMethodInsn(INVOKEVIRTUAL, SIGNATURE_JAVA_LANG_DOUBLE, "doubleValue", "()D", false);	}
public static void byteValue(final MethodVisitor mv) {		mv.visitTypeInsn(CHECKCAST, SIGNATURE_JAVA_LANG_BYTE);		mv.visitMethodInsn(INVOKEVIRTUAL, SIGNATURE_JAVA_LANG_BYTE, "byteValue", "()B", false);	}
public static void shortValue(final MethodVisitor mv) {		mv.visitTypeInsn(CHECKCAST, SIGNATURE_JAVA_LANG_SHORT);		mv.visitMethodInsn(INVOKEVIRTUAL, SIGNATURE_JAVA_LANG_SHORT, "shortValue", "()S", false);	}
public static void booleanValue(final MethodVisitor mv) {		mv.visitTypeInsn(CHECKCAST, SIGNATURE_JAVA_LANG_BOOLEAN);		mv.visitMethodInsn(INVOKEVIRTUAL, SIGNATURE_JAVA_LANG_BOOLEAN, "booleanValue", "()Z", false);	}
public static void charValue(final MethodVisitor mv) {		mv.visitTypeInsn(CHECKCAST, SIGNATURE_JAVA_LANG_CHARACTER);		mv.visitMethodInsn(INVOKEVIRTUAL, SIGNATURE_JAVA_LANG_CHARACTER, "charValue", "()C", false);	}
public Consumers<T> addAll(final Consumer<T>... consumers) {		Collections.addAll(consumerList, consumers);		return this;	}
@Override	public void accept(final T t) {		if (parallel) {			consumerList.parallelStream().forEach(consumer -> consumer.accept(t));		}		else {			consumerList.forEach(consumer -> consumer.accept(t));		}	}
@SuppressWarnings("unchecked")	protected Collection<T> createCollection(final int length) {		if (collectionType.isInterface()) {			if (collectionType == List.class) {				if (length > 0) {					return new ArrayList<>(length);				} else {					return new ArrayList<>();				}			}			if (collectionType == Set.class) {				if (length > 0) {					return new HashSet<>(length);				} else {					return new HashSet<>();				}			}			throw new TypeConversionException("Unknown collection: " + collectionType.getName());		}		if (length > 0) {			try {				Constructor<Collection<T>> ctor = (Constructor<Collection<T>>) collectionType.getConstructor(int.class);				return ctor.newInstance(Integer.valueOf(length));			} catch (Exception ex) {				// ignore exception			}		}		try {			return collectionType.getDeclaredConstructor().newInstance();		} catch (Exception ex) {			throw new TypeConversionException(ex);		}	}
protected Collection<T> convertToSingleElementCollection(final Object value) {		Collection<T> collection = createCollection(0);		//noinspection unchecked		collection.add((T) value);		return collection;	}
protected Collection<T> convertValueToCollection(Object value) {		if (value instanceof Iterable) {			Iterable iterable = (Iterable) value;			Collection<T> collection = createCollection(0);			for (Object element : iterable) {				collection.add(convertType(element));			}			return collection;		}		if (value instanceof CharSequence) {			value = CsvUtil.toStringArray(value.toString());		}		Class type = value.getClass();		if (type.isArray()) {			// convert arrays			Class componentType = type.getComponentType();			if (componentType.isPrimitive()) {				return convertPrimitiveArrayToCollection(value, componentType);			} else {				Object[] array = (Object[]) value;				Collection<T> result = createCollection(array.length);				for (Object a : array) {					result.add(convertType(a));				}				return result;			}		}		// everything else:		return convertToSingleElementCollection(value);	}
protected Collection<T> convertCollectionToCollection(final Collection value) {		Collection<T> collection = createCollection(value.size());		for (Object v : value) {			collection.add(convertType(v));		}		return collection;	}
@SuppressWarnings("AutoBoxing")	protected Collection<T> convertPrimitiveArrayToCollection(final Object value, final Class primitiveComponentType) {		Collection<T> result = null;		if (primitiveComponentType == int.class) {			int[] array = (int[]) value;			result = createCollection(array.length);			for (int a : array) {				result.add(convertType(a));			}		}		else if (primitiveComponentType == long.class) {			long[] array = (long[]) value;			result = createCollection(array.length);			for (long a : array) {				result.add(convertType(a));			}		}		else if (primitiveComponentType == float.class) {			float[] array = (float[]) value;			result = createCollection(array.length);			for (float a : array) {				result.add(convertType(a));			}		}		else if (primitiveComponentType == double.class) {			double[] array = (double[]) value;			result = createCollection(array.length);			for (double a : array) {				result.add(convertType(a));			}		}		else if (primitiveComponentType == short.class) {			short[] array = (short[]) value;			result = createCollection(array.length);			for (short a : array) {				result.add(convertType(a));			}		}		else if (primitiveComponentType == byte.class) {			byte[] array = (byte[]) value;			result = createCollection(array.length);			for (byte a : array) {				result.add(convertType(a));			}		}		else if (primitiveComponentType == char.class) {			char[] array = (char[]) value;			result = createCollection(array.length);			for (char a : array) {				result.add(convertType(a));			}		}		else if (primitiveComponentType == boolean.class) {			boolean[] array = (boolean[]) value;			result = createCollection(array.length);			for (boolean a : array) {				result.add(convertType(a));			}		}		return result;	}
@Override	protected WorkData process(final ClassReader cr, final TargetClassInfoReader targetClassInfoReader) {		ProxettaClassBuilder pcb = new ProxettaClassBuilder(				destClassWriter,				proxetta.getAspects(new ProxyAspect[0]),				resolveClassNameSuffix(),				requestedProxyClassName,				targetClassInfoReader);		cr.accept(pcb, 0);		return pcb.getWorkData();	}
final void addLineNumber(final int lineNumber) {    if (this.lineNumber == 0) {      this.lineNumber = (short) lineNumber;    } else {      if (otherLineNumbers == null) {        otherLineNumbers = new int[LINE_NUMBERS_CAPACITY_INCREMENT];      }      int otherLineNumberIndex = ++otherLineNumbers[0];      if (otherLineNumberIndex >= otherLineNumbers.length) {        int[] newLineNumbers = new int[otherLineNumbers.length + LINE_NUMBERS_CAPACITY_INCREMENT];        System.arraycopy(otherLineNumbers, 0, newLineNumbers, 0, otherLineNumbers.length);        otherLineNumbers = newLineNumbers;      }      otherLineNumbers[otherLineNumberIndex] = lineNumber;    }  }
final void accept(final MethodVisitor methodVisitor, final boolean visitLineNumbers) {    methodVisitor.visitLabel(this);    if (visitLineNumbers && lineNumber != 0) {      methodVisitor.visitLineNumber(lineNumber & 0xFFFF, this);      if (otherLineNumbers != null) {        for (int i = 1; i <= otherLineNumbers[0]; ++i) {          methodVisitor.visitLineNumber(otherLineNumbers[i], this);        }      }    }  }
final void put(      final ByteVector code, final int sourceInsnBytecodeOffset, final boolean wideReference) {    if ((flags & FLAG_RESOLVED) == 0) {      if (wideReference) {        addForwardReference(sourceInsnBytecodeOffset, FORWARD_REFERENCE_TYPE_WIDE, code.length);        code.putInt(-1);      } else {        addForwardReference(sourceInsnBytecodeOffset, FORWARD_REFERENCE_TYPE_SHORT, code.length);        code.putShort(-1);      }    } else {      if (wideReference) {        code.putInt(bytecodeOffset - sourceInsnBytecodeOffset);      } else {        code.putShort(bytecodeOffset - sourceInsnBytecodeOffset);      }    }  }
private void addForwardReference(      final int sourceInsnBytecodeOffset, final int referenceType, final int referenceHandle) {    if (forwardReferences == null) {      forwardReferences = new int[FORWARD_REFERENCES_CAPACITY_INCREMENT];    }    int lastElementIndex = forwardReferences[0];    if (lastElementIndex + 2 >= forwardReferences.length) {      int[] newValues = new int[forwardReferences.length + FORWARD_REFERENCES_CAPACITY_INCREMENT];      System.arraycopy(forwardReferences, 0, newValues, 0, forwardReferences.length);      forwardReferences = newValues;    }    forwardReferences[++lastElementIndex] = sourceInsnBytecodeOffset;    forwardReferences[++lastElementIndex] = referenceType | referenceHandle;    forwardReferences[0] = lastElementIndex;  }
final boolean resolve(final byte[] code, final int bytecodeOffset) {    this.flags |= FLAG_RESOLVED;    this.bytecodeOffset = bytecodeOffset;    if (forwardReferences == null) {      return false;    }    boolean hasAsmInstructions = false;    for (int i = forwardReferences[0]; i > 0; i -= 2) {      final int sourceInsnBytecodeOffset = forwardReferences[i - 1];      final int reference = forwardReferences[i];      final int relativeOffset = bytecodeOffset - sourceInsnBytecodeOffset;      int handle = reference & FORWARD_REFERENCE_HANDLE_MASK;      if ((reference & FORWARD_REFERENCE_TYPE_MASK) == FORWARD_REFERENCE_TYPE_SHORT) {        if (relativeOffset < Short.MIN_VALUE || relativeOffset > Short.MAX_VALUE) {          // Change the opcode of the jump instruction, in order to be able to find it later in          // ClassReader. These ASM specific opcodes are similar to jump instruction opcodes, except          // that the 2 bytes offset is unsigned (and can therefore represent values from 0 to          // 65535, which is sufficient since the size of a method is limited to 65535 bytes).          int opcode = code[sourceInsnBytecodeOffset] & 0xFF;          if (opcode < Opcodes.IFNULL) {            // Change IFEQ ... JSR to ASM_IFEQ ... ASM_JSR.            code[sourceInsnBytecodeOffset] = (byte) (opcode + Constants.ASM_OPCODE_DELTA);          } else {            // Change IFNULL and IFNONNULL to ASM_IFNULL and ASM_IFNONNULL.            code[sourceInsnBytecodeOffset] = (byte) (opcode + Constants.ASM_IFNULL_OPCODE_DELTA);          }          hasAsmInstructions = true;        }        code[handle++] = (byte) (relativeOffset >>> 8);        code[handle] = (byte) relativeOffset;      } else {        code[handle++] = (byte) (relativeOffset >>> 24);        code[handle++] = (byte) (relativeOffset >>> 16);        code[handle++] = (byte) (relativeOffset >>> 8);        code[handle] = (byte) relativeOffset;      }    }    return hasAsmInstructions;  }
final void markSubroutine(final short subroutineId) {    // Data flow algorithm: put this basic block in a list of blocks to process (which are blocks    // belonging to subroutine subroutineId) and, while there are blocks to process, remove one from    // the list, mark it as belonging to the subroutine, and add its successor basic blocks in the    // control flow graph to the list of blocks to process (if not already done).    Label listOfBlocksToProcess = this;    listOfBlocksToProcess.nextListElement = EMPTY_LIST;    while (listOfBlocksToProcess != EMPTY_LIST) {      // Remove a basic block from the list of blocks to process.      Label basicBlock = listOfBlocksToProcess;      listOfBlocksToProcess = listOfBlocksToProcess.nextListElement;      basicBlock.nextListElement = null;      // If it is not already marked as belonging to a subroutine, mark it as belonging to      // subroutineId and add its successors to the list of blocks to process (unless already done).      if (basicBlock.subroutineId == 0) {        basicBlock.subroutineId = subroutineId;        listOfBlocksToProcess = basicBlock.pushSuccessors(listOfBlocksToProcess);      }    }  }
final void addSubroutineRetSuccessors(final Label subroutineCaller) {    // Data flow algorithm: put this basic block in a list blocks to process (which are blocks    // belonging to a subroutine starting with this label) and, while there are blocks to process,    // remove one from the list, put it in a list of blocks that have been processed, add a return    // edge to the successor of subroutineCaller if applicable, and add its successor basic blocks    // in the control flow graph to the list of blocks to process (if not already done).    Label listOfProcessedBlocks = EMPTY_LIST;    Label listOfBlocksToProcess = this;    listOfBlocksToProcess.nextListElement = EMPTY_LIST;    while (listOfBlocksToProcess != EMPTY_LIST) {      // Move a basic block from the list of blocks to process to the list of processed blocks.      Label basicBlock = listOfBlocksToProcess;      listOfBlocksToProcess = basicBlock.nextListElement;      basicBlock.nextListElement = listOfProcessedBlocks;      listOfProcessedBlocks = basicBlock;      // Add an edge from this block to the successor of the caller basic block, if this block is      // the end of a subroutine and if this block and subroutineCaller do not belong to the same      // subroutine.      if ((basicBlock.flags & FLAG_SUBROUTINE_END) != 0          && basicBlock.subroutineId != subroutineCaller.subroutineId) {        basicBlock.outgoingEdges =            new Edge(                basicBlock.outputStackSize,                // By construction, the first outgoing edge of a basic block that ends with a jsr                // instruction leads to the jsr continuation block, i.e. where execution continues                // when ret is called (see {@link #FLAG_SUBROUTINE_CALLER}).                subroutineCaller.outgoingEdges.successor,                basicBlock.outgoingEdges);      }      // Add its successors to the list of blocks to process. Note that {@link #pushSuccessors} does      // not push basic blocks which are already in a list. Here this means either in the list of      // blocks to process, or in the list of already processed blocks. This second list is      // important to make sure we don't reprocess an already processed block.      listOfBlocksToProcess = basicBlock.pushSuccessors(listOfBlocksToProcess);    }    // Reset the {@link #nextListElement} of all the basic blocks that have been processed to null,    // so that this method can be called again with a different subroutine or subroutine caller.    while (listOfProcessedBlocks != EMPTY_LIST) {      Label newListOfProcessedBlocks = listOfProcessedBlocks.nextListElement;      listOfProcessedBlocks.nextListElement = null;      listOfProcessedBlocks = newListOfProcessedBlocks;    }  }
private Label pushSuccessors(final Label listOfLabelsToProcess) {    Label newListOfLabelsToProcess = listOfLabelsToProcess;    Edge outgoingEdge = outgoingEdges;    while (outgoingEdge != null) {      // By construction, the second outgoing edge of a basic block that ends with a jsr instruction      // leads to the jsr target (see {@link #FLAG_SUBROUTINE_CALLER}).      boolean isJsrTarget =          (flags & Label.FLAG_SUBROUTINE_CALLER) != 0 && outgoingEdge == outgoingEdges.nextEdge;      if (!isJsrTarget && outgoingEdge.successor.nextListElement == null) {        // Add this successor to the list of blocks to process, if it does not already belong to a        // list of labels.        outgoingEdge.successor.nextListElement = newListOfLabelsToProcess;        newListOfLabelsToProcess = outgoingEdge.successor;      }      outgoingEdge = outgoingEdge.nextEdge;    }    return newListOfLabelsToProcess;  }
protected int[] compareDigits(final String str1, int ndx1, final String str2, int ndx2) {		// iterate all digits in the first string		int zeroCount1 = 0;		while (charAt(str1, ndx1) == '0') {			zeroCount1++;			ndx1++;		}		int len1 = 0;		while (true) {			final char char1 = charAt(str1, ndx1);			final boolean isDigitChar1 = CharUtil.isDigit(char1);			if (!isDigitChar1) {				break;			}			len1++;			ndx1++;		}		// iterate all digits in the second string and compare with the first		int zeroCount2 = 0;		while (charAt(str2, ndx2) == '0') {			zeroCount2++;			ndx2++;		}		int len2 = 0;		int ndx1_new = ndx1 - len1;		int equalNumbers = 0;		while (true) {			final char char2 = charAt(str2, ndx2);			final boolean isDigitChar2 = CharUtil.isDigit(char2);			if (!isDigitChar2) {				break;			}			if (equalNumbers == 0 && (ndx1_new < ndx1)) {				equalNumbers = charAt(str1, ndx1_new++) - char2;			}			len2++;			ndx2++;		}		// compare		if (len1 != len2) {			// numbers are not equals size			return new int[] {len1 - len2};		}		if (equalNumbers != 0) {			return new int[] {equalNumbers};		}		// numbers are equal, but number of zeros is different		return new int[] {0, zeroCount1 - zeroCount2, ndx1, ndx2};	}
private char fixAccent(final char c) {		for (int i = 0; i < ACCENT_CHARS.length; i+=2) {			final char accentChar = ACCENT_CHARS[i];			if (accentChar == c) {				return ACCENT_CHARS[i + 1];			}		}		return c;	}
private static char charAt(final String string, final int ndx) {		if (ndx >= string.length()) {			return 0;		}		return string.charAt(ndx);	}
public ByteVector putByte(final int byteValue) {    int currentLength = length;    if (currentLength + 1 > data.length) {      enlarge(1);    }    data[currentLength++] = (byte) byteValue;    length = currentLength;    return this;  }
final ByteVector put11(final int byteValue1, final int byteValue2) {    int currentLength = length;    if (currentLength + 2 > data.length) {      enlarge(2);    }    byte[] currentData = data;    currentData[currentLength++] = (byte) byteValue1;    currentData[currentLength++] = (byte) byteValue2;    length = currentLength;    return this;  }
public ByteVector putShort(final int shortValue) {    int currentLength = length;    if (currentLength + 2 > data.length) {      enlarge(2);    }    byte[] currentData = data;    currentData[currentLength++] = (byte) (shortValue >>> 8);    currentData[currentLength++] = (byte) shortValue;    length = currentLength;    return this;  }
final ByteVector put12(final int byteValue, final int shortValue) {    int currentLength = length;    if (currentLength + 3 > data.length) {      enlarge(3);    }    byte[] currentData = data;    currentData[currentLength++] = (byte) byteValue;    currentData[currentLength++] = (byte) (shortValue >>> 8);    currentData[currentLength++] = (byte) shortValue;    length = currentLength;    return this;  }
final ByteVector put112(final int byteValue1, final int byteValue2, final int shortValue) {    int currentLength = length;    if (currentLength + 4 > data.length) {      enlarge(4);    }    byte[] currentData = data;    currentData[currentLength++] = (byte) byteValue1;    currentData[currentLength++] = (byte) byteValue2;    currentData[currentLength++] = (byte) (shortValue >>> 8);    currentData[currentLength++] = (byte) shortValue;    length = currentLength;    return this;  }
public ByteVector putInt(final int intValue) {    int currentLength = length;    if (currentLength + 4 > data.length) {      enlarge(4);    }    byte[] currentData = data;    currentData[currentLength++] = (byte) (intValue >>> 24);    currentData[currentLength++] = (byte) (intValue >>> 16);    currentData[currentLength++] = (byte) (intValue >>> 8);    currentData[currentLength++] = (byte) intValue;    length = currentLength;    return this;  }
final ByteVector put122(final int byteValue, final int shortValue1, final int shortValue2) {    int currentLength = length;    if (currentLength + 5 > data.length) {      enlarge(5);    }    byte[] currentData = data;    currentData[currentLength++] = (byte) byteValue;    currentData[currentLength++] = (byte) (shortValue1 >>> 8);    currentData[currentLength++] = (byte) shortValue1;    currentData[currentLength++] = (byte) (shortValue2 >>> 8);    currentData[currentLength++] = (byte) shortValue2;    length = currentLength;    return this;  }
public ByteVector putLong(final long longValue) {    int currentLength = length;    if (currentLength + 8 > data.length) {      enlarge(8);    }    byte[] currentData = data;    int intValue = (int) (longValue >>> 32);    currentData[currentLength++] = (byte) (intValue >>> 24);    currentData[currentLength++] = (byte) (intValue >>> 16);    currentData[currentLength++] = (byte) (intValue >>> 8);    currentData[currentLength++] = (byte) intValue;    intValue = (int) longValue;    currentData[currentLength++] = (byte) (intValue >>> 24);    currentData[currentLength++] = (byte) (intValue >>> 16);    currentData[currentLength++] = (byte) (intValue >>> 8);    currentData[currentLength++] = (byte) intValue;    length = currentLength;    return this;  }
public ByteVector putByteArray(      final byte[] byteArrayValue, final int byteOffset, final int byteLength) {    if (length + byteLength > data.length) {      enlarge(byteLength);    }    if (byteArrayValue != null) {      System.arraycopy(byteArrayValue, byteOffset, data, length, byteLength);    }    length += byteLength;    return this;  }
private void enlarge(final int size) {    int doubleCapacity = 2 * data.length;    int minimalCapacity = length + size;    byte[] newData = new byte[doubleCapacity > minimalCapacity ? doubleCapacity : minimalCapacity];    System.arraycopy(data, 0, newData, 0, length);    data = newData;  }
protected T authenticateUserViaHttpSession(final ActionRequest actionRequest) {		final HttpServletRequest servletRequest = actionRequest.getHttpServletRequest();		final UserSession<T> userSession = UserSession.get(servletRequest);		if (userSession == null) {			return null;		}		final T authToken = userSession.getAuthToken();		if (authToken == null) {			return null;		}		// granted		final T newAuthToken = userAuth().rotateToken(authToken);		if (newAuthToken != authToken) {			final UserSession<T> newUserSesion = new UserSession<>(newAuthToken, userAuth().tokenValue(newAuthToken));			newUserSesion.start(servletRequest, actionRequest.getHttpServletResponse());		}		return newAuthToken;	}
protected T authenticateUserViaToken(final ActionRequest actionRequest) {		final HttpServletRequest servletRequest = actionRequest.getHttpServletRequest();		// then try the auth token		final String token = ServletUtil.resolveAuthBearerToken(servletRequest);		if (token == null) {			return null;		}		final T authToken = userAuth().validateToken(token);		if (authToken == null) {			return null;		}		// granted		final T newAuthToken = userAuth().rotateToken(authToken);		actionRequest.getHttpServletResponse().setHeader("Authentication", "Bearer: " + userAuth().tokenValue(newAuthToken));		return newAuthToken;	}
protected T authenticateUserViaBasicAuth(final ActionRequest actionRequest) {		final HttpServletRequest servletRequest = actionRequest.getHttpServletRequest();		final String username = ServletUtil.resolveAuthUsername(servletRequest);		if (username == null) {			return null;		}		final String password = ServletUtil.resolveAuthPassword(servletRequest);		final T authToken = userAuth().login(username, password);		if (authToken == null) {			return null;		}		return authToken;	}
@Override	public Ref get(final ResultSet rs, final int index, final int dbSqlType) throws SQLException {		return rs.getRef(index);	}
@Override	public void set(final PreparedStatement st, final int index, final Ref value, final int dbSqlType) throws SQLException {		st.setRef(index, value);	}
private String calcIndexKey(final String key) {		String indexedKey = null;		if (key.indexOf('[') != -1) {			int i = -1;			indexedKey = key;			while ((i = indexedKey.indexOf('[', i + 1)) != -1) {				int j = indexedKey.indexOf(']', i);				String a = indexedKey.substring(0, i);				String b = indexedKey.substring(j);				indexedKey = a + "[*" + b;			}		}		return indexedKey;	}
public String findMessage(String bundleName, final Locale locale, final String key) {		String indexedKey = calcIndexKey(key);		// hierarchy		String name = bundleName;		while (true) {			String msg = getMessage(name, locale, key, indexedKey);			if (msg != null) {				return msg;			}			if (bundleName == null || bundleName.length() == 0) {				break;			}			int ndx = bundleName.lastIndexOf('.');			if (ndx == -1) {				bundleName = null;				name = fallbackBundlename;			} else {				bundleName = bundleName.substring(0, ndx);				name = bundleName + '.' + fallbackBundlename;			}		}		// default bundles		for (String bname : defaultBundles) {			String msg = getMessage(bname, locale, key, indexedKey);			if (msg != null) {				return msg;			}		}		return null;	}
public String findDefaultMessage(final Locale locale, final String key) {		String indexedKey = calcIndexKey(key);		String msg = getMessage(fallbackBundlename, locale, key, indexedKey);		if (msg != null) {			return msg;		}		for (String bname : defaultBundles) {			msg = getMessage(bname, locale, key, indexedKey);			if (msg != null) {				return msg;			}		}		return null;	}
public String getMessage(final String bundleName, final Locale locale, final String key) {		ResourceBundle bundle = findResourceBundle(bundleName, locale);		if (bundle == null) {			return null;		}/*		//jdk6:		if (bundle.containsKey(key) == false) {			return null;		}*/		try {			return bundle.getString(key);		} catch (MissingResourceException mrex) {			return null;		}	}
public ResourceBundle findResourceBundle(String bundleName, Locale locale) {		if (bundleName == null) {			bundleName = fallbackBundlename;		}		if (locale == null) {			locale = fallbackLocale;		}		if (!cacheResourceBundles) {			try {				return getBundle(bundleName, locale, ClassLoaderUtil.getDefaultClassLoader());			} catch (MissingResourceException ignore) {				return null;			}		}		String key = bundleName + '_' + locale.toLanguageTag();		try {			if (!misses.contains(key)) {				ResourceBundle bundle = notmisses.get(key);				if (bundle == null) {					bundle = getBundle(bundleName, locale, ClassLoaderUtil.getDefaultClassLoader());					notmisses.put(key, bundle);				}				return bundle;			}		} catch (MissingResourceException ignore) {			misses.add(key);		}		return null;	}
protected ResourceBundle getBundle(final String bundleName, final Locale locale, final ClassLoader classLoader) {		return ResourceBundle.getBundle(bundleName, locale, classLoader);	}
protected K get(final K[] array, final int index) {		return (K) Array.get(array, index);	}
protected <E> boolean isPersistent(final DbEntityDescriptor<E> ded, final E entity) {		final Object key = ded.getIdValue(entity);		if (key == null) {			return false;		}		if (key instanceof Number) {			final long value = ((Number)key).longValue();			if (value == 0) {				return false;			}		}		return true;	}
protected <E, ID> void setEntityId(final DbEntityDescriptor<E> ded, final E entity, final ID newIdValue) {		ded.setIdValue(entity, newIdValue);	}
public <E> E store(final E entity) {		final Class type = entity.getClass();		final DbEntityDescriptor ded = dbOom.entityManager().lookupType(type);		if (ded == null) {			throw new DbOomException("Not an entity: " + type);		}		if (!isPersistent(ded, entity)) {			final DbQuery q;			if (dbOom.config().isKeysGeneratedByDatabase()) {				q = query(dbOom.entities().insert(entity));				q.setGeneratedKey();				q.executeUpdate();				final Object nextId = q.getGeneratedKey();				setEntityId(ded, entity, nextId);			}			else {				final Object nextId = generateNextId(ded);				setEntityId(ded, entity, nextId);				q = query(dbOom.entities().insert(entity));				q.executeUpdate();			}			q.close();		}		else {			query(dbOom.entities().updateAll(entity)).autoClose().executeUpdate();		}		return entity;	}
public void save(final Object entity) {		final DbQuery q = query(dbOom.entities().insert(entity));		q.autoClose().executeUpdate();	}
public void update(final Object entity) {		query(dbOom.entities().updateAll(entity)).autoClose().executeUpdate();	}
public <E> E updateProperty(final E entity, final String name, final Object newValue) {		query(dbOom.entities().updateColumn(entity, name, newValue)).autoClose().executeUpdate();		BeanUtil.declared.setProperty(entity, name, newValue);		return entity;	}
public <E> E updateProperty(final E entity, final String name) {		Object value = BeanUtil.declared.getProperty(entity, name);		query(dbOom.entities().updateColumn(entity, name, value)).autoClose().executeUpdate();		return entity;	}
public <E, ID> E findById(final Class<E> entityType, final ID id) {		return query(dbOom.entities().findById(entityType, id)).autoClose().find(entityType);	}
public <E> E findOneByProperty(final Class<E> entityType, final String name, final Object value) {		return query(dbOom.entities().findByColumn(entityType, name, value)).autoClose().find(entityType);	}
@SuppressWarnings({"unchecked"})	public <E> E findOne(final Object criteria) {		return (E) query(dbOom.entities().find(criteria)).autoClose().find(criteria.getClass());	}
@SuppressWarnings({"unchecked"})	public <E> List<E> find(final Object criteria) {		return query(dbOom.entities().find(criteria)).autoClose().list(criteria.getClass());	}
public <E> List<E> find(final Class<E> entityType, final Object criteria) {		return query(dbOom.entities().find(entityType, criteria)).autoClose().list(entityType);	}
public <ID> void deleteById(final Class entityType, final ID id) {		query(dbOom.entities().deleteById(entityType, id)).autoClose().executeUpdate();	}
public void deleteById(final Object entity) {		if (entity != null) {			int result = query(dbOom.entities().deleteById(entity)).autoClose().executeUpdate();			if (result != 0) {				// now reset the ID value				Class type = entity.getClass();				DbEntityDescriptor ded = dbOom.entityManager().lookupType(type);				setEntityId(ded, entity, 0);			}		}	}
public long count(final Class entityType) {		return query(dbOom.entities().count(entityType)).autoClose().executeCount();	}
public <ID> void increaseProperty(final Class entityType, final ID id, final String name, final Number delta) {		query(dbOom.entities().increaseColumn(entityType, id, name, delta, true)).autoClose().executeUpdate();	}
public <ID> void decreaseProperty(final Class entityType, final ID id, final String name, final Number delta) {		query(dbOom.entities().increaseColumn(entityType, id, name, delta, false)).autoClose().executeUpdate();	}
public <E> List<E> findRelated(final Class<E> target, final Object source) {		return query(dbOom.entities().findForeign(target, source)).autoClose().list(target);	}
public <E> List<E> listAll(final Class<E> target) {		return query(dbOom.entities().from(target)).autoClose().list(target);	}
public boolean implicitlyCloseParentTagOnNewTag(String parentNodeName, String nodeName) {		if (parentNodeName == null) {			return false;		}		parentNodeName = parentNodeName.toLowerCase();		nodeName = nodeName.toLowerCase();		for (int i = 0; i < IMPLIED_ON_START.length; i+=2) {			if (StringUtil.equalsOne(parentNodeName, IMPLIED_ON_START[i]) != -1) {				if (StringUtil.equalsOne(nodeName, IMPLIED_ON_START[i + 1]) != -1) {					return true;				}			}		}		return false;	}
public boolean implicitlyCloseParentTagOnTagEnd(String parentNodeName, String nodeName) {		if (parentNodeName == null) {			return false;		}		parentNodeName = parentNodeName.toLowerCase();		nodeName = nodeName.toLowerCase();		for (int i = 0; i < IMPLIED_ON_END.length; i += 2) {			if (StringUtil.equalsOne(nodeName, IMPLIED_ON_END[i]) != -1) {				if (StringUtil.equalsOne(parentNodeName, IMPLIED_ON_END[i + 1]) != -1) {					return true;				}			}		}		return false;	}
public boolean implicitlyCloseTagOnEOF(String nodeName) {		if (nodeName == null) {			return false;		}		nodeName = nodeName.toLowerCase();		return StringUtil.equalsOne(nodeName, CLOSED_ON_EOF) != -1;	}
@Override	public void clear() {		entries = null;		Iterator<String> keys = getAttributeNames();		while (keys.hasNext()) {			removeAttribute(keys.next());		}	}
@Override	public Set<Entry<String, Object>> entrySet() {		if (entries == null) {			entries = new HashSet<>();			Iterator<String> iterator = getAttributeNames();			while (iterator.hasNext()) {				final String key = iterator.next();				final Object value = getAttribute(key);				entries.add(new Entry<String, Object>() {					@Override					public boolean equals(final Object obj) {						if (obj == null) {							return false;						}						if (this.getClass() != obj.getClass()) {							return false;						}						Entry entry = (Entry) obj;						return ((key == null) ? (entry.getKey() == null) : key.equals(entry.getKey())) && ((value == null) ? (entry.getValue() == null) : value.equals(entry.getValue()));					}					@Override					public int hashCode() {						return ((key == null) ? 0 : key.hashCode()) ^ ((value == null) ? 0 : value.hashCode());					}					@Override					public String getKey() {						return key;					}					@Override					public Object getValue() {						return value;					}					@Override					public Object setValue(final Object obj) {						setAttribute(key, obj);						return value;					}				});			}		}		return entries;	}
@Override	public Object put(final String key, final Object value) {		entries = null;		Object previous = get(key);		setAttribute(key, value);		return previous;	}
@Override	public Object remove(final Object key) {		entries = null;		Object value = get(key);		removeAttribute(key.toString());		return value;	}
@SuppressWarnings({"ThrowCaughtLocally"})	public static StackTraceElement[] getCurrentStackTrace() {		StackTraceElement[] ste = new Exception().getStackTrace();		if (ste.length > 1) {			StackTraceElement[] result = new StackTraceElement[ste.length - 1];			System.arraycopy(ste, 1, result, 0, ste.length - 1);			return result;		} else {			return ste;		}	}
public static StackTraceElement[] getStackTrace(final Throwable t, final String[] allow, final String[] deny) {		StackTraceElement[] st = t.getStackTrace();		ArrayList<StackTraceElement> result = new ArrayList<>(st.length);		elementLoop:		for (StackTraceElement element : st) {			String className = element.getClassName();			if (allow != null) {				boolean validElemenet = false;				for (String filter : allow) {					if (className.contains(filter)) {						validElemenet = true;						break;					}				}				if (!validElemenet) {					continue;				}			}			if (deny != null) {				for (String filter : deny) {					if (className.contains(filter)) {						continue elementLoop;					}				}			}			result.add(element);		}		st = new StackTraceElement[result.size()];		return result.toArray(st);	}
public static StackTraceElement[][] getStackTraceChain(Throwable t, final String[] allow, final String[] deny) {		ArrayList<StackTraceElement[]> result = new ArrayList<>();		while (t != null) {			StackTraceElement[] stack = getStackTrace(t, allow, deny);			result.add(stack);			t = t.getCause();		}		StackTraceElement[][] allStacks = new StackTraceElement[result.size()][];		for (int i = 0; i < allStacks.length; i++) {			allStacks[i] = result.get(i);		}		return allStacks;	}
public static Throwable[] getExceptionChain(Throwable throwable) {		ArrayList<Throwable> list = new ArrayList<>();		list.add(throwable);		while ((throwable = throwable.getCause()) != null) {			list.add(throwable);		}		Throwable[] result = new Throwable[list.size()];		return list.toArray(result);	}
public static String exceptionStackTraceToString(final Throwable t) {		StringWriter sw = new StringWriter();		PrintWriter pw = new PrintWriter(sw, true);		t.printStackTrace(pw);		StreamUtil.close(pw);		StreamUtil.close(sw);		return sw.toString();	}
public static String exceptionChainToString(Throwable t) {		StringWriter sw = new StringWriter();		PrintWriter pw = new PrintWriter(sw, true);		while (t != null) {			t.printStackTrace(pw);			t = t.getCause();		}		StreamUtil.close(pw);		StreamUtil.close(sw);		return sw.toString();	}
public static String buildMessage(final String message, Throwable cause) {		if (cause != null) {			cause = getRootCause(cause);			StringBuilder buf = new StringBuilder();			if (message != null) {				buf.append(message).append("; ");			}			buf.append("<--- ").append(cause);			return buf.toString();		} else {			return message;		}	}
public static Throwable getRootCause(final Throwable throwable) {		Throwable cause = throwable.getCause();		if (cause == null) {			return throwable;		}		Throwable t = throwable;		// defend against (malicious?) circularity		for (int i = 0; i < 1000; i++) {			cause = t.getCause();			if (cause == null) {				return t;			}			t = cause;		}		return throwable;	}
@SuppressWarnings({"unchecked"})	public static <T extends Throwable> T findCause(Throwable throwable, final Class<T> cause) {		while (throwable != null) {			if (throwable.getClass().equals(cause)) {				return (T) throwable;			}			throwable = throwable.getCause();		}		return null;	}
public static SQLException rollupSqlExceptions(final Collection<SQLException> exceptions) {		SQLException parent = null;		for (SQLException exception : exceptions) {			if (parent != null) {				exception.setNextException(parent);			}			parent = exception;		}		return parent;	}
public static String message(final Throwable throwable) {		String message = throwable.getMessage();		if (StringUtil.isBlank(message)) {			message = throwable.toString();		}		return message;	}
public static RuntimeException wrapToRuntimeException(final Throwable throwable) {		if (throwable instanceof RuntimeException) {			return (RuntimeException) throwable;		}		return new RuntimeException(throwable);	}
public static Throwable unwrapThrowable(final Throwable wrappedThrowable) {		Throwable unwrapped = wrappedThrowable;		while (true) {			if (unwrapped instanceof InvocationTargetException) {				unwrapped = ((InvocationTargetException) unwrapped).getTargetException();			}			else if (unwrapped instanceof UndeclaredThrowableException) {				unwrapped = ((UndeclaredThrowableException) unwrapped).getUndeclaredThrowable();			}			else {				return unwrapped;			}		}	}
public static JSONAnnotationValues of(final AnnotationParser annotationParser, final AnnotatedElement annotatedElement) {		if (!annotationParser.hasAnnotationOn(annotatedElement)) {			return null;		}		return new JSONAnnotationValues(annotationParser.of(annotatedElement));	}
protected void registerAsConsumer(final ClassScanner classScanner) {		classScanner.registerEntryConsumer(classPathEntry -> {			final String entryName = classPathEntry.name();			if (entryName.endsWith(actionClassSuffix)) {				try {					acceptActionClass(classPathEntry.loadClass());				} catch (Exception ex) {					log.debug("Invalid Madvoc action, ignoring: " + entryName);				}			}			else if (classPathEntry.isTypeSignatureInUse(MADVOC_COMPONENT_ANNOTATION)) {				try {					acceptMadvocComponentClass(classPathEntry.loadClass());				} catch (Exception ex) {					log.debug("Invalid Madvoc component ignoring: {}" + entryName);				}			}		});	}
protected boolean checkClass(final Class clazz) {		try {			if (clazz.isAnonymousClass()) {				return false;			}			if (clazz.isArray() || clazz.isEnum()) {				return false;			}			if (clazz.isInterface()) {				return false;			}			if (clazz.isLocalClass()) {				return false;			}			if ((clazz.isMemberClass() ^ Modifier.isStatic(clazz.getModifiers()))) {				return false;			}			if (clazz.isPrimitive()) {				return false;			}			int modifiers = clazz.getModifiers();			if (Modifier.isAbstract(modifiers)) {				return false;			}			return true;		} catch (Throwable ignore) {			return false;		}	}
@SuppressWarnings("NonConstantStringShouldBeStringBuffer")	protected void acceptActionClass(final Class<?> actionClass) {		if (actionClass == null) {			return;		}		if (!checkClass(actionClass)) {			return; 		}		if (actionClass.getAnnotation(MadvocAction.class) == null) {			return;		}		ClassDescriptor cd = ClassIntrospector.get().lookup(actionClass);		MethodDescriptor[] allMethodDescriptors = cd.getAllMethodDescriptors();		for (MethodDescriptor methodDescriptor : allMethodDescriptors) {			if (!methodDescriptor.isPublic()) {				continue;			}			// just public methods			final Method method = methodDescriptor.getMethod();			final boolean hasAnnotation = actionConfigManager.hasActionAnnotationOn(method);			if (!hasAnnotation) {				continue;			}			webappConfigurations.add(() -> actionsManager.registerAction(actionClass, method, null));		}	}
protected void acceptMadvocComponentClass(final Class componentClass) {		if (componentClass == null) {			return;		}		if (!checkClass(componentClass)) {			return;		}		madvocComponents.add(() -> madvocContainer.registerComponent(componentClass));	}
public static ClassLoader getDefaultClassLoader() {		ClassLoader cl = getContextClassLoader();		if (cl == null) {			Class callerClass = ClassUtil.getCallerClass(2);			cl = callerClass.getClassLoader();		}		return cl;	}
public static ClassLoader getSystemClassLoader() {		if (System.getSecurityManager() == null) {			return ClassLoader.getSystemClassLoader();		}		else {			return AccessController.doPrivileged(				(PrivilegedAction<ClassLoader>) ClassLoader::getSystemClassLoader);		}	}
public static Manifest getClasspathItemManifest(final File classpathItem) {		Manifest manifest = null;		if (classpathItem.isFile()) {			FileInputStream fis = null;			try {				fis = new FileInputStream(classpathItem);				JarFile jar = new JarFile(classpathItem);				manifest = jar.getManifest();			} catch (IOException ignore) {			}			finally {				StreamUtil.close(fis);			}		} else {			File metaDir = new File(classpathItem, "META-INF");			File manifestFile = null;			if (metaDir.isDirectory()) {				for (String m : MANIFESTS) {					File mFile = new File(metaDir, m);					if (mFile.isFile()) {						manifestFile = mFile;						break;					}				}			}			if (manifestFile != null) {				FileInputStream fis = null;				try {					fis = new FileInputStream(manifestFile);					manifest = new Manifest(fis);				} catch (IOException ignore) {				}				finally {					StreamUtil.close(fis);				}			}		}		return manifest;	}
public static String getClasspathItemBaseDir(final File classpathItem) {		String base;		if (classpathItem.isFile()) {			base = classpathItem.getParent();		} else {			base = classpathItem.toString();		}		return base;	}
public static File[] getDefaultClasspath(ClassLoader classLoader) {		Set<File> classpaths = new TreeSet<>();		while (classLoader != null) {			URL[] urls = ClassPathURLs.of(classLoader, null);			if (urls != null) {				for (URL u : urls) {					File f = FileUtil.toContainerFile(u);					if ((f != null) && f.exists()) {						try {							f = f.getCanonicalFile();							boolean newElement = classpaths.add(f);							if (newElement) {								addInnerClasspathItems(classpaths, f);							}						} catch (IOException ignore) {						}					}				}			}			classLoader = classLoader.getParent();		}		File[] result = new File[classpaths.size()];		return classpaths.toArray(result);	}
public static URL getResourceUrl(String resourceName, final ClassLoader classLoader) {		if (resourceName.startsWith("/")) {			resourceName = resourceName.substring(1);		}				URL resourceUrl;		// try #1 - using provided class loader		if (classLoader != null) {			resourceUrl = classLoader.getResource(resourceName);			if (resourceUrl != null) {				return resourceUrl;			}		}		// try #2 - using thread class loader		ClassLoader currentThreadClassLoader = Thread.currentThread().getContextClassLoader();		if ((currentThreadClassLoader != null) && (currentThreadClassLoader != classLoader)) {			resourceUrl = currentThreadClassLoader.getResource(resourceName);			if (resourceUrl != null) {				return resourceUrl;			}		}		// try #3 - using caller classloader, similar as Class.forName()		Class callerClass = ClassUtil.getCallerClass(2);		ClassLoader callerClassLoader = callerClass.getClassLoader();		if ((callerClassLoader != classLoader) && (callerClassLoader != currentThreadClassLoader)) {			resourceUrl = callerClassLoader.getResource(resourceName);			if (resourceUrl != null) {				return resourceUrl;			}		}		return null;	}
public static InputStream getResourceAsStream(final String resourceName, final ClassLoader callingClass) throws IOException {		URL url = getResourceUrl(resourceName, callingClass);		if (url != null) {			return url.openStream();		}		return null;	}
public static InputStream getResourceAsStream(final String resourceName, final ClassLoader callingClass, final boolean useCache) throws IOException {		URL url = getResourceUrl(resourceName, callingClass);		if (url != null) {			URLConnection urlConnection = url.openConnection();			urlConnection.setUseCaches(useCache);			return urlConnection.getInputStream();		}		return null;	}
public static InputStream getClassAsStream(final Class clazz) throws IOException {		return getResourceAsStream(ClassUtil.convertClassNameToFileName(clazz), clazz.getClassLoader());	}
public static InputStream getClassAsStream(final String className, final ClassLoader classLoader) throws IOException {		return getResourceAsStream(ClassUtil.convertClassNameToFileName(className), classLoader);	}
public static Class loadClass(final String className) throws ClassNotFoundException {		return ClassLoaderStrategy.get().loadClass(className, null);	}
public static Class loadClass(final String className, final ClassLoader classLoader) throws ClassNotFoundException {		return ClassLoaderStrategy.get().loadClass(className, classLoader);	}
public RouteChunk add(final String newValue) {		RouteChunk routeChunk = new RouteChunk(routes, this, newValue);		if (children == null) {			children = new RouteChunk[] {routeChunk};		}		else {			children = ArraysUtil.append(children, routeChunk);		}		return routeChunk;	}
public RouteChunk findOrCreateChild(final String value) {		if (children != null) {			for (RouteChunk child : children) {				if (child.get().equals(value)) {					return child;				}			}		}		return add(value);	}
public boolean match(final String value) {		if (pathMacros == null) {			return this.value.equals(value);		}		return pathMacros.match(value) != -1;	}
public static MultipartRequest getInstance(final HttpServletRequest request, final FileUploadFactory fileUploadFactory, final String encoding) throws IOException {		MultipartRequest mreq = (MultipartRequest) request.getAttribute(MREQ_ATTR_NAME);		if (mreq == null) {			mreq = new MultipartRequest(request, fileUploadFactory, encoding);			request.setAttribute(MREQ_ATTR_NAME, mreq);		}		if (!mreq.isParsed()) {			mreq.parseRequest();		}		return mreq;	}
public void parseRequest() throws IOException {		if (ServletUtil.isMultipartRequest(request)) {			parseRequestStream(request.getInputStream(), characterEncoding);		} else {			Enumeration names = request.getParameterNames();			while (names.hasMoreElements()) {				String paramName = (String) names.nextElement();				String[] values = request.getParameterValues(paramName);				putParameters(paramName, values);			}		}	}
@SuppressWarnings("unchecked")	protected Object convertType(final Object value, final Class type) {		return typeConverterManager.convertType(value, type);	}
@SuppressWarnings("unchecked")	protected Object convertToCollection(final Object value, final Class destinationType, final Class componentType) {		return typeConverterManager.convertToCollection(value, destinationType, componentType);	}
protected Object invokeSetter(final Setter setter, final BeanProperty bp, Object value) {		try {			final MapperFunction setterMapperFunction = setter.getMapperFunction();			if (setterMapperFunction != null) {				value = setterMapperFunction.apply(value);			}			final Class type = setter.getSetterRawType();			if (ClassUtil.isTypeOf(type, Collection.class)) {				Class componentType = setter.getSetterRawComponentType();				value = convertToCollection(value, type, componentType);			} else {				// no collections				value = convertType(value, type);			}			setter.invokeSetter(bp.bean, value);		} catch (Exception ex) {			if (isSilent) {				return null;			}			throw new BeanException("Setter failed: " + setter, ex);		}		return value;	}
protected Object arrayForcedGet(final BeanProperty bp, Object array, final int index) {		Class componentType = array.getClass().getComponentType();		if (!bp.last) {			array = ensureArraySize(bp, array, componentType, index);		}		Object value = Array.get(array, index);		if (value == null) {			try {				//noinspection unchecked				value = ClassUtil.newInstance(componentType);			} catch (Exception ex) {				if (isSilent) {					return null;				}				throw new BeanException("Invalid array element: " + bp.name + '[' + index + ']', bp, ex);			}			Array.set(array, index, value);		}		return value;	}
protected void arrayForcedSet(final BeanProperty bp, Object array, final int index, Object value) {		Class componentType = array.getClass().getComponentType();		array = ensureArraySize(bp, array, componentType, index);		value = convertType(value, componentType);		Array.set(array, index, value);	}
protected int indexOfDot(final String name) {		int ndx = 0;		int len = name.length();		boolean insideBracket = false;		while (ndx < len) {			char c = name.charAt(ndx);			if (insideBracket) {				if (c == ']') {					insideBracket = false;				}			} else {				if (c == '.') {					return ndx;				}				if (c == '[') {					insideBracket = true;				}			}			ndx++;		}		return -1;	}
protected String extractIndex(final BeanProperty bp) {		bp.index = null;		String name = bp.name;		int lastNdx = name.length() - 1;		if (lastNdx < 0) {			return null;		}		if (name.charAt(lastNdx) == ']') {			int leftBracketNdx = name.lastIndexOf('[');			if (leftBracketNdx != -1) {				bp.setName(name.substring(0, leftBracketNdx));				bp.index = name.substring(leftBracketNdx + 1, lastNdx);				return bp.index;			}		}		return null;	}
protected Object createBeanProperty(final BeanProperty bp) {		Setter setter = bp.getSetter(true);		if (setter == null) {			return null;		}		Class type = setter.getSetterRawType();		Object newInstance;		try {			newInstance = ClassUtil.newInstance(type);		} catch (Exception ex) {			if (isSilent) {				return null;			}			throw new BeanException("Invalid property: " + bp.name, bp, ex);		}		newInstance = invokeSetter(setter, bp, newInstance);		return newInstance;	}
protected Class extractGenericComponentType(final Getter getter) {		Class componentType = null;		if (getter != null) {			componentType = getter.getGetterRawComponentType();		}		if (componentType == null) {			componentType = Object.class;		}		return componentType;	}
protected Object convertIndexToMapKey(final Getter getter, final Object index) {		Class indexType = null;		if (getter != null) {			indexType = getter.getGetterRawKeyComponentType();		}		// check if set		if (indexType == null) {			indexType = Object.class;	// marker for no generic type		}		if (indexType == Object.class) {			return index;		}		try {			return convertType(index, indexType);		} catch (Exception ignore) {			return index;		}	}
protected Class extractType(final BeanProperty bp) {		Getter getter = bp.getGetter(isDeclared);		if (getter != null) {			if (bp.index != null) {				Class type = getter.getGetterRawComponentType();				return type == null ? Object.class : type;			}			return getter.getGetterRawType();		}		return null;	// this should not happens	}
public static UserSession get(final HttpServletRequest httpServletRequest) {		final HttpSession httpSession = httpServletRequest.getSession(false);		if (httpSession == null) {			return null;		}		return (UserSession) httpSession.getAttribute(AUTH_SESSION_NAME);	}
public static void stop(final HttpServletRequest servletRequest, final HttpServletResponse servletResponse) {		final HttpSession httpSession = servletRequest.getSession(false);		if (httpSession != null) {			httpSession.removeAttribute(AUTH_SESSION_NAME);		}		final Cookie cookie = ServletUtil.getCookie(servletRequest, AUTH_COOKIE_NAME);		if (cookie == null) {			return;		}		cookie.setMaxAge(0);		cookie.setPath("/");		servletResponse.addCookie(cookie);	}
public void start(final HttpServletRequest httpServletRequest, final HttpServletResponse httpServletResponse) {		final HttpSession httpSession = httpServletRequest.getSession(true);		httpSession.setAttribute(AUTH_SESSION_NAME, this);		final Cookie cookie = new Cookie(AUTH_COOKIE_NAME, authTokenValue);		//cookie.setDomain(SSORealm.SSO_DOMAIN);		cookie.setMaxAge(cookieMaxAge);		cookie.setPath("/");		httpServletResponse.addCookie(cookie);	}
public static Date toDate(final LocalDate localDate) {		return Date.from(localDate.atStartOfDay(ZoneId.systemDefault()).toInstant());	}
public static Calendar toCalendar(final LocalDateTime localDateTime) {		return GregorianCalendar.from(ZonedDateTime.of(localDateTime, ZoneId.systemDefault()));	}
public static String formatHttpDate(final long millis) {		final Date date = new Date(millis);		return HTTP_DATE_FORMAT.format(date);	}
public static long parseHttpTime(final String time) {		if (time == null) {			return -1;		}		try {			return TimeUtil.HTTP_DATE_FORMAT.parse(time).getTime();		}		catch (ParseException e) {			return -1;		}	}
public Class defineProxy(final Class target) {		ProxyProxettaFactory builder = proxetta.proxy();		builder.setTarget(target);		return builder.define();	}
public void add(final Check check) {		String name = check.getName();		List<Check> list = map.computeIfAbsent(name, k -> new ArrayList<>());		list.add(check);	}
public static ValidationContext resolveFor(final Class<?> target) {		ValidationContext vc = new ValidationContext();		vc.addClassChecks(target);		return vc;	}
public void addClassChecks(final Class target) {		final List<Check> list = cache.get(target, () -> {			final List<Check> newList = new ArrayList<>();			final ClassDescriptor cd = ClassIntrospector.get().lookup(target);			final PropertyDescriptor[] allProperties = cd.getAllPropertyDescriptors();			for (PropertyDescriptor propertyDescriptor : allProperties) {				collectPropertyAnnotationChecks(newList, propertyDescriptor);			}			return newList;		});		addAll(list);	}
protected void collectPropertyAnnotationChecks(final List<Check> annChecks, final PropertyDescriptor propertyDescriptor) {		FieldDescriptor fd = propertyDescriptor.getFieldDescriptor();		if (fd != null) {			Annotation[] annotations = fd.getField().getAnnotations();			collectAnnotationChecks(annChecks, propertyDescriptor.getType(), propertyDescriptor.getName(), annotations);		}		MethodDescriptor md = propertyDescriptor.getReadMethodDescriptor();		if (md != null) {			Annotation[] annotations = md.getMethod().getAnnotations();			collectAnnotationChecks(annChecks, propertyDescriptor.getType(), propertyDescriptor.getName(), annotations);		}		md = propertyDescriptor.getWriteMethodDescriptor();		if (md != null) {			Annotation[] annotations = md.getMethod().getAnnotations();			collectAnnotationChecks(annChecks, propertyDescriptor.getType(), propertyDescriptor.getName(), annotations);		}	}
@SuppressWarnings({"unchecked"})	protected void collectAnnotationChecks(final List<Check> annChecks, final Class targetType, final String targetName, final Annotation[] annotations) {		for (Annotation annotation : annotations) {			Constraint c = annotation.annotationType().getAnnotation(Constraint.class);			Class<? extends ValidationConstraint> constraintClass;			if (c == null) {				// if constraint is not available, try lookup				String constraintClassName = annotation.annotationType().getName() + "Constraint";				try {					constraintClass = ClassLoaderUtil.loadClass(constraintClassName, this.getClass().getClassLoader());				}				catch (ClassNotFoundException ingore) {					continue;				}			}			else {				constraintClass = c.value();			}			ValidationConstraint vc;			try {				vc = newConstraint(constraintClass, targetType);			} catch (Exception ex) {				throw new VtorException("Invalid constraint: " + constraintClass.getClass().getName(), ex);			}			vc.configure(annotation);			Check check = new Check(targetName, vc);			copyDefaultCheckProperties(check, annotation);			annChecks.add(check);		}	}
protected <V extends ValidationConstraint> V newConstraint(final Class<V> constraint, final Class targetType) throws Exception {		Constructor<V> ctor;		try {			ctor = constraint.getConstructor();			return ctor.newInstance();		} catch (NoSuchMethodException ignore) {			ctor = constraint.getConstructor(ValidationContext.class);			return ctor.newInstance(resolveFor(targetType));		}	}
protected void copyDefaultCheckProperties(final Check destCheck, final Annotation annotation) {		Integer severity = (Integer) ClassUtil.readAnnotationValue(annotation, ANN_SEVERITY);		destCheck.setSeverity(severity.intValue());		String[] profiles = (String[]) ClassUtil.readAnnotationValue(annotation, ANN_PROFILES);		destCheck.setProfiles(profiles);		String message = (String) ClassUtil.readAnnotationValue(annotation, ANN_MESSAGE);		destCheck.setMessage(message);	}
public static <T> CompletableFuture<T> failAfter(final long duration) {		final CompletableFuture<T> promise = new CompletableFuture<>();		SCHEDULER.schedule(() -> {			final TimeoutException ex = new TimeoutException("Timeout after " + duration);			return promise.completeExceptionally(ex);		}, duration, MILLISECONDS);		return promise;	}
@Override	public Array get(final ResultSet rs, final int index, final int dbSqlType) throws SQLException {		return rs.getArray(index);	}
@Override	public void set(final PreparedStatement st, final int index, final Array value, final int dbSqlType) throws SQLException {		st.setArray(index, value);	}
private static String encodeUriComponent(final String source, final String encoding, final URIPart uriPart) {		if (source == null) {			return null;		}		byte[] bytes = encodeBytes(StringUtil.getBytes(source, encoding), uriPart);		char[] chars = new char[bytes.length];		for (int i = 0; i < bytes.length; i++) {			chars[i] = (char) bytes[i];		}		return new String(chars);	}
private static byte[] encodeBytes(final byte[] source, final URIPart uriPart) {		ByteArrayOutputStream bos = new ByteArrayOutputStream(source.length);		for (byte b : source) {			if (b < 0) {				b += 256;			}			if (uriPart.isValid((char) b)) {				bos.write(b);			} else {				bos.write('%');				char hex1 = Character.toUpperCase(Character.forDigit((b >> 4) & 0xF, 16));				char hex2 = Character.toUpperCase(Character.forDigit(b & 0xF, 16));				bos.write(hex1);				bos.write(hex2);			}		}		return bos.toByteArray();	}
public static String encode(final String string, final String encoding) {		return encodeUriComponent(string, encoding, URIPart.UNRESERVED);	}
public static String encodeScheme(final String scheme, final String encoding) {		return encodeUriComponent(scheme, encoding, URIPart.SCHEME);	}
public static String encodeHost(final String host, final String encoding) {		return encodeUriComponent(host, encoding, URIPart.HOST);	}
public static String encodePort(final String port, final String encoding) {		return encodeUriComponent(port, encoding, URIPart.PORT);	}
public static String encodePath(final String path, final String encoding) {		return encodeUriComponent(path, encoding, URIPart.PATH);	}
public static String encodeQuery(final String query, final String encoding) {		return encodeUriComponent(query, encoding, URIPart.QUERY);	}
public static String encodeQueryParam(final String queryParam, final String encoding) {		return encodeUriComponent(queryParam, encoding, URIPart.QUERY_PARAM);	}
public static String encodeFragment(final String fragment, final String encoding) {		return encodeUriComponent(fragment, encoding, URIPart.FRAGMENT);	}
public static String encodeUri(final String uri, final String encoding) {		Matcher m = URI_PATTERN.matcher(uri);		if (m.matches()) {			String scheme = m.group(2);			String authority = m.group(3);			String userinfo = m.group(5);			String host = m.group(6);			String port = m.group(8);			String path = m.group(9);			String query = m.group(11);			String fragment = m.group(13);			return encodeUriComponents(scheme, authority, userinfo, host, port, path, query, fragment, encoding);		}		throw new IllegalArgumentException("Invalid URI: " + uri);	}
public static String encodeHttpUrl(final String httpUrl, final String encoding) {		Matcher m = HTTP_URL_PATTERN.matcher(httpUrl);		if (m.matches()) {			String scheme = m.group(1);			String authority = m.group(2);			String userinfo = m.group(4);			String host = m.group(5);			String portString = m.group(7);			String path = m.group(8);			String query = m.group(10);			return encodeUriComponents(scheme, authority, userinfo, host, portString, path, query, null, encoding);		}		throw new IllegalArgumentException("Invalid HTTP URL: " + httpUrl);	}
public static Builder build(final String path, final boolean encodePath) {		return new Builder(path, encodePath, JoddCore.encoding);	}
protected HashMap<String, PropertyDescriptor> inspectProperties() {		boolean scanAccessible = classDescriptor.isScanAccessible();		Class type = classDescriptor.getType();		HashMap<String, PropertyDescriptor> map = new HashMap<>();		Method[] methods = scanAccessible ? ClassUtil.getAccessibleMethods(type) : ClassUtil.getSupportedMethods(type);		for (int iteration = 0; iteration < 2; iteration++) {			// first find the getters, and then the setters!			for (Method method : methods) {				if (Modifier.isStatic(method.getModifiers())) {					continue;            // ignore static methods				}				boolean add = false;				boolean issetter = false;				String propertyName;				if (iteration == 0) {					propertyName = ClassUtil.getBeanPropertyGetterName(method);					if (propertyName != null) {						add = true;						issetter = false;					}				} else {					propertyName = ClassUtil.getBeanPropertySetterName(method);					if (propertyName != null) {						add = true;						issetter = true;					}				}				if (add) {					MethodDescriptor methodDescriptor = classDescriptor.getMethodDescriptor(method.getName(), method.getParameterTypes(), true);					addProperty(map, propertyName, methodDescriptor, issetter);				}			}		}		if (classDescriptor.isIncludeFieldsAsProperties()) {			FieldDescriptor[] fieldDescriptors = classDescriptor.getAllFieldDescriptors();			String[] prefix = classDescriptor.getPropertyFieldPrefix();			for (FieldDescriptor fieldDescriptor : fieldDescriptors) {				Field field = fieldDescriptor.getField();				if (Modifier.isStatic(field.getModifiers())) {					continue;            // ignore static fields				}				String name = field.getName();				if (prefix != null) {					for (String p : prefix) {						if (!name.startsWith(p)) {							continue;						}						name = name.substring(p.length());						break;					}				}				if (!map.containsKey(name)) {					// add missing field as a potential property					map.put(name, createPropertyDescriptor(name, fieldDescriptor));				}			}		}		return map;	}
protected void addProperty(final HashMap<String, PropertyDescriptor> map, final String name, final MethodDescriptor methodDescriptor, final boolean isSetter) {		MethodDescriptor setterMethod = isSetter ? methodDescriptor : null;		MethodDescriptor getterMethod = isSetter ? null : methodDescriptor;		PropertyDescriptor existing = map.get(name);		if (existing == null) {			// new property, just add it			PropertyDescriptor propertyDescriptor = createPropertyDescriptor(name, getterMethod, setterMethod);			map.put(name, propertyDescriptor);			return;		}		// property exist		if (!isSetter) {			// use existing setter			setterMethod = existing.getWriteMethodDescriptor();			// check existing			MethodDescriptor existingMethodDescriptor = existing.getReadMethodDescriptor();			if (existingMethodDescriptor != null) {				// check for special case of double get/is				// getter with the same name already exist				String methodName = methodDescriptor.getMethod().getName();				String existingMethodName = existingMethodDescriptor.getMethod().getName();				if (						existingMethodName.startsWith(METHOD_IS_PREFIX) &&						methodName.startsWith(METHOD_GET_PREFIX)) {					// ignore getter when ister exist					return;				}			}		} else {			// setter			// use existing getter			getterMethod = existing.getReadMethodDescriptor();			if (getterMethod != null) {				Class returnType = getterMethod.getMethod().getReturnType();				if (setterMethod != null) {					Class parameterType = setterMethod.getMethod().getParameterTypes()[0];					if (returnType != parameterType) {						// getter's type is different then setter's						return;					}				}			}		}		PropertyDescriptor propertyDescriptor = createPropertyDescriptor(name, getterMethod, setterMethod);		map.put(name, propertyDescriptor);	}
protected PropertyDescriptor createPropertyDescriptor(final String name, final MethodDescriptor getterMethod, final MethodDescriptor setterMethod) {		return new PropertyDescriptor(classDescriptor, name, getterMethod, setterMethod);	}
protected PropertyDescriptor createPropertyDescriptor(final String name, final FieldDescriptor fieldDescriptor) {			return new PropertyDescriptor(classDescriptor, name, fieldDescriptor);	}
public PropertyDescriptor[] getAllPropertyDescriptors() {		if (allProperties == null) {			PropertyDescriptor[] allProperties = new PropertyDescriptor[propertyDescriptors.size()];			int index = 0;			for (PropertyDescriptor propertyDescriptor : propertyDescriptors.values()) {				allProperties[index] = propertyDescriptor;				index++;			}			Arrays.sort(allProperties, new Comparator<PropertyDescriptor>() {				@Override				public int compare(final PropertyDescriptor pd1, final PropertyDescriptor pd2) {					return pd1.getName().compareTo(pd2.getName());				}			});			this.allProperties = allProperties;		}		return allProperties;	}
public String location() {		String location = header("location");		if (location == null) {			return null;		}		if (location.startsWith(StringPool.SLASH)) {			location = getHttpRequest().hostUrl() + location;		}		return location;	}
public Cookie[] cookies() {		List<String> newCookies = headers("set-cookie");		if (newCookies == null) {			return new Cookie[0];		}		List<Cookie> cookieList = new ArrayList<>(newCookies.size());		for (String cookieValue : newCookies) {			try {				Cookie cookie = new Cookie(cookieValue);				cookieList.add(cookie);			}			catch (Exception ex) {				// ignore			}		}		return cookieList.toArray(new Cookie[0]);	}
public HttpResponse unzip() {		String contentEncoding = contentEncoding();		if (contentEncoding != null && contentEncoding().equals("gzip")) {			if (body != null) {				headerRemove(HEADER_CONTENT_ENCODING);				try {					ByteArrayInputStream in = new ByteArrayInputStream(body.getBytes(StringPool.ISO_8859_1));					GZIPInputStream gzipInputStream = new GZIPInputStream(in);					ByteArrayOutputStream out = new ByteArrayOutputStream();					StreamUtil.copy(gzipInputStream, out);					body(out.toString(StringPool.ISO_8859_1));				} catch (IOException ioex) {					throw new HttpException(ioex);				}			}		}		return this;	}
@Override	protected Buffer buffer(final boolean fullResponse) {		// form		Buffer formBuffer = formBuffer();		// response		Buffer response = new Buffer();		response.append(httpVersion)			.append(SPACE)			.append(statusCode)			.append(SPACE)			.append(statusPhrase)			.append(CRLF);		populateHeaderAndBody(response, formBuffer, fullResponse);		return response;	}
public static HttpResponse readFrom(final InputStream in) {		InputStreamReader inputStreamReader;		try {			inputStreamReader = new InputStreamReader(in, StringPool.ISO_8859_1);		} catch (UnsupportedEncodingException unee) {			throw new HttpException(unee);		}		BufferedReader reader = new BufferedReader(inputStreamReader);		HttpResponse httpResponse = new HttpResponse();		// the first line		String line;		try {			line = reader.readLine();		} catch (IOException ioex) {			throw new HttpException(ioex);		}		if (line != null) {			line = line.trim();			int ndx = line.indexOf(' ');			int ndx2;			if (ndx > -1) {				httpResponse.httpVersion(line.substring(0, ndx));				ndx2 = line.indexOf(' ', ndx + 1);			}			else {				httpResponse.httpVersion(HTTP_1_1);				ndx2 = -1;				ndx = 0;			}			if (ndx2 == -1) {				ndx2 = line.length();			}			try {				httpResponse.statusCode(Integer.parseInt(line.substring(ndx, ndx2).trim()));			}			catch (NumberFormatException nfex) {				httpResponse.statusCode(-1);			}			httpResponse.statusPhrase(line.substring(ndx2).trim());		}		httpResponse.readHeaders(reader);		httpResponse.readBody(reader);		return httpResponse;	}
public HttpResponse close() {		HttpConnection httpConnection = httpRequest.httpConnection;		if (httpConnection != null) {			httpConnection.close();			httpRequest.httpConnection = null;		}		return this;	}
@Override	public boolean accept(final Scope referenceScope) {		Class<? extends Scope> refScopeType = referenceScope.getClass();		if (refScopeType == ProtoScope.class) {			return true;		}		if (refScopeType == SingletonScope.class) {			return true;		}		if (refScopeType == ThreadLocalScope.class) {			return true;		}		return false;	}
@Override	public void start() {		initLogger();		log.info("MADVOC start  ----------");		webApp = webAppSupplier == null ? new PetiteWebApp(joyPetiteSupplier.get().getPetiteContainer()) : webAppSupplier.get();		webApp.withRegisteredComponent(ActionConfigManager.class, acm -> {			acm.bindAnnotationConfig(Action.class, JoyActionConfig.class);			acm.bindAnnotationConfig(RestAction.class, JoyRestActionConfig.class);		});		if (servletContext != null) {			webApp.bindServletContext(servletContext);		}		final Props allProps = joyPropsSupplier.get().getProps();		webApp.withParams(allProps.innerMap(beanNamePrefix()));		webApp.registerComponent(new ProxettaSupplier(joyProxettaSupplier.get().getProxetta()));		webApp.registerComponent(ProxettaAwareActionsManager.class);		// Automagic Madvoc configurator will scan and register ALL!		// This way we reduce the startup time and have only one scanning.		// Scanning happens in the INIT phase.		final AutomagicMadvocConfigurator automagicMadvocConfigurator =			new AutomagicMadvocConfigurator(joyScannerSupplier.get().getClassScanner()) {				@Override				protected String createInfoMessage() {					return "Scanning completed in " + elapsed + "ms.";				}			};		webApp.registerComponent(automagicMadvocConfigurator);		webAppConsumers.accept(webApp);		webApp.start();		log.info("MADVOC OK!");	}
protected void printRoutes(final int width) {		final ActionsManager actionsManager = webApp.madvocContainer().lookupComponent(ActionsManager.class);		final List<ActionRuntime> actions = actionsManager.getAllActionRuntimes();		final Map<String, String> aliases = actionsManager.getAllAliases();		if (actions.isEmpty()) {			return;		}		final Print print = new Print();		print.line("Routes", width);		actions.stream()			.sorted(Comparator.comparing(				actionRuntime -> actionRuntime.getActionPath() + ' ' + actionRuntime.getActionMethod()))			.forEach(ar -> {				final String actionMethod = ar.getActionMethod();				print.out(Chalk256.chalk().yellow(), actionMethod == null ? "*" : actionMethod, 7);				print.space();				final String signature =					ClassUtil.getShortClassName(						ProxettaUtil.resolveTargetClass(ar.getActionClass()), 2)						+ '#' + ar.getActionClassMethod().getName();				print.outLeftRightNewLine(					Chalk256.chalk().green(), ar.getActionPath(),					Chalk256.chalk().blue(), signature,					width - 7 - 1				);			});		if (!aliases.isEmpty()) {			print.line("Aliases", width);			actions.stream()				.sorted(Comparator.comparing(					actionRuntime -> actionRuntime.getActionPath() + ' ' + actionRuntime.getActionMethod()))				.forEach(ar -> {					final String actionPath = ar.getActionPath();					for (final Map.Entry<String, String> entry : aliases.entrySet()) {						if (entry.getValue().equals(actionPath)) {							print.space(8);							print.outLeftRightNewLine(								Chalk256.chalk().green(), entry.getValue(),								Chalk256.chalk().blue(), entry.getKey(),								width - 8							);						}					}				});		}		print.line(width);	}
public byte[] encrypt(final byte[] content) {		FastByteBuffer fbb = new FastByteBuffer();		int length = content.length + 1;		int blockCount = length / blockSizeInBytes;		int remaining = length;		int offset = 0;		for (int i = 0; i < blockCount; i++) {			if (remaining == blockSizeInBytes) {				break;			}			byte[] encrypted = encryptBlock(content, offset);			fbb.append(encrypted);			offset += blockSizeInBytes;			remaining -= blockSizeInBytes;		}		if (remaining != 0) {			// process remaining bytes			byte[] block = new byte[blockSizeInBytes];			System.arraycopy(content, offset, block, 0, remaining - 1);			block[remaining - 1] = TERMINATOR;			byte[] encrypted = encryptBlock(block, 0);			fbb.append(encrypted);		}		return fbb.toArray();	}
public byte[] decrypt(final byte[] encryptedContent) {		FastByteBuffer fbb = new FastByteBuffer();		int length = encryptedContent.length;		int blockCount = length / blockSizeInBytes;		int offset = 0;		for (int i = 0; i < blockCount - 1; i++) {			byte[] decrypted = decryptBlock(encryptedContent, offset);			fbb.append(decrypted);			offset += blockSizeInBytes;		}		// process last block		byte[] decrypted = decryptBlock(encryptedContent, offset);		// find terminator		int ndx = blockSizeInBytes - 1;		while (ndx >= 0) {			if (decrypted[ndx] == TERMINATOR) {				break;			}			ndx--;		}		fbb.append(decrypted, 0, ndx);		return fbb.toArray();	}
public Object map2bean(final Map map, Class targetType) {		Object target = null;		// create targets type		String className = (String) map.get(classMetadataName);		if (className == null) {			if (targetType == null) {				// nothing to do, no information about target type found				target = map;			}		}		else {			checkClassName(jsonParser.classnameWhitelist, className);			try {				targetType = ClassLoaderUtil.loadClass(className);			} catch (ClassNotFoundException cnfex) {				throw new JsonException(cnfex);			}		}		if (target == null) {			target = jsonParser.newObjectInstance(targetType);		}		ClassDescriptor cd = ClassIntrospector.get().lookup(target.getClass());		boolean targetIsMap = target instanceof Map;		for (Object key : map.keySet()) {			String keyName = key.toString();			if (classMetadataName != null) {				if (keyName.equals(classMetadataName)) {					continue;				}			}			PropertyDescriptor pd = cd.getPropertyDescriptor(keyName, declared);			if (!targetIsMap && pd == null) {				// target property does not exist, continue				continue;			}			// value is one of JSON basic types, like Number, Map, List...			Object value = map.get(key);			Class propertyType = pd == null ? null : pd.getType();			Class componentType = pd == null ? null : pd.resolveComponentType(true);			if (value != null) {				if (value instanceof List) {					if (componentType != null && componentType != String.class) {						value = generifyList((List) value, componentType);					}				}				else if (value instanceof Map) {					// if the value we want to inject is a Map...					if (!ClassUtil.isTypeOf(propertyType, Map.class)) {						// ... and if target is NOT a map						value = map2bean((Map) value, propertyType);					}					else {						// target is also a Map, but we might need to generify it						Class keyType = pd == null ? null : pd.resolveKeyType(true);						if (keyType != String.class || componentType != String.class) {							// generify							value = generifyMap((Map) value, keyType, componentType);						}					}				}			}			if (targetIsMap) {				((Map)target).put(keyName, value);			}			else {				try {					setValue(target, pd, value);				} catch (Exception ignore) {					ignore.printStackTrace();				}			}		}		return target;	}
private Object generifyList(final List list, final Class componentType) {		for (int i = 0; i < list.size(); i++) {			Object element = list.get(i);			if (element != null) {				if (element instanceof Map) {					Object bean = map2bean((Map) element, componentType);					list.set(i, bean);				} else {					Object value = convert(element, componentType);					list.set(i, value);				}			}		}		return list;	}
private void setValue(final Object target, final PropertyDescriptor pd, Object value) throws InvocationTargetException, IllegalAccessException {		Class propertyType;		Setter setter = pd.getSetter(true);		if (setter != null) {			if (value != null) {				propertyType = setter.getSetterRawType();				value = jsonParser.convertType(value, propertyType);			}			setter.invokeSetter(target, value);		}	}
protected <K,V> Map<K, V> generifyMap(final Map<Object, Object> map, final Class<K> keyType, final Class<V> valueType) {		if (keyType == String.class) {			// only value type is changed, we can make value replacements			for (Map.Entry<Object, Object> entry : map.entrySet()) {				Object value = entry.getValue();				Object newValue = convert(value, valueType);				if (value != newValue) {					entry.setValue(newValue);				}			}			return (Map<K, V>) map;		}		// key is changed too, we need a new map		Map<K, V> newMap = new HashMap<>(map.size());		for (Map.Entry<Object, Object> entry : map.entrySet()) {			Object key = entry.getKey();			Object newKey = convert(key, keyType);			Object value = entry.getValue();			Object newValue = convert(value, valueType);			newMap.put((K)newKey, (V)newValue);		}		return newMap;	}
public Object execute() {		methodName = targetMethodName();		Class returnType = returnType();		if (returnType == String.class) {			return ProxyTarget.returnValue(targetMethodName());		}		return ProxyTarget.returnValue(null);	}
protected short[] convertValueToArray(final Object value) {		if (value instanceof Collection) {			final Collection collection = (Collection) value;			final short[] target = new short[collection.size()];			int i = 0;			for (final Object element : collection) {				target[i] = convertType(element);				i++;			}			return target;		}		if (value instanceof Iterable) {			final Iterable iterable = (Iterable) value;			final ArrayList<Short> shortArrayList = new ArrayList<>();			for (final Object element : iterable) {				final short convertedValue = convertType(element);				shortArrayList.add(Short.valueOf(convertedValue));			}			final short[] array = new short[shortArrayList.size()];			for (int i = 0; i < shortArrayList.size(); i++) {				final Short s = shortArrayList.get(i);				array[i] = s.shortValue();			}			return array;		}		if (value instanceof CharSequence) {			final String[] strings = StringUtil.splitc(value.toString(), ArrayConverter.NUMBER_DELIMITERS);			return convertArrayToArray(strings);		}		// everything else:		return convertToSingleElementArray(value);	}
@Override	public int compareTo(final Object o) {		DbEntityColumnDescriptor that = (DbEntityColumnDescriptor) o;		if (this.isId != that.isId) {			return this.isId ? -1 : 1;      // IDs should be the first in the array		}		return this.columnName.compareTo(that.columnName);	}
public HttpBrowser setDefaultHeader(final String name, final String value) {		defaultHeaders.addHeader(name, value);		return this;	}
public HttpResponse sendRequest(HttpRequest httpRequest) {		elapsedTime = System.currentTimeMillis();		// send request		httpRequest.followRedirects(false);		while (true) {			this.httpRequest = httpRequest;			HttpResponse previousResponse = this.httpResponse;			this.httpResponse = null;			addDefaultHeaders(httpRequest);			addCookies(httpRequest);			// send request			if (catchTransportExceptions) {				try {					this.httpResponse = _sendRequest(httpRequest, previousResponse);				}				catch (HttpException httpException) {					httpResponse = new HttpResponse();					httpResponse.assignHttpRequest(httpRequest);					httpResponse.statusCode(503);					httpResponse.statusPhrase("Service unavailable. " + ExceptionUtil.message(httpException));				}			}			else {				this.httpResponse =_sendRequest(httpRequest, previousResponse);			}			readCookies(httpResponse);			int statusCode = httpResponse.statusCode();			// 301: moved permanently			if (statusCode == 301) {				String newPath = httpResponse.location();				if (newPath == null) {					break;				}				httpRequest = HttpRequest.get(newPath);				continue;			}			// 302: redirect, 303: see other			if (statusCode == 302 || statusCode == 303) {				String newPath = httpResponse.location();				if (newPath == null) {					break;				}				httpRequest = HttpRequest.get(newPath);				continue;			}			// 307: temporary redirect, 308: permanent redirect			if (statusCode == 307 || statusCode == 308) {				String newPath = httpResponse.location();				if (newPath == null) {					break;				}				String originalMethod = httpRequest.method();				httpRequest = new HttpRequest()						.method(originalMethod)						.set(newPath);				continue;			}			break;		}		elapsedTime = System.currentTimeMillis() - elapsedTime;		return this.httpResponse;	}
protected HttpResponse _sendRequest(final HttpRequest httpRequest, final HttpResponse previouseResponse) {		if (!keepAlive) {			httpRequest.open(httpConnectionProvider);		} else {			// keeping alive			if (previouseResponse == null) {				httpRequest.open(httpConnectionProvider).connectionKeepAlive(true);			} else {				httpRequest.keepAlive(previouseResponse, true);			}		}		return httpRequest.send();	}
protected void addDefaultHeaders(final HttpRequest httpRequest) {		for (Map.Entry<String, String> entry : defaultHeaders.entries()) {			String name = entry.getKey();			if (!httpRequest.headers.contains(name)) {				httpRequest.headers.add(name, entry.getValue());			}		}	}
protected void readCookies(final HttpResponse httpResponse) {		Cookie[] newCookies = httpResponse.cookies();		for (Cookie cookie : newCookies) {			cookies.add(cookie.getName(), cookie);		}	}
protected void addCookies(final HttpRequest httpRequest) {		// prepare all cookies		List<Cookie> cookiesList = new ArrayList<>();		if (!cookies.isEmpty()) {			for (Map.Entry<String, Cookie> cookieEntry : cookies) {				cookiesList.add(cookieEntry.getValue());			}			httpRequest.cookies(cookiesList.toArray(new Cookie[0]));		}	}
public String sendMail(final Email email) {		try {			final MimeMessage msg = createMessage(email);			getService().sendMessage(msg, msg.getAllRecipients());			return msg.getMessageID();		} catch (final MessagingException msgexc) {			throw new MailException("Failed to send email: " + email, msgexc);		}	}
protected MimeMessage createMessage(final Email email) throws MessagingException {		final Email clone = email.clone();		final MimeMessage newMsg = new MimeMessage(getSession());		setPeople(clone, newMsg);		setSubject(clone, newMsg);		setSentDate(clone, newMsg);		setHeaders(clone, newMsg);		addBodyData(clone, newMsg);		return newMsg;	}
private void setSubject(final Email emailWithData, final MimeMessage msgToSet) throws MessagingException {		if (emailWithData.subjectEncoding() != null) {			msgToSet.setSubject(emailWithData.subject(), emailWithData.subjectEncoding());		} else {			msgToSet.setSubject(emailWithData.subject());		}	}
private void setSentDate(final Email emailWithData, final MimeMessage msgToSet) throws MessagingException {		Date date = emailWithData.sentDate();		if (date == null) {			date = new Date();		}		msgToSet.setSentDate(date);	}
private void setHeaders(final Email emailWithData, final MimeMessage msgToSet) throws MessagingException {		final Map<String, String> headers = emailWithData.headers();		if (headers != null) {			for (final Map.Entry<String, String> entry : headers.entrySet()) {				msgToSet.setHeader(entry.getKey(), entry.getValue());			}		}	}
private void setPeople(final Email emailWithData, final MimeMessage msgToSet) throws MessagingException {		msgToSet.setFrom(emailWithData.from().toInternetAddress());		msgToSet.setReplyTo(EmailAddress.convert(emailWithData.replyTo()));		setRecipients(emailWithData, msgToSet);	}
private void setRecipients(final Email emailWithData, final MimeMessage msgToSet) throws MessagingException {		// TO		final InternetAddress[] to = EmailAddress.convert(emailWithData.to());		if (to.length > 0) {			msgToSet.setRecipients(RecipientType.TO, to);		}		// CC		final InternetAddress[] cc = EmailAddress.convert(emailWithData.cc());		if (cc.length > 0) {			msgToSet.setRecipients(RecipientType.CC, cc);		}		// BCC		final InternetAddress[] bcc = EmailAddress.convert(emailWithData.bcc());		if (bcc.length > 0) {			msgToSet.setRecipients(RecipientType.BCC, bcc);		}	}
private void addBodyData(final Email emailWithData, final MimeMessage msgToSet) throws MessagingException {		final List<EmailMessage> messages = emailWithData.messages();		final int totalMessages = messages.size();		// Need to use new list since filterEmbeddedAttachments(List) removes attachments from the source List		final List<EmailAttachment<? extends DataSource>> attachments = new ArrayList<>(emailWithData.attachments());		if (attachments.isEmpty() && totalMessages == 1) {			// special case: no attachments and just one content			setContent(messages.get(0), msgToSet);		} else {			final MimeMultipart multipart = new MimeMultipart();			final MimeMultipart msgMultipart = new MimeMultipart(ALTERNATIVE);			multipart.addBodyPart(getBaseBodyPart(msgMultipart));			for (final EmailMessage emailMessage : messages) {				msgMultipart.addBodyPart(getBodyPart(emailMessage, attachments));			}			addAnyAttachments(attachments, multipart);			msgToSet.setContent(multipart);		}	}
private MimeBodyPart getBaseBodyPart(final MimeMultipart msgMultipart) throws MessagingException {		final MimeBodyPart bodyPart = new MimeBodyPart();		bodyPart.setContent(msgMultipart);		return bodyPart;	}
private void setContent(final EmailMessage emailWithData, final Part partToSet) throws MessagingException {		partToSet.setContent(emailWithData.getContent(), emailWithData.getMimeType() + CHARSET + emailWithData.getEncoding());	}
protected MimeBodyPart createAttachmentBodyPart(final EmailAttachment<? extends DataSource> attachment) throws MessagingException {		final MimeBodyPart part = new MimeBodyPart();		final String attachmentName = attachment.getEncodedName();		if (attachmentName != null) {			part.setFileName(attachmentName);		}		part.setDataHandler(new DataHandler(attachment.getDataSource()));		if (attachment.getContentId() != null) {			part.setContentID(StringPool.LEFT_CHEV + attachment.getContentId() + StringPool.RIGHT_CHEV);		}		if (attachment.isInline()) {			part.setDisposition(INLINE);		}		return part;	}
protected List<EmailAttachment<? extends DataSource>> filterEmbeddedAttachments(final List<EmailAttachment<? extends DataSource>> attachments, final EmailMessage emailMessage) {		final List<EmailAttachment<? extends DataSource>> embeddedAttachments = new ArrayList<>();		if (attachments == null || attachments.isEmpty() || emailMessage == null) {			return embeddedAttachments;		}		final Iterator<EmailAttachment<? extends DataSource>> iterator = attachments.iterator();		while (iterator.hasNext()) {			final EmailAttachment<? extends DataSource> emailAttachment = iterator.next();			if (emailAttachment.isEmbeddedInto(emailMessage)) {				embeddedAttachments.add(emailAttachment);				iterator.remove();			}		}		return embeddedAttachments;	}
private void addAnyAttachments(final List<EmailAttachment<? extends DataSource>> attachments, final MimeMultipart multipart) throws MessagingException {		for (final EmailAttachment<? extends DataSource> attachment : attachments) {			final MimeBodyPart bodyPart = createAttachmentBodyPart(attachment);			multipart.addBodyPart(bodyPart);		}	}
@Override	public int compareTo(final MutableInteger other) {		return value < other.value ? -1 : (value == other.value ? 0 : 1);	}
private String getDataFieldValue(final String dataHeader, final String fieldName) {		String value = null;		String token = String.valueOf((new StringBuffer(String.valueOf(fieldName))).append('=').append('"'));		int pos = dataHeader.indexOf(token);		if (pos > 0) {			int start = pos + token.length();			int end = dataHeader.indexOf('"', start);			if ((start > 0) && (end > 0)) {				value = dataHeader.substring(start, end);			}		}		return value;	}
private String getContentType(final String dataHeader) {		String token = "Content-Type:";		int start = dataHeader.indexOf(token);		if (start == -1) {			return StringPool.EMPTY;		}		start += token.length();		return dataHeader.substring(start).trim();	}
protected void saveResultSet(final ResultSet rs) {		if (resultSets == null) {			resultSets = new HashSet<>();		}		resultSets.add(rs);	}
protected void initSession(final DbSession session) {		if (session != null) {			this.session = session;			return;		}		final DbSessionProvider dbSessionProvider = dbOom.sessionProvider();		this.session = dbSessionProvider.getDbSession();	}
@SuppressWarnings("MagicConstant")	protected void initializeJdbc() {		// connection		if (connection == null) {			initSession(session);			connection = session.getConnection();		}		this.query = new DbQueryParser(sqlString);		// callable statement		if (query.callable) {			try {				if (debug) {					if (holdability != QueryHoldability.DEFAULT) {						callableStatement = new LoggableCallableStatement(							connection.prepareCall(query.sql, type.value(), concurrencyType.value(), holdability.value()),							query.sql						);					} else {						callableStatement = new LoggableCallableStatement(							connection.prepareCall(query.sql, type.value(), concurrencyType.value()),							query.sql						);					}				}				else {					if (holdability != QueryHoldability.DEFAULT) {						callableStatement = connection.prepareCall(							query.sql, type.value(), concurrencyType.value(), holdability.value());					} else {						callableStatement = connection.prepareCall(							query.sql, type.value(), concurrencyType.value());					}				}			}			catch (SQLException sex) {				throw new DbSqlException(this, "Error creating callable statement", sex);			}			preparedStatement = callableStatement;			statement = callableStatement;			return;		}		// prepared statement		if (query.prepared || forcePreparedStatement) {			try {				if (debug) {					if (generatedColumns != null) {						if (generatedColumns.length == 0) {							preparedStatement = new LoggablePreparedStatement(								connection.prepareStatement(query.sql, Statement.RETURN_GENERATED_KEYS),								query.sql);						} else {							preparedStatement = new LoggablePreparedStatement(								connection.prepareStatement(query.sql, generatedColumns),								query.sql);						}					} else {						if (holdability != QueryHoldability.DEFAULT) {							preparedStatement = new LoggablePreparedStatement(								connection.prepareStatement(query.sql, type.value(), concurrencyType.value(), holdability.value()),								query.sql);						} else {							preparedStatement = new LoggablePreparedStatement(								connection.prepareStatement(query.sql, type.value(), concurrencyType.value()),								query.sql);						}					}				} else {					if (generatedColumns != null) {						if (generatedColumns.length == 0) {							preparedStatement = connection.prepareStatement(query.sql, Statement.RETURN_GENERATED_KEYS);						} else {							preparedStatement = connection.prepareStatement(query.sql, generatedColumns);						}					} else {						if (holdability != QueryHoldability.DEFAULT) {							preparedStatement = connection.prepareStatement(								query.sql, type.value(), concurrencyType.value(), holdability.value());						} else {							preparedStatement = connection.prepareStatement(								query.sql, type.value(), concurrencyType.value());						}					}				}			}			catch (SQLException sex) {				throw new DbSqlException(this, "Error creating prepared statement", sex);			}			statement = preparedStatement;			return;		}		// statement		try {			if (holdability != QueryHoldability.DEFAULT) {				statement = connection.createStatement(type.value(), concurrencyType.value(), holdability.value());			} else {				statement = connection.createStatement(type.value(), concurrencyType.value());			}		} catch (SQLException sex) {			throw new DbSqlException(this, "Error creating statement", sex);		}	}
private SQLException closeQueryResultSets() {		SQLException sqlException = null;		if (resultSets != null) {			for (final ResultSet rs : resultSets) {				try {					rs.close();				} catch (SQLException sex) {					if (sqlException == null) {						sqlException = sex;					} else {						sqlException.setNextException(sex);					}				} finally {					totalOpenResultSetCount--;				}			}			resultSets.clear();			resultSets = null;		}		return sqlException;	}
public Q closeAllResultSets() {		final SQLException sex = closeQueryResultSets();		if (sex != null) {			throw new DbSqlException("Close associated ResultSets error", sex);		}		return _this();	}
protected SQLException closeQuery() {		SQLException sqlException = closeQueryResultSets();		if (statement != null) {			try {				statement.close();			} catch (SQLException sex) {				if (sqlException == null) {					sqlException = sex;				} else {					sqlException.setNextException(sex);				}			}			statement = null;		}		query = null;		queryState = CLOSED;		return sqlException;	}
@Override	@SuppressWarnings({"ClassReferencesSubclass"})	public void close() {		final SQLException sqlException = closeQuery();		connection = null;		if (this.session != null) {			this.session.detachQuery(this);		}		if (sqlException != null) {			throw new DbSqlException("Close query error", sqlException);		}	}
public void closeResultSet(final ResultSet rs) {		if (rs == null) {			return;		}		if (!resultSets.remove(rs)) {			throw new DbSqlException(this, "ResultSet is not created by this query");		}		try {			rs.close();		} catch (SQLException sex) {			throw new DbSqlException(this, "Close result set error", sex);		} finally {			totalOpenResultSetCount--;		}	}
public Q setFetchSize(final int rows) {		checkNotClosed();		this.fetchSize = rows;		if (statement != null) {			try {				statement.setFetchSize(fetchSize);			} catch (SQLException sex) {				throw new DbSqlException(this, "Unable to set fetch size: " + fetchSize, sex);			}		}		return _this();	}
public Q setMaxRows(final int maxRows) {		checkNotClosed();		this.maxRows = maxRows;		if (statement != null) {			try {				statement.setMaxRows(maxRows);			} catch (SQLException sex) {				throw new DbSqlException(this, "Unable to set max rows: " + maxRows, sex);			}		}		return _this();	}
public ResultSet execute() {		start = System.currentTimeMillis();		init();		ResultSet rs = null;		if (log.isDebugEnabled()) {			log.debug("Executing statement: " + getQueryString());		}		try {			if (preparedStatement == null) {				rs = statement.executeQuery(query.sql);			} else {				rs = preparedStatement.executeQuery();			}			rs.setFetchSize(fetchSize);		} catch (SQLException sex) {			DbUtil.close(rs);			throw new DbSqlException(this, "Query execution failed", sex);		}		saveResultSet(rs);		totalOpenResultSetCount++;		elapsed = System.currentTimeMillis() - start;		if (log.isDebugEnabled()) {			log.debug("execution time: " + elapsed + "ms");		}		return rs;	}
protected int executeUpdate(final boolean closeQuery) {		start = System.currentTimeMillis();		init();		final int result;		if (log.isDebugEnabled()) {			log.debug("Executing update: " + getQueryString());		}		try {			if (preparedStatement == null) {				if (generatedColumns != null) {					if (generatedColumns.length == 0) {						result = statement.executeUpdate(query.sql, Statement.RETURN_GENERATED_KEYS);					} else {						result = statement.executeUpdate(query.sql, generatedColumns);					}				} else {					result = statement.executeUpdate(query.sql);				}			} else {				result = preparedStatement.executeUpdate();			}		} catch (SQLException sex) {			throw new DbSqlException(this, "Query execution failed", sex);		}		if (closeQuery) {			close();		}		elapsed = System.currentTimeMillis() - start;		if (log.isDebugEnabled()) {			log.debug("execution time: " + elapsed + "ms");		}		return result;	}
protected long executeCount(final boolean close) {		start = System.currentTimeMillis();		init();		ResultSet rs = null;		if (log.isDebugEnabled()) {			log.debug("Executing prepared count: " + getQueryString());		}		try {			if (preparedStatement == null) {				rs = statement.executeQuery(query.sql);			} else {				rs = preparedStatement.executeQuery();			}			final long firstLong = DbUtil.getFirstLong(rs);			elapsed = System.currentTimeMillis() - start;			if (log.isDebugEnabled()) {				log.debug("execution time: " + elapsed + "ms");			}			return firstLong;		} catch (SQLException sex) {			throw new DbSqlException(this, "Count query failed", sex);		} finally {			DbUtil.close(rs);			if (close) {				close();			}		}	}
public <T> List<T> list(final QueryMapper<T> queryMapper) {		final ResultSet resultSet = execute();		final List<T> list = new ArrayList<>();		try {			while (resultSet.next()) {				final T t = queryMapper.process(resultSet);				if (t == null) {					break;				}				list.add(t);			}		} catch (SQLException sex) {			throw new DbSqlException(sex);		} finally {			DbUtil.close(resultSet);		}		return list;	}
public <T> T find(final QueryMapper<T> queryMapper) {		final ResultSet resultSet = execute();		try {			if (resultSet.next()) {				return queryMapper.process(resultSet);			}		} catch (SQLException sex) {			throw new DbSqlException(sex);		} finally {			DbUtil.close(resultSet);		}		return null;	}
public <T> Set<T> listSet(final QueryMapper<T> queryMapper) {		final ResultSet resultSet = execute();		final Set<T> set = new HashSet<>();		try {			while (resultSet.next()) {				final T t = queryMapper.process(resultSet);				if (t == null) {					break;				}				set.add(t);			}		} catch (SQLException sex) {			throw new DbSqlException(sex);		} finally {			DbUtil.close(resultSet);		}		return set;	}
public ResultSet getGeneratedColumns() {		checkInitialized();		if (generatedColumns == null) {			throw new DbSqlException(this, "No column is specified as auto-generated");		}		final ResultSet rs;		try {			rs = statement.getGeneratedKeys();		} catch (SQLException sex) {			throw new DbSqlException(this, "No generated keys", sex);		}		saveResultSet(rs);		totalOpenResultSetCount++;		return rs;	}
public long getGeneratedKey() {		checkInitialized();		final ResultSet rs = getGeneratedColumns();		try {			return DbUtil.getFirstLong(rs);		} catch (SQLException sex) {			throw new DbSqlException(this, "No generated key as long", sex);		} finally {			DbUtil.close(rs);			resultSets.remove(rs);			totalOpenResultSetCount--;		}	}
public String getQueryString() {		if (debug) {			if ((callableStatement != null)) {				if (preparedStatement instanceof LoggableCallableStatement) {					return ((LoggableCallableStatement) callableStatement).getQueryString();				}			}			if (preparedStatement != null) {				if (preparedStatement instanceof LoggablePreparedStatement) {					return ((LoggablePreparedStatement) preparedStatement).getQueryString();				}			}		}		if (query != null) {			return query.sql;		}		return sqlString;	}
public static EmailAddress of(String address) {		address = address.trim();		if (!StringUtil.endsWithChar(address, '>')) {			return new EmailAddress(null, address);		}		final int ndx = address.lastIndexOf('<');		if (ndx == -1) {			return new EmailAddress(null, address);		}		String email = address.substring(ndx + 1, address.length() - 1);		String personalName = address.substring(0, ndx).trim();		return new EmailAddress(personalName, email);	}
public InternetAddress toInternetAddress() throws AddressException {		try {			return new InternetAddress(email, personalName, JoddCore.encoding);		} catch (final UnsupportedEncodingException ueex) {			throw new AddressException(ueex.toString());		}	}
public static EmailAddress[] of(final Address... addresses) {		if (addresses == null) {			return EmailAddress.EMPTY_ARRAY;		}		if (addresses.length == 0) {			return EmailAddress.EMPTY_ARRAY;		}		final EmailAddress[] res = new EmailAddress[addresses.length];		for (int i = 0; i < addresses.length; i++) {			res[i] = EmailAddress.of(addresses[i]);		}		return res;	}
public static InternetAddress[] convert(final EmailAddress[] addresses) throws MessagingException {		if (addresses == null) {			return new InternetAddress[0];		}		final int numRecipients = addresses.length;		final InternetAddress[] address = new InternetAddress[numRecipients];		for (int i = 0; i < numRecipients; i++) {			address[i] = addresses[i].toInternetAddress();		}		return address;	}
@SuppressWarnings("unchecked")	public static <T> T proxyOf(final T target, final Class<? extends Aspect> aspectClass) {		final Aspect aspect;		try {			aspect = ClassUtil.newInstance(aspectClass, target);		}		catch (Exception e) {			throw new IllegalArgumentException("Can't create new instance of aspect class", e);		}		return (T) newProxyInstance(target.getClass().getClassLoader(), aspect, target.getClass().getInterfaces());	}
@SuppressWarnings("unchecked")	public static <T> T proxyOf(final Aspect aspect) {		final Object target = aspect.getTarget();		return (T) newProxyInstance(target.getClass().getClassLoader(), aspect, target.getClass().getInterfaces());	}
public String parse(String template, final Function<String, String> macroResolver) {		StringBuilder result = new StringBuilder(template.length());		int i = 0;		int len = template.length();		// strict flag means that start and end tag are not necessary		boolean strict;		if (macroPrefix == null) {			// when prefix is not specified, make it equals to macro start			// so we can use the same code			macroPrefix = macroStart;			strict = true;		}		else {			strict = false;		}		final int prefixLen = macroPrefix.length();		final int startLen = macroStart.length();		final int endLen = macroEnd.length();		while (i < len) {			int ndx = template.indexOf(macroPrefix, i);			if (ndx == -1) {				result.append(i == 0 ? template : template.substring(i));				break;			}			// check escaped			int j = ndx - 1;			boolean escape = false;			int count = 0;			while ((j >= 0) && (template.charAt(j) == escapeChar)) {				escape = !escape;				if (escape) {					count++;				}				j--;			}			if (resolveEscapes) {				result.append(template.substring(i, ndx - count));			} else {				result.append(template.substring(i, ndx));			}			if (escape) {				result.append(macroPrefix);				i = ndx + prefixLen;				continue;			}			// macro started, detect strict format			boolean detectedStrictFormat = strict;			if (!detectedStrictFormat) {				if (StringUtil.isSubstringAt(template, macroStart, ndx)) {					detectedStrictFormat = true;				}			}			int ndx1;			int ndx2;			if (!detectedStrictFormat) {				// not strict format: $foo				ndx += prefixLen;				ndx1 = ndx;				ndx2 = ndx;				while ((ndx2 < len) && CharUtil.isPropertyNameChar(template.charAt(ndx2))) {					ndx2++;				}				if (ndx2 == len) {					ndx2--;				}				while ((ndx2 > ndx) && !CharUtil.isAlphaOrDigit(template.charAt(ndx2))) {					ndx2--;				}				ndx2++;				if (ndx2 == ndx1 + 1) {					// no value, hence no macro					result.append(macroPrefix);					i = ndx1;					continue;				}			}			else {				// strict format: ${foo}				// find macros end				ndx += startLen;				ndx2 = template.indexOf(macroEnd, ndx);				if (ndx2 == -1) {					throw new IllegalArgumentException("Invalid template, unclosed macro at: " + (ndx - startLen));				}				// detect inner macros, there is no escaping				ndx1 = ndx;				while (ndx1 < ndx2) {					int n = StringUtil.indexOf(template, macroStart, ndx1, ndx2);					if (n == -1) {						break;					}					ndx1 = n + startLen;				}			}			final String name = template.substring(ndx1, ndx2);			// find value and append			Object value;			if (missingKeyReplacement != null || !replaceMissingKey) {				try {					value = macroResolver.apply(name);				} catch (Exception ignore) {					value = null;				}				if (value == null) {					if (replaceMissingKey) {						value = missingKeyReplacement;					} else {						if (detectedStrictFormat) {							value = template.substring(ndx1 - startLen, ndx2 + endLen);						} else {							value = template.substring(ndx1 - 1, ndx2);						}					}				}			} else {				value = macroResolver.apply(name);				if (value == null) {					value = StringPool.EMPTY;				}			}			if (ndx == ndx1) {				String stringValue = value.toString();				if (parseValues) {					if (stringValue.contains(macroStart)) {						stringValue = parse(stringValue, macroResolver);					}				}				result.append(stringValue);				i = ndx2;				if (detectedStrictFormat) {					i += endLen;				}			} else {				// inner macro				template = template.substring(0, ndx1 - startLen) + value.toString() + template.substring(ndx2 + endLen);				len = template.length();				i = ndx - startLen;			}		}		return result.toString();	}
public static <E> Enumeration<E> asEnumeration(final Iterator<E> iter) {		return new Enumeration<E>() {			@Override			public boolean hasMoreElements() {				return iter.hasNext();			}			@Override			public E nextElement() {				return iter.next();			}		};	}
public static <E> Iterator<E> asIterator(final Enumeration<E> e) {		return new Iterator<E>() {			@Override			public boolean hasNext() {				return e.hasMoreElements();			}			@Override			public E next() {				if (!hasNext()) {					throw new NoSuchElementException();				}				return e.nextElement();			}			@Override			public void remove() {				throw new UnsupportedOperationException();			}		};	}
public static <T> Collection<T> collectionOf(final Iterator<? extends T> iterator) {		final List<T> list = new ArrayList<>();		while (iterator.hasNext()) {			list.add(iterator.next());		}		return list;	}
public static <T> Stream<T> streamOf(final Iterator<T> iterator) {		return StreamSupport.stream(((Iterable<T>) () -> iterator).spliterator(), false);	}
public static <T> Stream<T> parallelStreamOf(final Iterator<T> iterator) {		return StreamSupport.stream(((Iterable<T>) () -> iterator).spliterator(), true);	}
public static <T> Stream<T> parallelStreamOf(final Iterable<T> iterable) {		return StreamSupport.stream(iterable.spliterator(), true);	}
@Override	public DbSession getDbSession() {		log.debug("Requesting thread session");		final DbSession session = ThreadDbSessionHolder.get();		if (session == null) {			throw new DbSqlException(					"No DbSession associated with current thread." +					"It seems that ThreadDbSessionHolder is not used.");		}		return session;	}
@Override	public int compare(final T o1, final T o2) {		for (Comparator<T> comparator : comparators) {			int result = comparator.compare(o1, o2);			if (result != 0) {				return result;			}		}		return 0;	}
public AddContentToZip add(final String content) {		return new AddContentToZip(StringUtil.getBytes(content, StringPool.UTF_8));	}
public ZipBuilder addFolder(final String folderName) throws IOException {		ZipUtil.addFolderToZip(zos, folderName, null);		return this;	}
public PetiteConfig setDefaultWiringMode(final WiringMode defaultWiringMode) {		if ((defaultWiringMode == null) || (defaultWiringMode == WiringMode.DEFAULT)) {			throw new PetiteException("Invalid default wiring mode: " + defaultWiringMode);		}		this.defaultWiringMode = defaultWiringMode;		return this;	}
protected WiringMode resolveWiringMode(WiringMode wiringMode) {		if ((wiringMode == null) || (wiringMode == WiringMode.DEFAULT)) {			wiringMode = defaultWiringMode;		}		return wiringMode;	}
protected void print(final Level level, final String message, final Throwable throwable) {		if (!isEnabled(level)) {			return;		}		StringBuilder msg = new StringBuilder()			.append(slf.getElapsedTime()).append(' ').append('[')			.append(level).append(']').append(' ')			.append(getCallerClass()).append(' ').append('-')			.append(' ').append(message);		System.out.println(msg.toString());		if (throwable != null) {			throwable.printStackTrace(System.out);		}	}
protected String getCallerClass() {		Exception exception = new Exception();		StackTraceElement[] stackTrace = exception.getStackTrace();		for (StackTraceElement stackTraceElement : stackTrace) {			String className = stackTraceElement.getClassName();			if (className.equals(SimpleLoggerProvider.class.getName())) {				continue;			}			if (className.equals(SimpleLogger.class.getName())) {				continue;			}			if (className.equals(Logger.class.getName())) {				continue;			}			return shortenClassName(className)				+ '.' + stackTraceElement.getMethodName()				+ ':' + stackTraceElement.getLineNumber();		}		return "N/A";	}
protected String shortenClassName(final String className) {		int lastDotIndex = className.lastIndexOf('.');		if (lastDotIndex == -1) {			return className;		}		StringBuilder shortClassName = new StringBuilder(className.length());		int start = 0;		while(true) {			shortClassName.append(className.charAt(start));			int next = className.indexOf('.', start);			if (next == lastDotIndex) {				break;			}			start = next + 1;			shortClassName.append('.');		}		shortClassName.append(className.substring(lastDotIndex));		return shortClassName.toString();	}
public JsonSerializer withSerializer(final String pathString, final TypeJsonSerializer typeJsonSerializer) {		if (pathSerializersMap == null) {			pathSerializersMap = new HashMap<>();		}		pathSerializersMap.put(Path.parse(pathString), typeJsonSerializer);		return this;	}
public JsonSerializer withSerializer(final Class type, final TypeJsonSerializer typeJsonSerializer) {		if (typeSerializersMap == null) {			typeSerializersMap = new TypeJsonSerializerMap(TypeJsonSerializerMap.get());		}		typeSerializersMap.register(type, typeJsonSerializer);		return this;	}
public JsonSerializer exclude(final boolean includeParent, final String... excludes) {		for (String exclude : excludes) {			if (includeParent) {				int dotIndex = exclude.lastIndexOf('.');				if (dotIndex != -1) {					PathQuery pathQuery = new PathQuery(exclude.substring(0, dotIndex), true);					rules.include(pathQuery);				}			}			PathQuery pathQuery = new PathQuery(exclude, false);			rules.exclude(pathQuery);		}		return this;	}
public JsonSerializer excludeTypes(final String... typeNames) {		if (excludedTypeNames == null) {			excludedTypeNames = typeNames;		} else {			excludedTypeNames = ArraysUtil.join(excludedTypeNames, typeNames);		}		return this;	}
public JsonSerializer excludeTypes(final Class... types) {		if (excludedTypes == null) {			excludedTypes = types;		} else {			excludedTypes = ArraysUtil.join(excludedTypes, types);		}		return this;	}
public void serialize(final Object source, final Appendable target) {		JsonContext jsonContext = createJsonContext(target);		jsonContext.serialize(source);	}
public String serialize(final Object source) {		FastCharBuffer fastCharBuffer = new FastCharBuffer();		serialize(source, fastCharBuffer);		return fastCharBuffer.toString();	}
public CharSequence serializeToCharSequence(final Object source) {		FastCharBuffer fastCharBuffer = new FastCharBuffer();		serialize(source, fastCharBuffer);		return fastCharBuffer;	}
public static <T extends Serializable> T cloneViaSerialization(final T obj) throws IOException, ClassNotFoundException {		FastByteArrayOutputStream bos = new FastByteArrayOutputStream();		ObjectOutputStream out = null;		ObjectInputStream in = null;		Object objCopy = null;		try {			out = new ObjectOutputStream(bos);			out.writeObject(obj);			out.flush();			byte[] bytes = bos.toByteArray();			in = new ObjectInputStream(new ByteArrayInputStream(bytes));			objCopy = in.readObject();		} finally {			StreamUtil.close(out);			StreamUtil.close(in);		}		return (T) objCopy;	}
public static void writeObject(final File dest, final Object object) throws IOException {		FileOutputStream fos = null;		BufferedOutputStream bos = null;		ObjectOutputStream oos = null;		try {			fos = new FileOutputStream(dest);			bos = new BufferedOutputStream(fos);			oos = new ObjectOutputStream(bos);			oos.writeObject(object);		} finally {			StreamUtil.close(oos);			StreamUtil.close(bos);			StreamUtil.close(fos);		}	}
public static Object readObject(final File source) throws IOException, ClassNotFoundException {		Object result = null;		FileInputStream fis = null;		BufferedInputStream bis = null;		ObjectInputStream ois = null;		try {			fis = new FileInputStream(source);			bis = new BufferedInputStream(fis);			ois = new ObjectInputStream(bis);			result = ois.readObject();		} finally {			StreamUtil.close(ois);			StreamUtil.close(bis);			StreamUtil.close(fis);		}		return result;	}
public static byte[] objectToByteArray(final Object obj) throws IOException {		FastByteArrayOutputStream bos = new FastByteArrayOutputStream();		ObjectOutputStream oos = null;		try {			oos = new ObjectOutputStream(bos);			oos.writeObject(obj);		} finally {			StreamUtil.close(oos);		}		return bos.toByteArray();	}
public static Object byteArrayToObject(final byte[] data) throws IOException, ClassNotFoundException {		Object retObj = null;		ByteArrayInputStream bais = new ByteArrayInputStream(data);		ObjectInputStream ois = null;		try {			ois = new ObjectInputStream(bais);			retObj = ois.readObject();		} finally {			StreamUtil.close(ois);		}		return retObj;	}
@Override	public Class[] resolveTables() {		List<Class> classes = new ArrayList<>(tableNames.length);		String lastTableName = null;		resultColumns.clear();		for (int i = 0; i < tableNames.length; i++) {			String tableName = tableNames[i];			String columnName = columnNames[i];			if (tableName == null) {				// maybe JDBC driver does not support it				throw new DbOomException(dbOomQuery, "Table name missing in meta-data");			}			if ((!tableName.equals(lastTableName)) || (resultColumns.contains(columnName))) {				resultColumns.clear();				lastTableName = tableName;				DbEntityDescriptor ded = dbEntityManager.lookupTableName(tableName);				if (ded == null) {					throw new DbOomException(dbOomQuery, "Table name not registered: " + tableName);				}				classes.add(ded.getType());			}			resultColumns.add(columnName);		}		return classes.toArray(new Class[0]);	}
protected DbEntityDescriptor[] resolveDbEntityDescriptors(final Class[] types) {		if (cachedDbEntityDescriptors == null) {			DbEntityDescriptor[] descs = new DbEntityDescriptor[types.length];			for (int i = 0; i < types.length; i++) {				Class type = types[i];				if (type != null) {					descs[i] = dbEntityManager.lookupType(type);				}			}			cachedDbEntityDescriptors = descs;		}		return cachedDbEntityDescriptors;	}
protected String[] resolveTypesTableNames(final Class[] types) {		if (types != cachedUsedTypes) {			cachedTypesTableNames = createTypesTableNames(types);			cachedUsedTypes = types;					}		return cachedTypesTableNames;	}
protected String[][] resolveMappedTypesTableNames(final Class[] types) {		if (cachedMappedNames == null) {			String[][] names = new String[types.length][];			for (int i = 0; i < types.length; i++) {				Class type = types[i];				if (type != null) {					DbEntityDescriptor ded = cachedDbEntityDescriptors[i];					if (ded != null) {						Class[] mappedTypes = ded.getMappedTypes();						if (mappedTypes != null) {							names[i] = createTypesTableNames(mappedTypes);						}					}				}			}			cachedMappedNames = names;		}		return cachedMappedNames;	}
protected String[] createTypesTableNames(final Class[] types) {		String[] names = new String[types.length];		for (int i = 0; i < types.length; i++) {			if (types[i] == null) {				names[i] = null;				continue;			}			DbEntityDescriptor ded = dbEntityManager.lookupType(types[i]);			if (ded != null) {				String tableName = ded.getTableName();				tableName = tableName.toUpperCase();				names[i] = tableName;			}		}		return names;	}
@SuppressWarnings({"unchecked"})	protected Object readColumnValue(final int colNdx, final Class destinationType, final Class<? extends SqlType> sqlTypeClass, final int columnDbSqlType) {		if (colNdx != cachedColumnNdx) {			try {				SqlType sqlType;				if (sqlTypeClass != null) {					sqlType = SqlTypeManager.get().lookupSqlType(sqlTypeClass);				} else {					sqlType = SqlTypeManager.get().lookup(destinationType);				}				if (sqlType != null) {					cachedColumnValue = sqlType.readValue(resultSet, colNdx + 1, destinationType, columnDbSqlType);				} else {					cachedColumnValue = resultSet.getObject(colNdx + 1);					cachedColumnValue = TypeConverterManager.get().convertType(cachedColumnValue, destinationType);				}			} catch (SQLException sex) {				throw new DbOomException(dbOomQuery, "Invalid value for column #" + (colNdx + 1), sex);			}			cachedColumnNdx = colNdx;		}		return cachedColumnValue;	}
@Override	public Object[] parseObjects(final Class... types) {		resultColumns.clear();		int totalTypes = types.length;		Object[] result = new Object[totalTypes];		boolean[] resultUsage = new boolean[totalTypes];		DbEntityDescriptor[] dbEntityDescriptors = resolveDbEntityDescriptors(types);		String[] typesTableNames = resolveTypesTableNames(types);		String[][] mappedNames = resolveMappedTypesTableNames(types);		int currentResult = 0;		cachedColumnNdx = -1;		int colNdx = 0;		while (colNdx < totalColumns) {			// no more types for mapping?			if (currentResult >= totalTypes) {				break;			}			// skip columns that doesn't map			Class currentType = types[currentResult];			if (currentType == null) {				colNdx++;				currentResult++;				resultColumns.clear();				continue;			}			String columnName = columnNames[colNdx];			int columnDbSqlType = columnDbSqlTypes[colNdx];			String tableName = tableNames[colNdx];			String resultTableName = typesTableNames[currentResult];						if (resultTableName == null) {				// match: simple type				result[currentResult] = readColumnValue(colNdx, currentType, null, columnDbSqlType);				resultUsage[currentResult] = true;				colNdx++;				currentResult++; resultColumns.clear();				continue;			}			// match table			boolean tableMatched = false;			if (tableName == null) {				tableMatched = true;			} else if (resultTableName.equals(tableName)) {				tableMatched = true;			} else {				String[] mapped = mappedNames[currentResult];				if (mapped != null) {					for (String m : mapped) {						if (m.equals(tableName)) {							tableMatched = true;							break;						}					}				}			}			if (tableMatched) {				if (!resultColumns.contains(columnName)) {					//DbEntityDescriptor ded = dbEntityManager.lookupType(currentType);					DbEntityDescriptor ded = dbEntityDescriptors[currentResult];					DbEntityColumnDescriptor dec = ded.findByColumnName(columnName);					String propertyName = (dec == null ? null : dec.getPropertyName());					// check if a property that matches column name exist					if (propertyName != null) {						// if current entity instance does not exist (i.e. we are at the first column						// of some entity), create the instance and store it						if (result[currentResult] == null) {							result[currentResult] = dbEntityManager.createEntityInstance(currentType);						}/*						boolean success = value != null ?										BeanUtil.setDeclaredPropertySilent(result[currentResult], propertyName, value) :										BeanUtil.hasDeclaredProperty(result[currentResult], propertyName);*/						Class type = BeanUtil.declared.getPropertyType(result[currentResult], propertyName);						if (type != null) {							// match: entity							dec.updateDbSqlType(columnDbSqlType);	// updates column db sql type information for the entity!!!							Class<? extends SqlType> sqlTypeClass = dec.getSqlTypeClass();							Object value = readColumnValue(colNdx, type, sqlTypeClass, columnDbSqlType);							if (value != null) {								// inject column value into existing entity								BeanUtil.declared.setProperty(result[currentResult], propertyName, value);								resultUsage[currentResult] = true;							}							colNdx++;							resultColumns.add(columnName);							continue;						}					}				}			}			// go to next type, i.e. result			currentResult++;			resultColumns.clear();		}		resultColumns.clear();		for (int i = 0; i < resultUsage.length; i++) {			if (!resultUsage[i]) {				result[i] = null;			}		}		if (cacheEntities) {			cacheResultSetEntities(result);		}		return result;	}
protected void cacheResultSetEntities(final Object[] result) {		if (entitiesCache == null) {			entitiesCache = new HashMap<>();		}		for (int i = 0; i < result.length; i++) {			Object object = result[i];			if (object == null) {				continue;			}			DbEntityDescriptor ded = cachedDbEntityDescriptors[i];			if (ded == null) {	// not a type, continue				continue;			}			// calculate key			Object key;			if (ded.hasIdColumn()) {				//noinspection unchecked				key = ded.getKeyValue(object);			} else {				key = object;			}			Object cachedObject = entitiesCache.get(key);			if (cachedObject == null) {				// object is not in the cache, add it				entitiesCache.put(key, object);			} else {				// object is in the cache, replace it				result[i] = cachedObject;			}		}	}
public ProviderDefinition[] resolve(final Class type, final String name) {		ClassDescriptor cd = ClassIntrospector.get().lookup(type);		MethodDescriptor[] methods = cd.getAllMethodDescriptors();		List<ProviderDefinition> list = new ArrayList<>();		for (MethodDescriptor methodDescriptor : methods) {			Method method = methodDescriptor.getMethod();			PetiteProvider petiteProvider = method.getAnnotation(PetiteProvider.class);			if (petiteProvider == null) {				continue;			}			String providerName = petiteProvider.value();			if (StringUtil.isBlank(providerName)) {				// default provider name				providerName = method.getName();				if (providerName.endsWith("Provider")) {					providerName = StringUtil.substring(providerName, 0, -8);				}			}			ProviderDefinition providerDefinition;			if (Modifier.isStatic(method.getModifiers())) {				providerDefinition = new ProviderDefinition(providerName, method);			} else {				providerDefinition = new ProviderDefinition(providerName, name, method);			}			list.add(providerDefinition);		}		ProviderDefinition[] providers;		if (list.isEmpty()) {			providers = ProviderDefinition.EMPTY;		} else {			providers = list.toArray(new ProviderDefinition[0]);		}		return providers;	}
public String convertEntityNameToTableName(String entityName) {		int ndx = entityName.indexOf(entityNameTerminator);		if (ndx != -1) {			entityName = entityName.substring(0, ndx);		}		StringBuilder tableName = new StringBuilder(entityName.length() * 2);		if (prefix != null) {			tableName.append(prefix);		}		if (splitCamelCase) {			String convertedTableName = Format.fromCamelCase(entityName, separatorChar);			tableName.append(convertedTableName);		} else {			tableName.append(entityName);		}		if (suffix != null) {			tableName.append(suffix);		}		if (!changeCase) {			return tableName.toString();		}		return uppercase ?				toUppercase(tableName).toString() :				toLowercase(tableName).toString();	}
public String convertTableNameToEntityName(final String tableName) {		StringBuilder className = new StringBuilder(tableName.length());		int len = tableName.length();		int i = 0;		if (prefix != null) {			if (tableName.startsWith(prefix)) {				i = prefix.length();			}		}		if (suffix != null) {			if (tableName.endsWith(suffix)) {				len -= suffix.length();			}		}		if (splitCamelCase) {			boolean toUpper = true;			for (; i < len; i++) {				char c = tableName.charAt(i);				if (c == separatorChar) {					toUpper = true;					continue;				}				if (toUpper) {					className.append(Character.toUpperCase(c));					toUpper = false;				} else {					className.append(Character.toLowerCase(c));				}			}			return className.toString();		}		return tableName.substring(i, len);	}
public String applyToTableName(final String tableName) {		String entityName = convertTableNameToEntityName(tableName);		return convertEntityNameToTableName(entityName);	}
@Override	public synchronized void init() {		if (initialised) {			return;		}		if (log.isInfoEnabled()) {			log.info("Core connection pool initialization");		}		try {			Class.forName(driver);		}		catch (ClassNotFoundException cnfex) {			throw new DbSqlException("Database driver not found: " + driver, cnfex);		}		if (minConnections > maxConnections) {			minConnections = maxConnections;		}		availableConnections = new ArrayList<>(maxConnections);		busyConnections = new ArrayList<>(maxConnections);		for (int i = 0; i < minConnections; i++) {			try {				Connection conn = DriverManager.getConnection(url, user, password); 				availableConnections.add(new ConnectionData(conn));			} catch (SQLException sex) {				throw new DbSqlException("No database connection", sex);			}		}		initialised = true;	}
@Override	public synchronized Connection getConnection() {		if (availableConnections == null) {			throw new DbSqlException("Connection pool is not initialized");		}		if (!availableConnections.isEmpty()) {			int lastIndex = availableConnections.size() - 1;			ConnectionData existingConnection = availableConnections.get(lastIndex);			availableConnections.remove(lastIndex);						// If conn on available list is closed (e.g., it timed out), then remove it from available list			// and repeat the process of obtaining a conn. Also wake up threads that were waiting for a			// conn because maxConnection limit was reached.			long now = System.currentTimeMillis();			boolean isValid = isConnectionValid(existingConnection, now);			if (!isValid) {				if (log.isDebugEnabled()) {					log.debug("Pooled connection not valid, resetting");				}				notifyAll();				 // freed up a spot for anybody waiting				return getConnection();			} else {				if (log.isDebugEnabled()) {					log.debug("Returning valid pooled connection");				}				busyConnections.add(existingConnection);				existingConnection.lastUsed = now;				return existingConnection.connection;			}		}		if (log.isDebugEnabled()) {			log.debug("No more available connections");		}		// no available connections		if (((availableConnections.size() + busyConnections.size()) < maxConnections) && !connectionPending) {			makeBackgroundConnection();		} else if (!waitIfBusy) {			throw new DbSqlException("Connection limit reached: " + maxConnections);		}		// wait for either a new conn to be established (if you called makeBackgroundConnection) or for		// an existing conn to be freed up.		try {			wait();		} catch (InterruptedException ie) {			// ignore		}		// someone freed up a conn, so try again.		return getConnection();	}
private boolean isConnectionValid(final ConnectionData connectionData, final long now) {		if (!validateConnection) {			return true;		}				if (now < connectionData.lastUsed + validationTimeout) {			return true;		}		Connection conn = connectionData.connection;		if (validationQuery == null) {			try {				return !conn.isClosed();			} catch (SQLException sex) {				return false;			}		}				boolean valid = true;		Statement st = null;		try {			st = conn.createStatement();			st.execute(validationQuery);		} catch (SQLException sex) {			valid = false;		} finally {			if (st != null) {				try {					st.close();				} catch (SQLException ignore) {				}			}		}		return valid;	}
@Override	public synchronized void close() {		if (log.isInfoEnabled()) {			log.info("Core connection pool shutdown");		}		closeConnections(availableConnections);		availableConnections = new ArrayList<>(maxConnections);		closeConnections(busyConnections);		busyConnections = new ArrayList<>(maxConnections);	}
@Override	protected void renderView(final ActionRequest actionRequest, final String target) throws Exception {		HttpServletRequest request = actionRequest.getHttpServletRequest();		HttpServletResponse response = actionRequest.getHttpServletResponse();		RequestDispatcher dispatcher = request.getRequestDispatcher(target);		if (dispatcher == null) {			response.sendError(SC_NOT_FOUND, "Result not found: " + target);	// should never happened			return;		}		// If we're included, then include the view, otherwise do forward.		// This allow the page to, for example, set content type.		if (DispatcherUtil.isPageIncluded(request, response)) {			dispatcher.include(request, response);		} else {			dispatcher.forward(request, response);		}	}
@Override	protected String locateTarget(final ActionRequest actionRequest, String path) {		String target;		if (path.endsWith(StringPool.SLASH)) {			path = path + defaultViewPageName;		}		for (final String ext : defaultViewExtensions) {			target = path + ext;			if (targetExists(actionRequest, target)) {				return target;			}		}		return null;	}
protected boolean targetExists(final ActionRequest actionRequest, final String target) {		if (log.isDebugEnabled()) {			log.debug("target check: " + target);		}		final ServletContext servletContext = actionRequest.getHttpServletRequest().getServletContext();		try {			return servletContext.getResource(target) != null;		} catch (MalformedURLException ignore) {			return false;		}	}
@Override	public PrintWriter getWriter() throws IOException {		preResponseCommit();		if (buffer == null) {			return getResponse().getWriter();		}		return buffer.getWriter();	}
@Override	public ServletOutputStream getOutputStream() throws IOException {		preResponseCommit();		if (buffer == null) {			return getResponse().getOutputStream();		}		return buffer.getOutputStream();	}
public char[] getBufferContentAsChars() {		if (buffer == null) {			return null;		}		if (!buffer.isUsingStream()) {			return buffer.toCharArray();		}		byte[] content = buffer.toByteArray();		String encoding = getContentTypeEncoding();		if (encoding == null) {			// assume default encoding			return CharUtil.toCharArray(content);		} else {			return CharUtil.toCharArray(content, encoding);		}	}
public void writeContentToResponse(final char[] content) throws IOException {		if (buffer == null) {			return;		}		if (buffer.isUsingStream()) {			ServletOutputStream outputStream = getResponse().getOutputStream();			String encoding = getContentTypeEncoding();			if (encoding == null) {				outputStream.write(CharUtil.toByteArray(content));			} else {				outputStream.write(CharUtil.toByteArray(content, encoding));			}			outputStream.flush();		} else {			Writer out = getResponse().getWriter();			out.write(content);			out.flush();		}	}
public void writeContentToResponse() throws IOException {		if (buffer == null) {			return;		}		if (buffer.isUsingStream()) {			ServletOutputStream outputStream = getResponse().getOutputStream();			outputStream.write(buffer.toByteArray());			outputStream.flush();		} else {			Writer out = getResponse().getWriter();			out.write(buffer.toCharArray());			out.flush();		}	}
@Override	public void setContentType(final String type) {		super.setContentType(type);		contentTypeResolver = new ContentTypeHeaderResolver(type);		if (bufferContentType(type, contentTypeResolver.getMimeType(), contentTypeResolver.getEncoding())) {			enableBuffering();		} else {			disableBuffering();		}	}
@Override	public void setHeader(final String name, final String value) {		String lowerName = name.toLowerCase();		if (lowerName.equals(CONTENT_TYPE)) {			setContentType(value);		} else if (buffer == null || !lowerName.equals(CONTENT_LENGTH)) {			super.setHeader(name, value);		}	}
@Override	public void setIntHeader(final String name, final int value) {		if (buffer == null || !name.equalsIgnoreCase(CONTENT_LENGTH)) {			super.setIntHeader(name, value);		}	}
public void print(final String string) throws IOException {		if (isBufferStreamBased()) {			String encoding = getContentTypeEncoding();			byte[] bytes;			if (encoding == null) {				bytes = string.getBytes();			} else {				bytes = string.getBytes(encoding);			}			buffer.getOutputStream().write(bytes);			return;		}		// make sure at least writer is initialized		buffer.getWriter().write(string);	}
protected JsonResult login() {		T authToken;		authToken = loginViaBasicAuth(servletRequest);		if (authToken == null) {			authToken = loginViaRequestParams(servletRequest);		}		if (authToken == null) {			log.warn("Login failed.");			return JsonResult.of(HttpStatus.error401().unauthorized("Login failed."));		}		log.info("login OK!");		final UserSession<T> userSession = new UserSession<>(authToken, userAuth.tokenValue(authToken));		userSession.start(servletRequest, servletResponse);		// return token		return tokenAsJson(authToken);	}
protected JsonResult tokenAsJson(final T authToken) {		final JsonObject jsonObject = new JsonObject();		jsonObject.put("token", userAuth.tokenValue(authToken));		return JsonResult.of(jsonObject);	}
protected T loginViaRequestParams(final HttpServletRequest servletRequest) {		final String username = servletRequest.getParameter(PARAM_USERNAME).trim();		if (StringUtil.isEmpty(username)) {			return null;		}		final String password = servletRequest.getParameter(PARAM_PASSWORD).trim();		return userAuth.login(username, password);	}
protected T loginViaBasicAuth(final HttpServletRequest servletRequest) {		final String username = ServletUtil.resolveAuthUsername(servletRequest);		if (username == null) {			return null;		}		final String password = ServletUtil.resolveAuthPassword(servletRequest);		return userAuth.login(username, password);	}
protected JsonResult logout() {		log.debug("logout user");		UserSession.stop(servletRequest, servletResponse);		return JsonResult.of(HttpStatus.ok());	}
private static <V> Set<V> set(final int size, final V[] array) {		int index = 0;		final Set<V> set = new HashSet<>();		for (final V v : array) {			set.add(v);			index++;			if (index == size) {				break;			}		}		return set;	}
public static File file(String fileName) {		fileName = StringUtil.replace(fileName, USER_HOME, SystemUtil.info().getHomeDir());		return new File(fileName);	}
public static File toFile(final URL url) {		String fileName = toFileName(url);		if (fileName == null) {			return null;		}		return file(fileName);	}
public static String toFileName(final URL url) {		if ((url == null) || !(url.getProtocol().equals(FILE_PROTOCOL))) {			return null;		}		String filename = url.getFile().replace('/', File.separatorChar);		return URLDecoder.decode(filename, encoding());	}
public static File toContainerFile(final URL url) {		String protocol = url.getProtocol();		if (protocol.equals(FILE_PROTOCOL)) {			return toFile(url);		}		String path = url.getPath();		return new File(URI.create(			path.substring(ZERO, path.lastIndexOf("!/"))));	}
public static File mkdirs(final File dirs) throws IOException {		if (dirs.exists()) {			checkIsDirectory(dirs);			return dirs;		}		return checkCreateDirectory(dirs);	}
public static File mkdir(final File dir) throws IOException {		if (dir.exists()) {			checkIsDirectory(dir);			return dir;		}		return checkCreateDirectory(dir);	}
public static void touch(final File file) throws IOException {		if (!file.exists()) {			StreamUtil.close(new FileOutputStream(file, false));		}		file.setLastModified(System.currentTimeMillis());	}
public static void copyFile(final File srcFile, final File destFile) throws IOException {		checkFileCopy(srcFile, destFile);		_copyFile(srcFile, destFile);	}
private static void _copyFile(final File srcFile, final File destFile) throws IOException {		if (destFile.exists()) {			if (destFile.isDirectory()) {				throw new IOException("Destination '" + destFile + "' is a directory");			}		}		// do copy file		FileInputStream input = null;		FileOutputStream output = null;		try {			input = new FileInputStream(srcFile);			output = new FileOutputStream(destFile, false);			StreamUtil.copy(input, output);		} finally {			StreamUtil.close(output);			StreamUtil.close(input);		}		// done		if (srcFile.length() != destFile.length()) {			throw new IOException("Copy file failed of '" + srcFile + "' to '" + destFile + "' due to different sizes");		}		destFile.setLastModified(srcFile.lastModified());	}
public static File copyFileToDir(final File srcFile, final File destDir) throws IOException {		checkExistsAndDirectory(destDir);		File destFile = file(destDir, srcFile.getName());		copyFile(srcFile, destFile);		return destFile;	}
public static void copyDir(final File srcDir, final File destDir) throws IOException {		checkDirCopy(srcDir, destDir);		_copyDirectory(srcDir, destDir);	}
private static void _moveFile(final File srcFile, final File destFile) throws IOException {		if (destFile.exists()) {			checkIsFile(destFile);			destFile.delete();		}		final boolean rename = srcFile.renameTo(destFile);		if (!rename) {			_copyFile(srcFile, destFile);			srcFile.delete();		}	}
public static File moveFileToDir(final File srcFile, final File destDir) throws IOException {		checkExistsAndDirectory(destDir);		return moveFile(srcFile, file(destDir, srcFile.getName()));	}
private static void _moveDirectory(final File srcDest, File destDir) throws IOException {		if (destDir.exists()) {			checkIsDirectory(destDir);			destDir = file(destDir, destDir.getName());			destDir.mkdir();		}		final boolean rename = srcDest.renameTo(destDir);		if (!rename) {			_copyDirectory(srcDest, destDir);			deleteDir(srcDest);		}	}
public static void cleanDir(final File destDir) throws IOException {		checkExists(destDir);		checkIsDirectory(destDir);		File[] files = destDir.listFiles();		if (files == null) {			throw new IOException("Failed to list contents of: " + destDir);		}		IOException exception = null;		for (File file : files) {			try {				if (file.isDirectory()) {					deleteDir(file);				} else {					file.delete();				}			} catch (IOException ioex) {				exception = ioex;				continue;			}		}		if (exception != null) {			throw exception;		}	}
public static char[] readUTFChars(final File file) throws IOException {		checkExists(file);		checkIsFile(file);		UnicodeInputStream in = unicodeInputStreamOf(file);		try {			return StreamUtil.readChars(in, detectEncoding(in));		} finally {			StreamUtil.close(in);		}	}
public static char[] readChars(final File file, final String encoding) throws IOException {		checkExists(file);		checkIsFile(file);		InputStream in = streamOf(file, encoding);		try {			return StreamUtil.readChars(in, encoding);		} finally {			StreamUtil.close(in);		}	}
public static void writeChars(final File dest, final char[] data, final String encoding) throws IOException {		outChars(dest, data, encoding, false);	}
protected static void outChars(final File dest, final char[] data, final String encoding, final boolean append) throws IOException {		if (dest.exists()) {			checkIsFile(dest);		}		Writer out = new BufferedWriter(StreamUtil.outputStreamWriterOf(new FileOutputStream(dest, append), encoding));		try {			out.write(data);		} finally {			StreamUtil.close(out);		}	}
public static String readUTFString(final File file) throws IOException {		UnicodeInputStream in = unicodeInputStreamOf(file);		try {			return StreamUtil.copy(in, detectEncoding(in)).toString();		} finally {			StreamUtil.close(in);		}	}
public static String readUTFString(final InputStream inputStream) throws IOException {		UnicodeInputStream in = null;		try {			in = new UnicodeInputStream(inputStream, null);			return StreamUtil.copy(in, detectEncoding(in)).toString();		} finally {			StreamUtil.close(in);		}	}
public static String readString(final File file, final String encoding) throws IOException {		checkExists(file);		checkIsFile(file);		InputStream in = streamOf(file, encoding);		try {			return StreamUtil.copy(in, encoding).toString();		} finally {			StreamUtil.close(in);		}	}
public static void writeString(final File dest, final String data, final String encoding) throws IOException {		outString(dest, data, encoding, false);	}
public static void appendString(final File dest, final String data, final String encoding) throws IOException {		outString(dest, data, encoding, true);	}
protected static void outString(final File dest, final String data, final String encoding, final boolean append) throws IOException {		if (dest.exists()) {			checkIsFile(dest);		}		FileOutputStream out = null;		try {			out = new FileOutputStream(dest, append);			out.write(data.getBytes(encoding));		} finally {			StreamUtil.close(out);		}	}
public static void writeStream(final FileOutputStream out, final InputStream in) throws IOException {		try {			StreamUtil.copy(in, out);		} finally {			StreamUtil.close(out);		}	}
public static String[] readLines(final File file, final String encoding) throws IOException {		checkExists(file);		checkIsFile(file);		List<String> list = new ArrayList<>();		InputStream in = streamOf(file, encoding);		try {			BufferedReader br = new BufferedReader(StreamUtil.inputStreamReadeOf(in, encoding));			String strLine;			while ((strLine = br.readLine()) != null) {				list.add(strLine);			}		} finally {			StreamUtil.close(in);		}		return list.toArray(new String[0]);	}
public static byte[] readBytes(final File file, final int count) throws IOException {		checkExists(file);		checkIsFile(file);		long numToRead = file.length();		if (numToRead >= Integer.MAX_VALUE) {			throw new IOException("File is larger then max array size");		}		if (count > NEGATIVE_ONE && count < numToRead) {			numToRead = count;		}		byte[] bytes = new byte[(int) numToRead];		RandomAccessFile randomAccessFile = new RandomAccessFile(file, "r");		randomAccessFile.readFully(bytes);		randomAccessFile.close();		return bytes;	}
public static void writeBytes(final File dest, final byte[] data, final int off, final int len) throws IOException {		outBytes(dest, data, off, len, false);	}
public static void appendBytes(final File dest, final byte[] data, final int off, final int len) throws IOException {		outBytes(dest, data, off, len, true);	}
protected static void outBytes(final File dest, final byte[] data, final int off, final int len, final boolean append) throws IOException {		if (dest.exists()) {			checkIsFile(dest);		}		FileOutputStream out = null;		try {			out = new FileOutputStream(dest, append);			out.write(data, off, len);		} finally {			StreamUtil.close(out);		}	}
public static boolean compare(final String file1, final String file2) throws IOException {		return compare(file(file1), file(file2));	}
public static boolean compare(final File one, final File two) throws IOException {		boolean file1Exists = one.exists();		if (file1Exists != two.exists()) {			return false;		}		if (!file1Exists) {			return true;		}		if ((!one.isFile()) || (!two.isFile())) {			throw new IOException("Only files can be compared");		}		if (one.length() != two.length()) {			return false;		}		if (equals(one, two)) {			return true;		}		InputStream input1 = null;		InputStream input2 = null;		try {			input1 = new FileInputStream(one);			input2 = new FileInputStream(two);			return StreamUtil.compare(input1, input2);		} finally {			StreamUtil.close(input1);			StreamUtil.close(input2);		}	}
public static boolean isNewer(final File file, final File reference) {		checkReferenceExists(reference);		return isNewer(file, reference.lastModified());	}
public static boolean isOlder(final File file, final File reference) {		checkReferenceExists(reference);		return isOlder(file, reference.lastModified());	}
public static void copy(final File src, final File dest) throws IOException {		if (src.isDirectory()) {			copyDir(src, dest);			return;		}		if (dest.isDirectory()) {			copyFileToDir(src, dest);			return;		}		copyFile(src, dest);	}
public static void move(final File src, final File dest) throws IOException {		if (src.isDirectory()) {			moveDir(src, dest);			return;		}		if (dest.isDirectory()) {			moveFileToDir(src, dest);			return;		}		moveFile(src, dest);	}
public static void delete(final File dest) throws IOException {		if (dest.isDirectory()) {			deleteDir(dest);			return;		}		deleteFile(dest);	}
public static boolean isAncestor(final File ancestor, final File file, final boolean strict) {		File parent = strict ? getParentFile(file) : file;		while (true) {			if (parent == null) {				return false;			}			if (parent.equals(ancestor)) {				return true;			}			parent = getParentFile(parent);		}	}
public static File getParentFile(final File file) {		int skipCount = ZERO;		File parentFile = file;		while (true) {			parentFile = parentFile.getParentFile();			if (parentFile == null) {				return null;			}			if (StringPool.DOT.equals(parentFile.getName())) {				continue;			}			if (StringPool.DOTDOT.equals(parentFile.getName())) {				skipCount++;				continue;			}			if (skipCount > ZERO) {				skipCount--;				continue;			}			return parentFile;		}	}
public static boolean isFilePathAcceptable(File file, final FileFilter fileFilter) {		do {			if (fileFilter != null && !fileFilter.accept(file)) {				return false;			}			file = file.getParentFile();		} while (file != null);		return true;	}
public static File createTempDirectory(final String prefix, final String suffix, final File tempDir) throws IOException {		File file = createTempFile(prefix, suffix, tempDir);		file.delete();		file.mkdir();		return file;	}
public static File createTempFile(final String prefix, final String suffix, final File tempDir, final boolean create) throws IOException {		File file = createTempFile(prefix, suffix, tempDir);		file.delete();		if (create) {			file.createNewFile();		}		return file;	}
public static File createTempFile(final String prefix, final String suffix, final File tempDir) throws IOException {		int exceptionsCount = ZERO;		while (true) {			try {				return File.createTempFile(prefix, suffix, tempDir).getCanonicalFile();			} catch (IOException ioex) {  // fixes java.io.WinNTFileSystem.createFileExclusively access denied				if (++exceptionsCount >= 50) {					throw ioex;				}			}		}	}
public static boolean isBinary(final File file) throws IOException {		byte[] bytes = readBytes(file, 128);		for (byte b : bytes) {			if (b < 32 && b != 9 && b != 10 && b != 13) {				return true;			}		}		return false;	}
private static InputStream streamOf(final File file, final String encoding) throws IOException {		InputStream in = new FileInputStream(file);		if (encoding.startsWith("UTF")) {			in = unicodeInputStreamOf(in, encoding);		}		return in;	}
private static String detectEncoding(final UnicodeInputStream in) {		String encoding = in.getDetectedEncoding();		if (encoding == null) {			encoding = StringPool.UTF_8;		}		return encoding;	}
private static void checkReferenceExists(final File file) throws IllegalArgumentException {		try {			checkExists(file);		} catch (FileNotFoundException e) {			throw new IllegalArgumentException("Reference file not found: " + file);		}	}
private static File checkCreateDirectory(final File dir) throws IOException {		if (!dir.mkdirs()) {			throw new IOException(MSG_CANT_CREATE + dir);		}		return dir;	}
private static void checkDirCopy(final File srcDir, final File destDir) throws IOException {		checkExists(srcDir);		checkIsDirectory(srcDir);		if (equals(srcDir, destDir)) {			throw new IOException("Source '" + srcDir + "' and destination '" + destDir + "' are equal");		}	}
private static void checkFileCopy(final File srcFile, final File destFile) throws IOException {		checkExists(srcFile);		checkIsFile(srcFile);		if (equals(srcFile, destFile)) {			throw new IOException("Files '" + srcFile + "' and '" + destFile + "' are equal");		}		File destParent = destFile.getParentFile();		if (destParent != null && !destParent.exists()) {			checkCreateDirectory(destParent);		}	}
public FastBooleanBuffer append(final FastBooleanBuffer buff) {		if (buff.offset == 0) {			return this;		}		append(buff.buffer, 0, buff.offset);		return this;	}
public void printUsage(final String commandName) {		final StringBuilder usage = new StringBuilder(commandName);		for (final Option option : options) {			if (option.shortName != null) {				usage.append(" [-").append(option.shortName).append("]");			} else if (option.longName != null) {				usage.append(" [--").append(option.longName).append("]");			}		}		for (final Param param : params) {			usage.append(" ").append(param.label);		}		System.out.println(usage);	}
public Method resolveActionMethod(final Class<?> actionClass, final String methodName) {		MethodDescriptor methodDescriptor = ClassIntrospector.get().lookup(actionClass).getMethodDescriptor(methodName, false);		if (methodDescriptor == null) {			throw new MadvocException("Public method not found: " + actionClass.getSimpleName() + "#" + methodName);		}		return methodDescriptor.getMethod();	}
public ActionRuntime registerAction(final Class actionClass, final String actionMethodName, final ActionDefinition actionDefinition) {		Method actionMethod = resolveActionMethod(actionClass, actionMethodName);		return registerAction(actionClass, actionMethod, actionDefinition);	}
public ActionRuntime registerAction(final Class actionClass, final Method actionMethod, final ActionDefinition actionDefinition) {		final ActionRuntime actionRuntime = actionMethodParser.parse(actionClass, actionMethod, actionDefinition);		if (actionRuntime == null) {			return null;		}		return registerActionRuntime(actionRuntime);	}
public ActionRuntime registerActionRuntime(final ActionRuntime actionRuntime) {		final String actionPath = actionRuntime.getActionPath();		final String method = actionRuntime.getActionMethod();		log.debug(() -> "Madvoc action: " + ifNotNull(method, m -> m + " ") + actionRuntime.getActionPath() + " => " + actionRuntime.createActionString());		final RouteChunk routeChunk = routes.registerPath(method, actionPath);		if (routeChunk.value() != null) {			// existing chunk			if (detectDuplicatePathsEnabled) {				throw new MadvocException("Duplicate action path for [" + actionRuntime + "] occupied by: [" + routeChunk.value() + "]");			}		}		else {			actionsCount++;		}		routeChunk.bind(actionRuntime);		// finally		runtimes.put(actionRuntime.createActionString(), actionRuntime);		// async check		if (actionRuntime.isAsync()) {			asyncMode = true;		}		return actionRuntime;	}
public ActionRuntime lookup(final String method, final String[] actionPath) {		return routes.lookup(method, actionPath);	}
public void registerPathAlias(final String alias, final String path) {		final String existing = pathAliases.put(alias, path);		if (existing != null) {			throw new MadvocException("Duplicated alias detected: [" + alias + "] for paths: " + path + ", " + existing);		}	}
public boolean next() {		if (!looping) {			return false;		}		if (last) {			return false;		}		if (count == 0) {			value = start;			first = true;		} else {			value += step;			first = false;		}		count++;		last = isLastIteration(value + step);		return true;	}
public static CharArraySequence from(final char[] value, final int offset, final int len) {		final char[] buffer = new char[value.length];		System.arraycopy(value, offset, buffer, 0, len);		return new CharArraySequence(buffer);	}
public FastShortBuffer append(final FastShortBuffer buff) {		if (buff.offset == 0) {			return this;		}		append(buff.buffer, 0, buff.offset);		return this;	}
public Object execute() throws Exception {		String methodName = ProxyTarget.targetMethodName();		Class[] argTypes = ProxyTarget.createArgumentsClassArray();		Object[] args = ProxyTarget.createArgumentsArray();		// lookup method on target object class (and not #targetClass!()		Class type = _target.getClass();		Method method = type.getMethod(methodName, argTypes);		// remember context classloader		ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();		Object result;		try {			// change class loader			Thread.currentThread().setContextClassLoader(type.getClassLoader());			// invoke			result = method.invoke(_target, args);		}		finally {			// return context classloader			Thread.currentThread().setContextClassLoader(contextClassLoader);		}		return ProxyTarget.returnValue(result);	}
@Override	public JoyScanner scanClasspathOf(final Class applicationClass) {		requireNotStarted(classScanner);		appClasses.add(applicationClass);		return this;	}
@Override	public JoyScanner scanClasspathOf(final Object applicationObject) {		requireNotStarted(classScanner);		return scanClasspathOf(applicationObject.getClass());	}
@Override	public void start() {		initLogger();		log.info("SCANNER start ----------");		classScanner = new ClassScanner() {			@Override			protected void scanJarFile(final File file) {				log.debug("Scanning jar: " + file);				super.scanJarFile(file);			}			@Override			protected void scanClassPath(final File root) {				log.debug("Scanning path: " + root);				super.scanClassPath(root);			}		};		if (log.isDebugEnabled()) {			log.debug("Scan entries: " + Converter.get().toString(includedEntries));			log.debug("Scan jars: " + Converter.get().toString(includedJars));			log.debug("Scan exclude jars: " + Converter.get().toString(excludedJars));			log.debug("Scan ignore exception: " + ignoreExceptions);		}		classScanner.excludeCommonEntries();		classScanner.excludeCommonJars();		classScanner.excludeJars(excludedJars.toArray(new String[0]));		if (includedEntries.isEmpty() && includedJars.isEmpty()) {			// nothing was explicitly included			classScanner.excludeAllEntries(false);		}		else {			// something was included by user			classScanner.excludeAllEntries(true);			includedEntries.add("jodd.*");		}		classScanner			.detectEntriesMode(true)			.includeEntries(includedEntries.toArray(new String[0]))			.includeJars(includedJars.toArray(new String[0]))			.ignoreException(ignoreExceptions)			.scanDefaultClasspath();		appClasses.forEach(clazz -> classScanner.scan(ClassPathURLs.of(null, clazz)));		log.info("SCANNER OK!");	}
@Override	public void script(final Tag tag, final CharSequence body) {		if (!insideConditionalComment) {			String src = Util.toString(tag.getAttributeValue("src"));			if (src == null) {				super.script(tag, body);				return;			}			if (jsBundleAction.acceptLink(src)) {				String link = jsBundleAction.processLink(src);				if (link != null) {					tag.setAttributeValue("src", link);					super.script(tag, body);				}				return;			}		}		super.script(tag, body);	}
@Override	public void condComment(final CharSequence expression, final boolean isStartingTag, final boolean isHidden, final boolean isHiddenEndTag) {		insideConditionalComment = isStartingTag;		super.condComment(expression, isStartingTag, isHidden, isHiddenEndTag);	}
public char[] postProcess(char[] content) {		content = jsBundleAction.replaceBundleId(content);		content = cssBundleAction.replaceBundleId(content);		return content;	}
public static <V> V callAndWrapException(final Callable<V> callable) {		try {			return callable.call();		}		catch (IOException ioex) {			throw new UncheckedIOException(ioex);		}		catch (RuntimeException rtex) {			throw rtex;		}		catch (Exception t) {			throw new UncheckedException(t);		}	}
public static void runAndWrapException(final CallableVoid callable) {		try {			callable.call();		}		catch (IOException ioex) {			throw new UncheckedIOException(ioex);		}		catch (RuntimeException rtex) {			throw rtex;		}		catch (Exception t) {			throw new UncheckedException(t);		}	}
protected final int find(final char target, int from, final int end) {		while (from < end) {			if (input[from] == target) {				break;			}			from++;		}		return (from == end) ? -1 : from;	}
protected final int find(final char[] target, int from, final int end) {		while (from < end) {			if (match(target, from)) {				break;			}			from++;		}		return (from == end) ? -1 : from;	}
protected final boolean match(final char[] target, final int ndx) {		if (ndx + target.length >= total) {			return false;		}		int j = ndx;		for (int i = 0; i < target.length; i++, j++) {			if (input[j] != target[i]) {				return false;			}		}		return true;	}
public final boolean matchUpperCase(final char[] uppercaseTarget) {		if (ndx + uppercaseTarget.length > total) {			return false;		}		int j = ndx;		for (int i = 0; i < uppercaseTarget.length; i++, j++) {			final char c = CharUtil.toUpperAscii(input[j]);			if (c != uppercaseTarget[i]) {				return false;			}		}		return true;	}
protected final CharSequence charSequence(final int from, final int to) {		if (from == to) {			return CharArraySequence.EMPTY;		}		return CharArraySequence.of(input, from, to - from);	}
protected Position position(final int position) {		int line;		int offset;		int lastNewLineOffset;		if (position > lastOffset) {			line = 1;			offset = 0;			lastNewLineOffset = 0;		} else {			line = lastLine;			offset = lastOffset;			lastNewLineOffset = lastLastNewLineOffset;		}		while (offset < position) {			final char c = input[offset];			if (c == '\n') {				line++;				lastNewLineOffset = offset + 1;			}			offset++;		}		lastOffset = offset;		lastLine = line;		lastLastNewLineOffset = lastNewLineOffset;		return new Position(position, line, position - lastNewLineOffset + 1);	}
public JtxTransaction maybeRequestTransaction(final JtxTransactionMode txMode, final Object scope) {		if (txMode == null) {			return null;		}		JtxTransaction currentTx = txManager.getTransaction();		JtxTransaction requestedTx = txManager.requestTransaction(txMode, scope);		if (currentTx == requestedTx) {			return null;		}		return requestedTx;	}
public boolean maybeCommitTransaction(final JtxTransaction tx) {		if (tx == null) {			return false;		}		log.debug("commit tx");		tx.commit();		return true;	}
public boolean markOrRollbackTransaction(JtxTransaction tx, final Throwable cause) {		if (tx == null) {			tx = getCurrentTransaction();			if (tx == null) {				return false;			}			log.debug("set rollback only tx");			tx.setRollbackOnly(cause);			return false;		}		log.debug("rollback tx");		tx.rollback();		return true;	}
public static URL[] of(ClassLoader classLoader, Class clazz) {		if (clazz == null) {			clazz = ClassPathURLs.class;		}		if (classLoader == null) {			classLoader = clazz.getClassLoader();		}		final Set<URL> urls = new LinkedHashSet<>();		while (classLoader != null) {			if (classLoader instanceof URLClassLoader) {				URLClassLoader urlClassLoader = (URLClassLoader) classLoader;				URL[] allURLS = urlClassLoader.getURLs();				Collections.addAll(urls, allURLS);				break;			}			URL classUrl = classModuleUrl(classLoader, clazz);			if (classUrl != null) {				urls.add(classUrl);			}			classUrl = classModuleUrl(classLoader, ClassPathURLs.class);			if (classUrl != null) {				urls.add(classUrl);			}			ModuleDescriptor moduleDescriptor = clazz.getModule().getDescriptor();			if (moduleDescriptor != null) {				moduleDescriptor.requires().forEach(req -> {					ModuleLayer.boot()						.findModule(req.name())						.ifPresent(mod -> {							ClassLoader moduleClassLoader = mod.getClassLoader();							if (moduleClassLoader != null) {								URL url = moduleClassLoader.getResource(MANIFEST);								if (url != null) {									url = fixManifestUrl(url);									urls.add(url);								}							}						});				});			}			classLoader = classLoader.getParent();		}		return urls.toArray(new URL[0]);	}
@Benchmark    public String encode_Apache_Base32() {        return new org.apache.commons.codec.binary.Base32(false).encodeAsString(to_be_encoded);    }
public Email bcc(final EmailAddress to) {		this.bcc = ArraysUtil.append(this.bcc, to);		return _this();	}
public Email bcc(final String personalName, final String bcc) {		return bcc(new EmailAddress(personalName, bcc));	}
public Email bcc(final EmailAddress... bccs) {		this.bcc = ArraysUtil.join(this.bcc, valueOrEmptyArray(bccs));		return _this();	}
@Override	public FileUpload create(final MultipartRequestInputStream input) {		return new AdaptiveFileUpload(input, memoryThreshold, uploadPath, maxFileSize, breakOnError, fileExtensions, allowFileExtensions);	}
public void registerDefaults() {		// main		map.put(Object.class, new ObjectJsonSerializer());		map.put(Map.class, new MapJsonSerializer());		map.put(Iterable.class, new IterableJsonSerializer());		map.put(JsonObject.class, new JsonObjectSerializer());		map.put(JsonArray.class, new JsonArraySerializer());		// arrays		map.put(int[].class, new IntArrayJsonSerializer());		map.put(long[].class, new LongArrayJsonSerializer());		map.put(double[].class, new DoubleArrayJsonSerializer());		map.put(float[].class, new FloatArrayJsonSerializer());		map.put(boolean[].class, new BooleanArrayJsonSerializer());		map.put(byte[].class, new ByteArrayJsonSerializer());		map.put(Integer[].class, new ArraysJsonSerializer<Integer>() {			@Override			protected int getLength(final Integer[] array) {				return array.length;			}			@Override			protected Integer get(final Integer[] array, final int index) {				return array[index];			}		});		map.put(Long[].class, new ArraysJsonSerializer<Long>() {			@Override			protected int getLength(final Long[] array) {				return array.length;			}			@Override			protected Long get(final Long[] array, final int index) {				return array[index];			}		});		map.put(Arrays.class, new ArraysJsonSerializer());		// strings		TypeJsonSerializer jsonSerializer = new CharSequenceJsonSerializer();		map.put(String.class, jsonSerializer);		map.put(StringBuilder.class, jsonSerializer);		map.put(CharSequence.class, jsonSerializer);		// number		jsonSerializer = new NumberJsonSerializer();		map.put(Number.class, jsonSerializer);		map.put(Integer.class, jsonSerializer);		map.put(int.class, jsonSerializer);		map.put(Long.class, jsonSerializer);		map.put(long.class, jsonSerializer);		DoubleJsonSerializer doubleJsonSerializer = new DoubleJsonSerializer();		map.put(Double.class, doubleJsonSerializer);		map.put(double.class, doubleJsonSerializer);		FloatJsonSerializer floatJsonSerializer = new FloatJsonSerializer();		map.put(Float.class, floatJsonSerializer);		map.put(float.class, floatJsonSerializer);		map.put(BigInteger.class, jsonSerializer);		map.put(BigDecimal.class, jsonSerializer);		// other		map.put(Boolean.class, new BooleanJsonSerializer());		map.put(boolean.class, new BooleanJsonSerializer());		map.put(Date.class, new DateJsonSerializer());		map.put(Calendar.class, new CalendarJsonSerializer());		map.put(JulianDate.class, new JulianDateSerializer());		map.put(LocalDateTime.class, new LocalDateTimeSerializer());		map.put(LocalDate.class, new LocalDateSerializer());		map.put(LocalTime.class, new LocalTimeSerializer());		map.put(Enum.class, new EnumJsonSerializer());		map.put(File.class, new FileJsonSerializer(FileJsonSerializer.Type.PATH));		//map.putUnsafe();(Collection.class, new CollectionJsonSerializer());		jsonSerializer = new CharacterJsonSerializer();		map.put(Character.class, jsonSerializer);		map.put(char.class, jsonSerializer);		map.put(UUID.class, new UUIDJsonSerializer());		map.put(Class.class, new ClassJsonSerializer());		// clear cache		cache.clear();	}
public void register(final Class type, final TypeJsonSerializer typeJsonSerializer) {		map.put(type, typeJsonSerializer);		cache.clear();	}
protected TypeJsonSerializer lookupSerializer(final Class type) {		TypeJsonSerializer tjs = map.get(type);		if (tjs == null) {			if (defaultSerializerMap != null) {				tjs = defaultSerializerMap.map.get(type);			}		}		return tjs;	}
protected void putFile(final String name, final FileUpload value) {		if (requestFiles == null) {			requestFiles = new HashMap<>();		}		FileUpload[] fileUploads = requestFiles.get(name);		if (fileUploads != null) {			fileUploads = ArraysUtil.append(fileUploads, value);		} else {			fileUploads = new FileUpload[] {value};		}		requestFiles.put(name, fileUploads);	}
public void parseRequestStream(final InputStream inputStream, final String encoding) throws IOException {		setParsed();		MultipartRequestInputStream input = new MultipartRequestInputStream(inputStream);		input.readBoundary();		while (true) {			FileUploadHeader header = input.readDataHeader(encoding);			if (header == null) {				break;			}			if (header.isFile) {				String fileName = header.fileName;				if (fileName.length() > 0) {					if (header.contentType.indexOf("application/x-macbinary") > 0) {						input.skipBytes(128);					}				}				FileUpload newFile = fileUploadFactory.create(input);				newFile.processStream();				if (fileName.length() == 0) {					// file was specified, but no name was provided, therefore it was not uploaded					if (newFile.getSize() == 0) {						newFile.size = -1;					}				}				putFile(header.formFieldName, newFile);			} else {				// no file, therefore it is regular form parameter.				FastByteArrayOutputStream fbos = new FastByteArrayOutputStream();				input.copyAll(fbos);				String value = encoding != null ? new String(fbos.toByteArray(), encoding) : new String(fbos.toByteArray());				putParameter(header.formFieldName, value);			}			input.skipBytes(1);			input.mark(1);			// read byte, but may be end of stream			int nextByte = input.read();			if (nextByte == -1 || nextByte == '-') {				input.reset();				break;			}			input.reset();		}	}
public String getParameter(final String paramName) {		if (requestParameters == null) {			return null;		}		String[] values = requestParameters.get(paramName);		if ((values != null) && (values.length > 0)) {			return values[0];		}		return null;	}
public String[] getParameterValues(final String paramName) {		if (requestParameters == null) {			return null;		}		return requestParameters.get(paramName);	}
public FileUpload getFile(final String paramName) {		if (requestFiles == null) {			return null;		}		FileUpload[] values = requestFiles.get(paramName);		if ((values != null) && (values.length > 0)) {			return values[0];		}		return null;	}
public FileUpload[] getFiles(final String paramName) {		if (requestFiles == null) {			return null;		}		return requestFiles.get(paramName);	}
@Override	public void init(final FilterConfig filterConfig) {		this.filterConfig = filterConfig;		this.encoding = filterConfig.getInitParameter("encoding");		if (this.encoding == null) {			this.encoding = JoddCore.encoding;		}		this.ignore = Converter.get().toBooleanValue(filterConfig.getInitParameter("ignore"), true);	}
public void parse(final DbSqlBuilder sqlBuilder, final String template) {		int length = template.length();		int last = 0;		while (true) {			int mark = template.indexOf('$', last);			if (mark == -1) {				if (last < length) {					sqlBuilder.appendRaw(template.substring(last));				}				break;			}			int escapesCount = countEscapes(template, mark);                // check if escaped			if (escapesCount > 0) {				boolean isEscaped = escapesCount % 2 != 0;				int escapesToAdd = escapesCount >> 1;				sqlBuilder.appendRaw(template.substring(last, mark - escapesCount + escapesToAdd) + '$');				if (isEscaped) {					last = mark + 1;					continue;				}			} else {				sqlBuilder.appendRaw(template.substring(last, mark));			}			int end;			if (template.startsWith(MACRO_TABLE, mark)) {				mark += MACRO_TABLE.length();				end = findMacroEnd(template, mark);				onTable(sqlBuilder, template.substring(mark, end));			} else if (template.startsWith(MACRO_COLUMN, mark)) {				mark += MACRO_COLUMN.length();				end = findMacroEnd(template, mark);				onColumn(sqlBuilder, template.substring(mark, end));			} else if (template.startsWith(MACRO_MATCH, mark)) {				mark += MACRO_MATCH.length();				end = findMacroEnd(template, mark);				onMatch(sqlBuilder, template.substring(mark, end));			} else if (template.startsWith(MACRO_VALUE, mark)) {				mark += MACRO_VALUE.length();				end = findMacroEnd(template, mark);				onValue(sqlBuilder, template.substring(mark, end));			} else {				mark++;           // reference found				end = mark;       // find macro end				while (end < length) {					if (!isReferenceChar(template, end)) {						break;					}					end++;				}				onReference(sqlBuilder, template.substring(mark, end));				end--;			}			end++;			last = end;		}	}
protected int findMacroEnd(final String template, final int fromIndex) {		int endIndex = template.indexOf('}', fromIndex);		if (endIndex == -1) {			throw new DbSqlBuilderException("Template syntax error, some macros are not closed. Error at: '..." + template.substring(fromIndex));		}		return endIndex;	}
protected int countEscapes(final String template, int macroIndex) {		macroIndex--;		int escapeCount = 0;		while (macroIndex >= 0) {			if (template.charAt(macroIndex) != ESCAPE_CHARACTER) {				break;			}			escapeCount++;			macroIndex--;		}		return escapeCount;	}
protected void onTable(final DbSqlBuilder sqlBuilder, final String allTables) {		String[] tables = StringUtil.split(allTables, StringPool.COMMA);		for (String table : tables) {			sqlBuilder.table(table);		}	}
public static String buildQuery(final HttpMultiMap<?> queryMap, final String encoding) {		if (queryMap.isEmpty()) {			return StringPool.EMPTY;		}		int queryMapSize = queryMap.size();		StringBand query = new StringBand(queryMapSize * 4);		int count = 0;		for (Map.Entry<String, ?> entry : queryMap) {			String key = entry.getKey();			key = URLCoder.encodeQueryParam(key, encoding);			Object value = entry.getValue();			if (value == null) {				if (count != 0) {					query.append('&');				}				query.append(key);				count++;			} else {				if (count != 0) {					query.append('&');				}				query.append(key);				count++;				query.append('=');				String valueString = URLCoder.encodeQueryParam(value.toString(), encoding);				query.append(valueString);			}		}		return query.toString();	}
public static HttpMultiMap<String> parseQuery(final String query, final boolean decode) {		final HttpMultiMap<String> queryMap = HttpMultiMap.newCaseInsensitiveMap();		if (StringUtil.isBlank(query)) {			return queryMap;		}		int lastNdx = 0;		while (lastNdx < query.length()) {			int ndx = query.indexOf('&', lastNdx);			if (ndx == -1) {				ndx = query.length();			}			final String paramAndValue = query.substring(lastNdx, ndx);			ndx = paramAndValue.indexOf('=');			if (ndx == -1) {				queryMap.add(paramAndValue, null);			}			else {				String name = paramAndValue.substring(0, ndx);				if (decode) {					name = URLDecoder.decodeQuery(name);				}				String value = paramAndValue.substring(ndx + 1);				if (decode) {					value = URLDecoder.decodeQuery(value);				}				queryMap.add(name, value);			}			lastNdx += paramAndValue.length() + 1;		}		return queryMap;	}
public static String prepareHeaderParameterName(final String headerName) {		// special cases		if (headerName.equals("etag")) {			return HttpBase.HEADER_ETAG;		}		if (headerName.equals("www-authenticate")) {			return "WWW-Authenticate";		}		char[] name = headerName.toCharArray();		boolean capitalize = true;		for (int i = 0; i < name.length; i++) {			char c = name[i];			if (c == '-') {				capitalize = true;				continue;			}			if (capitalize) {				name[i] = Character.toUpperCase(c);				capitalize = false;			} else {				name[i] = Character.toLowerCase(c);			}		}		return new String(name);	}
public static String extractMediaType(final String contentType) {		int index = contentType.indexOf(';');		if (index == -1) {			return contentType;		}		return contentType.substring(0, index);	}
public static String extractHeaderParameter(final String header, final String parameter, final char separator) {		int index = 0;		while (true) {			index = header.indexOf(separator, index);			if (index == -1) {				return null;			}			index++;			// skip whitespaces			while (index < header.length() && header.charAt(index) == ' ') {				index++;			}			int eqNdx = header.indexOf('=', index);			if (eqNdx == -1) {				return null;			}			String paramName = header.substring(index, eqNdx);			eqNdx++;			if (!paramName.equalsIgnoreCase(parameter)) {				index = eqNdx;				continue;			}			int endIndex = header.indexOf(';', eqNdx);			if (endIndex == -1) {				return header.substring(eqNdx);			} else {				return header.substring(eqNdx, endIndex);			}		}	}
public static void setPreparedStatementObject(final PreparedStatement preparedStatement, final int index, final Object value, final int targetSqlType) throws SQLException {		if (value == null) {			preparedStatement.setNull(index, Types.NULL);			return;		}		switch (targetSqlType) {			case Types.VARCHAR:			case Types.LONGVARCHAR:			case Types.CHAR:				preparedStatement.setString(index, Converter.get().toString(value));				break;			case Types.INTEGER:			case Types.SMALLINT:			case Types.TINYINT:				preparedStatement.setInt(index, Converter.get().toIntValue(value));				break;			case Types.BIGINT:				preparedStatement.setLong(index, Converter.get().toLongValue(value));				break;			case Types.BOOLEAN:			case Types.BIT:				preparedStatement.setBoolean(index, Converter.get().toBooleanValue(value));				break;			case Types.DATE:				preparedStatement.setDate(index, TypeConverterManager.get().convertType(value, java.sql.Date.class));				break;			case Types.NUMERIC:			case Types.DECIMAL:				preparedStatement.setBigDecimal(index, Converter.get().toBigDecimal(value));				break;			case Types.DOUBLE:				preparedStatement.setDouble(index, Converter.get().toDoubleValue(value));				break;			case Types.REAL:			case Types.FLOAT:				preparedStatement.setFloat(index, Converter.get().toFloatValue(value));			    break;			case Types.TIME:				preparedStatement.setTime(index, TypeConverterManager.get().convertType(value, java.sql.Time.class));				break;			case Types.TIMESTAMP:				preparedStatement.setTimestamp(index, TypeConverterManager.get().convertType(value, Timestamp.class));				break;			case Types.BINARY:			case Types.VARBINARY:				preparedStatement.setBytes(index, TypeConverterManager.get().convertType(value, byte[].class));				break;			default:				if (targetSqlType != SqlType.DB_SQLTYPE_NOT_AVAILABLE) {					preparedStatement.setObject(index, value, targetSqlType);				} else {					preparedStatement.setObject(index, value);				}		}	}
@Override	public boolean init(final String actionPath, final String[] separators) {		String prefix = separators[0];		String split = separators[1];		String suffix = separators[2];		macrosCount = StringUtil.count(actionPath, prefix);		if (macrosCount == 0) {			return false;		}		names = new String[macrosCount];		patterns = new String[macrosCount];		fixed = new String[macrosCount + 1];		int offset = 0;		int i = 0;		while (true) {			int[] ndx = StringUtil.indexOfRegion(actionPath, prefix, suffix, offset);			if (ndx == null) {				break;			}			fixed[i] = actionPath.substring(offset, ndx[0]);			String name = actionPath.substring(ndx[1], ndx[2]);			// name:pattern			String pattern = null;			int colonNdx = name.indexOf(split);			if (colonNdx != -1) {				pattern = name.substring(colonNdx + 1).trim();				name = name.substring(0, colonNdx).trim();			}			this.patterns[i] = pattern;			this.names[i] = name;			// iterate			offset = ndx[3];			i++;		}		if (offset < actionPath.length()) {			fixed[i] = actionPath.substring(offset);		} else {			fixed[i] = StringPool.EMPTY;		}		return true;	}
@Override	public int match(final String actionPath) {		String[] values = process(actionPath, true);		if (values == null) {			return -1;		}		int macroChars = 0;		for (String value : values) {			if (value != null) {				macroChars += value.length();			}		}		return actionPath.length() - macroChars;	}
private String[] process(final String actionPath, final boolean match) {		// first check the first fixed as a prefix		if (match && !actionPath.startsWith(fixed[0])) {			return null;		}		String[] values = new String[macrosCount];		int offset = fixed[0].length();		int i = 0;		while (i < macrosCount) {			int nexti = i;			// defines next fixed string to match			String nextFixed;			while (true) {				nexti++;				if (nexti > macrosCount) {					nextFixed = null;	// match to the end of line					break;				}				nextFixed = fixed[nexti];				if (nextFixed.length() != 0) {					break;				}				// next fixed is an empty string, so skip the next macro.			}			// find next fixed string			int ndx;			if (nextFixed != null) {				ndx = actionPath.indexOf(nextFixed, offset);			} else {				ndx = actionPath.length();			}			if (ndx == -1) {				return null;			}			String macroValue = actionPath.substring(offset, ndx);			values[i] = macroValue;			if (match && patterns[i] != null) {				if (!matchValue(i, macroValue)) {					return null;				}			}			if (nextFixed == null) {				offset = ndx;				break;			}			// iterate			int nextFixedLength = nextFixed.length();			offset = ndx + nextFixedLength;			i = nexti;		}		if (offset != actionPath.length()) {			// action path is not consumed fully during this matching			return null;		}		return values;	}
public String toHtml(final Node node, final Appendable appendable) {		NodeVisitor renderer = createRenderer(appendable);		node.visit(renderer);		return appendable.toString();	}
public String toInnerHtml(final Node node, final Appendable appendable) {		NodeVisitor renderer = createRenderer(appendable);		node.visitChildren(renderer);		return appendable.toString();	}
@Override	public String getHeader(final String header) {		if (isExcluded(header)) {			return null;		}		return super.getHeader(header);	}
@Override	public void put(final K key, final V object, final long timeout) {		Objects.requireNonNull(object);		final long stamp = lock.writeLock();		try {			CacheObject<K,V> co = new CacheObject<>(key, object, timeout);			if (timeout != 0) {				existCustomTimeout = true;			}			if (isReallyFull(key)) {				pruneCache();			}			cacheMap.put(key, co);		}		finally {			lock.unlockWrite(stamp);		}	}
@Override	public V get(final K key) {		long stamp = lock.readLock();		try {			CacheObject<K,V> co = cacheMap.get(key);			if (co == null) {				missCount++;				return null;			}			if (co.isExpired()) {				final long newStamp = lock.tryConvertToWriteLock(stamp);				if (newStamp != 0L) {					stamp = newStamp;					// lock is upgraded to write lock				}				else {					// manually upgrade lock to write lock					lock.unlockRead(stamp);					stamp = lock.writeLock();				}				CacheObject<K,V> removedCo = cacheMap.remove(key);				if (removedCo != null) {					onRemove(removedCo.key, removedCo.cachedObject);				}				missCount++;				return null;			}			hitCount++;			return co.getObject();		}		finally {			lock.unlock(stamp);		}	}
@Override	public V remove(final K key) {		V removedValue = null;		final long stamp = lock.writeLock();		try {			CacheObject<K,V> co = cacheMap.remove(key);			if (co != null) {				onRemove(co.key, co.cachedObject);				removedValue = co.cachedObject;			}		}		finally {			lock.unlockWrite(stamp);		}		return removedValue;	}
@Override	public void clear() {		final long stamp = lock.writeLock();		try {			cacheMap.clear();		}		finally {			lock.unlockWrite(stamp);		}	}
@Override	public Map<K, V> snapshot() {		final long stamp = lock.writeLock();		try {			Map<K, V> map = new HashMap<>(cacheMap.size());			cacheMap.forEach((key, cacheValue) -> map.put(key, cacheValue.getObject()));			return map;		}		finally {			lock.unlockWrite(stamp);		}	}
public void configureWith(final ServletContext servletContext) {		webAppClassName = servletContext.getInitParameter(PARAM_MADVOC_WEBAPP);		paramsFiles = Converter.get().toStringArray(servletContext.getInitParameter(PARAM_MADVOC_PARAMS));		madvocConfiguratorClassName = servletContext.getInitParameter(PARAM_MADVOC_CONFIGURATOR);	}
@SuppressWarnings("InstanceofCatchParameter")	public WebApp startWebApplication(final ServletContext servletContext) {		try {			WebApp webApp = _start(servletContext);			log.info("Madvoc is up and running.");			return webApp;		}		catch (Exception ex) {			if (log != null) {				log.error("Madvoc startup failure.", ex);			} else {				ex.printStackTrace();			}			if (ex instanceof MadvocException) {				throw (MadvocException) ex;			}			throw new MadvocException(ex);		}	}
public void stopWebApplication() {		log.info("Madvoc shutting down...");		if (servletContext != null) {			servletContext.removeAttribute(MADVOC_ATTR);		}		webapp.shutdown();		webapp = null;	}
protected WebApp createWebApplication() {		if ((webAppClassName == null) && (webAppClass == null)) {			return new WebApp();		}		final WebApp webApp;		try {			if (webAppClassName != null) {				webAppClass = ClassLoaderUtil.loadClass(webAppClassName);			}			webApp = (WebApp) ClassUtil.newInstance(webAppClass);		}		catch (Exception ex) {			throw new MadvocException("Unable to load Madvoc web application class: " + webAppClassName, ex);		}		return webApp;	}
protected Props loadMadvocParams(final String[] patterns) {		if (log.isInfoEnabled()) {			log.info("Loading Madvoc parameters from: " + Converter.get().toString(patterns));		}		try {			return new Props().loadFromClasspath(patterns);		} catch (Exception ex) {			throw new MadvocException("Unable to load Madvoc parameters from: " +					Converter.get().toString(patterns) + ".properties': " + ex.toString(), ex);		}	}
protected void resolveMadvocConfigClass() {		if ((madvocConfiguratorClassName == null) && (madvocConfiguratorClass == null)) {			return;		}		try {			if (madvocConfiguratorClassName != null) {				madvocConfiguratorClass = ClassLoaderUtil.loadClass(madvocConfiguratorClassName);			}			log.info("Configuring Madvoc using: " + madvocConfiguratorClass.getName());		} catch (Exception ex) {			throw new MadvocException("Unable to load Madvoc configurator class: " + madvocConfiguratorClassName, ex);		}	}
public static Class of(final String className, final byte[] classData, ClassLoader classLoader) {		if (classLoader == null) {			classLoader = ClassLoaderUtil.getDefaultClassLoader();		}		try {			final Method defineClassMethod = ClassLoader.class.getDeclaredMethod("defineClass", String.class, byte[].class, int.class, int.class);			defineClassMethod.setAccessible(true);			return (Class) defineClassMethod.invoke(classLoader, className, classData, 0, classData.length);		} catch (Throwable th) {			throw new RuntimeException("Define class failed: " + className, th);		}	}
protected void reset() {		this.ndx = 0;		this.textLen = 0;		this.path = new Path();		this.notFirstObject = false;		if (useAltPaths) {			path.altPath = new Path();		}		if (classMetadataName != null) {			mapToBean = createMapToBean(classMetadataName);		}	}
public JsonParser lazy(final boolean lazy) {		this.lazy = lazy;		this.mapSupplier = lazy ? LAZYMAP_SUPPLIER : HASHMAP_SUPPLIER;		this.listSupplier = lazy ? LAZYLIST_SUPPLIER : ARRAYLIST_SUPPLIER;		return this;	}
public JsonParser map(final String path, final Class target) {		if (path == null) {			rootType = target;			return this;		}		if (mappings == null) {			mappings = new HashMap<>();		}		mappings.put(Path.parse(path), target);		return this;	}
protected Class replaceWithMappedTypeForPath(final Class target) {		if (mappings == null) {			return target;		}		Class newType;		// first try alt paths		Path altPath = path.getAltPath();		if (altPath != null) {			if (!altPath.equals(path)) {				newType = mappings.get(altPath);				if (newType != null) {					return newType;				}			}		}		// now check regular paths		newType = mappings.get(path);		if (newType != null) {			return newType;		}		return target;	}
public JsonParser withValueConverter(final String path, final ValueConverter valueConverter) {		if (convs == null) {			convs = new HashMap<>();		}		convs.put(Path.parse(path), valueConverter);		return this;	}
public JsonParser allowClass(final String classPattern) {		if (super.classnameWhitelist == null) {			super.classnameWhitelist = new ArrayList<>();		}		classnameWhitelist.add(classPattern);		return this;	}
@SuppressWarnings("unchecked")	public <T> T parse(final String input, final Class<T> targetType) {		rootType = targetType;		return _parse(UnsafeUtil.getChars(input));	}
public <T> List<T> parseAsList(final String string, final Class<T> componentType) {		return new JsonParser()			.map(JsonParser.VALUES, componentType)			.parse(string);	}
public <K, V> Map<K, V> parseAsMap(		final String string, final Class<K> keyType, final Class<V> valueType) {		return new JsonParser()			.map(JsonParser.KEYS, keyType)			.map(JsonParser.VALUES, valueType)			.parse(string);	}
@SuppressWarnings("unchecked")	public <T> T parse(final char[] input, final Class<T> targetType) {		rootType = targetType;		return _parse(input);	}
protected Object parseValue(final Class targetType, final Class keyType, final Class componentType) {		final ValueConverter valueConverter;		final char c = input[ndx];		switch (c) {			case '\'':				if (!looseMode) {					break;				}			case '"':				ndx++;				Object string = parseStringContent(c);				valueConverter = lookupValueConverter();				if (valueConverter != null) {					return valueConverter.convert(string);				}				if (targetType != null && targetType != String.class) {					string = convertType(string, targetType);				}				return string;			case '{':				ndx++;				if (lazy) {					if (notFirstObject) {						final Object value = new ObjectParser(this, targetType, keyType, componentType);						skipObject();						return value;					}					else {						notFirstObject = true;					}				}				return parseObjectContent(targetType, keyType, componentType);			case '[':				ndx++;				return parseArrayContent(targetType, componentType);			case '0':			case '1':			case '2':			case '3':			case '4':			case '5':			case '6':			case '7':			case '8':			case '9':			case '-':				Object number = parseNumber();				valueConverter = lookupValueConverter();				if (valueConverter != null) {					return valueConverter.convert(number);				}				if (targetType != null) {					number = convertType(number, targetType);				}				return number;			case 'n':				ndx++;				if (match(N_ULL)) {					valueConverter = lookupValueConverter();					if (valueConverter != null) {						return valueConverter.convert(null);					}					return null;				}				break;			case 't':				ndx++;				if (match(T_RUE)) {					Object value = Boolean.TRUE;					valueConverter = lookupValueConverter();					if (valueConverter != null) {						return valueConverter.convert(value);					}					if (targetType != null) {						value = convertType(value, targetType);					}					return value;				}				break;			case 'f':				ndx++;				if (match(F_ALSE)) {					Object value = Boolean.FALSE;					valueConverter = lookupValueConverter();					if (valueConverter != null) {						return valueConverter.convert(value);					}					if (targetType != null) {						value = convertType(value, targetType);					}					return value;				}				break;		}		if (looseMode) {			// try to parse unquoted string			Object string = parseUnquotedStringContent();			valueConverter = lookupValueConverter();			if (valueConverter != null) {				return valueConverter.convert(string);			}			if (targetType != null && targetType != String.class) {				string = convertType(string, targetType);			}			return string;		}		syntaxError("Invalid char: " + input[ndx]);		return null;	}
private Object resolveLazyValue(Object value) {		if (value instanceof Supplier) {			value = ((Supplier)value).get();		}		return value;	}
private void skipObject() {		int bracketCount = 1;		boolean insideString = false;		while (ndx < total) {			final char c = input[ndx];			if (insideString) {				if (c == '\"' && notPrecededByEvenNumberOfBackslashes()) {					insideString = false;				}			} else if (c == '\"') {				insideString = true;			} else if (c == '{') {				bracketCount++;			} else if (c == '}') {				bracketCount--;				if (bracketCount == 0) {					ndx++;					return;				}			}			ndx++;		}	}
protected String parseString() {		char quote = '\"';		if (looseMode) {			quote = consumeOneOf('\"', '\'');			if (quote == 0) {				return parseUnquotedStringContent();			}		} else {			consume(quote);		}		return parseStringContent(quote);	}
protected String parseStringContent(final char quote) {		final int startNdx = ndx;		// roll-out until the end of the string or the escape char		while (true) {			final char c = input[ndx];			if (c == quote) {				// no escapes found, just use existing string				ndx++;				return new String(input, startNdx, ndx - 1 - startNdx);			}			if (c == '\\') {				break;			}			ndx++;		}		// escapes found, proceed differently		textLen = ndx - startNdx;		growEmpty();//		for (int i = startNdx, j = 0; j < textLen; i++, j++) {//			text[j] = input[i];//		}		System.arraycopy(input, startNdx, text, 0, textLen);		// escape char, process everything until the end		while (true) {			char c = input[ndx];			if (c == quote) {				// done				ndx++;				final String str = new String(text, 0, textLen);				textLen = 0;				return str;			}			if (c == '\\') {				// escape char found				ndx++;				c = input[ndx];				switch (c) {					case '\"' : c = '\"'; break;					case '\\' : c = '\\'; break;					case '/' : c = '/'; break;					case 'b' : c = '\b'; break;					case 'f' : c = '\f'; break;					case 'n' : c = '\n'; break;					case 'r' : c = '\r'; break;					case 't' : c = '\t'; break;					case 'u' :						ndx++;						c = parseUnicode();						break;					default:						if (looseMode) {							if (c != '\'') {								c = '\\';								ndx--;							}						}						else {							syntaxError("Invalid escape char: " + c);						}				}			}			text[textLen] = c;			textLen++;			growAndCopy();			ndx++;		}	}
protected void growAndCopy() {		if (textLen == text.length) {			int newSize = text.length << 1;			char[] newText = new char[newSize];			if (textLen > 0) {				System.arraycopy(text, 0, newText, 0, textLen);			}			text = newText;		}	}
protected char parseUnicode() {		int i0 = CharUtil.hex2int(input[ndx++]);		int i1 = CharUtil.hex2int(input[ndx++]);		int i2 = CharUtil.hex2int(input[ndx++]);		int i3 = CharUtil.hex2int(input[ndx]);		return (char) ((i0 << 12) + (i1 << 8) + (i2 << 4) + i3);	}
protected String parseUnquotedStringContent() {		final int startNdx = ndx;		while (true) {			final char c = input[ndx];			if (c <= ' ' || CharUtil.equalsOne(c, UNQUOTED_DELIMETERS)) {				final int currentNdx = ndx;				// done				skipWhiteSpaces();				return new String(input, startNdx, currentNdx - startNdx);			}			ndx++;		}	}
protected Number parseNumber() {		final int startIndex = ndx;		char c = input[ndx];		boolean isDouble = false;		boolean isExp = false;		if (c == '-') {			ndx++;		}		while (true) {			if (isEOF()) {				break;			}			c = input[ndx];			if (c >= '0' && c <= '9') {				ndx++;				continue;			}			if (c <= 32) {		// white space				break;			}			if (c == ',' || c == '}' || c == ']') {	// delimiter				break;			}			if (c == '.') {				isDouble = true;			}			else if (c == 'e' || c == 'E') {				isExp = true;			}			ndx++;		}		final String value = new String(input, startIndex, ndx - startIndex);		if (isDouble) {			return Double.valueOf(value);		}		long longNumber;		if (isExp) {			longNumber = Double.valueOf(value).longValue();		}		else {			if (value.length() >= 19) {				// if string is 19 chars and longer, it can be over the limit				BigInteger bigInteger = new BigInteger(value);				if (isGreaterThanLong(bigInteger)) {					return bigInteger;				}				longNumber = bigInteger.longValue();			}			else {				longNumber = Long.parseLong(value);			}		}		if ((longNumber >= Integer.MIN_VALUE) && (longNumber <= Integer.MAX_VALUE)) {			return (int) longNumber;		}		return longNumber;	}
protected Object parseArrayContent(Class targetType, Class componentType) {		// detect special case		if (targetType == Object.class) {			targetType = List.class;		}		// continue		targetType = replaceWithMappedTypeForPath(targetType);		if (componentType == null && targetType != null && targetType.isArray()) {			componentType = targetType.getComponentType();		}		path.push(VALUES);		componentType = replaceWithMappedTypeForPath(componentType);		Collection<Object> target = newArrayInstance(targetType);		boolean koma = false;		mainloop:		while (true) {			skipWhiteSpaces();			char c = input[ndx];			if (c == ']') {				if (koma) {					syntaxError("Trailing comma");				}				ndx++;				path.pop();				return target;			}			Object value = parseValue(componentType, null, null);			target.add(value);			skipWhiteSpaces();			c = input[ndx];			switch (c) {				case ']': ndx++; break mainloop;				case ',': ndx++; koma = true; break;				default: syntaxError("Invalid char: expected ] or ,");			}		}		path.pop();		if (targetType != null) {			return convertType(target, targetType);		}		return target;	}
protected Object parseObjectContent(Class targetType, Class valueKeyType, Class valueType) {		// detect special case		if (targetType == Object.class) {			targetType = Map.class;		}		// continue		targetType = replaceWithMappedTypeForPath(targetType);		Object target;		boolean isTargetTypeMap = true;		boolean isTargetRealTypeMap = true;		ClassDescriptor targetTypeClassDescriptor = null;		TypeData typeData = null;		if (targetType != null) {			targetTypeClassDescriptor = ClassIntrospector.get().lookup(targetType);			// find if the target is really a map			// because when classMetadataName != null we are forcing			// map usage locally in this method			isTargetRealTypeMap = targetTypeClassDescriptor.isMap();			typeData = jsonAnnotationManager.lookupTypeData(targetType);		}		if (isTargetRealTypeMap) {			// resolve keys only for real maps			path.push(KEYS);			valueKeyType = replaceWithMappedTypeForPath(valueKeyType);			path.pop();		}		if (classMetadataName == null) {			// create instance of target type, no 'class' information			target = newObjectInstance(targetType);			isTargetTypeMap = isTargetRealTypeMap;		} else {			// all beans will be created first as a map			target = mapSupplier.get();		}		boolean koma = false;		mainloop:		while (true) {			skipWhiteSpaces();			char c = input[ndx];			if (c == '}') {				if (koma) {					syntaxError("Trailing comma");				}				ndx++;				break;			}			koma = false;			String key = parseString();			String keyOriginal = key;			skipWhiteSpaces();			consume(':');			skipWhiteSpaces();			// read the type of the simple property			PropertyDescriptor pd = null;			Class propertyType = null;			Class keyType = null;			Class componentType = null;			// resolve simple property			if (!isTargetRealTypeMap) {				// replace key with real property value				key = jsonAnnotationManager.resolveRealName(targetType, key);			}			if (!isTargetTypeMap) {				pd = targetTypeClassDescriptor.getPropertyDescriptor(key, true);				if (pd != null) {					propertyType = pd.getType();					keyType = pd.resolveKeyType(true);					componentType = pd.resolveComponentType(true);				}			}			Object value;			if (!isTargetTypeMap) {				// *** inject into bean					path.push(key);					value = parseValue(propertyType, keyType, componentType);					path.pop();				if (typeData.rules.match(keyOriginal, !typeData.strict)) {					if (pd != null) {						if (lazy) {							// need to resolve lazy value before injecting objects into it							value = resolveLazyValue(value);						}						// only inject values if target property exist						injectValueIntoObject(target, pd, value);					}				}			}			else {				Object keyValue = key;				if (valueKeyType != null) {					keyValue = convertType(key, valueKeyType);				}				// *** add to map				if (isTargetRealTypeMap) {					path.push(VALUES, key);					valueType = replaceWithMappedTypeForPath(valueType);				} else {					path.push(key);				}				value = parseValue(valueType, null, null);				path.pop();				((Map) target).put(keyValue, value);			}			skipWhiteSpaces();			c = input[ndx];			switch (c) {				case '}': ndx++; break mainloop;				case ',': ndx++; koma = true; break;				default: syntaxError("Invalid char: expected } or ,");			}		}		// done		// convert Map to target type		if (classMetadataName != null) {			target = mapToBean.map2bean((Map) target, targetType);		}		return target;	}
protected char consumeOneOf(final char c1, final char c2) {		char c = input[ndx];		if ((c != c1) && (c != c2)) {			return 0;		}		ndx++;		return c;	}
protected final boolean match(final char[] target) {		for (char c : target) {			if (input[ndx] != c) {				return false;			}			ndx++;		}		return true;	}
protected void syntaxError(final String message) {		String left = "...";		String right = "...";		int offset = 10;		int from = ndx - offset;		if (from < 0) {			from = 0;			left = StringPool.EMPTY;		}		int to = ndx + offset;		if (to > input.length) {			to = input.length;			right = StringPool.EMPTY;		}		final CharSequence str = CharArraySequence.of(input, from, to - from);		throw new JsonException(				"Syntax error! " + message + "\n" +				"offset: " + ndx + " near: \"" + left + str + right + "\"");	}
@Override	public void visit(final int version, int access, final String name, final String signature, final String superName, String[] interfaces) {		wd.init(name, superName, this.suffix, this.reqProxyClassName);		// no superclass		wd.superName = AsmUtil.SIGNATURE_JAVA_LANG_OBJECT;		// change access of destination		access &= ~AsmUtil.ACC_ABSTRACT;		access &= ~AsmUtil.ACC_INTERFACE;		// write destination class		if (targetClassOrInterface.isInterface()) {			// target is interface			wd.wrapInterface = true;			interfaces = new String[] {targetClassOrInterface.getName().replace('.', '/')};		} else {			// target is class			wd.wrapInterface = false;			if (targetInterface != null) {				// interface provided				interfaces = new String[] {targetInterface.getName().replace('.', '/')};			} else {				// no interface provided, use all				//interfaces = null;			}		}		final int v = ProxettaAsmUtil.resolveJavaVersion(version);		wd.dest.visit(v, access, wd.thisReference, signature, wd.superName, interfaces);		wd.proxyAspects = new ProxyAspectData[aspects.length];		for (int i = 0; i < aspects.length; i++) {			wd.proxyAspects[i] = new ProxyAspectData(wd, aspects[i], i);		}		// create new field wrapper field and store it's reference into work-data		wd.wrapperRef = targetFieldName;		wd.wrapperType = 'L' + name + ';';		if (createTargetInDefaultCtor) {			// create private, final field			final FieldVisitor fv = wd.dest.visitField(AsmUtil.ACC_PRIVATE | AsmUtil.ACC_FINAL, wd.wrapperRef, wd.wrapperType, null, null);			fv.visitEnd();			createEmptyCtorThatCreatesTarget();		}		else {			// create public, non-final field			final FieldVisitor fv = wd.dest.visitField(AsmUtil.ACC_PUBLIC, wd.wrapperRef, wd.wrapperType, null, null);			fv.visitEnd();			createEmptyCtor();		}	}
protected void createEmptyCtor() {		final MethodVisitor mv = wd.dest.visitMethod(AsmUtil.ACC_PUBLIC, INIT, "()V", null, null);		mv.visitCode();		mv.visitVarInsn(Opcodes.ALOAD, 0);		mv.visitMethodInsn(			Opcodes.INVOKESPECIAL,			AsmUtil.SIGNATURE_JAVA_LANG_OBJECT,			INIT, "()V",			false);		mv.visitInsn(Opcodes.RETURN);		mv.visitMaxs(1, 1);		mv.visitEnd();	}
@Override	public MethodVisitor visitMethod(final int access, final String name, final String desc, final String signature, final String[] exceptions) {		MethodSignatureVisitor msign = targetClassInfo.lookupMethodSignatureVisitor(access, name, desc, wd.superReference);		if (msign == null) {			return null;		}		// ignore all destination constructors		if (name.equals(INIT)) {			return null;		}		// ignore all destination static block		if (name.equals(CLINIT)) {			return null;		}		// skip all static methods		if (Modifier.isStatic(access)) {			return null;		}		return applyProxy(msign);	}
protected void createSimpleMethodWrapper(final MethodSignatureVisitor msign) {		int access = msign.getAccessFlags();		access &= ~ACC_ABSTRACT;		access &= ~ACC_NATIVE;		MethodVisitor mv = wd.dest.visitMethod(				access, msign.getMethodName(), msign.getDescription(), msign.getAsmMethodSignature(), msign.getExceptions());		mv.visitCode();		mv.visitVarInsn(ALOAD, 0);		mv.visitFieldInsn(GETFIELD, wd.thisReference, wd.wrapperRef, wd.wrapperType);		loadVirtualMethodArguments(mv, msign);		if (wd.wrapInterface) {			mv.visitMethodInsn(				INVOKEINTERFACE,				wd.wrapperType.substring(1, wd.wrapperType.length() - 1),				msign.getMethodName(),				msign.getDescription(),				true);		} else {			mv.visitMethodInsn(				INVOKEVIRTUAL,				wd.wrapperType.substring(1, wd.wrapperType.length() - 1),				msign.getMethodName(),				msign.getDescription(),				false);		}		ProxettaAsmUtil.prepareReturnValue(mv, msign, 0);		visitReturn(mv, msign, true);		mv.visitMaxs(0, 0);		mv.visitEnd();	}
@Override	public String getSignature() {		if (signature == null) {			String decl = getDeclaration();			int ndx = decl.indexOf(')');			ndx++;			String retType = decl.substring(ndx);			StringBuilder methodDeclaration = new StringBuilder(50);			methodDeclaration.append(retType).append(' ').append(methodName).append(decl, 0, ndx);			String exceptionsAsString = getExceptionsAsString();			if (exceptionsAsString != null) {				methodDeclaration.append(" throws ").append(exceptionsAsString);			}			signature = methodDeclaration.toString();		}		return signature;	}
private String resolveRawTypeName(String typeName) {		if (typeName == null) {			return null;		}		boolean isArray = typeName.startsWith(StringPool.LEFT_SQ_BRACKET);		if (isArray) {			typeName = typeName.substring(1);		}		String rawTypeName;		if (generics.containsKey(typeName)) {			rawTypeName = generics.get(typeName);		}		else {			rawTypeName = declaredTypeGeneric.getOrDefault(typeName, typeName);		}		if (isArray) {			rawTypeName = '[' + rawTypeName;		}		return rawTypeName;	}
public BeanReferences resolveReferenceFromValue(final PropertyDescriptor propertyDescriptor, final String refName) {		BeanReferences references;		if (refName == null || refName.isEmpty()) {			references = buildDefaultReference(propertyDescriptor);		}		else {			references = BeanReferences.of(refName);		}		references = references.removeDuplicateNames();		return references;	}
public BeanReferences[] resolveReferenceFromValues(final Executable methodOrCtor, final String... parameterReferences) {		BeanReferences[] references = convertRefToReferences(parameterReferences);		if (references == null || references.length == 0) {			references = buildDefaultReferences(methodOrCtor);		}		if (methodOrCtor.getParameterTypes().length != references.length) {			throw new PetiteException("Different number of method parameters and references for: " +				methodOrCtor.getDeclaringClass().getName() + '#' + methodOrCtor.getName());		}		removeAllDuplicateNames(references);		return references;	}
public BeanReferences readReferenceFromAnnotation(final PropertyDescriptor propertyDescriptor) {		final MethodDescriptor writeMethodDescriptor = propertyDescriptor.getWriteMethodDescriptor();		final FieldDescriptor fieldDescriptor = propertyDescriptor.getFieldDescriptor();		PetiteInject ref = null;		if (writeMethodDescriptor != null) {			ref = writeMethodDescriptor.getMethod().getAnnotation(PetiteInject.class);		}		if (ref == null && fieldDescriptor != null) {			ref = fieldDescriptor.getField().getAnnotation(PetiteInject.class);		}		if (ref == null) {			return null;		}		BeanReferences reference = null;		String name = ref.value().trim();		if (name.length() != 0) {			reference = BeanReferences.of(name);		}		reference = updateReferencesWithDefaultsIfNeeded(propertyDescriptor, reference);		reference = reference.removeDuplicateNames();		return reference;	}
public BeanReferences[] readAllReferencesFromAnnotation(final Executable methodOrCtor) {		PetiteInject petiteInject = methodOrCtor.getAnnotation(PetiteInject.class);		final Parameter[] parameters = methodOrCtor.getParameters();		BeanReferences[] references;		final boolean hasAnnotationOnMethodOrCtor;		if (petiteInject != null) {			references = convertAnnValueToReferences(petiteInject.value());			hasAnnotationOnMethodOrCtor = true;		}		else {			references = new BeanReferences[parameters.length];			hasAnnotationOnMethodOrCtor = false;		}		int parametersWithAnnotationCount = 0;		for (int i = 0; i < parameters.length; i++) {			Parameter parameter = parameters[i];			petiteInject = parameter.getAnnotation(PetiteInject.class);			if (petiteInject == null) {				// no annotation on argument				continue;			}			// there is annotation on argument, override values			String annotationValue = readAnnotationValue(petiteInject);			if (annotationValue != null) {				references[i] = BeanReferences.of(annotationValue);			}			parametersWithAnnotationCount++;		}		if (!hasAnnotationOnMethodOrCtor) {			if (parametersWithAnnotationCount == 0) {				return null;			}			if (parametersWithAnnotationCount != parameters.length) {				throw new PetiteException("All arguments must be annotated with PetiteInject");			}		}		references = updateReferencesWithDefaultsIfNeeded(methodOrCtor, references);		removeAllDuplicateNames(references);		return references;	}
private String readAnnotationValue(final PetiteInject annotation) {		String value = annotation.value().trim();		if (value.isEmpty()) {			return null;		}		return value;	}
private BeanReferences[] buildDefaultReferences(final Executable methodOrCtor) {		final boolean useParamo = petiteConfig.getUseParamo();		final PetiteReferenceType[] lookupReferences = petiteConfig.getLookupReferences();		MethodParameter[] methodParameters = null;		if (useParamo) {			methodParameters = Paramo.resolveParameters(methodOrCtor);		}		final Class[] paramTypes = methodOrCtor.getParameterTypes();		final BeanReferences[] references = new BeanReferences[paramTypes.length];		for (int j = 0; j < paramTypes.length; j++) {			String[] ref = new String[lookupReferences.length];			references[j] = BeanReferences.of(ref);			for (int i = 0; i < ref.length; i++) {				switch (lookupReferences[i]) {					case NAME:						ref[i] = methodParameters != null ? methodParameters[j].getName() : null;						break;					case TYPE_SHORT_NAME:						ref[i] = StringUtil.uncapitalize(paramTypes[j].getSimpleName());						break;					case TYPE_FULL_NAME:						ref[i] = paramTypes[j].getName();						break;				}			}		}		return references;	}
public BeanReferences buildDefaultReference(final PropertyDescriptor propertyDescriptor) {		final PetiteReferenceType[] lookupReferences = petiteConfig.getLookupReferences();		final String[] references = new String[lookupReferences.length];		for (int i = 0; i < references.length; i++) {			switch (lookupReferences[i]) {				case NAME:					references[i] = propertyDescriptor.getName();					break;				case TYPE_SHORT_NAME:					references[i] = StringUtil.uncapitalize(propertyDescriptor.getType().getSimpleName());					break;				case TYPE_FULL_NAME:					references[i] = propertyDescriptor.getType().getName();					break;			}		}		return BeanReferences.of(references);	}
private void removeAllDuplicateNames(final BeanReferences[] allBeanReferences) {		for (int i = 0; i < allBeanReferences.length; i++) {			BeanReferences references = allBeanReferences[i];			allBeanReferences[i] = references.removeDuplicateNames();		}	}
private BeanReferences[] convertRefToReferences(final String[] references) {		if (references == null) {			return null;		}		BeanReferences[] ref = new BeanReferences[references.length];		for (int i = 0; i < references.length; i++) {			ref[i] = BeanReferences.of(references[i]);		}		return ref;	}
private BeanReferences[] convertAnnValueToReferences(String value) {		if (value == null) {			return null;		}		value = value.trim();		if (value.length() == 0) {			return null;		}		String[] refNames = Converter.get().toStringArray(value);		BeanReferences[] references = new BeanReferences[refNames.length];		for (int i = 0; i < refNames.length; i++) {			references[i] = BeanReferences.of(refNames[i].trim());		}		return references;	}
public void runJoy(final Consumer<JoddJoyRuntime> consumer) {		final JoddJoy joddJoy = new JoddJoy();		final JoddJoyRuntime joyRuntime = joddJoy.startOnlyBackend();		joddJoy.withDb(joyDb -> setJtxManager(joyRuntime.getJtxManager()));		final JtxTransaction tx = startRwTx();		final Print print = new Print();		try {			print.line("START", 80);			print.newLine();			consumer.accept(joyRuntime);			print.newLine();			print.line("END", 80);			if (tx != null) {				tx.commit();			}		} catch (Throwable throwable) {			throwable.printStackTrace();			if (tx != null) {				tx.rollback();			}		}		joddJoy.stop();	}
private JtxTransaction startRwTx() {		if (jtxManager == null) {			return null;		}		return jtxManager.requestTransaction(new JtxTransactionMode(JtxPropagationBehavior.PROPAGATION_REQUIRED, false));	}
public static Method findMethod(final Class c, final String methodName) {		return findDeclaredMethod(c, methodName, true);	}
public static <T> Constructor<T> findConstructor(final Class<T> clazz, final Class<?>... parameterTypes) {		final Constructor<?>[] constructors = clazz.getConstructors();		Class<?>[] pts;		for (Constructor<?> constructor : constructors) {			pts = constructor.getParameterTypes();			if (isAllAssignableFrom(pts, parameterTypes)) {				return (Constructor<T>) constructor;			}		}		return null;	}
public static boolean isAllAssignableFrom(final Class<?>[] typesTarget, final Class<?>[] typesFrom) {		if (typesTarget.length == typesFrom.length) {			for (int i = 0; i < typesTarget.length; i++) {				if (!typesTarget[i].isAssignableFrom(typesFrom[i])) {					return false;				}			}			return true;		}		return false;	}
public static Class[] getClasses(final Object... objects) {		if (objects.length == 0) {			return EMPTY_CLASS_ARRAY;		}		Class[] result = new Class[objects.length];		for (int i = 0; i < objects.length; i++) {			if (objects[i] != null) {				result[i] = objects[i].getClass();			}		}		return result;	}
public static boolean isTypeOf(final Class<?> lookupClass, final Class<?> targetClass) {		if (targetClass == null || lookupClass == null) {			return false;		}		return targetClass.isAssignableFrom(lookupClass);	}
public static boolean isInstanceOf(final Object object, final Class target) {		if (object == null || target == null) {			return false;		}		return target.isInstance(object);	}
public static Class[] resolveAllInterfaces(final Class type) {		Set<Class> bag = new LinkedHashSet<>();		_resolveAllInterfaces(type, bag);		return bag.toArray(new Class[0]);	}
public static Class[] resolveAllSuperclasses(Class type) {		List<Class> list = new ArrayList<>();		while (true) {			type = type.getSuperclass();			if ((type == null) || (type == Object.class)) {				break;			}			list.add(type);		}		return list.toArray(new Class[0]);	}
public static Method[] getAccessibleMethods(Class clazz, final Class limit) {		Package topPackage = clazz.getPackage();		List<Method> methodList = new ArrayList<>();		int topPackageHash = topPackage == null ? 0 : topPackage.hashCode();		boolean top = true;		do {			if (clazz == null) {				break;			}			Method[] declaredMethods = clazz.getDeclaredMethods();			for (Method method : declaredMethods) {				if (Modifier.isVolatile(method.getModifiers())) {				    continue;				}//				if (Modifier.isAbstract(method.getModifiers())) {//					continue;//				}				if (top) {				// add all top declared methods					methodList.add(method);					continue;				}				int modifier = method.getModifiers();				if (Modifier.isPrivate(modifier)) {					continue;										// ignore super private methods				}				if (Modifier.isAbstract(modifier)) {		// ignore super abstract methods					continue;				}				if (Modifier.isPublic(modifier)) {					addMethodIfNotExist(methodList, method);		// add super public methods					continue;				}				if (Modifier.isProtected(modifier)) {					addMethodIfNotExist(methodList, method);		// add super protected methods					continue;				}				// add super default methods from the same package				Package pckg = method.getDeclaringClass().getPackage();				int pckgHash = pckg == null ? 0 : pckg.hashCode();				if (pckgHash == topPackageHash) {					addMethodIfNotExist(methodList, method);				}			}			top = false;		} while ((clazz = clazz.getSuperclass()) != limit);		Method[] methods = new Method[methodList.size()];		for (int i = 0; i < methods.length; i++) {			methods[i] = methodList.get(i);		}		return methods;	}
public static Method[] getSupportedMethods(final Class clazz, final Class limit) {		final ArrayList<Method> supportedMethods = new ArrayList<>();		for (Class c = clazz; c != limit && c!= null; c = c.getSuperclass()) {			final Method[] methods = c.getDeclaredMethods();			for (final Method method : methods) {				boolean found = false;				for (final Method supportedMethod : supportedMethods) {					if (compareSignatures(method, supportedMethod)) {						found = true;						break;					}				}				if (!found) {					supportedMethods.add(method);				}			}		}		return supportedMethods.toArray(new Method[0]);	}
public static boolean compareDeclarations(final Method first, final Method second) {		if (first.getReturnType() != second.getReturnType()) {			return false;		}		return compareSignatures(first, second);	}
public static boolean compareSignatures(final Method first, final Method second) {		if (!first.getName().equals(second.getName())) {			return false;		}		return compareParameters(first.getParameterTypes(), second.getParameterTypes());	}
public static boolean compareParameters(final Class[] first, final Class[] second) {		if (first.length != second.length) {			return false;		}		for (int i = 0; i < first.length; i++) {			if (first[i] != second[i]) {				return false;			}		}		return true;	}
public static void forceAccess(final AccessibleObject accObject) {		try {			if (System.getSecurityManager() == null)				accObject.setAccessible(true);			else {				AccessController.doPrivileged((PrivilegedAction) () -> {					accObject.setAccessible(true);					return null;				});			}		} catch (SecurityException sex) {			// ignore		}	}
public static boolean isPublicPublic(final Member member) {		if (Modifier.isPublic(member.getModifiers())) {			if (Modifier.isPublic(member.getDeclaringClass().getModifiers())) {				return true;			}		}		return false;	}
@SuppressWarnings("unchecked")	public static <T> T newInstance(final Class<T> clazz, final Object... params) throws InstantiationException, IllegalAccessException, InvocationTargetException, NoSuchMethodException {		if (params.length == 0) {			return newInstance(clazz);		}		final Class<?>[] paramTypes = getClasses(params);		final Constructor<?> constructor = findConstructor(clazz, paramTypes);		if (constructor == null) {			throw new InstantiationException("No constructor matched parameter types.");		}		return (T) constructor.newInstance(params);	}
@SuppressWarnings("unchecked")	public static <T> T newInstance(final Class<T> type) throws IllegalAccessException, InstantiationException, NoSuchMethodException, InvocationTargetException {		if (type.isPrimitive()) {			if (type == int.class) {				return (T) Integer.valueOf(0);			}			if (type == long.class) {				return (T) Long.valueOf(0);			}			if (type == boolean.class) {				return (T) Boolean.FALSE;			}			if (type == float.class) {				return (T) Float.valueOf(0);			}			if (type == double.class) {				return (T) Double.valueOf(0);			}			if (type == byte.class) {				return (T) Byte.valueOf((byte) 0);			}			if (type == short.class) {				return (T) Short.valueOf((short) 0);			}			if (type == char.class) {				return (T) Character.valueOf((char) 0);			}			throw new IllegalArgumentException("Invalid primitive: " + type);		}		if (type.getName().startsWith("java.")) {			if (type == Integer.class) {				return (T) Integer.valueOf(0);			}			if (type == String.class) {				return (T) StringPool.EMPTY;			}			if (type == Long.class) {				return (T) Long.valueOf(0);			}			if (type == Boolean.class) {				return (T) Boolean.FALSE;			}			if (type == Float.class) {				return (T) Float.valueOf(0);			}			if (type == Double.class) {				return (T) Double.valueOf(0);			}			if (type == Map.class) {				return (T) new HashMap();			}			if (type == List.class) {				return (T) new ArrayList();			}			if (type == Set.class) {				return (T) new HashSet();			}			if (type == Collection.class) {				return (T) new ArrayList();			}			if (type == Byte.class) {				return (T) Byte.valueOf((byte) 0);			}			if (type == Short.class) {				return (T) Short.valueOf((short) 0);			}			if (type == Character.class) {				return (T) Character.valueOf((char) 0);			}		}		if (type.isEnum()) {			return type.getEnumConstants()[0];		}		if (type.isArray()) {			return (T) Array.newInstance(type.getComponentType(), 0);		}		Constructor<T> declaredConstructor = type.getDeclaredConstructor();		forceAccess(declaredConstructor);		return declaredConstructor.newInstance();	}
public static boolean isAssignableFrom(final Member member1, final Member member2) {		return member1.getDeclaringClass().isAssignableFrom(member2.getDeclaringClass());	}
public static Class[] getSuperclasses(final Class type) {		int i = 0;		for (Class x = type.getSuperclass(); x != null; x = x.getSuperclass()) {			i++;		}		Class[] result = new Class[i];		i = 0;		for (Class x = type.getSuperclass(); x != null; x = x.getSuperclass()) {			result[i] = x;			i++;		}		return result;	}
public static boolean isBeanProperty(final Method method) {		if (isObjectMethod(method)) {			return false;		}		String methodName = method.getName();		Class returnType = method.getReturnType();		Class[] paramTypes =  method.getParameterTypes();		if (methodName.startsWith(METHOD_GET_PREFIX)) {		// getter method must starts with 'get' and it is not getClass()			if ((returnType != null) && (paramTypes.length == 0)) {	// getter must have a return type and no arguments				return true;			}		} else if (methodName.startsWith(METHOD_IS_PREFIX)) {		    // ister must starts with 'is'			if ((returnType != null)  && (paramTypes.length == 0)) {	// ister must have return type and no arguments				return true;			}		} else if (methodName.startsWith(METHOD_SET_PREFIX)) {	// setter must start with a 'set'			if (paramTypes.length == 1) {				        // setter must have just one argument				return true;			}		}		return false;	}
public static String getBeanPropertyGetterName(final Method method) {		int prefixLength = getBeanPropertyGetterPrefixLength(method);		if (prefixLength == 0) {			return null;		}		String methodName = method.getName().substring(prefixLength);		return StringUtil.decapitalize(methodName);	}
public static String getBeanPropertySetterName(final Method method) {		int prefixLength = getBeanPropertySetterPrefixLength(method);		if (prefixLength == 0) {			return null;		}		String methodName = method.getName().substring(prefixLength);		return StringUtil.decapitalize(methodName);	}
public static Class getComponentType(final Type type, final Class implClass, int index) {		Class[] componentTypes = getComponentTypes(type, implClass);		if (componentTypes == null) {			return null;		}		if (index < 0) {			index += componentTypes.length;		}		if (index >= componentTypes.length) {			return null;		}		return componentTypes[index];	}
public static Class[] getComponentTypes(final Type type, final Class implClass) {		if (type instanceof Class) {			Class clazz = (Class) type;			if (clazz.isArray()) {				return new Class[] {clazz.getComponentType()};			}		}		else if (type instanceof ParameterizedType) {			ParameterizedType pt = (ParameterizedType) type;			Type[] generics = pt.getActualTypeArguments();			if (generics.length == 0) {				return null;			}			Class[] types = new Class[generics.length];			for (int i = 0; i < generics.length; i++) {				types[i] = getRawType(generics[i], implClass);			}			return types;		}		else if (type instanceof GenericArrayType) {			GenericArrayType gat = (GenericArrayType) type;			Class rawType = getRawType(gat.getGenericComponentType(), implClass);			if (rawType == null) {				return null;			}			return new Class[] {rawType};		}		return null;	}
public static String typeToString(final Type type) {		StringBuilder sb = new StringBuilder();		typeToString(sb, type, new HashSet<Type>());		return sb.toString();	}
public static Object readAnnotationValue(final Annotation annotation, final String name) {		try {			Method method  = annotation.annotationType().getDeclaredMethod(name);			return method.invoke(annotation);		} catch (Exception ignore) {			return null;		}	}
public static Class getCallerClass(int framesToSkip) {		if (SECURITY_MANAGER != null) {			return SECURITY_MANAGER.getCallerClass(framesToSkip);		}		StackTraceElement[] stackTraceElements = new Throwable().getStackTrace();		if (framesToSkip >= 2) {			framesToSkip += 4;		}		String className = stackTraceElements[framesToSkip].getClassName();		try {			return Thread.currentThread().getContextClassLoader().loadClass(className);		} catch (ClassNotFoundException cnfex) {			throw new UnsupportedOperationException(className + " not found.");		}	}
public static Class getCallerClass() {		String className = null;		StackTraceElement[] stackTraceElements = new Throwable().getStackTrace();		for (StackTraceElement stackTraceElement : stackTraceElements) {			className = stackTraceElement.getClassName();			String methodName = stackTraceElement.getMethodName();			if (methodName.equals("loadClass")) {				if (className.contains(ClassLoaderStrategy.class.getSimpleName())) {					continue;				}				if (className.equals(ClassLoaderUtil.class.getName())) {					continue;				}			} else if (methodName.equals("getCallerClass")) {				continue;			}			break;		}		try {			return Thread.currentThread().getContextClassLoader().loadClass(className);		} catch (ClassNotFoundException cnfex) {			throw new UnsupportedOperationException(className + " not found.");		}	}
public static Class findEnum(Class target) {		if (target.isPrimitive()) {			return null;		}		while (target != Object.class) {			if (target.isEnum()) {				return target;			}			target = target.getSuperclass();		}		return null;	}
public static Class<?> childClassOf(final Class<?> parentClass, final Object instance) {		if (instance == null || instance == Object.class) {			return null;		}		if (parentClass != null) {			if (parentClass.isInterface()) {				return null;			}		}		Class<?> childClass = instance.getClass();		while (true) {			Class<?> parent = childClass.getSuperclass();			if (parent == parentClass) {				return childClass;			}			if (parent == null) {				return null;			}			childClass = parent;		}	}
public static JarFile jarFileOf(final Class<?> klass) {		URL url = klass.getResource(			"/" + klass.getName().replace('.', '/') + ".class");		if (url == null) {			return null;		}		String s = url.getFile();		int beginIndex = s.indexOf("file:") + "file:".length();		int endIndex = s.indexOf(".jar!");		if (endIndex == -1) {			return null;		}		endIndex += ".jar".length();		String f = s.substring(beginIndex, endIndex);		// decode URL string - it may contain encoded chars (e.g. whitespaces) which are not supported for file-instances		f = URLDecoder.decode(f, "UTF-8");		File file = new File(f);		try {			return file.exists() ? new JarFile(file) : null;		} catch (IOException e) {			throw new IllegalStateException(e);		}	}
public static String convertClassNameToFileName(Class clazz) {		if (clazz.isArray()) {			clazz = clazz.getComponentType();		}		return convertClassNameToFileName(clazz.getName());	}
public static boolean isKotlinClass(final Class type) {		final Annotation[] annotations = type.getAnnotations();		for (Annotation annotation : annotations) {			if (annotation.annotationType().getName().equals("kotlin.Metadata")) {				return true;			}		}		return false;	}
public static boolean isIntegerType(final int type) {		return (type == Types.INTEGER) || (type == Types.SMALLINT) || (type == Types.TINYINT) || (type == Types.BIT);	}
public static void sleep(final long ms) {		try {			Thread.sleep(ms);		} catch (InterruptedException iex) {			Thread.currentThread().interrupt();		}	}
public static void sleep() {		try {			Thread.sleep(Long.MAX_VALUE);		} catch (InterruptedException iex) {			Thread.currentThread().interrupt();		}	}
public static void wait(final Object obj) {		synchronized (obj) {			try {				obj.wait();			} catch (InterruptedException inex) {				Thread.currentThread().interrupt();			}		}	}
public static void join(final Thread thread) {		try {			thread.join();		} catch (InterruptedException inex) {			Thread.currentThread().interrupt();		}	}
public static ThreadFactory daemonThreadFactory(final String name, final int priority) {		return new ThreadFactory() {			private AtomicInteger count = new AtomicInteger();			@Override			public Thread newThread(final Runnable r) {				Thread thread = new Thread(r);				thread.setName(name + '-' + count.incrementAndGet());				thread.setDaemon(true);				thread.setPriority(priority);				return thread;			}		};	}
@Override	public T get() {		if (!initialized) {			synchronized (this) {				if (!initialized) {					final T t = supplier.get();					value = t;					initialized = true;					supplier = null;					return t;				}			}		}		return value;	}
public void visitParameter(final String name, final int access) {    if (api < Opcodes.ASM5) {      throw new UnsupportedOperationException(REQUIRES_ASM5);    }    if (mv != null) {      mv.visitParameter(name, access);    }  }
public AnnotationVisitor visitAnnotation(final String descriptor, final boolean visible) {    if (mv != null) {      return mv.visitAnnotation(descriptor, visible);    }    return null;  }
public AnnotationVisitor visitTypeAnnotation(      final int typeRef, final TypePath typePath, final String descriptor, final boolean visible) {    if (api < Opcodes.ASM5) {      throw new UnsupportedOperationException(REQUIRES_ASM5);    }    if (mv != null) {      return mv.visitTypeAnnotation(typeRef, typePath, descriptor, visible);    }    return null;  }
public AnnotationVisitor visitParameterAnnotation(      final int parameter, final String descriptor, final boolean visible) {    if (mv != null) {      return mv.visitParameterAnnotation(parameter, descriptor, visible);    }    return null;  }
public void visitFrame(      final int type,      final int numLocal,      final Object[] local,      final int numStack,      final Object[] stack) {    if (mv != null) {      mv.visitFrame(type, numLocal, local, numStack, stack);    }  }
public void visitFieldInsn(      final int opcode, final String owner, final String name, final String descriptor) {    if (mv != null) {      mv.visitFieldInsn(opcode, owner, name, descriptor);    }  }
public void visitMethodInsn(      final int opcode,      final String owner,      final String name,      final String descriptor,      final boolean isInterface) {    if (api < Opcodes.ASM5) {      if (isInterface != (opcode == Opcodes.INVOKEINTERFACE)) {        throw new IllegalArgumentException("INVOKESPECIAL/STATIC on interfaces requires ASM5");      }      visitMethodInsn(opcode, owner, name, descriptor);      return;    }    if (mv != null) {      mv.visitMethodInsn(opcode, owner, name, descriptor, isInterface);    }  }
public void visitInvokeDynamicInsn(      final String name,      final String descriptor,      final Handle bootstrapMethodHandle,      final Object... bootstrapMethodArguments) {    if (api < Opcodes.ASM5) {      throw new UnsupportedOperationException(REQUIRES_ASM5);    }    if (mv != null) {      mv.visitInvokeDynamicInsn(name, descriptor, bootstrapMethodHandle, bootstrapMethodArguments);    }  }
public void visitJumpInsn(final int opcode, final Label label) {    if (mv != null) {      mv.visitJumpInsn(opcode, label);    }  }
public void visitMultiANewArrayInsn(final String descriptor, final int numDimensions) {    if (mv != null) {      mv.visitMultiANewArrayInsn(descriptor, numDimensions);    }  }
public void visitTryCatchBlock(      final Label start, final Label end, final Label handler, final String type) {    if (mv != null) {      mv.visitTryCatchBlock(start, end, handler, type);    }  }
public AnnotationVisitor visitLocalVariableAnnotation(      final int typeRef,      final TypePath typePath,      final Label[] start,      final Label[] end,      final int[] index,      final String descriptor,      final boolean visible) {    if (api < Opcodes.ASM5) {      throw new UnsupportedOperationException(REQUIRES_ASM5);    }    if (mv != null) {      return mv.visitLocalVariableAnnotation(          typeRef, typePath, start, end, index, descriptor, visible);    }    return null;  }
void convertToWriter(final Writer writer, final Properties properties, final Map<String, Properties> profiles)			throws IOException {		final BufferedWriter bw = getBufferedWriter(writer);		writeBaseAndProfileProperties(bw, properties, profiles);		writeProfilePropertiesThatAreNotInTheBase(bw, properties, profiles);		bw.flush();	}
@Override	public void processStream() throws IOException {		FastByteArrayOutputStream out = new FastByteArrayOutputStream();		size = 0;		if (maxFileSize == -1) {			size += input.copyAll(out);		} else {			size += input.copyMax(out, maxFileSize + 1);		// one more byte to detect larger files			if (size > maxFileSize) {				fileTooBig = true;				valid = false;				input.skipToBoundary();				return;			}		}		data = out.toByteArray();		size = data.length;		valid = true;	}
@Override	public boolean hasNext() {		if (hasNext == null) {			hasNext = Boolean.valueOf(moveToNext());		}		return hasNext.booleanValue();	}
@Override	public T next() {		if (hasNext == null) {			hasNext = Boolean.valueOf(moveToNext());		}		if (hasNext == false) {			throw new NoSuchElementException();		}		if (!entityAwareMode) {			hasNext = null;			return newElement;		}		count++;		T result = previousElement;		previousElement = newElement;		hasNext = null;		return result;	}
private boolean moveToNext() {		if (last) {			// last has been set to true, so no more rows to iterate - close everything			if (closeOnEnd) {				query.close();			} else {				query.closeResultSet(resultSetMapper.getResultSet());			}			return false;		}		while (true) {			if (!resultSetMapper.next()) {				// no more rows, no more parsing, previousElement is the last one to iterate				last = true;				return entityAwareMode;			}			// parse row			Object[] objects = resultSetMapper.parseObjects(types);			Object row = query.resolveRowResults(objects);			newElement = (T) row;			if (entityAwareMode) {				if (count == 0 && previousElement == null) {					previousElement = newElement;					continue;				}				if (previousElement != null && newElement != null) {					boolean equals;					if (newElement.getClass().isArray()) {						equals = Arrays.equals((Object[]) previousElement, (Object[]) newElement);					} else {						equals = previousElement.equals(newElement);					}					if (equals) {						continue;					}				}			}			break;		}		return true;	}
@SuppressWarnings({"unchecked"})	public static <T> T[] join(T[]... arrays) {		Class<T> componentType = (Class<T>) arrays.getClass().getComponentType().getComponentType();		return join(componentType, arrays);	}
@SuppressWarnings({"unchecked"})	public static <T> T[] join(Class<T> componentType, T[][] arrays) {		if (arrays.length == 1) {			return arrays[0];		}		int length = 0;		for (T[] array : arrays) {			length += array.length;		}		T[] result = (T[]) Array.newInstance(componentType, length);		length = 0;		for (T[] array : arrays) {			System.arraycopy(array, 0, result, length, array.length);			length += array.length;		}		return result;	}
public static double[] join(double[]... arrays) {		if (arrays.length == 0) {			return new double[0];		}		if (arrays.length == 1) {			return arrays[0];		}		int length = 0;		for (double[] array : arrays) {			length += array.length;		}		double[] result = new double[length];		length = 0;		for (double[] array : arrays) {			System.arraycopy(array, 0, result, length, array.length);			length += array.length;		}		return result;	}
public static <T> T[] resize(T[] buffer, int newSize) {		Class<T> componentType = (Class<T>) buffer.getClass().getComponentType();		T[] temp = (T[]) Array.newInstance(componentType, newSize);		System.arraycopy(buffer, 0, temp, 0, buffer.length >= newSize ? newSize : buffer.length);		return temp;	}
public static String[] resize(String[] buffer, int newSize) {		String[] temp = new String[newSize];		System.arraycopy(buffer, 0, temp, 0, buffer.length >= newSize ? newSize : buffer.length);		return temp;	}
public static <T> T[] append(T[] buffer, T newElement) {		T[] t = resize(buffer, buffer.length + 1);		t[buffer.length] = newElement;		return t;	}
@SuppressWarnings({"unchecked"})	public static <T> T[] remove(T[] buffer, int offset, int length, Class<T> componentType) {		int len2 = buffer.length - length;		T[] temp = (T[]) Array.newInstance(componentType, len2);		System.arraycopy(buffer, 0, temp, 0, offset);		System.arraycopy(buffer, offset + length, temp, offset, len2 - offset);		return temp;	}
public static boolean[] remove(boolean[] buffer, int offset, int length) {		int len2 = buffer.length - length;		boolean[] temp = new boolean[len2];		System.arraycopy(buffer, 0, temp, 0, offset);		System.arraycopy(buffer, offset + length, temp, offset, len2 - offset);		return temp;	}
public static <T> T[] subarray(T[] buffer, int offset, int length) {		Class<T> componentType = (Class<T>) buffer.getClass().getComponentType();		return subarray(buffer, offset, length, componentType);	}
@SuppressWarnings({"unchecked"})	public static <T> T[] subarray(T[] buffer, int offset, int length, Class<T> componentType) {		T[] temp = (T[]) Array.newInstance(componentType, length);		System.arraycopy(buffer, offset, temp, 0, length);		return temp;	}
public static String[] subarray(String[] buffer, int offset, int length) {		String[] temp = new String[length];		System.arraycopy(buffer, offset, temp, 0, length);		return temp;	}
public static String[] insert(String[] dest, String[] src, int offset) {		String[] temp = new String[dest.length + src.length];		System.arraycopy(dest, 0, temp, 0, offset);		System.arraycopy(src, 0, temp, offset, src.length);		System.arraycopy(dest, offset, temp, src.length + offset, dest.length - offset);		return temp;	}
public static <T> T[] insertAt(T[] dest, T[] src, int offset) {		Class<T> componentType = (Class<T>) dest.getClass().getComponentType();		return insertAt(dest, src, offset, componentType);	}
@SuppressWarnings({"unchecked"})	public static <T> T[] insertAt(T[] dest, T[] src, int offset, Class componentType) {		T[] temp = (T[]) Array.newInstance(componentType, dest.length + src.length - 1);		System.arraycopy(dest, 0, temp, 0, offset);		System.arraycopy(src, 0, temp, offset, src.length);		System.arraycopy(dest, offset + 1, temp, src.length + offset, dest.length - offset - 1);		return temp;	}
public static byte[] values(Byte[] array) {		byte[] dest = new byte[array.length];		for (int i = 0; i < array.length; i++) {			Byte v = array[i];			if (v != null) {				dest[i] = v.byteValue();			}		}		return dest;	}
public static Byte[] valuesOf(byte[] array) {		Byte[] dest = new Byte[array.length];		for (int i = 0; i < array.length; i++) {			dest[i] = Byte.valueOf(array[i]);		}		return dest;	}
public static char[] values(Character[] array) {		char[] dest = new char[array.length];		for (int i = 0; i < array.length; i++) {			Character v = array[i];			if (v != null) {				dest[i] = v.charValue();			}		}		return dest;	}
public static Character[] valuesOf(char[] array) {		Character[] dest = new Character[array.length];		for (int i = 0; i < array.length; i++) {			dest[i] = Character.valueOf(array[i]);		}		return dest;	}
public static short[] values(Short[] array) {		short[] dest = new short[array.length];		for (int i = 0; i < array.length; i++) {			Short v = array[i];			if (v != null) {				dest[i] = v.shortValue();			}		}		return dest;	}
public static Short[] valuesOf(short[] array) {		Short[] dest = new Short[array.length];		for (int i = 0; i < array.length; i++) {			dest[i] = Short.valueOf(array[i]);		}		return dest;	}
public static int[] values(Integer[] array) {		int[] dest = new int[array.length];		for (int i = 0; i < array.length; i++) {			Integer v = array[i];			if (v != null) {				dest[i] = v.intValue();			}		}		return dest;	}
public static Integer[] valuesOf(int[] array) {		Integer[] dest = new Integer[array.length];		for (int i = 0; i < array.length; i++) {			dest[i] = Integer.valueOf(array[i]);		}		return dest;	}
public static long[] values(Long[] array) {		long[] dest = new long[array.length];		for (int i = 0; i < array.length; i++) {			Long v = array[i];			if (v != null) {				dest[i] = v.longValue();			}		}		return dest;	}
public static Long[] valuesOf(long[] array) {		Long[] dest = new Long[array.length];		for (int i = 0; i < array.length; i++) {			dest[i] = Long.valueOf(array[i]);		}		return dest;	}
public static float[] values(Float[] array) {		float[] dest = new float[array.length];		for (int i = 0; i < array.length; i++) {			Float v = array[i];			if (v != null) {				dest[i] = v.floatValue();			}		}		return dest;	}
public static Float[] valuesOf(float[] array) {		Float[] dest = new Float[array.length];		for (int i = 0; i < array.length; i++) {			dest[i] = Float.valueOf(array[i]);		}		return dest;	}
public static double[] values(Double[] array) {		double[] dest = new double[array.length];		for (int i = 0; i < array.length; i++) {			Double v = array[i];			if (v != null) {				dest[i] = v.doubleValue();			}		}		return dest;	}
public static Double[] valuesOf(double[] array) {		Double[] dest = new Double[array.length];		for (int i = 0; i < array.length; i++) {			dest[i] = Double.valueOf(array[i]);		}		return dest;	}
public static boolean[] values(Boolean[] array) {		boolean[] dest = new boolean[array.length];		for (int i = 0; i < array.length; i++) {			Boolean v = array[i];			if (v != null) {				dest[i] = v.booleanValue();			}		}		return dest;	}
public static Boolean[] valuesOf(boolean[] array) {		Boolean[] dest = new Boolean[array.length];		for (int i = 0; i < array.length; i++) {			dest[i] = Boolean.valueOf(array[i]);		}		return dest;	}
public static int indexOf(byte[] array, byte value, int startIndex, int endIndex) {		for (int i = startIndex; i < endIndex; i++) {			if (array[i] == value) {				return i;			}		}		return -1;	}
public static int indexOf(char[] array, char value) {		for (int i = 0; i < array.length; i++) {			if (array[i] == value) {				return i;			}		}		return -1;	}
public static int indexOf(float[] array, float value) {		for (int i = 0; i < array.length; i++) {			if (Float.compare(array[i], value) == 0) {				return i;			}		}		return -1;	}
public static int indexOf(float[] array, float value, int startIndex, int endIndex) {		for (int i = startIndex; i < endIndex; i++) {			if (Float.compare(array[i], value) == 0) {				return i;			}		}		return -1;	}
public static int indexOf(double[] array, double value) {		for (int i = 0; i < array.length; i++) {			if (Double.compare(array[i], value) == 0) {				return i;			}		}		return -1;	}
public static int indexOf(double[] array, double value, int startIndex, int endIndex) {		for (int i = startIndex; i < endIndex; i++) {			if (Double.compare(array[i], value) == 0) {				return i;			}		}		return -1;	}
public static int indexOf(Object[] array, Object value) {		for (int i = 0; i < array.length; i++) {			if (array[i].equals(value)) {				return i;			}		}		return -1;	}
public static int indexOf(byte[] array, byte[] sub, int startIndex) {		return indexOf(array, sub, startIndex, array.length);	}
public static int indexOf(double[] array, double[] sub, int startIndex, int endIndex) {		int sublen = sub.length;		if (sublen == 0) {			return startIndex;		}		int total = endIndex - sublen + 1;		double c = sub[0];		mainloop:		for (int i = startIndex; i < total; i++) {			if (Double.compare(array[i], c) != 0) {				continue;			}			int j = 1;			int k = i + 1;			while (j < sublen) {				if (Double.compare(sub[j], array[k]) != 0) {					continue mainloop;				}				j++; k++;			}			return i;		}		return -1;	}
public static String[] toStringArray(Object[] array) {		if (array == null) {			return null;		}		String[] result = new String[array.length];		for (int i = 0; i < array.length; i++) {			result[i] = StringUtil.toString(array[i]);		}		return result;	}
public static String[] toStringArray(String[] array) {		if (array == null) {			return null;		}		String[] result = new String[array.length];		for (int i = 0; i < array.length; i++) {			result[i] = String.valueOf(array[i]);		}		return result;	}
public LagartoDOMBuilder enableXhtmlMode() {		config.ignoreWhitespacesBetweenTags = false;			// collect all whitespaces		config.setCaseSensitive(true);							// XHTML is case sensitive		config.setEnableRawTextModes(false);					// all tags are parsed in the same way		config.enabledVoidTags = true;							// list of void tags		config.selfCloseVoidTags = true;						// self close void tags		config.impliedEndTags = false;							// no implied tag ends		config.setEnableConditionalComments(false);				// don't enable IE conditional comments		config.setParseXmlTags(false);							// enable XML mode in parsing		return this;	}
@Override	public Document parse(final char[] content) {		LagartoParser lagartoParser = new LagartoParser(content);		return doParse(lagartoParser);	}
protected Document doParse(final LagartoParser lagartoParser) {		lagartoParser.setConfig(config);		LagartoDOMBuilderTagVisitor domBuilderTagVisitor =				new LagartoDOMBuilderTagVisitor(this);		lagartoParser.parse(domBuilderTagVisitor);		return domBuilderTagVisitor.getDocument();	}
@Override  public void visitParameter(final String name, final int access) {    if (parameters == null) {      parameters = new ByteVector();    }    ++parametersCount;    parameters.putShort((name == null) ? 0 : symbolTable.addConstantUtf8(name)).putShort(access);  }
private void computeAllFrames() {    // Complete the control flow graph with exception handler blocks.    Handler handler = firstHandler;    while (handler != null) {      String catchTypeDescriptor =          handler.catchTypeDescriptor == null ? "java/lang/Throwable" : handler.catchTypeDescriptor;      int catchType = Frame.getAbstractTypeFromInternalName(symbolTable, catchTypeDescriptor);      // Mark handlerBlock as an exception handler.      Label handlerBlock = handler.handlerPc.getCanonicalInstance();      handlerBlock.flags |= Label.FLAG_JUMP_TARGET;      // Add handlerBlock as a successor of all the basic blocks in the exception handler range.      Label handlerRangeBlock = handler.startPc.getCanonicalInstance();      Label handlerRangeEnd = handler.endPc.getCanonicalInstance();      while (handlerRangeBlock != handlerRangeEnd) {        handlerRangeBlock.outgoingEdges =            new Edge(catchType, handlerBlock, handlerRangeBlock.outgoingEdges);        handlerRangeBlock = handlerRangeBlock.nextBasicBlock;      }      handler = handler.nextHandler;    }    // Create and visit the first (implicit) frame.    Frame firstFrame = firstBasicBlock.frame;    firstFrame.setInputFrameFromDescriptor(symbolTable, accessFlags, descriptor, this.maxLocals);    firstFrame.accept(this);    // Fix point algorithm: add the first basic block to a list of blocks to process (i.e. blocks    // whose stack map frame has changed) and, while there are blocks to process, remove one from    // the list and update the stack map frames of its successor blocks in the control flow graph    // (which might change them, in which case these blocks must be processed too, and are thus    // added to the list of blocks to process). Also compute the maximum stack size of the method,    // as a by-product.    Label listOfBlocksToProcess = firstBasicBlock;    listOfBlocksToProcess.nextListElement = Label.EMPTY_LIST;    int maxStackSize = 0;    while (listOfBlocksToProcess != Label.EMPTY_LIST) {      // Remove a basic block from the list of blocks to process.      Label basicBlock = listOfBlocksToProcess;      listOfBlocksToProcess = listOfBlocksToProcess.nextListElement;      basicBlock.nextListElement = null;      // By definition, basicBlock is reachable.      basicBlock.flags |= Label.FLAG_REACHABLE;      // Update the (absolute) maximum stack size.      int maxBlockStackSize = basicBlock.frame.getInputStackSize() + basicBlock.outputStackMax;      if (maxBlockStackSize > maxStackSize) {        maxStackSize = maxBlockStackSize;      }      // Update the successor blocks of basicBlock in the control flow graph.      Edge outgoingEdge = basicBlock.outgoingEdges;      while (outgoingEdge != null) {        Label successorBlock = outgoingEdge.successor.getCanonicalInstance();        boolean successorBlockChanged =            basicBlock.frame.merge(symbolTable, successorBlock.frame, outgoingEdge.info);        if (successorBlockChanged && successorBlock.nextListElement == null) {          // If successorBlock has changed it must be processed. Thus, if it is not already in the          // list of blocks to process, add it to this list.          successorBlock.nextListElement = listOfBlocksToProcess;          listOfBlocksToProcess = successorBlock;        }        outgoingEdge = outgoingEdge.nextEdge;      }    }    // Loop over all the basic blocks and visit the stack map frames that must be stored in the    // StackMapTable attribute. Also replace unreachable code with NOP* ATHROW, and remove it from    // exception handler ranges.    Label basicBlock = firstBasicBlock;    while (basicBlock != null) {      if ((basicBlock.flags & (Label.FLAG_JUMP_TARGET | Label.FLAG_REACHABLE))          == (Label.FLAG_JUMP_TARGET | Label.FLAG_REACHABLE)) {        basicBlock.frame.accept(this);      }      if ((basicBlock.flags & Label.FLAG_REACHABLE) == 0) {        // Find the start and end bytecode offsets of this unreachable block.        Label nextBasicBlock = basicBlock.nextBasicBlock;        int startOffset = basicBlock.bytecodeOffset;        int endOffset = (nextBasicBlock == null ? code.length : nextBasicBlock.bytecodeOffset) - 1;        if (endOffset >= startOffset) {          // Replace its instructions with NOP ... NOP ATHROW.          for (int i = startOffset; i < endOffset; ++i) {            code.data[i] = Opcodes.NOP;          }          code.data[endOffset] = (byte) Opcodes.ATHROW;          // Emit a frame for this unreachable block, with no local and a Throwable on the stack          // (so that the ATHROW could consume this Throwable if it were reachable).          int frameIndex = visitFrameStart(startOffset, /* numLocal = */ 0, /* numStack = */ 1);          currentFrame[frameIndex] =              Frame.getAbstractTypeFromInternalName(symbolTable, "java/lang/Throwable");          visitFrameEnd();          // Remove this unreachable basic block from the exception handler ranges.          firstHandler = Handler.removeRange(firstHandler, basicBlock, nextBasicBlock);          // The maximum stack size is now at least one, because of the Throwable declared above.          maxStackSize = Math.max(maxStackSize, 1);        }      }      basicBlock = basicBlock.nextBasicBlock;    }    this.maxStack = maxStackSize;  }
private void computeMaxStackAndLocal() {    // Complete the control flow graph with exception handler blocks.    Handler handler = firstHandler;    while (handler != null) {      Label handlerBlock = handler.handlerPc;      Label handlerRangeBlock = handler.startPc;      Label handlerRangeEnd = handler.endPc;      // Add handlerBlock as a successor of all the basic blocks in the exception handler range.      while (handlerRangeBlock != handlerRangeEnd) {        if ((handlerRangeBlock.flags & Label.FLAG_SUBROUTINE_CALLER) == 0) {          handlerRangeBlock.outgoingEdges =              new Edge(Edge.EXCEPTION, handlerBlock, handlerRangeBlock.outgoingEdges);        } else {          // If handlerRangeBlock is a JSR block, add handlerBlock after the first two outgoing          // edges to preserve the hypothesis about JSR block successors order (see          // {@link #visitJumpInsn}).          handlerRangeBlock.outgoingEdges.nextEdge.nextEdge =              new Edge(                  Edge.EXCEPTION, handlerBlock, handlerRangeBlock.outgoingEdges.nextEdge.nextEdge);        }        handlerRangeBlock = handlerRangeBlock.nextBasicBlock;      }      handler = handler.nextHandler;    }    // Complete the control flow graph with the successor blocks of subroutines, if needed.    if (hasSubroutines) {      // First step: find the subroutines. This step determines, for each basic block, to which      // subroutine(s) it belongs. Start with the main "subroutine":      short numSubroutines = 1;      firstBasicBlock.markSubroutine(numSubroutines);      // Then, mark the subroutines called by the main subroutine, then the subroutines called by      // those called by the main subroutine, etc.      for (short currentSubroutine = 1; currentSubroutine <= numSubroutines; ++currentSubroutine) {        Label basicBlock = firstBasicBlock;        while (basicBlock != null) {          if ((basicBlock.flags & Label.FLAG_SUBROUTINE_CALLER) != 0              && basicBlock.subroutineId == currentSubroutine) {            Label jsrTarget = basicBlock.outgoingEdges.nextEdge.successor;            if (jsrTarget.subroutineId == 0) {              // If this subroutine has not been marked yet, find its basic blocks.              jsrTarget.markSubroutine(++numSubroutines);            }          }          basicBlock = basicBlock.nextBasicBlock;        }      }      // Second step: find the successors in the control flow graph of each subroutine basic block      // 'r' ending with a RET instruction. These successors are the virtual successors of the basic      // blocks ending with JSR instructions (see {@link #visitJumpInsn)} that can reach 'r'.      Label basicBlock = firstBasicBlock;      while (basicBlock != null) {        if ((basicBlock.flags & Label.FLAG_SUBROUTINE_CALLER) != 0) {          // By construction, jsr targets are stored in the second outgoing edge of basic blocks          // that ends with a jsr instruction (see {@link #FLAG_SUBROUTINE_CALLER}).          Label subroutine = basicBlock.outgoingEdges.nextEdge.successor;          subroutine.addSubroutineRetSuccessors(basicBlock);        }        basicBlock = basicBlock.nextBasicBlock;      }    }    // Data flow algorithm: put the first basic block in a list of blocks to process (i.e. blocks    // whose input stack size has changed) and, while there are blocks to process, remove one    // from the list, update the input stack size of its successor blocks in the control flow    // graph, and add these blocks to the list of blocks to process (if not already done).    Label listOfBlocksToProcess = firstBasicBlock;    listOfBlocksToProcess.nextListElement = Label.EMPTY_LIST;    int maxStackSize = maxStack;    while (listOfBlocksToProcess != Label.EMPTY_LIST) {      // Remove a basic block from the list of blocks to process. Note that we don't reset      // basicBlock.nextListElement to null on purpose, to make sure we don't reprocess already      // processed basic blocks.      Label basicBlock = listOfBlocksToProcess;      listOfBlocksToProcess = listOfBlocksToProcess.nextListElement;      // Compute the (absolute) input stack size and maximum stack size of this block.      int inputStackTop = basicBlock.inputStackSize;      int maxBlockStackSize = inputStackTop + basicBlock.outputStackMax;      // Update the absolute maximum stack size of the method.      if (maxBlockStackSize > maxStackSize) {        maxStackSize = maxBlockStackSize;      }      // Update the input stack size of the successor blocks of basicBlock in the control flow      // graph, and add these blocks to the list of blocks to process, if not already done.      Edge outgoingEdge = basicBlock.outgoingEdges;      if ((basicBlock.flags & Label.FLAG_SUBROUTINE_CALLER) != 0) {        // Ignore the first outgoing edge of the basic blocks ending with a jsr: these are virtual        // edges which lead to the instruction just after the jsr, and do not correspond to a        // possible execution path (see {@link #visitJumpInsn} and        // {@link Label#FLAG_SUBROUTINE_CALLER}).        outgoingEdge = outgoingEdge.nextEdge;      }      while (outgoingEdge != null) {        Label successorBlock = outgoingEdge.successor;        if (successorBlock.nextListElement == null) {          successorBlock.inputStackSize =              (short) (outgoingEdge.info == Edge.EXCEPTION ? 1 : inputStackTop + outgoingEdge.info);          successorBlock.nextListElement = listOfBlocksToProcess;          listOfBlocksToProcess = successorBlock;        }        outgoingEdge = outgoingEdge.nextEdge;      }    }    this.maxStack = maxStackSize;  }
private void addSuccessorToCurrentBasicBlock(final int info, final Label successor) {    currentBasicBlock.outgoingEdges = new Edge(info, successor, currentBasicBlock.outgoingEdges);  }
private void endCurrentBasicBlockWithNoSuccessor() {    if (compute == COMPUTE_ALL_FRAMES) {      Label nextBasicBlock = new Label();      nextBasicBlock.frame = new Frame(nextBasicBlock);      nextBasicBlock.resolve(code.data, code.length);      lastBasicBlock.nextBasicBlock = nextBasicBlock;      lastBasicBlock = nextBasicBlock;      currentBasicBlock = null;    } else if (compute == COMPUTE_MAX_STACK_AND_LOCAL) {      currentBasicBlock.outputStackMax = (short) maxRelativeStackSize;      currentBasicBlock = null;    }  }
int visitFrameStart(final int offset, final int numLocal, final int numStack) {    int frameLength = 3 + numLocal + numStack;    if (currentFrame == null || currentFrame.length < frameLength) {      currentFrame = new int[frameLength];    }    currentFrame[0] = offset;    currentFrame[1] = numLocal;    currentFrame[2] = numStack;    return 3;  }
void visitFrameEnd() {    if (previousFrame != null) {      if (stackMapTableEntries == null) {        stackMapTableEntries = new ByteVector();      }      putFrame();      ++stackMapTableNumberOfEntries;    }    previousFrame = currentFrame;    currentFrame = null;  }
private void putFrame() {    final int numLocal = currentFrame[1];    final int numStack = currentFrame[2];    if (symbolTable.getMajorVersion() < Opcodes.V1_6) {      // Generate a StackMap attribute entry, which are always uncompressed.      stackMapTableEntries.putShort(currentFrame[0]).putShort(numLocal);      putAbstractTypes(3, 3 + numLocal);      stackMapTableEntries.putShort(numStack);      putAbstractTypes(3 + numLocal, 3 + numLocal + numStack);      return;    }    final int offsetDelta =        stackMapTableNumberOfEntries == 0            ? currentFrame[0]            : currentFrame[0] - previousFrame[0] - 1;    final int previousNumlocal = previousFrame[1];    final int numLocalDelta = numLocal - previousNumlocal;    int type = Frame.FULL_FRAME;    if (numStack == 0) {      switch (numLocalDelta) {        case -3:        case -2:        case -1:          type = Frame.CHOP_FRAME;          break;        case 0:          type = offsetDelta < 64 ? Frame.SAME_FRAME : Frame.SAME_FRAME_EXTENDED;          break;        case 1:        case 2:        case 3:          type = Frame.APPEND_FRAME;          break;        default:          // Keep the FULL_FRAME type.          break;      }    } else if (numLocalDelta == 0 && numStack == 1) {      type =          offsetDelta < 63              ? Frame.SAME_LOCALS_1_STACK_ITEM_FRAME              : Frame.SAME_LOCALS_1_STACK_ITEM_FRAME_EXTENDED;    }    if (type != Frame.FULL_FRAME) {      // Verify if locals are the same as in the previous frame.      int frameIndex = 3;      for (int i = 0; i < previousNumlocal && i < numLocal; i++) {        if (currentFrame[frameIndex] != previousFrame[frameIndex]) {          type = Frame.FULL_FRAME;          break;        }        frameIndex++;      }    }    switch (type) {      case Frame.SAME_FRAME:        stackMapTableEntries.putByte(offsetDelta);        break;      case Frame.SAME_LOCALS_1_STACK_ITEM_FRAME:        stackMapTableEntries.putByte(Frame.SAME_LOCALS_1_STACK_ITEM_FRAME + offsetDelta);        putAbstractTypes(3 + numLocal, 4 + numLocal);        break;      case Frame.SAME_LOCALS_1_STACK_ITEM_FRAME_EXTENDED:        stackMapTableEntries            .putByte(Frame.SAME_LOCALS_1_STACK_ITEM_FRAME_EXTENDED)            .putShort(offsetDelta);        putAbstractTypes(3 + numLocal, 4 + numLocal);        break;      case Frame.SAME_FRAME_EXTENDED:        stackMapTableEntries.putByte(Frame.SAME_FRAME_EXTENDED).putShort(offsetDelta);        break;      case Frame.CHOP_FRAME:        stackMapTableEntries            .putByte(Frame.SAME_FRAME_EXTENDED + numLocalDelta)            .putShort(offsetDelta);        break;      case Frame.APPEND_FRAME:        stackMapTableEntries            .putByte(Frame.SAME_FRAME_EXTENDED + numLocalDelta)            .putShort(offsetDelta);        putAbstractTypes(3 + previousNumlocal, 3 + numLocal);        break;      case Frame.FULL_FRAME:      default:        stackMapTableEntries.putByte(Frame.FULL_FRAME).putShort(offsetDelta).putShort(numLocal);        putAbstractTypes(3, 3 + numLocal);        stackMapTableEntries.putShort(numStack);        putAbstractTypes(3 + numLocal, 3 + numLocal + numStack);        break;    }  }
private void putAbstractTypes(final int start, final int end) {    for (int i = start; i < end; ++i) {      Frame.putAbstractType(symbolTable, currentFrame[i], stackMapTableEntries);    }  }
private void putFrameType(final Object type) {    if (type instanceof Integer) {      stackMapTableEntries.putByte(((Integer) type).intValue());    } else if (type instanceof String) {      stackMapTableEntries          .putByte(Frame.ITEM_OBJECT)          .putShort(symbolTable.addConstantClass((String) type).index);    } else {      stackMapTableEntries          .putByte(Frame.ITEM_UNINITIALIZED)          .putShort(((Label) type).bytecodeOffset);    }  }
boolean canCopyMethodAttributes(      final ClassReader source,      final int methodInfoOffset,      final int methodInfoLength,      final boolean hasSyntheticAttribute,      final boolean hasDeprecatedAttribute,      final int descriptorIndex,      final int signatureIndex,      final int exceptionsOffset) {    // If the method descriptor has changed, with more locals than the max_locals field of the    // original Code attribute, if any, then the original method attributes can't be copied. A    // conservative check on the descriptor changes alone ensures this (being more precise is not    // worth the additional complexity, because these cases should be rare -- if a transform changes    // a method descriptor, most of the time it needs to change the method's code too).    if (source != symbolTable.getSource()        || descriptorIndex != this.descriptorIndex        || signatureIndex != this.signatureIndex        || hasDeprecatedAttribute != ((accessFlags & Opcodes.ACC_DEPRECATED) != 0)) {      return false;    }    boolean needSyntheticAttribute =        symbolTable.getMajorVersion() < Opcodes.V1_5 && (accessFlags & Opcodes.ACC_SYNTHETIC) != 0;    if (hasSyntheticAttribute != needSyntheticAttribute) {      return false;    }    if (exceptionsOffset == 0) {      if (numberOfExceptions != 0) {        return false;      }    } else if (source.readUnsignedShort(exceptionsOffset) == numberOfExceptions) {      int currentExceptionOffset = exceptionsOffset + 2;      for (int i = 0; i < numberOfExceptions; ++i) {        if (source.readUnsignedShort(currentExceptionOffset) != exceptionIndexTable[i]) {          return false;        }        currentExceptionOffset += 2;      }    }    // Don't copy the attributes yet, instead store their location in the source class reader so    // they can be copied later, in {@link #putMethodInfo}. Note that we skip the 6 header bytes    // of the method_info JVMS structure.    this.sourceOffset = methodInfoOffset + 6;    this.sourceLength = methodInfoLength - 6;    return true;  }
int computeMethodInfoSize() {    // If this method_info must be copied from an existing one, the size computation is trivial.    if (sourceOffset != 0) {      // sourceLength excludes the first 6 bytes for access_flags, name_index and descriptor_index.      return 6 + sourceLength;    }    // 2 bytes each for access_flags, name_index, descriptor_index and attributes_count.    int size = 8;    // For ease of reference, we use here the same attribute order as in Section 4.7 of the JVMS.    if (code.length > 0) {      if (code.length > 65535) {        throw new MethodTooLargeException(            symbolTable.getClassName(), name, descriptor, code.length);      }      symbolTable.addConstantUtf8(Constants.CODE);      // The Code attribute has 6 header bytes, plus 2, 2, 4 and 2 bytes respectively for max_stack,      // max_locals, code_length and attributes_count, plus the bytecode and the exception table.      size += 16 + code.length + Handler.getExceptionTableSize(firstHandler);      if (stackMapTableEntries != null) {        boolean useStackMapTable = symbolTable.getMajorVersion() >= Opcodes.V1_6;        symbolTable.addConstantUtf8(useStackMapTable ? Constants.STACK_MAP_TABLE : "StackMap");        // 6 header bytes and 2 bytes for number_of_entries.        size += 8 + stackMapTableEntries.length;      }      if (lineNumberTable != null) {        symbolTable.addConstantUtf8(Constants.LINE_NUMBER_TABLE);        // 6 header bytes and 2 bytes for line_number_table_length.        size += 8 + lineNumberTable.length;      }      if (localVariableTable != null) {        symbolTable.addConstantUtf8(Constants.LOCAL_VARIABLE_TABLE);        // 6 header bytes and 2 bytes for local_variable_table_length.        size += 8 + localVariableTable.length;      }      if (localVariableTypeTable != null) {        symbolTable.addConstantUtf8(Constants.LOCAL_VARIABLE_TYPE_TABLE);        // 6 header bytes and 2 bytes for local_variable_type_table_length.        size += 8 + localVariableTypeTable.length;      }      if (lastCodeRuntimeVisibleTypeAnnotation != null) {        size +=            lastCodeRuntimeVisibleTypeAnnotation.computeAnnotationsSize(                Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS);      }      if (lastCodeRuntimeInvisibleTypeAnnotation != null) {        size +=            lastCodeRuntimeInvisibleTypeAnnotation.computeAnnotationsSize(                Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS);      }      if (firstCodeAttribute != null) {        size +=            firstCodeAttribute.computeAttributesSize(                symbolTable, code.data, code.length, maxStack, maxLocals);      }    }    if (numberOfExceptions > 0) {      symbolTable.addConstantUtf8(Constants.EXCEPTIONS);      size += 8 + 2 * numberOfExceptions;    }    boolean useSyntheticAttribute = symbolTable.getMajorVersion() < Opcodes.V1_5;    if ((accessFlags & Opcodes.ACC_SYNTHETIC) != 0 && useSyntheticAttribute) {      symbolTable.addConstantUtf8(Constants.SYNTHETIC);      size += 6;    }    if (signatureIndex != 0) {      symbolTable.addConstantUtf8(Constants.SIGNATURE);      size += 8;    }    if ((accessFlags & Opcodes.ACC_DEPRECATED) != 0) {      symbolTable.addConstantUtf8(Constants.DEPRECATED);      size += 6;    }    if (lastRuntimeVisibleAnnotation != null) {      size +=          lastRuntimeVisibleAnnotation.computeAnnotationsSize(              Constants.RUNTIME_VISIBLE_ANNOTATIONS);    }    if (lastRuntimeInvisibleAnnotation != null) {      size +=          lastRuntimeInvisibleAnnotation.computeAnnotationsSize(              Constants.RUNTIME_INVISIBLE_ANNOTATIONS);    }    if (lastRuntimeVisibleParameterAnnotations != null) {      size +=          AnnotationWriter.computeParameterAnnotationsSize(              Constants.RUNTIME_VISIBLE_PARAMETER_ANNOTATIONS,              lastRuntimeVisibleParameterAnnotations,              visibleAnnotableParameterCount == 0                  ? lastRuntimeVisibleParameterAnnotations.length                  : visibleAnnotableParameterCount);    }    if (lastRuntimeInvisibleParameterAnnotations != null) {      size +=          AnnotationWriter.computeParameterAnnotationsSize(              Constants.RUNTIME_INVISIBLE_PARAMETER_ANNOTATIONS,              lastRuntimeInvisibleParameterAnnotations,              invisibleAnnotableParameterCount == 0                  ? lastRuntimeInvisibleParameterAnnotations.length                  : invisibleAnnotableParameterCount);    }    if (lastRuntimeVisibleTypeAnnotation != null) {      size +=          lastRuntimeVisibleTypeAnnotation.computeAnnotationsSize(              Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS);    }    if (lastRuntimeInvisibleTypeAnnotation != null) {      size +=          lastRuntimeInvisibleTypeAnnotation.computeAnnotationsSize(              Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS);    }    if (defaultValue != null) {      symbolTable.addConstantUtf8(Constants.ANNOTATION_DEFAULT);      size += 6 + defaultValue.length;    }    if (parameters != null) {      symbolTable.addConstantUtf8(Constants.METHOD_PARAMETERS);      // 6 header bytes and 1 byte for parameters_count.      size += 7 + parameters.length;    }    if (firstAttribute != null) {      size += firstAttribute.computeAttributesSize(symbolTable);    }    return size;  }
void putMethodInfo(final ByteVector output) {    boolean useSyntheticAttribute = symbolTable.getMajorVersion() < Opcodes.V1_5;    int mask = useSyntheticAttribute ? Opcodes.ACC_SYNTHETIC : 0;    output.putShort(accessFlags & ~mask).putShort(nameIndex).putShort(descriptorIndex);    // If this method_info must be copied from an existing one, copy it now and return early.    if (sourceOffset != 0) {      output.putByteArray(symbolTable.getSource().b, sourceOffset, sourceLength);      return;    }    // For ease of reference, we use here the same attribute order as in Section 4.7 of the JVMS.    int attributeCount = 0;    if (code.length > 0) {      ++attributeCount;    }    if (numberOfExceptions > 0) {      ++attributeCount;    }    if ((accessFlags & Opcodes.ACC_SYNTHETIC) != 0 && useSyntheticAttribute) {      ++attributeCount;    }    if (signatureIndex != 0) {      ++attributeCount;    }    if ((accessFlags & Opcodes.ACC_DEPRECATED) != 0) {      ++attributeCount;    }    if (lastRuntimeVisibleAnnotation != null) {      ++attributeCount;    }    if (lastRuntimeInvisibleAnnotation != null) {      ++attributeCount;    }    if (lastRuntimeVisibleParameterAnnotations != null) {      ++attributeCount;    }    if (lastRuntimeInvisibleParameterAnnotations != null) {      ++attributeCount;    }    if (lastRuntimeVisibleTypeAnnotation != null) {      ++attributeCount;    }    if (lastRuntimeInvisibleTypeAnnotation != null) {      ++attributeCount;    }    if (defaultValue != null) {      ++attributeCount;    }    if (parameters != null) {      ++attributeCount;    }    if (firstAttribute != null) {      attributeCount += firstAttribute.getAttributeCount();    }    // For ease of reference, we use here the same attribute order as in Section 4.7 of the JVMS.    output.putShort(attributeCount);    if (code.length > 0) {      // 2, 2, 4 and 2 bytes respectively for max_stack, max_locals, code_length and      // attributes_count, plus the bytecode and the exception table.      int size = 10 + code.length + Handler.getExceptionTableSize(firstHandler);      int codeAttributeCount = 0;      if (stackMapTableEntries != null) {        // 6 header bytes and 2 bytes for number_of_entries.        size += 8 + stackMapTableEntries.length;        ++codeAttributeCount;      }      if (lineNumberTable != null) {        // 6 header bytes and 2 bytes for line_number_table_length.        size += 8 + lineNumberTable.length;        ++codeAttributeCount;      }      if (localVariableTable != null) {        // 6 header bytes and 2 bytes for local_variable_table_length.        size += 8 + localVariableTable.length;        ++codeAttributeCount;      }      if (localVariableTypeTable != null) {        // 6 header bytes and 2 bytes for local_variable_type_table_length.        size += 8 + localVariableTypeTable.length;        ++codeAttributeCount;      }      if (lastCodeRuntimeVisibleTypeAnnotation != null) {        size +=            lastCodeRuntimeVisibleTypeAnnotation.computeAnnotationsSize(                Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS);        ++codeAttributeCount;      }      if (lastCodeRuntimeInvisibleTypeAnnotation != null) {        size +=            lastCodeRuntimeInvisibleTypeAnnotation.computeAnnotationsSize(                Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS);        ++codeAttributeCount;      }      if (firstCodeAttribute != null) {        size +=            firstCodeAttribute.computeAttributesSize(                symbolTable, code.data, code.length, maxStack, maxLocals);        codeAttributeCount += firstCodeAttribute.getAttributeCount();      }      output          .putShort(symbolTable.addConstantUtf8(Constants.CODE))          .putInt(size)          .putShort(maxStack)          .putShort(maxLocals)          .putInt(code.length)          .putByteArray(code.data, 0, code.length);      Handler.putExceptionTable(firstHandler, output);      output.putShort(codeAttributeCount);      if (stackMapTableEntries != null) {        boolean useStackMapTable = symbolTable.getMajorVersion() >= Opcodes.V1_6;        output            .putShort(                symbolTable.addConstantUtf8(                    useStackMapTable ? Constants.STACK_MAP_TABLE : "StackMap"))            .putInt(2 + stackMapTableEntries.length)            .putShort(stackMapTableNumberOfEntries)            .putByteArray(stackMapTableEntries.data, 0, stackMapTableEntries.length);      }      if (lineNumberTable != null) {        output            .putShort(symbolTable.addConstantUtf8(Constants.LINE_NUMBER_TABLE))            .putInt(2 + lineNumberTable.length)            .putShort(lineNumberTableLength)            .putByteArray(lineNumberTable.data, 0, lineNumberTable.length);      }      if (localVariableTable != null) {        output            .putShort(symbolTable.addConstantUtf8(Constants.LOCAL_VARIABLE_TABLE))            .putInt(2 + localVariableTable.length)            .putShort(localVariableTableLength)            .putByteArray(localVariableTable.data, 0, localVariableTable.length);      }      if (localVariableTypeTable != null) {        output            .putShort(symbolTable.addConstantUtf8(Constants.LOCAL_VARIABLE_TYPE_TABLE))            .putInt(2 + localVariableTypeTable.length)            .putShort(localVariableTypeTableLength)            .putByteArray(localVariableTypeTable.data, 0, localVariableTypeTable.length);      }      if (lastCodeRuntimeVisibleTypeAnnotation != null) {        lastCodeRuntimeVisibleTypeAnnotation.putAnnotations(            symbolTable.addConstantUtf8(Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS), output);      }      if (lastCodeRuntimeInvisibleTypeAnnotation != null) {        lastCodeRuntimeInvisibleTypeAnnotation.putAnnotations(            symbolTable.addConstantUtf8(Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS), output);      }      if (firstCodeAttribute != null) {        firstCodeAttribute.putAttributes(            symbolTable, code.data, code.length, maxStack, maxLocals, output);      }    }    if (numberOfExceptions > 0) {      output          .putShort(symbolTable.addConstantUtf8(Constants.EXCEPTIONS))          .putInt(2 + 2 * numberOfExceptions)          .putShort(numberOfExceptions);      for (int exceptionIndex : exceptionIndexTable) {        output.putShort(exceptionIndex);      }    }    if ((accessFlags & Opcodes.ACC_SYNTHETIC) != 0 && useSyntheticAttribute) {      output.putShort(symbolTable.addConstantUtf8(Constants.SYNTHETIC)).putInt(0);    }    if (signatureIndex != 0) {      output          .putShort(symbolTable.addConstantUtf8(Constants.SIGNATURE))          .putInt(2)          .putShort(signatureIndex);    }    if ((accessFlags & Opcodes.ACC_DEPRECATED) != 0) {      output.putShort(symbolTable.addConstantUtf8(Constants.DEPRECATED)).putInt(0);    }    if (lastRuntimeVisibleAnnotation != null) {      lastRuntimeVisibleAnnotation.putAnnotations(          symbolTable.addConstantUtf8(Constants.RUNTIME_VISIBLE_ANNOTATIONS), output);    }    if (lastRuntimeInvisibleAnnotation != null) {      lastRuntimeInvisibleAnnotation.putAnnotations(          symbolTable.addConstantUtf8(Constants.RUNTIME_INVISIBLE_ANNOTATIONS), output);    }    if (lastRuntimeVisibleParameterAnnotations != null) {      AnnotationWriter.putParameterAnnotations(          symbolTable.addConstantUtf8(Constants.RUNTIME_VISIBLE_PARAMETER_ANNOTATIONS),          lastRuntimeVisibleParameterAnnotations,          visibleAnnotableParameterCount == 0              ? lastRuntimeVisibleParameterAnnotations.length              : visibleAnnotableParameterCount,          output);    }    if (lastRuntimeInvisibleParameterAnnotations != null) {      AnnotationWriter.putParameterAnnotations(          symbolTable.addConstantUtf8(Constants.RUNTIME_INVISIBLE_PARAMETER_ANNOTATIONS),          lastRuntimeInvisibleParameterAnnotations,          invisibleAnnotableParameterCount == 0              ? lastRuntimeInvisibleParameterAnnotations.length              : invisibleAnnotableParameterCount,          output);    }    if (lastRuntimeVisibleTypeAnnotation != null) {      lastRuntimeVisibleTypeAnnotation.putAnnotations(          symbolTable.addConstantUtf8(Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS), output);    }    if (lastRuntimeInvisibleTypeAnnotation != null) {      lastRuntimeInvisibleTypeAnnotation.putAnnotations(          symbolTable.addConstantUtf8(Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS), output);    }    if (defaultValue != null) {      output          .putShort(symbolTable.addConstantUtf8(Constants.ANNOTATION_DEFAULT))          .putInt(defaultValue.length)          .putByteArray(defaultValue.data, 0, defaultValue.length);    }    if (parameters != null) {      output          .putShort(symbolTable.addConstantUtf8(Constants.METHOD_PARAMETERS))          .putInt(1 + parameters.length)          .putByte(parametersCount)          .putByteArray(parameters.data, 0, parameters.length);    }    if (firstAttribute != null) {      firstAttribute.putAttributes(symbolTable, output);    }  }
final void collectAttributePrototypes(final Attribute.Set attributePrototypes) {    attributePrototypes.addAttributes(firstAttribute);    attributePrototypes.addAttributes(firstCodeAttribute);  }
@Override	protected WorkData process(final ClassReader cr, final TargetClassInfoReader targetClassInfoReader) {		InvokeClassBuilder icb = new InvokeClassBuilder(				destClassWriter,				proxetta.getAspects(new InvokeAspect[0]),				resolveClassNameSuffix(),				requestedProxyClassName,				targetClassInfoReader);		cr.accept(icb, 0);		return icb.getWorkData();	}
public void injectContext(final Object targetObject) {		final Class targetType = targetObject.getClass();		final ScopeData scopeData = scopeDataInspector.inspectClassScopesWithCache(targetType);		final Targets targets = new Targets(targetObject, scopeData);		// inject no context		scopeResolver.forEachScope(madvocScope -> madvocScope.inject(targets));		// inject special case		scopeResolver.forScope(ParamsScope.class, scope -> scope.inject(targets));		// inject servlet context		final ServletContext servletContext = madvocController.getApplicationContext();		if (servletContext != null) {			scopeResolver.forEachScope(madvocScope -> madvocScope.inject(servletContext, targets));		}	}
public List<CssSelector> parse() {		try {			lexer.yylex();			if (lexer.selectors.isEmpty()) {				return null;			}			// fixes last combinator			CssSelector last = lexer.selectors.get(lexer.selectors.size() - 1);			if (last.getCombinator() == Combinator.DESCENDANT) {				last.setCombinator(null);			}			// set previous css selector			CssSelector prevCssSelector = null;			for (CssSelector cssSelector : lexer.selectors) {				if (prevCssSelector != null) {					cssSelector.setPrevCssSelector(prevCssSelector);				}				prevCssSelector = cssSelector;			}			return lexer.selectors;		} catch (IOException ioex) {			throw new CSSellyException(ioex);		}	}
public static List<List<CssSelector>> parse(final String query) {		String[] singleQueries = StringUtil.splitc(query, ',');		List<List<CssSelector>> selectors = new ArrayList<>(singleQueries.length);		for (String singleQuery: singleQueries) {			selectors.add(new CSSelly(singleQuery).parse());		}		return selectors;	}
public static void registerPseudoClass(final Class<? extends PseudoClass> pseudoClassType) {		PseudoClass pseudoClass;		try {			pseudoClass = ClassUtil.newInstance(pseudoClassType);		} catch (Exception ex) {			throw new CSSellyException(ex);		}		PSEUDO_CLASS_MAP.put(pseudoClass.getPseudoClassName(), pseudoClass);	}
public static PseudoClass lookupPseudoClass(final String pseudoClassName) {		PseudoClass pseudoClass = PSEUDO_CLASS_MAP.get(pseudoClassName);		if (pseudoClass == null) {			throw new CSSellyException("Unsupported pseudo class: " + pseudoClassName);		}		return pseudoClass;	}
@Override	public boolean accept(final List<Node> currentResults, final Node node, final int index) {		return pseudoClass.match(currentResults, node, index);	}
public void invoke(final ActionRequest actionRequest) {		if (executorService == null) {			throw new MadvocException("No action is marked as async!");		}		final HttpServletRequest servletRequest = actionRequest.getHttpServletRequest();		log.debug(() -> "Async call to: " + actionRequest);		final AsyncContext asyncContext = servletRequest.startAsync();		executorService.submit(() -> {			try {				actionRequest.invoke();			} catch (Exception ex) {				log.error("Invoking async action path failed: " , ExceptionUtil.unwrapThrowable(ex));			} finally {				asyncContext.complete();			}		});	}
public static void close(final Closeable closeable) {		if (closeable != null) {			if (closeable instanceof Flushable) {				try {					((Flushable) closeable).flush();				} catch (IOException ignored) {				}			}			try {				closeable.close();			} catch (IOException ignored) {			}		}	}
public static int copy(final Reader input, final Writer output, final int count) throws IOException {		if (count == ALL) {			return copy(input, output);		}		int numToRead = count;		char[] buffer = new char[numToRead];		int totalRead = ZERO;		int read;		while (numToRead > ZERO) {			read = input.read(buffer, ZERO, bufferSize(numToRead));			if (read == NEGATIVE_ONE) {				break;			}			output.write(buffer, ZERO, read);			numToRead = numToRead - read;			totalRead = totalRead + read;		}		output.flush();		return totalRead;	}
public static int copy(final InputStream input, final OutputStream output, final int count) throws IOException {		if (count == ALL) {			return copy(input, output);		}		int numToRead = count;		byte[] buffer = new byte[numToRead];		int totalRead = ZERO;		int read;		while (numToRead > ZERO) {			read = input.read(buffer, ZERO, bufferSize(numToRead));			if (read == NEGATIVE_ONE) {				break;			}			output.write(buffer, ZERO, read);			numToRead = numToRead - read;			totalRead = totalRead + read;		}		output.flush();		return totalRead;	}
public static byte[] readAvailableBytes(final InputStream input) throws IOException {		int numToRead = input.available();		byte[] buffer = new byte[numToRead];		int totalRead = ZERO;		int read;		while ((totalRead < numToRead) && (read = input.read(buffer, totalRead, numToRead - totalRead)) >= ZERO) {			totalRead = totalRead + read;		}		if (totalRead < numToRead) {			throw new IOException("Failed to completely read InputStream");		}		return buffer;	}
public static <T extends OutputStream> T copy(final Reader input, final T output, final String encoding, final int count) throws IOException {		try (Writer out = outputStreamWriterOf(output, encoding)) {			copy(input, out, count);			return output;		}	}
public static FastByteArrayOutputStream copyToOutputStream(final InputStream input, final int count) throws IOException {		try (FastByteArrayOutputStream output = createFastByteArrayOutputStream()) {			copy(input, output, count);			return output;		}	}
public static FastByteArrayOutputStream copyToOutputStream(final Reader input, final String encoding, final int count) throws IOException {		try (FastByteArrayOutputStream output = createFastByteArrayOutputStream()) {			copy(input, output, encoding, count);			return output;		}	}
public static FastCharArrayWriter copy(final InputStream input, final String encoding, final int count) throws IOException {		try (FastCharArrayWriter output = createFastCharArrayWriter()) {			copy(input, output, encoding, count);			return output;		}	}
public static FastCharArrayWriter copy(final Reader input, final int count) throws IOException {		try (FastCharArrayWriter output = createFastCharArrayWriter()) {			copy(input, output, count);			return output;		}	}
public static InputStreamReader inputStreamReadeOf(final InputStream input, final String encoding) throws UnsupportedEncodingException {		return new InputStreamReader(input, encoding);	}
public static OutputStreamWriter outputStreamWriterOf(final OutputStream output, final String encoding) throws UnsupportedEncodingException {		return new OutputStreamWriter(output, encoding);	}
protected String[] getAllBeanPropertyNames(final Class type, final boolean declared) {		ClassDescriptor classDescriptor = ClassIntrospector.get().lookup(type);		PropertyDescriptor[] propertyDescriptors = classDescriptor.getAllPropertyDescriptors();		ArrayList<String> names = new ArrayList<>(propertyDescriptors.length);		for (PropertyDescriptor propertyDescriptor : propertyDescriptors) {			MethodDescriptor getter = propertyDescriptor.getReadMethodDescriptor();			if (getter != null) {				if (getter.matchDeclared(declared)) {					names.add(propertyDescriptor.getName());				}			}			else if (includeFields) {				FieldDescriptor field = propertyDescriptor.getFieldDescriptor();				if (field != null) {					if (field.matchDeclared(declared)) {						names.add(field.getName());					}				}			}		}		return names.toArray(new String[0]);	}
protected String[] resolveProperties(final Object bean, final boolean declared) {		String[] properties;		if (bean instanceof Map) {			Set keys = ((Map) bean).keySet();			properties = new String[keys.size()];			int ndx = 0;			for (Object key : keys) {				properties[ndx] = key.toString();				ndx++;			}		} else {			properties = getAllBeanPropertyNames(bean.getClass(), declared);		}		return properties;	}
public void visit() {		String[] properties = resolveProperties(source, declared);		for (String name : properties) {			if (name == null) {				continue;			}			if (!rules.match(name, blacklist)) {				continue;			}			Object value;			String propertyName = name;			if (isSourceMap) {				propertyName = LEFT_SQ_BRACKET + name + RIGHT_SQ_BRACKET;			}			if (declared) {				value = BeanUtil.declared.getProperty(source, propertyName);			} else {				value = BeanUtil.pojo.getProperty(source, propertyName);			}			if (value == null && ignoreNullValues) {				continue;			}			if (value instanceof String && StringUtil.isEmpty((String) value)) {				continue;			}			visitProperty(name, value);		}	}
@Override	public boolean accept(final String propertyName, final String rule, final boolean include) {		return propertyName.equals(rule);	}
@Override	public ClassDescriptor lookup(final Class type) {		return cache.get(type, () ->			new ClassDescriptor(				type,				scanAccessible,				enhancedProperties,				includeFieldsAsProperties,				propertyFieldPrefix));	}
public MethodInjectionPoint[] resolve(final Class type) {		// lookup methods		ClassDescriptor cd = ClassIntrospector.get().lookup(type);		List<MethodInjectionPoint> list = new ArrayList<>();		MethodDescriptor[] allMethods = cd.getAllMethodDescriptors();		for (MethodDescriptor methodDescriptor : allMethods) {			Method method = methodDescriptor.getMethod();			if (ClassUtil.isBeanPropertySetter(method)) {				// ignore setters				continue;			}			if (method.getParameterTypes().length == 0) {				// ignore methods with no argument				continue;			}			BeanReferences[] references = referencesResolver.readAllReferencesFromAnnotation(method);			if (references != null) {				MethodInjectionPoint methodInjectionPoint = new MethodInjectionPoint(method, references);				list.add(methodInjectionPoint);			}		}		final MethodInjectionPoint[] methodInjectionPoints;		if (list.isEmpty()) {			methodInjectionPoints = MethodInjectionPoint.EMPTY;		} else {			methodInjectionPoints = list.toArray(new MethodInjectionPoint[0]);		}		return methodInjectionPoints;	}
protected void readFilterConfigParameters(final FilterConfig filterConfig, final Object target, final String... parameters) {		for (String parameter : parameters) {			String value = filterConfig.getInitParameter(parameter);			if (value != null) {				BeanUtil.declared.setProperty(target, parameter, value);			}		}	}
protected HtmlStaplerBundlesManager createBundleManager(final ServletContext servletContext, final Strategy strategy) {		String webRoot = servletContext.getRealPath(StringPool.EMPTY);		String contextPath = ServletUtil.getContextPath(servletContext);		return new HtmlStaplerBundlesManager(contextPath, webRoot, strategy);	}
protected void sendBundleFile(final HttpServletResponse resp, final File bundleFile) throws IOException {		OutputStream out = resp.getOutputStream();		FileInputStream fileInputStream = new FileInputStream(bundleFile);		try {			StreamUtil.copy(fileInputStream, out);		}		finally {			StreamUtil.close(fileInputStream);		}	}
public void configure() {		long elapsed = System.currentTimeMillis();		final ClassScanner classScanner = new ClassScanner();		classScanner.detectEntriesMode(true);		classScanner.scanDefaultClasspath();		classScannerConsumers.accept(classScanner);		registerAsConsumer(classScanner);		try {			classScanner.start();		} catch (Exception ex) {			throw new DbOomException("Scan classpath error", ex);		}		elapsed = System.currentTimeMillis() - elapsed;		if (log.isInfoEnabled()) {			log.info("DbEntityManager configured in " + elapsed + "ms. Total entities: " + dbEntityManager.getTotalNames());		}	}
public void registerAsConsumer(final ClassScanner classScanner) {		classScanner.registerEntryConsumer(classPathEntry -> {			if (!classPathEntry.isTypeSignatureInUse(DB_TABLE_ANNOTATION_BYTES)) {				return;			}			final Class<?> beanClass;			try {				beanClass = classPathEntry.loadClass();			} catch (ClassNotFoundException cnfex) {				throw new DbOomException("Entry class not found: " + classPathEntry.name(), cnfex);			}			if (beanClass == null) {				return;			}			final DbTable dbTable = beanClass.getAnnotation(DbTable.class);			if (dbTable == null) {				return;			}			if (registerAsEntities) {				dbEntityManager.registerEntity(beanClass);			} else {				dbEntityManager.registerType(beanClass);			}		});	}
public void setRandomDigestChars(final int randomDigestChars) {		this.randomDigestChars = randomDigestChars;		if (randomDigestChars == 0) {			uniqueDigestKey = null;		}		else {			uniqueDigestKey = new RandomString().randomAlphaNumeric(randomDigestChars);		}	}
protected File createBundleFile(final String bundleId) {		File folder = new File(bundleFolder, staplerPath);		if (!folder.exists()) {			folder.mkdirs();		}		return new File(folder, bundleId);	}
public File lookupBundleFile(String bundleId) {		if ((mirrors != null) && (!mirrors.isEmpty())) {			String realBundleId = mirrors.remove(bundleId);			if (realBundleId != null) {				bundleId = realBundleId;			}		}		return createBundleFile(bundleId);	}
public File lookupGzipBundleFile(final File file) throws IOException {		String path = file.getPath() + ZipUtil.GZIP_EXT;		File gzipFile = new File(path);		if (!gzipFile.exists()) {			if (log.isDebugEnabled()) {				log.debug("gzip bundle to " + path);			}			ZipUtil.gzip(file);		}		return gzipFile;	}
public synchronized String registerBundle(final String contextPath, final String actionPath, final String tempBundleId, final String bundleContentType, final List<String> sources) {		if (tempBundleId == null || sources.isEmpty()) {			if (strategy == Strategy.ACTION_MANAGED) {				// page does not include any resource source file				actionBundles.put(actionPath, StringPool.EMPTY);			}			return null;		}		// create unique digest from the collected sources		String[] sourcesArray = sources.toArray(new String[0]);		for (int i = 0, sourcesArrayLength = sourcesArray.length; i < sourcesArrayLength; i++) {			sourcesArray[i] = sourcesArray[i].trim().toLowerCase();		}		if (sortResources) {			Arrays.sort(sourcesArray);		}		StringBand sb = new StringBand(sourcesArray.length);		for (String src : sourcesArray) {			sb.append(src);		}		String sourcesString = sb.toString();		String bundleId = createDigest(sourcesString);		bundleId += '.' + bundleContentType;		// bundle appears for the first time, create the bundle		if (strategy == Strategy.ACTION_MANAGED) {			actionBundles.put(actionPath, bundleId);			mirrors.put(tempBundleId, bundleId);		}		try {			createBundle(contextPath, actionPath, bundleId, sources);		} catch (IOException ioex) {			throw new HtmlStaplerException("Can't create bundle", ioex);		}		return bundleId;	}
protected String createDigest(final String source) {		final DigestEngine digestEngine = DigestEngine.sha256();		final byte[] bytes = digestEngine.digest(CharUtil.toSimpleByteArray(source));		String digest = Base32.encode(bytes);		if (uniqueDigestKey != null) {			digest += uniqueDigestKey;		}		return digest;	}
protected void createBundle(final String contextPath, final String actionPath, final String bundleId, final List<String>sources) throws IOException {		final File bundleFile = createBundleFile(bundleId);		if (bundleFile.exists()) {			return;		}		StringBand sb = new StringBand(sources.size() * 2);		for (String src : sources) {			if (sb.length() != 0) {				sb.append(StringPool.NEWLINE);			}			String content;			if (isExternalResource(src)) {				content = downloadString(src);			} else {				if (!downloadLocal) {					// load local resource from file system					String localFile = webRoot;					if (src.startsWith(contextPath + '/')) {						src = src.substring(contextPath.length());					}					if (src.startsWith(StringPool.SLASH)) {						// absolute path						localFile += src;					} else {						// relative path						localFile += '/' + FileNameUtil.getPathNoEndSeparator(actionPath) + '/' + src;					}					// trim link parameters, if any					int qmndx = localFile.indexOf('?');					if (qmndx != -1) {						localFile = localFile.substring(0, qmndx);					}					try {						content = FileUtil.readString(localFile);					} catch (IOException ioex) {						if (notFoundExceptionEnabled) {							throw ioex;						}						if (log.isWarnEnabled()) {							log.warn(ioex.getMessage());						}						content = null;					}				} else {					// download local resource					String localUrl = localAddressAndPort;					if (src.startsWith(StringPool.SLASH)) {						localUrl += contextPath + src;					} else {						localUrl += contextPath + FileNameUtil.getPath(actionPath) + '/' + src;					}					content = downloadString(localUrl);				}				if (content != null) {					if (isCssResource(src)) {						content = fixCssRelativeUrls(content, src);					}				}			}			if (content != null) {				content = onResourceContent(content);				sb.append(content);			}		}		FileUtil.writeString(bundleFile, sb.toString());		if (log.isInfoEnabled()) {			log.info("Bundle created: " + bundleId);		}	}
public synchronized void reset() {		if (strategy == Strategy.ACTION_MANAGED) {			actionBundles.clear();			mirrors.clear();		}		final FindFile ff = new FindFile();		ff.includeDirs(false);		ff.searchPath(new File(bundleFolder, staplerPath));		File f;		int count = 0;		while ((f = ff.nextFile()) != null) {			f.delete();			count++;		}		if (log.isInfoEnabled()) {			log.info("reset: " + count + " bundle files deleted.");		}	}
protected String fixCssRelativeUrls(final String content, final String src) {		final String path = FileNameUtil.getPath(src);		final Matcher matcher = CSS_URL_PATTERN.matcher(content);		final StringBuilder sb = new StringBuilder(content.length());		int start = 0;		while (matcher.find()) {			sb.append(content, start, matcher.start());			final String matchedUrl = StringUtil.removeChars(matcher.group(1), "'\"");			final String url;			if (matchedUrl.startsWith("https://") || matchedUrl.startsWith("http://") || matchedUrl.startsWith("data:")) {				url = "url('" + matchedUrl + "')";			}			else {				url = fixRelativeUrl(matchedUrl, path);			}			sb.append(url);			start = matcher.end();		}		sb.append(content.substring(start));		return sb.toString();	}
protected String fixRelativeUrl(final String url, final String offsetPath) {		final StringBuilder res = new StringBuilder();		res.append("url('");		if (!url.startsWith(StringPool.SLASH)) {			res				.append("../")				.append(offsetPath);		}		res.append(url).append("')");		return res.toString();	}
public DbSqlBuilder update(final Object entity) {		String tableRef = createTableRefName(entity);		if (!dbOomConfig.isUpdateAcceptsTableAlias()) {			tableRef = null;		}		return sql().$(UPDATE).table(entity, tableRef).set(tableRef, entity).$(WHERE).matchIds(tableRef, entity);	}
public DbSqlBuilder updateAll(final Object entity) {		String tableRef = createTableRefName(entity);		if (!dbOomConfig.isUpdateAcceptsTableAlias()) {			tableRef = null;		}		return sql().$(UPDATE).table(entity, tableRef).setAll(tableRef, entity).$(WHERE).matchIds(tableRef, entity);	}
public DbSqlBuilder updateColumn(final Object entity, final String columnRef, final Object value) {		String tableRef = createTableRefName(entity);		if (!dbOomConfig.isUpdateAcceptsTableAlias()) {			tableRef = null;		}		return sql().$(UPDATE).table(entity, tableRef).$(SET).ref(null, columnRef).$(EQUALS).columnValue(value).$(WHERE).matchIds(tableRef, entity);	}
public DbSqlBuilder updateColumn(final Object entity, final String columnRef) {		final Object value = BeanUtil.pojo.getProperty(entity, columnRef);		return updateColumn(entity, columnRef, value);	}
public DbSqlBuilder delete(final Object entity) {		final String tableRef = createTableRefName(entity);		return sql().$(DELETE_FROM).table(entity, null, tableRef).$(WHERE).match(tableRef, entity);	}
public DbSqlBuilder deleteByAll(final Object entity) {		final String tableRef = createTableRefName(entity);		return sql().$(DELETE_FROM).table(entity, null, tableRef).$(WHERE).matchAll(tableRef, entity);	}
public DbSqlBuilder deleteById(final Object entity) {		final String tableRef = createTableRefName(entity);		return sql().$(DELETE_FROM).table(entity, null, tableRef).$(WHERE).matchIds(tableRef, entity);	}
public DbSqlBuilder deleteById(final Object entityType, final Object id) {		final String tableRef = createTableRefName(entityType);		return sql().			$(DELETE_FROM).table(entityType, null, tableRef).			$(WHERE).refId(tableRef).$(EQUALS).columnValue(id);	}
public DbSqlBuilder find(final Class target, final Object matchEntity) {		final String tableRef = createTableRefName(target);		return sql().$(SELECT).column(tableRef).$(FROM).table(target, tableRef).$(WHERE).match(tableRef, matchEntity);	}
public DbSqlBuilder find(final Object entity) {		final String tableRef = createTableRefName(entity);		return sql().$(SELECT).column(tableRef).$(FROM).table(entity, tableRef).$(WHERE).match(tableRef, entity);	}
public DbSqlBuilder findByAll(final Object entity) {		final String tableRef = createTableRefName(entity);		return sql().$(SELECT).column(tableRef).$(FROM).table(entity, tableRef).$(WHERE).matchAll(tableRef, entity);	}
public DbSqlBuilder findByColumn(final Class entity, final String column, final Object value) {		final String tableRef = createTableRefName(entity);		return sql().$(SELECT).column(tableRef).$(FROM).table(entity, tableRef).$(WHERE).ref(tableRef, column).$(EQUALS).columnValue(value);	}
public DbSqlBuilder findForeign(final Class entity, final Object value) {		final String tableRef = createTableRefName(entity);		final DbEntityDescriptor dedFk = entityManager.lookupType(value.getClass());		final String tableName = dbOomConfig.getTableNames().convertTableNameToEntityName(dedFk.getTableName());		final String columnName = dbOomConfig.getColumnNames().convertColumnNameToPropertyName(dedFk.getIdColumnName());		final String fkColumn = uncapitalize(tableName) + capitalize(columnName);		final Object idValue = BeanUtil.pojo.getProperty(value, dedFk.getIdPropertyName());		return sql().$(SELECT).column(tableRef).$(FROM).table(entity, tableRef).$(WHERE).ref(tableRef, fkColumn).$(EQUALS).columnValue(idValue);	}
public DbSqlBuilder findAll(final Object entity) {		final String tableRef = createTableRefName(entity);		return sql().$(SELECT).column(tableRef).$(FROM).table(entity, tableRef);	}
public DbSqlBuilder findById(final Object entity) {		final String tableRef = createTableRefName(entity);		return sql().$(SELECT).column(tableRef).$(FROM).table(entity, tableRef).$(WHERE).matchIds(tableRef, entity);	}
public DbSqlBuilder findById(final Object entityType, final Object id) {		final String tableRef = createTableRefName(entityType);		return sql().$(SELECT).column(tableRef).$(FROM).table(entityType, tableRef)				.$(WHERE).refId(tableRef).$(EQUALS).columnValue(id);	}
public DbSqlBuilder count(final Object entity) {		final String tableRef = createTableRefName(entity);		return sql().$(SELECT_COUNT_1_FROM).table(entity, tableRef).$(WHERE).match(tableRef, entity);	}
public DbSqlBuilder count(final Class entityType) {		final String tableRef = createTableRefName(entityType);		return sql().$(SELECT_COUNT_1_FROM).table(entityType, tableRef);	}
public DbSqlBuilder countAll(final Object entity) {		final String tableRef = createTableRefName(entity);		return sql().$(SELECT_COUNT_1_FROM).table(entity, tableRef).$(WHERE).matchAll(tableRef, entity);	}
public DbSqlBuilder increaseColumn(final Class entity, final Object id, final String columnRef, final Number delta, final boolean increase) {		final String tableRef = createTableRefName(entity);		return sql().$(UPDATE).table(entity, null, tableRef).$(SET)				.ref(null, columnRef).$(EQUALS).ref(null, columnRef)				.$(increase ? StringPool.PLUS : StringPool.DASH)				.columnValue(delta).$(WHERE).refId(tableRef).$(EQUALS).columnValue(id);	}
protected static String createTableRefName(final Object entity) {		Class type = entity.getClass();		type = (type == Class.class ? (Class) entity : type);		return (type.getSimpleName() + '_');	}
@Override	public DbSession getDbSession() {		log.debug("Requesting db TX manager session");		final DbJtxTransaction jtx = (DbJtxTransaction) jtxTxManager.getTransaction();		if (jtx == null) {			throw new DbSqlException(					"No transaction is in progress and DbSession can't be provided. " +					"It seems that transaction manager is not used to begin a transaction.");		}		return jtx.requestResource();	}
public String ref(final Object dummy) {		if (dummy != null) {			if (dummy instanceof String) {				return (String) dummy;			}			throw new MethrefException("Target method not collected");		}		return ref();	}
public String ref() {		if (instance == null) {			return null;		}		try {			Field f = instance.getClass().getDeclaredField("$__methodName$0");			f.setAccessible(true);			Object name = f.get(instance);			if (name == null) {				throw new MethrefException("Target method not collected");			}			return name.toString();		} catch (Exception ex) {			if (ex instanceof MethrefException) {				throw ((MethrefException) ex);			}			throw new MethrefException("Methref field not found", ex);		}	}
@Override	public synchronized ActionRuntime registerAction(Class actionClass, final Method actionMethod, ActionDefinition actionDefinition) {		if (proxettaSupplier == null) {			return super.registerAction(actionClass, actionMethod, actionDefinition);		}		if (actionDefinition == null) {			actionDefinition = actionMethodParser.parseActionDefinition(actionClass, actionMethod);		}		// create proxy for action class if not already created		Class existing = proxyActionClasses.get(actionClass);		if (existing == null) {			final Proxetta proxetta = proxettaSupplier.get();			existing = proxetta.proxy().setTarget(actionClass).define();			proxyActionClasses.put(actionClass, existing);		}		actionClass = existing;		return super.registerAction(actionClass, actionMethod, actionDefinition);	}
protected T[] convertToSingleElementArray(final Object value) {		T[] singleElementArray = createArray(1);		singleElementArray[0] = convertType(value);		return singleElementArray;	}
protected T[] convertValueToArray(final Object value) {		if (value instanceof Collection) {			Collection collection = (Collection) value;			T[] target = createArray(collection.size());			int i = 0;			for (Object element : collection) {				target[i] = convertType(element);				i++;			}			return target;		}		if (value instanceof Iterable) {			Iterable iterable = (Iterable) value;			List<T> list = new ArrayList<>();			for (Object element : iterable) {				list.add(convertType(element));			}			T[] target = createArray(list.size());			return list.toArray(target);		}		if (value instanceof CharSequence) {			String[] strings = convertStringToArray(value.toString());			return convertArrayToArray(strings);		}		// everything else:		return convertToSingleElementArray(value);	}
@SuppressWarnings("AutoBoxing")	protected T[] convertPrimitiveArrayToArray(final Object value, final Class primitiveComponentType) {		T[] result = null;		if (primitiveComponentType == int.class) {			int[] array = (int[]) value;			result = createArray(array.length);			for (int i = 0; i < array.length; i++) {				result[i] = convertType(array[i]);			}		}		else if (primitiveComponentType == long.class) {			long[] array = (long[]) value;			result = createArray(array.length);			for (int i = 0; i < array.length; i++) {				result[i] = convertType(array[i]);			}		}		else if (primitiveComponentType == float.class) {			float[] array = (float[]) value;			result = createArray(array.length);			for (int i = 0; i < array.length; i++) {				result[i] = convertType(array[i]);			}		}		else if (primitiveComponentType == double.class) {			double[] array = (double[]) value;			result = createArray(array.length);			for (int i = 0; i < array.length; i++) {				result[i] = convertType(array[i]);			}		}		else if (primitiveComponentType == short.class) {			short[] array = (short[]) value;			result = createArray(array.length);			for (int i = 0; i < array.length; i++) {				result[i] = convertType(array[i]);			}		}		else if (primitiveComponentType == byte.class) {			byte[] array = (byte[]) value;			result = createArray(array.length);			for (int i = 0; i < array.length; i++) {				result[i] = convertType(array[i]);			}		}		else if (primitiveComponentType == char.class) {			char[] array = (char[]) value;			result = createArray(array.length);			for (int i = 0; i < array.length; i++) {				result[i] = convertType(array[i]);			}		}		else if (primitiveComponentType == boolean.class) {			boolean[] array = (boolean[]) value;			result = createArray(array.length);			for (int i = 0; i < array.length; i++) {				result[i] = convertType(array[i]);			}		}		return result;	}
public Map<String, String> parseSignatureForGenerics(final String signature, final boolean isInterface) {		if (signature == null) {			return Collections.emptyMap();		}		final Map<String, String> genericsMap = new HashMap<>();		SignatureReader sr = new SignatureReader(signature);		StringBuilder sb = new StringBuilder();		TraceSignatureVisitor v = new TraceSignatureVisitor(sb, isInterface) {			String genericName;			@Override			public void visitFormalTypeParameter(final String name) {				genericName = name;				super.visitFormalTypeParameter(name);			}			@Override			public void visitClassType(final String name) {				if (genericName != null) {					genericsMap.put(genericName, 'L' + name + ';');					genericName = null;				}				super.visitClassType(name);			}		};		sr.accept(v);		return genericsMap;	}
public SetInjectionPoint[] resolve(final Class type, final boolean autowire) {		ClassDescriptor cd = ClassIntrospector.get().lookup(type);		List<SetInjectionPoint> list = new ArrayList<>();		PropertyDescriptor[] allProperties = cd.getAllPropertyDescriptors();		for (PropertyDescriptor propertyDescriptor : allProperties) {			if (propertyDescriptor.isGetterOnly()) {				continue;			}			Class propertyType = propertyDescriptor.getType();			if (!ClassUtil.isTypeOf(propertyType, Collection.class)) {				continue;			}			MethodDescriptor writeMethodDescriptor = propertyDescriptor.getWriteMethodDescriptor();			FieldDescriptor fieldDescriptor = propertyDescriptor.getFieldDescriptor();			PetiteInject ref = null;			if (writeMethodDescriptor != null) {				ref = writeMethodDescriptor.getMethod().getAnnotation(PetiteInject.class);			}			if (ref == null && fieldDescriptor != null) {				ref = fieldDescriptor.getField().getAnnotation(PetiteInject.class);			}			if ((!autowire) && (ref == null)) {				continue;			}			list.add(new SetInjectionPoint(propertyDescriptor));		}		SetInjectionPoint[] fields;		if (list.isEmpty()) {			fields = SetInjectionPoint.EMPTY;		} else {			fields = list.toArray(new SetInjectionPoint[0]);		}		return fields;	}
public boolean pushValue(final Object value) {		for (int i = 0; i < bagSize; i++) {			JsonValueContext valueContext = bag.get(i);			if (valueContext.getValue() == value) {				return true;			}		}		if (bagSize == bag.size()) {			lastValueContext = new JsonValueContext(value);			bag.add(lastValueContext);		}		else {			lastValueContext = bag.get(bagSize);			lastValueContext.reuse(value);		}		bagSize++;		return false;	}
@Override	public void pushName(final String name, final boolean withComma) {		JsonValueContext valueContext = peekValueContext();		if (valueContext != null) {			valueContext.setPropertyName(name);		}		super.pushName(name, withComma);	}
@Override	public void writeComma() {		JsonValueContext valueContext = peekValueContext();		if (valueContext != null) {			valueContext.incrementIndex();		}		super.writeComma();	}
public boolean serialize(final Object object) {		if (object == null) {			write(NULL);			return true;		}		TypeJsonSerializer typeJsonSerializer = null;		// callback		if (serializerResolver != null) {			typeJsonSerializer = serializerResolver.apply(object);		}		if (typeJsonSerializer == null) {			// + read paths map			if (jsonSerializer.pathSerializersMap != null) {				typeJsonSerializer = jsonSerializer.pathSerializersMap.get(path);			}			final Class type = object.getClass();			// + read local types map			if (jsonSerializer.typeSerializersMap != null) {				typeJsonSerializer = jsonSerializer.typeSerializersMap.lookup(type);			}			// + globals			if (typeJsonSerializer == null) {				typeJsonSerializer = TypeJsonSerializerMap.get().lookup(type);			}		}		return typeJsonSerializer.serialize(this, object);	}
public boolean matchIgnoredPropertyTypes(final Class propertyType, final boolean excludeMaps, final boolean include) {		if (!include) {			return false;		}		if (propertyType != null) {			if (!jsonSerializer.deep) {				ClassDescriptor propertyTypeClassDescriptor = ClassIntrospector.get().lookup(propertyType);				if (propertyTypeClassDescriptor.isArray()) {					return false;				}				if (propertyTypeClassDescriptor.isCollection()) {					return false;				}				if (excludeMaps) {					if (propertyTypeClassDescriptor.isMap()) {						return false;					}				}			}			// still not excluded, continue with excluded types and type names			// + excluded types			if (jsonSerializer.excludedTypes != null) {				for (Class excludedType : jsonSerializer.excludedTypes) {					if (ClassUtil.isTypeOf(propertyType, excludedType)) {						return false;					}				}			}			// + exclude type names			final String propertyTypeName = propertyType.getName();			if (jsonSerializer.excludedTypeNames != null) {				for (String excludedTypeName : jsonSerializer.excludedTypeNames) {					if (Wildcard.match(propertyTypeName, excludedTypeName)) {						return false;					}				}			}		}		return true;	}
public void closeSession() {		log.debug("Closing db session");		SQLException sqlException = null;		if (queries != null) {			for (DbQueryBase query : queries) {				SQLException sex = query.closeQuery();				if (sex != null) {					if (sqlException == null) {						sqlException = sex;					} else {						sqlException.setNextException(sex);					}				}			}		}		if (connection != null) {			if (txActive) {				throw new DbSqlException("TX was not closed before closing the session");			}			connectionProvider.closeConnection(connection);			connection = null;		}		queries = null;		if (sqlException != null) {			throw new DbSqlException("Closing DbSession failed", sqlException);		}	}
protected void openConnectionForQuery() {		if (connection == null) {			connection = connectionProvider.getConnection();			txActive = false;	// txAction should already be false			try {				connection.setAutoCommit(true);			} catch (SQLException sex) {				throw new DbSqlException("Failed to open non-TX connection", sex);			}		}	}
protected void openTx() {		if (connection == null) {			connection = connectionProvider.getConnection();		}		txActive = true;		try {			connection.setAutoCommit(false);			if (txMode.getIsolation() != DbTransactionMode.ISOLATION_DEFAULT) {				connection.setTransactionIsolation(txMode.getIsolation());			}			connection.setReadOnly(txMode.isReadOnly());		} catch (SQLException sex) {			throw new DbSqlException("Open TX failed", sex);		}	}
protected void closeTx() {		txActive = false;		try {			connection.setAutoCommit(true);		} catch (SQLException sex) {			throw new DbSqlException("Close TX failed", sex);		}	}
public void commitTransaction() {		log.debug("Committing transaction");		assertTxIsActive();		try {			connection.commit();		} catch (SQLException sex) {			throw new DbSqlException("Commit TX failed", sex);		} finally {			closeTx();		}	}
public void rollbackTransaction() {		log.debug("Rolling-back transaction");		assertTxIsActive();		try {			connection.rollback();		} catch (SQLException sex) {			throw new DbSqlException("Rollback TX failed", sex);		} finally {			closeTx();		}	}
protected String replaceActionNameMacros(String path, final ActionNames actionNames) {		final String packageName = actionNames.packageName();		final String className = actionNames.className();		final String methodName = actionNames.methodName();		final String httpMethod = actionNames.httpMethod();		if (packageName != null) {			path = StringUtil.replace(path, PACKAGE_MACRO, packageName);		}		if (className != null) {			path = StringUtil.replace(path, CLASS_MACRO, className);		}		if (methodName != null) {			path = StringUtil.replace(path, METHOD_MACRO, methodName);		}		if (httpMethod != null) {			path = StringUtil.replace(path, HTTPMETHOD_MACRO, httpMethod);		}		return path;	}
protected ActionDefinition createActionDef(String path, String httpMethod, String resultBasePath, final ActionNames actionNames) {		path = replaceActionNameMacros(path, actionNames);		if (httpMethod != null) {			httpMethod = replaceActionNameMacros(httpMethod, actionNames);		}		if (resultBasePath != null) {			resultBasePath = replaceActionNameMacros(resultBasePath, actionNames);		}		return new ActionDefinition(path, httpMethod, resultBasePath);	}
protected boolean isAbsolutePath(final String path) {		if (path == null) {			return false;		}		return path.startsWith(StringPool.SLASH);	}
public static Properties createFromFile(final File file) throws IOException {		Properties prop = new Properties();		loadFromFile(prop, file);		return prop;	}
public static void loadFromFile(final Properties p, final String fileName) throws IOException {		loadFromFile(p, new File(fileName));	}
public static void loadFromFile(final Properties p, final File file) throws IOException {		FileInputStream fis = null;		try {			fis = new FileInputStream(file);			p.load(fis);		} finally {			StreamUtil.close(fis);		}	}
public static void writeToFile(final Properties p, final String fileName) throws IOException {		writeToFile(p, new File(fileName), null);	}
public static void writeToFile(final Properties p, final String fileName, final String header) throws IOException {		writeToFile(p, new File(fileName), header);	}
public static void writeToFile(final Properties p, final File file) throws IOException {		writeToFile(p, file, null);	}
public static void writeToFile(final Properties p, final File file, final String header) throws IOException {		FileOutputStream fos = null;		try {			fos = new FileOutputStream(file);			p.store(fos, header);		} finally {			StreamUtil.close(fos);		}	}
public static Properties createFromString(final String data) throws IOException {		Properties p = new Properties();		loadFromString(p, data);		return p;	}
public static void loadFromString(final Properties p, final String data) throws IOException {		try (ByteArrayInputStream is = new ByteArrayInputStream(data.getBytes(StringPool.ISO_8859_1))) {			p.load(is);		}	}
public static Properties subset(final Properties p, String prefix, final boolean stripPrefix) {		if (StringUtil.isBlank(prefix)) {			return p;		}		if (!prefix.endsWith(StringPool.DOT)) {			prefix += '.';		}		Properties result = new Properties();		int baseLen = prefix.length();		for (Object o : p.keySet()) {			String key = (String) o;			if (key.startsWith(prefix)) {				result.setProperty(stripPrefix ? key.substring(baseLen) : key, p.getProperty(key));			}		}		return result;	}
public static Properties createFromClasspath(final String... rootTemplate) {		Properties p = new Properties();		return loadFromClasspath(p, rootTemplate);	}
public static Properties loadFromClasspath(final Properties p, final String... rootTemplate) {			ClassScanner.create()				.registerEntryConsumer(entryData -> UncheckedException.runAndWrapException(() -> p.load(entryData.openInputStream())))				.includeResources(true)				.ignoreException(true)				.excludeAllEntries(true)				.includeEntries(rootTemplate)				.scanDefaultClasspath();		return p;	}
public static String getProperty(final Map map, final String key) {		return getProperty(map, key, null);	}
public static String getProperty(final Map map, final String key, final String defaultValue) {		Object val = map.get(key);		return (val instanceof String) ? (String) val : defaultValue;	}
public static void resolveAllVariables(final Properties prop) {		for (Object o : prop.keySet()) {			String key = (String) o;			String value = resolveProperty(prop, key);			prop.setProperty(key, value);		}	}
public static String resolveProperty(final Map map, final String key) {		String value = getProperty(map, key);		if (value == null) {			return null;		}		value = stp.parse(value, macroName -> getProperty(map, macroName));		return value;	}
public String resolveScope(final Class type, final String methodName) {		if (scopePattern == null) {			return null;		}		String ctx = scopePattern;		ctx = StringUtil.replace(ctx, JTXCTX_PATTERN_CLASS, type.getName());		ctx = StringUtil.replace(ctx, JTXCTX_PATTERN_METHOD, methodName);		return ctx;	}
public synchronized JtxTransactionMode getTxMode(final Class type, final String methodName, final Class[] methodArgTypes, final String unique) {		String signature = type.getName() + '#' + methodName + '%' + unique;		JtxTransactionMode txMode = txmap.get(signature);		if (txMode == null) {			if (!txmap.containsKey(signature)) {				final Method m;				try {					m = type.getMethod(methodName, methodArgTypes);				} catch (NoSuchMethodException nsmex) {					throw new ProxettaException(nsmex);				}				final TransactionAnnotationValues txAnn = readTransactionAnnotation(m);				if (txAnn != null) {					txMode = new JtxTransactionMode(						txAnn.propagation(),						txAnn.isolation(),						txAnn.readOnly(),						txAnn.timeout()					);				} else {					txMode = defaultTransactionMode;				}				txmap.put(signature, txMode);			}		}		return txMode;	}
@SuppressWarnings( {"unchecked"})	public void registerAnnotations(final Class<? extends Annotation>[] annotations) {		this.annotations = annotations;		this.annotationParsers = new AnnotationParser[annotations.length];		for (int i = 0; i < annotations.length; i++) {			annotationParsers[i] = TransactionAnnotationValues.parserFor(annotations[i]);		}	}
protected TransactionAnnotationValues readTransactionAnnotation(final Method method) {		for (AnnotationParser annotationParser : annotationParsers) {			TransactionAnnotationValues tad = TransactionAnnotationValues.of(annotationParser, method);			if (tad != null) {				return tad;			}		}		return null;	}
public void addIdSelector(String id) {		id = unescape(id);		selectors.add(new AttributeSelector(ID, EQUALS, id));	}
@Override	public boolean accept(final Node node) {		// match element name with node name		if (!matchElement(node)) {			return false;		}		// match attributes		int totalSelectors = selectorsCount();		for (int i = 0; i < totalSelectors; i++) {			Selector selector = getSelector(i);			// just attr name existence			switch (selector.getType()) {				case ATTRIBUTE:					if (!((AttributeSelector) selector).accept(node)) {						return false;					}					break;				case PSEUDO_CLASS:					if (!((PseudoClassSelector) selector).accept(node)) {						return false;					}					break;				case PSEUDO_FUNCTION:					if (!((PseudoFunctionSelector) selector).accept(node)) {						return false;					}					break;			}		}		return true;	}
protected boolean matchElement(final Node node) {		if (node.getNodeType() != Node.NodeType.ELEMENT) {			return false;		}		String element = getElement();		String nodeName = node.getNodeName();		return element.equals(StringPool.STAR) || element.equals(nodeName);	}
public boolean accept(final List<Node> currentResults, final Node node, final int index) {		// match attributes		int totalSelectors = selectorsCount();		for (int i = 0; i < totalSelectors; i++) {			Selector selector = getSelector(i);			// just attr name existence			switch (selector.getType()) {				case PSEUDO_FUNCTION:					if (!((PseudoFunctionSelector) selector).accept(currentResults, node, index)) {						return false;					}					break;				case PSEUDO_CLASS:					if (!((PseudoClassSelector) selector).accept(currentResults, node, index)) {						return false;					}					break;				default:			}		}		return true;	}
protected String unescape(final String value) {		if (value.indexOf('\\') == -1) {			return value;		}		return StringUtil.remove(value, '\\');	}
private String[] buildJrePackages(final int javaVersionNumber) {		final ArrayList<String> packages = new ArrayList<>();		switch (javaVersionNumber) {			case 9:			case 8:			case 7:			case 6:			case 5:				// in Java1.5, the apache stuff moved				packages.add("com.sun.org.apache");				// fall through...			case 4:				if (javaVersionNumber == 4) {					packages.add("org.apache.crimson");					packages.add("org.apache.xalan");					packages.add("org.apache.xml");					packages.add("org.apache.xpath");				}				packages.add("org.ietf.jgss");				packages.add("org.w3c.dom");				packages.add("org.xml.sax");				// fall through...			case 3:				packages.add("org.omg");				packages.add("com.sun.corba");				packages.add("com.sun.jndi");				packages.add("com.sun.media");				packages.add("com.sun.naming");				packages.add("com.sun.org.omg");				packages.add("com.sun.rmi");				packages.add("sunw.io");				packages.add("sunw.util");				// fall through...			case 2:				packages.add("com.sun.java");				packages.add("com.sun.image");				// fall through...			case 1:			default:				// core stuff				packages.add("sun");				packages.add("java");				packages.add("javax");				break;		}		return packages.toArray(new String[0]);	}
private int detectJavaVersionNumber() {		String javaVersion = JAVA_VERSION;		final int lastDashNdx = javaVersion.lastIndexOf('-');		if (lastDashNdx != -1) {			javaVersion = javaVersion.substring(0, lastDashNdx);		}		if (javaVersion.startsWith("1.")) {			// up to java 8			final int index = javaVersion.indexOf('.', 2);			return Integer.parseInt(javaVersion.substring(2, index));		} else {			final int index = javaVersion.indexOf('.');			return Integer.parseInt(index == -1 ? javaVersion : javaVersion.substring(0, index));		}	}
protected <T extends Node> T cloneTo(final T dest) {//		dest.nodeValue = nodeValue;		// already  in clone implementations!		dest.parentNode = parentNode;		if (attributes != null) {			dest.attributes = new ArrayList<>(attributes.size());			for (int i = 0, attributesSize = attributes.size(); i < attributesSize; i++) {				Attribute attr = attributes.get(i);				dest.attributes.add(attr.clone());			}		}		if (childNodes != null) {			dest.childNodes = new ArrayList<>(childNodes.size());			for (int i = 0, childNodesSize = childNodes.size(); i < childNodesSize; i++) {				Node child = childNodes.get(i);				Node childClone = child.clone();				childClone.parentNode = dest;    // fix parent!				dest.childNodes.add(childClone);			}		}		return dest;	}
public void detachFromParent() {		if (parentNode == null) {			return;		}		if (parentNode.childNodes != null) {			parentNode.childNodes.remove(siblingIndex);			parentNode.reindexChildren();		}		parentNode = null;	}
public void addChild(final Node node) {		node.detachFromParent();		node.parentNode = this;		initChildNodes(node);		childNodes.add(node);		reindexChildrenOnAdd(1);	}
public void addChild(final Node... nodes) {		if (nodes.length == 0) {			return;	// nothing to add		}		for (Node node : nodes) {			node.detachFromParent();			node.parentNode = this;			initChildNodes(node);			childNodes.add(node);		}		reindexChildrenOnAdd(nodes.length);	}
public void insertChild(final Node node, final int index) {		node.detachFromParent();		node.parentNode = this;		try {			initChildNodes(node);			childNodes.add(index, node);		} catch (IndexOutOfBoundsException ignore) {			throw new LagartoDOMException("Invalid node index: " + index);		}		reindexChildren();	}
public void insertBefore(final Node newChild, final Node refChild) {		int siblingIndex = refChild.getSiblingIndex();		refChild.parentNode.insertChild(newChild, siblingIndex);	}
public void insertBefore(final Node[] newChilds, final Node refChild) {		if (newChilds.length == 0) {			return;		}		int siblingIndex = refChild.getSiblingIndex();		refChild.parentNode.insertChild(newChilds, siblingIndex);	}
public void insertAfter(final Node newChild, final Node refChild) {		int siblingIndex = refChild.getSiblingIndex() + 1;		if (siblingIndex == refChild.parentNode.getChildNodesCount()) {			refChild.parentNode.addChild(newChild);		} else {			refChild.parentNode.insertChild(newChild, siblingIndex);		}	}
public void insertAfter(final Node[] newChilds, final Node refChild) {		if (newChilds.length == 0) {			return;		}		int siblingIndex = refChild.getSiblingIndex() + 1;		if (siblingIndex == refChild.parentNode.getChildNodesCount()) {			refChild.parentNode.addChild(newChilds);		} else {			refChild.parentNode.insertChild(newChilds, siblingIndex);		}	}
public Node removeChild(final int index) {		if (childNodes == null) {			return null;		}		Node node;		try {			node = childNodes.get(index);		} catch (IndexOutOfBoundsException ignore) {			return null;		}		node.detachFromParent();		return node;	}
public void removeAllChilds() {		List<Node> removedNodes = childNodes;		childNodes = null;		childElementNodes = null;		childElementNodesCount = 0;		if (removedNodes != null) {			for (int i = 0, removedNodesSize = removedNodes.size(); i < removedNodesSize; i++) {				Node removedNode = removedNodes.get(i);				removedNode.detachFromParent();			}		}	}
public Attribute getAttribute(final int index) {		if (attributes == null) {			return null;		}		if ((index < 0) || (index >= attributes.size())) {			return null;		}		return attributes.get(index);	}
public boolean hasAttribute(String name) {		if (attributes == null) {			return false;		}		if (!ownerDocument.config.isCaseSensitive()) {			name = name.toLowerCase();		}		for (int i = 0, attributesSize = attributes.size(); i < attributesSize; i++) {			Attribute attr = attributes.get(i);			if (attr.getName().equals(name)) {				return true;			}		}		return false;	}
public String getAttribute(final String name) {		Attribute attribute = getAttributeInstance(name);		if (attribute == null) {			return null;		}		return attribute.getValue();	}
public void setAttribute(String name, final String value) {		initAttributes();		String rawAttributeName = name;		if (!ownerDocument.config.isCaseSensitive()) {			name = name.toLowerCase();		}		// search if attribute with the same name exist		for (int i = 0, attributesSize = attributes.size(); i < attributesSize; i++) {			Attribute attr = attributes.get(i);			if (attr.getName().equals(name)) {				attr.setValue(value);				return;			}		}		attributes.add(new Attribute(rawAttributeName, name, value));	}
public boolean isAttributeContaining(final String name, final String word) {		Attribute attr = getAttributeInstance(name);		if (attr == null) {			return false;		}		return attr.isContaining(word);	}
public Node findChildNodeWithName(final String name) {		if (childNodes == null) {			return null;		}		for (final Node childNode : childNodes) {			if (childNode.getNodeName().equals(name)) {				return childNode;			}		}		return null;	}
public Node[] filterChildNodes(final Predicate<Node> nodePredicate) {		if (childNodes == null) {			return new Node[0];		}		return childNodes.stream()			.filter(nodePredicate)			.toArray(Node[]::new);	}
public Node getChild(final int index) {		if (childNodes == null) {			return null;		}		if ((index < 0) || (index >= childNodes.size())) {			return null;		}		return childNodes.get(index);	}
public Node getChild(final int... indexes) {		Node node = this;		for (int index : indexes) {			node = node.getChild(index);		}		return node;	}
public Element getChildElement(final int index) {		initChildElementNodes();		if ((index < 0) || (index >= childElementNodes.length)) {			return null;		}		return childElementNodes[index];	}
public Node getFirstChild() {		if (childNodes == null) {			return null;		}		if (childNodes.isEmpty()) {			return null;		}		return childNodes.get(0);	}
public Node getLastChild() {		if (childNodes == null) {			return null;		}		if (childNodes.isEmpty()) {			return null;		}		return childNodes.get(getChildNodesCount() - 1);	}
public Element getLastChildElement(final String elementName) {		if (childNodes == null) {			return null;		}		int from = childNodes.size() - 1;		for (int i = from; i >= 0; i--) {			Node child = childNodes.get(i);			if (child.getNodeType() == NodeType.ELEMENT && elementName.equals(child.getNodeName())) {				child.initSiblingNames();				return (Element) child;			}		}		return null;	}
public boolean check() {		if (childNodes == null) {			return true;		}		// children		int siblingElementIndex = 0;		for (int i = 0, childNodesSize = childNodes.size(); i < childNodesSize; i++) {			Node childNode = childNodes.get(i);			if (childNode.siblingIndex != i) {				return false;			}			if (childNode.getNodeType() == NodeType.ELEMENT) {				if (childNode.siblingElementIndex != siblingElementIndex) {					return false;				}				siblingElementIndex++;			}		}		if (childElementNodesCount != siblingElementIndex) {			return false;		}		// child element nodes		if (childElementNodes != null) {			if (childElementNodes.length != childElementNodesCount) {				return false;			}			int childCount = getChildNodesCount();			for (int i = 0; i < childCount; i++) {				Node child = getChild(i);				if (child.siblingElementIndex >= 0) {					if (childElementNodes[child.siblingElementIndex] != child) {						return false;					}				}			}		}		// sibling names		if (siblingNameIndex != -1) {			List<Node> siblings = parentNode.childNodes;			int index = 0;			for (int i = 0, siblingsSize = siblings.size(); i < siblingsSize; i++) {				Node sibling = siblings.get(i);				if (sibling.siblingNameIndex == -1						&& nodeType == NodeType.ELEMENT						&& nodeName.equals(sibling.getNodeName())) {					if (sibling.siblingNameIndex != index++) {						return false;					}				}			}		}		// process children		for (Node childNode : childNodes) {			if (!childNode.check()) {				return false;			}		}		return true;	}
protected void reindexChildren() {		int siblingElementIndex = 0;		for (int i = 0, childNodesSize = childNodes.size(); i < childNodesSize; i++) {			Node childNode = childNodes.get(i);			childNode.siblingIndex = i;			childNode.siblingNameIndex = -1;	// reset sibling name info			if (childNode.getNodeType() == NodeType.ELEMENT) {				childNode.siblingElementIndex = siblingElementIndex;				siblingElementIndex++;			}		}		childElementNodesCount = siblingElementIndex;		childElementNodes = null;	// reset child element nodes	}
protected void initChildElementNodes() {		if (childElementNodes == null) {			childElementNodes = new Element[childElementNodesCount];			int childCount = getChildNodesCount();			for (int i = 0; i < childCount; i++) {				Node child = getChild(i);				if (child.siblingElementIndex >= 0) {					childElementNodes[child.siblingElementIndex] = (Element) child;				}			}		}	}
protected void initSiblingNames() {		if (siblingNameIndex == -1) {			List<Node> siblings = parentNode.childNodes;			int index = 0;			for (int i = 0, siblingsSize = siblings.size(); i < siblingsSize; i++) {				Node sibling = siblings.get(i);				if (sibling.siblingNameIndex == -1						&& nodeType == NodeType.ELEMENT						&& nodeName.equals(sibling.getNodeName())) {					sibling.siblingNameIndex = index++;				}			}		}	}
protected void initChildNodes(final Node newNode) {		if (childNodes == null) {			childNodes = new ArrayList<>();		}		if (ownerDocument != null) {			if (newNode.ownerDocument != ownerDocument) {				changeOwnerDocument(newNode, ownerDocument);			}		}	}
protected void changeOwnerDocument(final Node node, final Document ownerDocument) {		node.ownerDocument = ownerDocument;		int childCount = node.getChildNodesCount();		for (int i = 0; i < childCount; i++) {			Node child = node.getChild(i);			changeOwnerDocument(child, ownerDocument);		}	}
public Node getNextSibling() {		List<Node> siblings = parentNode.childNodes;		int index = siblingIndex + 1;		if (index >= siblings.size()) {			return null;		}		return siblings.get(index);	}
public Node getNextSiblingElement() {		parentNode.initChildElementNodes();		if (siblingElementIndex == -1) {			int max = parentNode.getChildNodesCount();			for (int i = siblingIndex; i < max; i++) {				Node sibling = parentNode.childNodes.get(i);				if (sibling.getNodeType() == NodeType.ELEMENT) {					return sibling;				}			}			return null;		}		int index = siblingElementIndex + 1;		if (index >= parentNode.childElementNodesCount) {			return null;		}		return parentNode.childElementNodes[index];	}
public Node getNextSiblingName() {		if (nodeName == null) {			return null;		}		initSiblingNames();		int index = siblingNameIndex + 1;		int max = parentNode.getChildNodesCount();		for (int i = siblingIndex + 1; i < max; i++) {			Node sibling = parentNode.childNodes.get(i);			if ((index == sibling.siblingNameIndex) && nodeName.equals(sibling.getNodeName())) {				return sibling;			}		}		return null;	}
public Node getPreviousSibling() {		List<Node> siblings = parentNode.childNodes;		int index = siblingIndex - 1;		if (index < 0) {			return null;		}		return siblings.get(index);	}
public Node getPreviousSiblingElement() {		parentNode.initChildElementNodes();		if (siblingElementIndex == -1) {			for (int i = siblingIndex - 1; i >= 0; i--) {				Node sibling = parentNode.childNodes.get(i);				if (sibling.getNodeType() == NodeType.ELEMENT) {					return sibling;				}			}			return null;		}		int index = siblingElementIndex - 1;		if (index < 0) {			return null;		}		return parentNode.childElementNodes[index];	}
public Node getPreviousSiblingName() {		if (nodeName == null) {			return null;		}		initSiblingNames();		int index = siblingNameIndex -1;		for (int i = siblingIndex; i >= 0; i--) {			Node sibling = parentNode.childNodes.get(i);			if ((index == sibling.siblingNameIndex) && nodeName.equals(sibling.getNodeName())) {				return sibling;			}		}		return null;	}
public String getTextContent() {		StringBuilder sb = new StringBuilder(getChildNodesCount() + 1);		appendTextContent(sb);		return sb.toString();	}
public void appendTextContent(final Appendable appendable) {		if (nodeValue != null) {			if ((nodeType == NodeType.TEXT) || (nodeType == NodeType.CDATA)) {				try {					appendable.append(nodeValue);				} catch (IOException ioex) {					throw new LagartoDOMException(ioex);				}			}		}		if (childNodes != null) {			for (int i = 0, childNodesSize = childNodes.size(); i < childNodesSize; i++) {				Node childNode = childNodes.get(i);				childNode.appendTextContent(appendable);			}		}	}
public String getHtml() {		LagartoDomBuilderConfig lagartoDomBuilderConfig;		if (ownerDocument == null) {			lagartoDomBuilderConfig = ((Document) this).getConfig();		} else {			lagartoDomBuilderConfig = ownerDocument.getConfig();		}		LagartoHtmlRenderer lagartoHtmlRenderer =				lagartoDomBuilderConfig.getLagartoHtmlRenderer();		return lagartoHtmlRenderer.toHtml(this, new StringBuilder());	}
public String getInnerHtml() {		LagartoDomBuilderConfig lagartoDomBuilderConfig;		if (ownerDocument == null) {			lagartoDomBuilderConfig = ((Document) this).getConfig();		} else {			lagartoDomBuilderConfig = ownerDocument.getConfig();		}		LagartoHtmlRenderer lagartoHtmlRenderer =				lagartoDomBuilderConfig.getLagartoHtmlRenderer();		return lagartoHtmlRenderer.toInnerHtml(this, new StringBuilder());	}
protected void visitChildren(final NodeVisitor nodeVisitor) {		if (childNodes != null) {			for (int i = 0, childNodesSize = childNodes.size(); i < childNodesSize; i++) {				Node childNode = childNodes.get(i);				childNode.visit(nodeVisitor);			}		}	}
public String getCssPath() {		StringBuilder path = new StringBuilder();		Node node = this;		while (node != null) {			String nodeName = node.getNodeName();			if (nodeName != null) {				StringBuilder sb = new StringBuilder();				sb.append(' ').append(nodeName);				String id = node.getAttribute("id");				if (id != null) {					sb.append('#').append(id);				}				path.insert(0, sb);			}			node = node.getParentNode();		}		if (path.charAt(0) == ' ') {			return path.substring(1);		}		return path.toString();	}
protected void onDecoraTag(final Tag tag) {		String tagName = tag.getName().toString();		if (tag.getType() == TagType.SELF_CLOSING) {			checkNestedDecoraTags();			decoraTagName = tagName.substring(7);			decoraTagStart = tag.getTagPosition();			decoraTagEnd = tag.getTagPosition() + tag.getTagLength();			defineDecoraTag();			return;		}		if (tag.getType() == TagType.START) {			checkNestedDecoraTags();			decoraTagName = tagName.substring(7);			decoraTagStart = tag.getTagPosition();			decoraTagDefaultValueStart = tag.getTagPosition() + tag.getTagLength();			return;		}		// closed tag type		decoraTagEnd = tag.getTagPosition() + tag.getTagLength();		decoraTagDefaultValueEnd = tag.getTagPosition();		defineDecoraTag();	}
protected void onIdAttrStart(final Tag tag) {		String id = tag.getId().toString().substring(7);		String tagName;		String idName;		int dashIndex = id.indexOf('-');		if (dashIndex == -1) {			tagName = id;			idName = null;		} else {			tagName = id.substring(0, dashIndex);			idName = id.substring(dashIndex + 1);		}		if (tag.getType() == TagType.SELF_CLOSING) {			checkNestedDecoraTags();			decoraTagName = tagName;			decoraIdName = idName;			decoraTagStart = tag.getTagPosition();			decoraTagEnd = tag.getTagPosition() + tag.getTagLength();			defineDecoraTag();			return;		}		if (tag.getType() == TagType.START) {			checkNestedDecoraTags();			decoraTagName = tagName;			decoraIdName = idName;			decoraTagStart = tag.getTagPosition();			decoraTagDefaultValueStart = tag.getTagPosition() + tag.getTagLength();			closingTagName = tag.getName().toString();			closingTagDeepLevel = tag.getDeepLevel();		}	}
protected void defineDecoraTag() {		DecoraTag decoraTag =				decoraTagDefaultValueStart == 0 ?					new DecoraTag(decoraTagName, decoraIdName, decoraTagStart, decoraTagEnd) :					new DecoraTag(							decoraTagName, decoraIdName,							decoraTagStart, decoraTagEnd,							decoraTagDefaultValueStart, decoraTagDefaultValueEnd - decoraTagDefaultValueStart);		decoraTags.add(decoraTag);		decoraTagName = null;		decoraIdName = null;		closingTagName = null;		decoraTagDefaultValueStart = 0;	}
@Override	public JoyProxetta addProxyAspect(final ProxyAspect proxyAspect) {		requireNotStarted(proxetta);		this.proxyAspects.add(proxyAspect);		return this;	}
@Override	public void start() {		initLogger();		log.info("PROXETTA start ----------");		final ProxyAspect[] proxyAspectsArray = this.proxyAspects.toArray(new ProxyAspect[0]);		log.debug("Total proxy aspects: " + proxyAspectsArray.length);//		proxetta = Proxetta.wrapperProxetta().setCreateTargetInDefaultCtor(true).withAspects(proxyAspectsArray);		proxetta = Proxetta.proxyProxetta().withAspects(proxyAspectsArray);		log.info("PROXETTA OK!");	}
@Benchmark	public Object map() {		final FastCharBuffer sb = new FastCharBuffer();		for (final int index : indexes) {			sb.append(map.get(TYPES[index]));		}		return sb;	}
@Override	public Timestamp get(final ResultSet rs, final int index, final int dbSqlType) throws SQLException {		return rs.getTimestamp(index);	}
@Override	public void set(final PreparedStatement st, final int index, final Timestamp value, final int dbSqlType) throws SQLException {		st.setTimestamp(index, value);	}
public static String getMimeType(final String ext) {		String mimeType = lookupMimeType(ext);		if (mimeType == null) {			mimeType = MIME_APPLICATION_OCTET_STREAM;		}		return mimeType;	}
public static String[] findExtensionsByMimeTypes(String mimeType, final boolean useWildcard) {		final ArrayList<String> extensions = new ArrayList<>();		mimeType = mimeType.toLowerCase();		final String[] mimeTypes = StringUtil.splitc(mimeType, ", ");		for (final Map.Entry<String, String> entry : MIME_TYPE_MAP.entrySet()) {			final String entryExtension = entry.getKey();			final String entryMimeType = entry.getValue().toLowerCase();			final int matchResult = useWildcard ?					Wildcard.matchOne(entryMimeType, mimeTypes) :					StringUtil.equalsOne(entryMimeType, mimeTypes);			if (matchResult != -1) {				extensions.add(entryExtension);			}		}		if (extensions.isEmpty()) {			return StringPool.EMPTY_ARRAY;		}		return extensions.toArray(new String[0]);	}
@Override	public Boolean get(final ResultSet rs, final int index, final int dbSqlType) throws SQLException {		return Boolean.valueOf(rs.getBoolean(index));	}
@Override	public void set(final PreparedStatement st, final int index, final Boolean value, final int dbSqlType) throws SQLException {		st.setBoolean(index, value.booleanValue());	}
public void addRootPackage(final String rootPackage, String mapping) {		if (packages == null) {			packages = new String[0];		}		if (mappings == null) {			mappings = new String[0];		}		// fix mapping		if (mapping.length() > 0) {			// mapping must start with the slash			if (!mapping.startsWith(StringPool.SLASH)) {				mapping = StringPool.SLASH + mapping;			}			// mapping must NOT end with the slash			if (mapping.endsWith(StringPool.SLASH)) {				mapping = StringUtil.substring(mapping, 0, -1);			}		}		// detect duplicates		for (int i = 0; i < packages.length; i++) {			if (packages[i].equals(rootPackage)) {				if (mappings[i].equals(mapping)) {					// both package and the mappings are the same					return;				}				throw new MadvocException("Different mappings for the same root package: " + rootPackage);			}		}		packages = ArraysUtil.append(packages, rootPackage);		mappings = ArraysUtil.append(mappings, mapping);	}
public void addRootPackageOf(final Class actionClass, final String mapping) {		addRootPackage(actionClass.getPackage().getName(), mapping);	}
public String findRootPackageForActionPath(final String actionPath) {		if (mappings == null) {			return null;		}		int ndx = -1;		int delta = Integer.MAX_VALUE;		for (int i = 0; i < mappings.length; i++) {			String mapping = mappings[i];			boolean found = false;			if (actionPath.equals(mapping)) {				found = true;			} else {				mapping += StringPool.SLASH;				if (actionPath.startsWith(mapping)) {					found = true;				}			}			if (found) {				int distance = actionPath.length() - mapping.length();				if (distance < delta) {					ndx = i;					delta = distance;				}			}		}		if (ndx == -1) {			return null;		}		return packages[ndx];	}
public String findPackagePathForActionPackage(final String actionPackage) {		if (packages == null) {			return null;		}		if (packagePaths == null) {			packagePaths = new HashMap<>();		}		String packagePath = packagePaths.get(actionPackage);		if (packagePath != null) {			return packagePath;		}		int ndx = -1;		int delta = Integer.MAX_VALUE;		for (int i = 0; i < packages.length; i++) {			String rootPackage = packages[i];			if (rootPackage.equals(actionPackage)) {				// exact match				ndx = i;				delta = 0;				break;			}			rootPackage += '.';			if (actionPackage.startsWith(rootPackage)) {				// found, action package contains root package				int distanceFromTheRoot = actionPackage.length() - rootPackage.length();				if (distanceFromTheRoot < delta) {					ndx = i;					delta = distanceFromTheRoot;				}			}		}		if (ndx == -1) {			return null;		}		String packageActionPath = delta == 0 ? StringPool.EMPTY : StringUtil.substring(actionPackage, - delta - 1, 0);		packageActionPath = packageActionPath.replace('.', '/');		String result = mappings[ndx] + packageActionPath;		packagePaths.put(actionPackage, result);		return result;	}
public DbSession beginTransaction(final JtxTransactionMode jtxMode, final boolean active) {		DbSession session = new DbSession(connectionProvider);		if (active) {			log.debug("begin jtx");			session.beginTransaction(JtxDbUtil.convertToDbMode(jtxMode));		}		return session;	}
public void commitTransaction(final DbSession resource) {		if (resource.isTransactionActive()) {			log.debug("commit jtx");			resource.commitTransaction();		}		resource.closeSession();	}
public void rollbackTransaction(final DbSession resource) {		try {			if (resource.isTransactionActive()) {				log.debug("rollback tx");				resource.rollbackTransaction();			}		} catch (Exception ex) {			throw new JtxException(ex);		} finally {			resource.closeSession();		}	}
public static String createViolationsJsonString(final HttpServletRequest request, final List<Violation> violations) {		if (violations == null) {			return StringPool.EMPTY;		}		StringBuilder sb = new StringBuilder().append('[');		for (int i = 0, violationsSize = violations.size(); i < violationsSize; i++) {			Violation violation = violations.get(i);			if (i != 0) {				sb.append(',');			}			sb.append('{');			sb.append("\"name\":\"").append(violation.getName()).append('"').append(',');			sb.append("\"msg\":\"").append(resolveValidationMessage(request, violation)).append('"');			sb.append('}');		}		sb.append(']');		return sb.toString();	}
public static String resolveValidationMessage(final HttpServletRequest request, final Violation violation) {		ValidationConstraint vc = violation.getConstraint();		String key = vc != null ? vc.getClass().getName() : violation.getName();		String msg = LocalizationUtil.findMessage(request, key);		if (msg != null) {			return beanTemplateParser.parseWithBean(msg, violation);		}		return null;	}
public BeanReferences removeDuplicateNames() {		if (names.length < 2) {			return this;		}		int nullCount = 0;		for (int i = 1; i < names.length; i++) {			String thisRef = names[i];			if (thisRef == null) {				nullCount++;				continue;			}			for (int j = 0; j < i; j++) {				if (names[j] == null) {					continue;				}				if (thisRef.equals(names[j])) {					names[i] = null;					break;				}			}		}		if (nullCount == 0) {			return this;		}		String[] newRefs = new String[names.length - nullCount];		int ndx = 0;		for (String name : names) {			if (name == null) {				continue;			}			newRefs[ndx] = name;			ndx++;		}		return new BeanReferences(newRefs);	}
@Override	public JoyProps addPropsFile(final String namePattern) {		requireNotStarted(props);		this.propsNamePatterns.add(namePattern);		return this;	}
@Override	public void start() {		initLogger();		log.info("PROPS start ----------");		props = createProps();		props.loadSystemProperties("sys");		props.loadEnvironment("env");		log.debug("Loaded sys&env props: " + props.countTotalProperties() + " properties.");		props.setActiveProfiles(propsProfiles.toArray(new String[0]));		// prepare patterns		final String[] patterns = new String[propsNamePatterns.size() + 1];		patterns[0] = "/" + nameSupplier.get() + "*.prop*";		for (int i = 0; i < propsNamePatterns.size(); i++) {			patterns[i + 1] = propsNamePatterns.get(i);		}		log.debug("Loading props from classpath...");		final long startTime = System.currentTimeMillis();		props.loadFromClasspath(patterns);		log.debug("Props scanning completed in " + (System.currentTimeMillis() - startTime) + "ms.");		log.debug("Total properties: " + props.countTotalProperties());		log.info("PROPS OK!");	}
protected Props createProps() {		final Props props = new Props();		props.setSkipEmptyProps(true);		props.setIgnoreMissingMacros(true);		return props;	}
public void forEachTarget(final Consumer<Target> targetConsumer) {		for (final Target target : targets) {			targetConsumer.accept(target);		}	}
public void forEachTargetAndIn(final MadvocScope scope, final BiConsumer<Target, InjectionPoint> biConsumer) {		for (final Target target : targets) {			final ScopeData scopeData = target.scopeData();			if (scopeData.in() == null) {				continue;			}			for (final InjectionPoint in : scopeData.in()) {				if (in.scope() != scope) {					continue;				}				biConsumer.accept(target, in);			}		}	}
public void forEachTargetAndOut(final MadvocScope scope, final BiConsumer<Target, InjectionPoint> biConsumer) {		for (final Target target : targets) {			final ScopeData scopeData = target.scopeData();			if (scopeData.out() == null) {				continue;			}			for (final InjectionPoint out : scopeData.out()) {				if (out.scope() != scope) {					continue;				}				biConsumer.accept(target, out);			}		}	}
public Object[] extractParametersValues() {		final Object[] values = new Object[targets.length - 1];		for (int i = 1; i < targets.length; i++) {			values[i - 1] = targets[i].value();		}		return values;	}
protected Target[] makeTargets(final Target actionTarget, final MethodParam[] methodParams) {		if (methodParams == null) {			// action does not have method parameters, so there is just one target			return new Target[]{actionTarget};		}		// action has method arguments, so there is more then one target		final Target[] target = new Target[methodParams.length + 1];		target[0] = actionTarget;		final Object action = actionTarget.value();		for (int i = 0; i < methodParams.length; i++) {			final MethodParam methodParam = methodParams[i];			final Class paramType = methodParam.type();			final Target paramTarget;			if (methodParam.annotationType() == null) {				// parameter is NOT annotated, create new value for the target				// the class itself will be a base class, and should be scanned				final ScopeData newScopeData = methodParam.scopeData().inspector().inspectClassScopesWithCache(paramType);				paramTarget = Target.ofValue(createActionMethodArgument(paramType, action), newScopeData);			}			else if (methodParam.annotationType() == Out.class) {				// parameter is annotated with *only* OUT annotation				// create the output value now AND to save the type				paramTarget = Target.ofMethodParam(methodParam, createActionMethodArgument(paramType, action));			}			else {				// parameter is annotated with any IN annotation				// create target with NO value, as the value will be created later				paramTarget = Target.ofMethodParam(methodParam, type -> createActionMethodArgument(type, action));			}			target[i + 1] = paramTarget;		}		return target;	}
@SuppressWarnings({"unchecked", "NullArgumentToVariableArgMethod"})	protected Object createActionMethodArgument(final Class type, final Object action) {		try {			if (type.getEnclosingClass() == null || Modifier.isStatic(type.getModifiers())) {				// regular or static class				return ClassUtil.newInstance(type);			} else {				// member class				Constructor ctor = type.getDeclaredConstructor(type.getDeclaringClass());				ctor.setAccessible(true);				return ctor.newInstance(action);			}		} catch (Exception ex) {			throw new MadvocException(ex);		}	}
@Override	public void sessionCreated(final HttpSessionEvent httpSessionEvent) {		HttpSession session = httpSessionEvent.getSession();		sessionMap.putIfAbsent(session.getId(), session);		for (HttpSessionListener listener : listeners) {			listener.sessionCreated(httpSessionEvent);		}	}
@Override	public void sessionDestroyed(final HttpSessionEvent httpSessionEvent) {		HttpSession session = httpSessionEvent.getSession();		sessionMap.remove(session.getId());		for (HttpSessionListener listener : listeners) {			listener.sessionDestroyed(httpSessionEvent);		}	}
public String getString(final int pos) {		CharSequence cs = (CharSequence) list.get(pos);		return cs == null ? null : cs.toString();	}
public Integer getInteger(final int pos) {		Number number = (Number) list.get(pos);		if (number == null) {			return null;		}		if (number instanceof Integer) {			// avoid unnecessary unbox/box			return (Integer) number;		}		return number.intValue();	}
public Long getLong(final int pos) {		Number number = (Number) list.get(pos);		if (number == null) {			return null;		}		if (number instanceof Long) {			// avoids unnecessary unbox/box			return (Long) number;		}		return number.longValue();	}
public Double getDouble(final int pos) {		Number number = (Number) list.get(pos);		if (number == null) {			return null;		}		if (number instanceof Double) {			// avoids unnecessary unbox/box			return (Double) number;		}		return number.doubleValue();	}
public Float getFloat(final int pos) {		Number number = (Number) list.get(pos);		if (number == null) {			return null;		}		if (number instanceof Float) {			// avoids unnecessary unbox/box			return (Float) number;		}		return number.floatValue();	}
public JsonObject getJsonObject(final int pos) {		Object val = list.get(pos);		if (val instanceof Map) {			val = new JsonObject((Map) val);		}		return (JsonObject) val;	}
public JsonArray getJsonArray(final int pos) {		Object val = list.get(pos);		if (val instanceof List) {			val = new JsonArray((List) val);		}		return (JsonArray) val;	}
public byte[] getBinary(final int pos) {		String val = (String) list.get(pos);		if (val == null) {			return null;		}		return Base64.getDecoder().decode(val);	}
public Object getValue(final int pos) {		Object val = list.get(pos);		if (val instanceof Map) {			val = new JsonObject((Map) val);		}		else if (val instanceof List) {			val = new JsonArray((List) val);		}		return val;	}
public JsonArray add(final Enum value) {		if (value == null) {			list.add(null);		} else {			list.add(value.name());		}		return this;	}
public JsonArray add(Object value) {		Objects.requireNonNull(value);		value = JsonObject.resolveValue(value);		list.add(value);		return this;	}
public JsonArray addAll(final JsonArray array) {		Objects.requireNonNull(array);		list.addAll(array.list);		return this;	}
public Object remove(final int pos) {		Object removed = list.remove(pos);		if (removed instanceof Map) {			return new JsonObject((Map) removed);		}		if (removed instanceof ArrayList) {			return new JsonArray((List) removed);		}		return removed;	}
@Override	public void render(final ActionRequest actionRequest, final Object resultValue) throws Exception {		final PathResult pathResult;		if (resultValue == null) {			pathResult = resultOf(StringPool.EMPTY);		} else {			if (resultValue instanceof String) {				pathResult = resultOf(resultValue);			}			else {				pathResult = (PathResult) resultValue;			}		}		final String resultBasePath = actionRequest.getActionRuntime().getResultBasePath();		final String path = pathResult != null ? pathResult.path() : StringPool.EMPTY;		final String actionAndResultPath = resultBasePath + (pathResult != null ? ':' + path : StringPool.EMPTY);		String target = targetCache.get(actionAndResultPath);		if (target == null) {			if (log.isDebugEnabled()) {				log.debug("new target: " + actionAndResultPath);			}			target = resolveTarget(actionRequest, path);			if (target == null) {				targetNotFound(actionRequest, actionAndResultPath);				return;			}			if (log.isDebugEnabled()) {				log.debug("target found: " + target);			}			// store target in cache			targetCache.put(actionAndResultPath, target);		}		// the target exists, continue		renderView(actionRequest, target);	}
protected String resolveTarget(final ActionRequest actionRequest, final String resultValue) {		String resultBasePath = actionRequest.getActionRuntime().getResultBasePath();		ResultPath resultPath = resultMapper.resolveResultPath(resultBasePath, resultValue);		String actionPath = resultPath.path();		String path = actionPath;		String value = resultPath.value();		if (StringUtil.isEmpty(value)) {			value = null;		}		String target;		while (true) {			// variant #1: with value			if (value != null) {				if (path == null) {					// only value remains					int lastSlashNdx = actionPath.lastIndexOf('/');					if (lastSlashNdx != -1) {						target = actionPath.substring(0, lastSlashNdx + 1) + value;					} else {						target = '/' + value;					}				} else {					target = path + '.' + value;				}				target = locateTarget(actionRequest, target);				if (target != null) {						break;				}			}			if (path != null) {				// variant #2: without value				target = locateTarget(actionRequest, path);				if (target != null) {					break;				}			}			// continue			if (path == null) {				// path not found				return null;			}			int dotNdx = MadvocUtil.lastIndexOfDotAfterSlash(path);			if (dotNdx == -1) {				path = null;			} else {				path = path.substring(0, dotNdx);			}		}		return target;	}
protected void targetNotFound(final ActionRequest actionRequest, final String actionAndResultPath) throws IOException {		final HttpServletResponse response = actionRequest.getHttpServletResponse();		if (!response.isCommitted()) {			response.sendError(SC_NOT_FOUND, "Result not found: " + actionAndResultPath);		}	}
@Override	public void render(final ActionRequest actionRequest, final Object resultValue) throws Exception {		final Redirect redirectResult;		if (resultValue == null) {			redirectResult = Redirect.to(StringPool.EMPTY);		} else {			if (resultValue instanceof String) {				redirectResult = Redirect.to((String)resultValue);			}			else {				redirectResult = (Redirect) resultValue;			}		}		final String resultBasePath = actionRequest.getActionRuntime().getResultBasePath();		final String redirectPath = redirectResult.path();		final String resultPath;		if (redirectPath.startsWith("http://") || redirectPath.startsWith("https://")) {			resultPath = redirectPath;		}		else {			resultPath = resultMapper.resolveResultPathString(resultBasePath, redirectPath);		}		HttpServletRequest request = actionRequest.getHttpServletRequest();		HttpServletResponse response = actionRequest.getHttpServletResponse();		String path = resultPath;		path = beanTemplateParser.parseWithBean(path, actionRequest.getAction());		DispatcherUtil.redirect(request, response, path);	}
private void processInputStartTag(final Tag tag) {		// INPUT		CharSequence tagType = tag.getAttributeValue(TYPE);		if (tagType == null) {			return;		}		CharSequence nameSequence = tag.getAttributeValue(NAME);		if (nameSequence == null) {			return;		}		String name = nameSequence.toString();		Object valueObject = resolver.value(name);		if (valueObject == null) {			return;		}		String tagTypeName = tagType.toString().toLowerCase();		if (				tagTypeName.equals(TEXT) ||				tagTypeName.equals(HIDDEN) ||				tagTypeName.equals(IMAGE) ||				tagTypeName.equals(PASSWORD)) {			String value = valueToString(name, valueObject);			if (value == null) {				return;			}			tag.setAttribute(VALUE, value);		}		else if (tagTypeName.equals(CHECKBOX)) {			CharSequence tagValue = tag.getAttributeValue(VALUE);			if (tagValue == null) {				tagValue = TRUE;			}			tagValue = tagValue.toString();			if (valueObject.getClass().isArray()) {				// checkbox group				String[] vs = StringUtil.toStringArray(valueObject);				for (String vsk : vs) {					if ((vsk != null) && (vsk.contentEquals(tagValue))) {						tag.setAttribute(CHECKED, null);					}				}			} else if (tagValue.equals(valueObject.toString())) {				tag.setAttribute(CHECKED, null);			}		}		else if (tagType.equals(RADIO)) {			CharSequence tagValue = tag.getAttributeValue(VALUE);			if (tagValue != null) {				tagValue = tagValue.toString();				if (tagValue.equals(valueObject.toString())) {					tag.setAttribute(CHECKED, null);				}			}		}	}
protected String valueToString(final String name, final Object valueObject) {		if (!valueObject.getClass().isArray()) {			return valueObject.toString();		}		// array		String[] array = (String[]) valueObject;		if (valueNameIndexes == null) {			valueNameIndexes = new HashMap<>();		}		MutableInteger index = valueNameIndexes.get(name);		if (index == null) {			index = new MutableInteger(0);			valueNameIndexes.put(name, index);		}		if (index.value >= array.length) {			return null;		}		String result = array[index.value];		index.value++;		return result;	}
@SuppressWarnings("unchecked")	public <T extends ActionInterceptor> MadvocRouter interceptor(final Class<T> actionInterceptorClass) {		interceptorsManager.resolve(actionInterceptorClass);		return this;	}
@SuppressWarnings("unchecked")	public <T extends ActionInterceptor> MadvocRouter interceptor(final Class<T> actionInterceptorClass, final Consumer<T> interceptorConsumer) {		T interceptor = (T) interceptorsManager.resolve(actionInterceptorClass);		interceptorConsumer.accept(interceptor);		return this;	}
@SuppressWarnings("unchecked")	public <T extends ActionFilter> MadvocRouter filter(final Class<T> actionFilterClass) {		filtersManager.resolve(actionFilterClass);		return this;	}
public boolean match(final List<Node> currentResults, final Node node, final int index, final E expression) {		return true;	}
public String getPseudoFunctionName() {		String name = getClass().getSimpleName().toLowerCase();		name = name.replace('_', '-');		return name;	}
public String createActionString() {		if (actionHandler != null) {			return actionHandler.getClass().getName();		}		String className = actionClass.getName();		final int ndx = className.indexOf("$$");		if (ndx != -1) {			className = className.substring(0, ndx);		}		return className + '#' + actionClassMethod.getName();	}
@Override	public Integer get(final ResultSet rs, final int index, final int dbSqlType) throws SQLException {		return Integer.valueOf(rs.getInt(index));	}
@Override	public void set(final PreparedStatement st, final int index, final Integer value, final int dbSqlType) throws SQLException {		st.setInt(index, value.intValue());	}
public PropertyInjectionPoint[] resolve(Class type, final boolean autowire) {		final List<PropertyInjectionPoint> list = new ArrayList<>();		final Set<String> usedPropertyNames = new HashSet<>();		// lookup fields		while (type != Object.class) {			final ClassDescriptor cd = ClassIntrospector.get().lookup(type);			final PropertyDescriptor[] allPropertyDescriptors = cd.getAllPropertyDescriptors();			for (PropertyDescriptor propertyDescriptor : allPropertyDescriptors) {				if (propertyDescriptor.isGetterOnly()) {					continue;				}				if (usedPropertyNames.contains(propertyDescriptor.getName())) {					continue;				}				Class propertyType = propertyDescriptor.getType();				if (ClassUtil.isTypeOf(propertyType, Collection.class)) {					continue;				}				BeanReferences reference = referencesResolver.readReferenceFromAnnotation(propertyDescriptor);				if (reference == null) {					if (!autowire) {						continue;					} else {						reference = referencesResolver.buildDefaultReference(propertyDescriptor);					}				}				list.add(new PropertyInjectionPoint(propertyDescriptor, reference));				usedPropertyNames.add(propertyDescriptor.getName());			}			// go to the supertype			type = type.getSuperclass();		}		final PropertyInjectionPoint[] fields;		if (list.isEmpty()) {			fields = PropertyInjectionPoint.EMPTY;		} else {			fields = list.toArray(new PropertyInjectionPoint[0]);		}		return fields;	}
private Socket createSocks4ProxySocket(final String host, final int port) {		Socket socket = null;		final String proxyHost = proxy.getProxyAddress();		final int proxyPort = proxy.getProxyPort();		final String user = proxy.getProxyUsername();		try {			socket = Sockets.connect(proxyHost, proxyPort, connectionTimeout);			final InputStream in = socket.getInputStream();			final OutputStream out = socket.getOutputStream();			socket.setTcpNoDelay(true);			byte[] buf = new byte[1024];			// 1) CONNECT			int index = 0;			buf[index++] = 4;			buf[index++] = 1;			buf[index++] = (byte) (port >>> 8);			buf[index++] = (byte) (port & 0xff);			InetAddress addr = InetAddress.getByName(host);			byte[] byteAddress = addr.getAddress();			for (byte byteAddres : byteAddress) {				buf[index++] = byteAddres;			}			if (user != null) {				System.arraycopy(user.getBytes(), 0, buf, index, user.length());				index += user.length();			}			buf[index++] = 0;			out.write(buf, 0, index);			// 2) RESPONSE			int len = 6;			int s = 0;			while (s < len) {				int i = in.read(buf, s, len - s);				if (i <= 0) {					throw new HttpException(ProxyInfo.ProxyType.SOCKS4, "stream is closed");				}				s += i;			}			if (buf[0] != 0) {				throw new HttpException(ProxyInfo.ProxyType.SOCKS4, "proxy returned VN " + buf[0]);			}			if (buf[1] != 90) {				try {					socket.close();				} catch (Exception ignore) {				}				throw new HttpException(ProxyInfo.ProxyType.SOCKS4, "proxy returned CD " + buf[1]);			}			byte[] temp = new byte[2];			in.read(temp, 0, 2);			return socket;		} catch (RuntimeException rtex) {			closeSocket(socket);			throw rtex;		} catch (Exception ex) {			closeSocket(socket);			throw new HttpException(ProxyInfo.ProxyType.SOCKS4, ex.toString(), ex);		}	}
protected Attribute read(      final ClassReader classReader,      final int offset,      final int length,      final char[] charBuffer,      final int codeAttributeOffset,      final Label[] labels) {    Attribute attribute = new Attribute(type);    attribute.content = new byte[length];    System.arraycopy(classReader.b, offset, attribute.content, 0, length);    return attribute;  }
protected ByteVector write(      final ClassWriter classWriter,      final byte[] code,      final int codeLength,      final int maxStack,      final int maxLocals) {    return new ByteVector(content);  }
final int getAttributeCount() {    int count = 0;    Attribute attribute = this;    while (attribute != null) {      count += 1;      attribute = attribute.nextAttribute;    }    return count;  }
final int computeAttributesSize(final SymbolTable symbolTable) {    final byte[] code = null;    final int codeLength = 0;    final int maxStack = -1;    final int maxLocals = -1;    return computeAttributesSize(symbolTable, code, codeLength, maxStack, maxLocals);  }
final int computeAttributesSize(      final SymbolTable symbolTable,      final byte[] code,      final int codeLength,      final int maxStack,      final int maxLocals) {    final ClassWriter classWriter = symbolTable.classWriter;    int size = 0;    Attribute attribute = this;    while (attribute != null) {      symbolTable.addConstantUtf8(attribute.type);      size += 6 + attribute.write(classWriter, code, codeLength, maxStack, maxLocals).length;      attribute = attribute.nextAttribute;    }    return size;  }
final void putAttributes(final SymbolTable symbolTable, final ByteVector output) {    final byte[] code = null;    final int codeLength = 0;    final int maxStack = -1;    final int maxLocals = -1;    putAttributes(symbolTable, code, codeLength, maxStack, maxLocals, output);  }
final void putAttributes(      final SymbolTable symbolTable,      final byte[] code,      final int codeLength,      final int maxStack,      final int maxLocals,      final ByteVector output) {    final ClassWriter classWriter = symbolTable.classWriter;    Attribute attribute = this;    while (attribute != null) {      ByteVector attributeContent =          attribute.write(classWriter, code, codeLength, maxStack, maxLocals);      // Put attribute_name_index and attribute_length.      output.putShort(symbolTable.addConstantUtf8(attribute.type)).putInt(attributeContent.length);      output.putByteArray(attributeContent.data, 0, attributeContent.length);      attribute = attribute.nextAttribute;    }  }
public Set<ActionResult> getAllActionResults() {		final Set<ActionResult> set = new HashSet<>(allResults.size());		allResults.forEachValue(set::add);		return set;	}
protected ActionResult register(final ActionResult result) {		Class<? extends ActionResult> actionResultClass = result.getClass();		// check existing		ActionResult existingResult = allResults.get(actionResultClass);		if (existingResult != null) {			if (log.isDebugEnabled()) {				log.debug("ActionResult already registered: " + actionResultClass);			}			return existingResult;		}		allResults.put(actionResultClass, result);		// + init		initializeResult(result);		return result;	}
private ActionResult lookupAndRegisterIfMissing(final Class<? extends ActionResult> actionResultClass) {		ActionResult actionResult = allResults.get(actionResultClass);		if (actionResult == null) {			actionResult = register(actionResultClass);		}		return actionResult;	}
public ActionResult lookup(final ActionRequest actionRequest, final Object resultObject) {		ActionResult actionResultHandler = null;		// + read @RenderWith value on method		{			final ActionRuntime actionRuntime = actionRequest.getActionRuntime();			final Class<? extends ActionResult> actionResultClass = actionRuntime.getActionResult();			if (actionResultClass != null) {				actionResultHandler = lookupAndRegisterIfMissing(actionResultClass);			}		}		// + use @RenderWith value on resulting object if exist		if (actionResultHandler == null && resultObject != null) {			final RenderWith renderWith = resultObject.getClass().getAnnotation(RenderWith.class);			if (renderWith != null) {				actionResultHandler = lookupAndRegisterIfMissing(renderWith.value());			}			else if (resultObject instanceof ActionResult) {				// special case - returned value is already the ActionResult				actionResultHandler = (ActionResult) resultObject;			}		}		// + use action configuration		if (actionResultHandler == null) {			final ActionRuntime actionRuntime = actionRequest.getActionRuntime();			final Class<? extends ActionResult> actionResultClass = actionRuntime.getDefaultActionResult();			if (actionResultClass != null) {				actionResultHandler = lookupAndRegisterIfMissing(actionResultClass);			}		}		if (actionResultHandler == null) {			throw new MadvocException("ActionResult not found for: " + resultObject);		}		// set action result object into action request!		actionRequest.bindActionResult(resultObject);		return actionResultHandler;	}
protected ActionResult createResult(final Class<? extends ActionResult> actionResultClass) {		try {			return ClassUtil.newInstance(actionResultClass);		} catch (Exception ex) {			throw new MadvocException("Invalid Madvoc result: " + actionResultClass, ex);		}	}
public static boolean equalsOne(final char c, final CharSequence match) {		for (int i = 0; i < match.length(); i++) {			char aMatch = match.charAt(i);			if (c == aMatch) {				return true;			}		}		return false;	}
public static int findFirstEqual(final CharSequence source, final int index, final CharSequence match) {		for (int i = index; i < source.length(); i++) {			if (equalsOne(source.charAt(i), match)) {				return i;			}		}		return -1;	}
public static int findFirstEqual(final char[] source, final int index, final char match) {		for (int i = index; i < source.length; i++) {			if (source[i] == match) {				return i;			}		}		return -1;	}
public CommandLine args(final String... arguments) {		if (arguments != null && arguments.length > 0) {			Collections.addAll(cmdLine, arguments);		}		return this;	}
public CommandLine env(final String key, final String value) {		if (env == null) {			env = new HashMap<>();		}		env.put(key, value);		return this;	}
public ProcessRunner.ProcessResult run() {		ByteArrayOutputStream baos = new ByteArrayOutputStream();		out = err = baos;		try {			baos.write(StringUtil.join(cmdLine, ' ').getBytes());			baos.write(StringPool.BYTES_NEW_LINE);		}		catch (IOException ignore) {		}		ProcessBuilder processBuilder = new ProcessBuilder();		processBuilder.command(cmdLine);		if (cleanEnvironment) {			processBuilder.environment().clear();		}		if (env != null) {			processBuilder.environment().putAll(env);		}		processBuilder.directory(workingDirectory);		Process process = null;		try {			process = processBuilder.start();		}		catch (IOException ioex) {			return writeException(baos, ioex);		}		StreamGobbler outputGobbler = new StreamGobbler(process.getInputStream(), out, outPrefix);		StreamGobbler errorGobbler = new StreamGobbler(process.getErrorStream(), err, errPrefix);		outputGobbler.start();		errorGobbler.start();		int result;		try {			result = process.waitFor();		}		catch (InterruptedException iex) {			return writeException(baos, iex);		}		outputGobbler.waitFor();		errorGobbler.waitFor();		return new ProcessRunner.ProcessResult(result, baos.toString());	}
public static void invoke(final Object listener, final Class listenerType) {		if (listenerType == Init.class) {			((Init) listener).init();			return;		}		if (listenerType == Start.class) {			((Start) listener).start();			return;		}		if (listenerType == Ready.class) {			((Ready) listener).ready();			return;		}		if (listenerType == Stop.class) {			((Stop) listener).stop();			return;		}		throw new MadvocException("Invalid listener");	}
final void copyFrom(final Frame frame) {    inputLocals = frame.inputLocals;    inputStack = frame.inputStack;    outputStackStart = 0;    outputLocals = frame.outputLocals;    outputStack = frame.outputStack;    outputStackTop = frame.outputStackTop;    initializationCount = frame.initializationCount;    initializations = frame.initializations;  }
static int getAbstractTypeFromApiFormat(final SymbolTable symbolTable, final Object type) {    if (type instanceof Integer) {      return CONSTANT_KIND | ((Integer) type).intValue();    } else if (type instanceof String) {      String descriptor = Type.getObjectType((String) type).getDescriptor();      return getAbstractTypeFromDescriptor(symbolTable, descriptor, 0);    } else {      return UNINITIALIZED_KIND          | symbolTable.addUninitializedType("", ((Label) type).bytecodeOffset);    }  }
private static int getAbstractTypeFromDescriptor(      final SymbolTable symbolTable, final String buffer, final int offset) {    String internalName;    switch (buffer.charAt(offset)) {      case 'V':        return 0;      case 'Z':      case 'C':      case 'B':      case 'S':      case 'I':        return INTEGER;      case 'F':        return FLOAT;      case 'J':        return LONG;      case 'D':        return DOUBLE;      case 'L':        internalName = buffer.substring(offset + 1, buffer.length() - 1);        return REFERENCE_KIND | symbolTable.addType(internalName);      case '[':        int elementDescriptorOffset = offset + 1;        while (buffer.charAt(elementDescriptorOffset) == '[') {          ++elementDescriptorOffset;        }        int typeValue;        switch (buffer.charAt(elementDescriptorOffset)) {          case 'Z':            typeValue = BOOLEAN;            break;          case 'C':            typeValue = CHAR;            break;          case 'B':            typeValue = BYTE;            break;          case 'S':            typeValue = SHORT;            break;          case 'I':            typeValue = INTEGER;            break;          case 'F':            typeValue = FLOAT;            break;          case 'J':            typeValue = LONG;            break;          case 'D':            typeValue = DOUBLE;            break;          case 'L':            internalName = buffer.substring(elementDescriptorOffset + 1, buffer.length() - 1);            typeValue = REFERENCE_KIND | symbolTable.addType(internalName);            break;          default:            throw new IllegalArgumentException();        }        return ((elementDescriptorOffset - offset) << DIM_SHIFT) | typeValue;      default:        throw new IllegalArgumentException();    }  }
final void setInputFrameFromDescriptor(      final SymbolTable symbolTable,      final int access,      final String descriptor,      final int maxLocals) {    inputLocals = new int[maxLocals];    inputStack = new int[0];    int inputLocalIndex = 0;    if ((access & Opcodes.ACC_STATIC) == 0) {      if ((access & Constants.ACC_CONSTRUCTOR) == 0) {        inputLocals[inputLocalIndex++] =            REFERENCE_KIND | symbolTable.addType(symbolTable.getClassName());      } else {        inputLocals[inputLocalIndex++] = UNINITIALIZED_THIS;      }    }    for (Type argumentType : Type.getArgumentTypes(descriptor)) {      int abstractType =          getAbstractTypeFromDescriptor(symbolTable, argumentType.getDescriptor(), 0);      inputLocals[inputLocalIndex++] = abstractType;      if (abstractType == LONG || abstractType == DOUBLE) {        inputLocals[inputLocalIndex++] = TOP;      }    }    while (inputLocalIndex < maxLocals) {      inputLocals[inputLocalIndex++] = TOP;    }  }
final void setInputFrameFromApiFormat(      final SymbolTable symbolTable,      final int numLocal,      final Object[] local,      final int numStack,      final Object[] stack) {    int inputLocalIndex = 0;    for (int i = 0; i < numLocal; ++i) {      inputLocals[inputLocalIndex++] = getAbstractTypeFromApiFormat(symbolTable, local[i]);      if (local[i] == Opcodes.LONG || local[i] == Opcodes.DOUBLE) {        inputLocals[inputLocalIndex++] = TOP;      }    }    while (inputLocalIndex < inputLocals.length) {      inputLocals[inputLocalIndex++] = TOP;    }    int numStackTop = 0;    for (int i = 0; i < numStack; ++i) {      if (stack[i] == Opcodes.LONG || stack[i] == Opcodes.DOUBLE) {        ++numStackTop;      }    }    inputStack = new int[numStack + numStackTop];    int inputStackIndex = 0;    for (int i = 0; i < numStack; ++i) {      inputStack[inputStackIndex++] = getAbstractTypeFromApiFormat(symbolTable, stack[i]);      if (stack[i] == Opcodes.LONG || stack[i] == Opcodes.DOUBLE) {        inputStack[inputStackIndex++] = TOP;      }    }    outputStackTop = 0;    initializationCount = 0;  }
private int getLocal(final int localIndex) {    if (outputLocals == null || localIndex >= outputLocals.length) {      // If this local has never been assigned in this basic block, it is still equal to its value      // in the input frame.      return LOCAL_KIND | localIndex;    } else {      int abstractType = outputLocals[localIndex];      if (abstractType == 0) {        // If this local has never been assigned in this basic block, so it is still equal to its        // value in the input frame.        abstractType = outputLocals[localIndex] = LOCAL_KIND | localIndex;      }      return abstractType;    }  }
private void setLocal(final int localIndex, final int abstractType) {    // Create and/or resize the output local variables array if necessary.    if (outputLocals == null) {      outputLocals = new int[10];    }    int outputLocalsLength = outputLocals.length;    if (localIndex >= outputLocalsLength) {      int[] newOutputLocals = new int[Math.max(localIndex + 1, 2 * outputLocalsLength)];      System.arraycopy(outputLocals, 0, newOutputLocals, 0, outputLocalsLength);      outputLocals = newOutputLocals;    }    // Set the local variable.    outputLocals[localIndex] = abstractType;  }
private void push(final int abstractType) {    // Create and/or resize the output stack array if necessary.    if (outputStack == null) {      outputStack = new int[10];    }    int outputStackLength = outputStack.length;    if (outputStackTop >= outputStackLength) {      int[] newOutputStack = new int[Math.max(outputStackTop + 1, 2 * outputStackLength)];      System.arraycopy(outputStack, 0, newOutputStack, 0, outputStackLength);      outputStack = newOutputStack;    }    // Pushes the abstract type on the output stack.    outputStack[outputStackTop++] = abstractType;    // Updates the maximum size reached by the output stack, if needed (note that this size is    // relative to the input stack size, which is not known yet).    short outputStackSize = (short) (outputStackStart + outputStackTop);    if (outputStackSize > owner.outputStackMax) {      owner.outputStackMax = outputStackSize;    }  }
private void push(final SymbolTable symbolTable, final String descriptor) {    int typeDescriptorOffset = descriptor.charAt(0) == '(' ? descriptor.indexOf(')') + 1 : 0;    int abstractType = getAbstractTypeFromDescriptor(symbolTable, descriptor, typeDescriptorOffset);    if (abstractType != 0) {      push(abstractType);      if (abstractType == LONG || abstractType == DOUBLE) {        push(TOP);      }    }  }
private void pop(final int elements) {    if (outputStackTop >= elements) {      outputStackTop -= elements;    } else {      // If the number of elements to be popped is greater than the number of elements in the output      // stack, clear it, and pop the remaining elements from the input stack.      outputStackStart -= elements - outputStackTop;      outputStackTop = 0;    }  }
private void pop(final String descriptor) {    char firstDescriptorChar = descriptor.charAt(0);    if (firstDescriptorChar == '(') {      pop((Type.getArgumentsAndReturnSizes(descriptor) >> 2) - 1);    } else if (firstDescriptorChar == 'J' || firstDescriptorChar == 'D') {      pop(2);    } else {      pop(1);    }  }
private void addInitializedType(final int abstractType) {    // Create and/or resize the initializations array if necessary.    if (initializations == null) {      initializations = new int[2];    }    int initializationsLength = initializations.length;    if (initializationCount >= initializationsLength) {      int[] newInitializations =          new int[Math.max(initializationCount + 1, 2 * initializationsLength)];      System.arraycopy(initializations, 0, newInitializations, 0, initializationsLength);      initializations = newInitializations;    }    // Store the abstract type.    initializations[initializationCount++] = abstractType;  }
private int getInitializedType(final SymbolTable symbolTable, final int abstractType) {    if (abstractType == UNINITIALIZED_THIS        || (abstractType & (DIM_MASK | KIND_MASK)) == UNINITIALIZED_KIND) {      for (int i = 0; i < initializationCount; ++i) {        int initializedType = initializations[i];        int dim = initializedType & DIM_MASK;        int kind = initializedType & KIND_MASK;        int value = initializedType & VALUE_MASK;        if (kind == LOCAL_KIND) {          initializedType = dim + inputLocals[value];        } else if (kind == STACK_KIND) {          initializedType = dim + inputStack[inputStack.length - value];        }        if (abstractType == initializedType) {          if (abstractType == UNINITIALIZED_THIS) {            return REFERENCE_KIND | symbolTable.addType(symbolTable.getClassName());          } else {            return REFERENCE_KIND                | symbolTable.addType(symbolTable.getType(abstractType & VALUE_MASK).value);          }        }      }    }    return abstractType;  }
void execute(      final int opcode, final int arg, final Symbol argSymbol, final SymbolTable symbolTable) {    // Abstract types popped from the stack or read from local variables.    int abstractType1;    int abstractType2;    int abstractType3;    int abstractType4;    switch (opcode) {      case Opcodes.NOP:      case Opcodes.INEG:      case Opcodes.LNEG:      case Opcodes.FNEG:      case Opcodes.DNEG:      case Opcodes.I2B:      case Opcodes.I2C:      case Opcodes.I2S:      case Opcodes.GOTO:      case Opcodes.RETURN:        break;      case Opcodes.ACONST_NULL:        push(NULL);        break;      case Opcodes.ICONST_M1:      case Opcodes.ICONST_0:      case Opcodes.ICONST_1:      case Opcodes.ICONST_2:      case Opcodes.ICONST_3:      case Opcodes.ICONST_4:      case Opcodes.ICONST_5:      case Opcodes.BIPUSH:      case Opcodes.SIPUSH:      case Opcodes.ILOAD:        push(INTEGER);        break;      case Opcodes.LCONST_0:      case Opcodes.LCONST_1:      case Opcodes.LLOAD:        push(LONG);        push(TOP);        break;      case Opcodes.FCONST_0:      case Opcodes.FCONST_1:      case Opcodes.FCONST_2:      case Opcodes.FLOAD:        push(FLOAT);        break;      case Opcodes.DCONST_0:      case Opcodes.DCONST_1:      case Opcodes.DLOAD:        push(DOUBLE);        push(TOP);        break;      case Opcodes.LDC:        switch (argSymbol.tag) {          case Symbol.CONSTANT_INTEGER_TAG:            push(INTEGER);            break;          case Symbol.CONSTANT_LONG_TAG:            push(LONG);            push(TOP);            break;          case Symbol.CONSTANT_FLOAT_TAG:            push(FLOAT);            break;          case Symbol.CONSTANT_DOUBLE_TAG:            push(DOUBLE);            push(TOP);            break;          case Symbol.CONSTANT_CLASS_TAG:            push(REFERENCE_KIND | symbolTable.addType("java/lang/Class"));            break;          case Symbol.CONSTANT_STRING_TAG:            push(REFERENCE_KIND | symbolTable.addType("java/lang/String"));            break;          case Symbol.CONSTANT_METHOD_TYPE_TAG:            push(REFERENCE_KIND | symbolTable.addType("java/lang/invoke/MethodType"));            break;          case Symbol.CONSTANT_METHOD_HANDLE_TAG:            push(REFERENCE_KIND | symbolTable.addType("java/lang/invoke/MethodHandle"));            break;          case Symbol.CONSTANT_DYNAMIC_TAG:            push(symbolTable, argSymbol.value);            break;          default:            throw new AssertionError();        }        break;      case Opcodes.ALOAD:        push(getLocal(arg));        break;      case Opcodes.LALOAD:      case Opcodes.D2L:        pop(2);        push(LONG);        push(TOP);        break;      case Opcodes.DALOAD:      case Opcodes.L2D:        pop(2);        push(DOUBLE);        push(TOP);        break;      case Opcodes.AALOAD:        pop(1);        abstractType1 = pop();        push(abstractType1 == NULL ? abstractType1 : ELEMENT_OF + abstractType1);        break;      case Opcodes.ISTORE:      case Opcodes.FSTORE:      case Opcodes.ASTORE:        abstractType1 = pop();        setLocal(arg, abstractType1);        if (arg > 0) {          int previousLocalType = getLocal(arg - 1);          if (previousLocalType == LONG || previousLocalType == DOUBLE) {            setLocal(arg - 1, TOP);          } else if ((previousLocalType & KIND_MASK) == LOCAL_KIND              || (previousLocalType & KIND_MASK) == STACK_KIND) {            // The type of the previous local variable is not known yet, but if it later appears            // to be LONG or DOUBLE, we should then use TOP instead.            setLocal(arg - 1, previousLocalType | TOP_IF_LONG_OR_DOUBLE_FLAG);          }        }        break;      case Opcodes.LSTORE:      case Opcodes.DSTORE:        pop(1);        abstractType1 = pop();        setLocal(arg, abstractType1);        setLocal(arg + 1, TOP);        if (arg > 0) {          int previousLocalType = getLocal(arg - 1);          if (previousLocalType == LONG || previousLocalType == DOUBLE) {            setLocal(arg - 1, TOP);          } else if ((previousLocalType & KIND_MASK) == LOCAL_KIND              || (previousLocalType & KIND_MASK) == STACK_KIND) {            // The type of the previous local variable is not known yet, but if it later appears            // to be LONG or DOUBLE, we should then use TOP instead.            setLocal(arg - 1, previousLocalType | TOP_IF_LONG_OR_DOUBLE_FLAG);          }        }        break;      case Opcodes.IASTORE:      case Opcodes.BASTORE:      case Opcodes.CASTORE:      case Opcodes.SASTORE:      case Opcodes.FASTORE:      case Opcodes.AASTORE:        pop(3);        break;      case Opcodes.LASTORE:      case Opcodes.DASTORE:        pop(4);        break;      case Opcodes.POP:      case Opcodes.IFEQ:      case Opcodes.IFNE:      case Opcodes.IFLT:      case Opcodes.IFGE:      case Opcodes.IFGT:      case Opcodes.IFLE:      case Opcodes.IRETURN:      case Opcodes.FRETURN:      case Opcodes.ARETURN:      case Opcodes.TABLESWITCH:      case Opcodes.LOOKUPSWITCH:      case Opcodes.ATHROW:      case Opcodes.MONITORENTER:      case Opcodes.MONITOREXIT:      case Opcodes.IFNULL:      case Opcodes.IFNONNULL:        pop(1);        break;      case Opcodes.POP2:      case Opcodes.IF_ICMPEQ:      case Opcodes.IF_ICMPNE:      case Opcodes.IF_ICMPLT:      case Opcodes.IF_ICMPGE:      case Opcodes.IF_ICMPGT:      case Opcodes.IF_ICMPLE:      case Opcodes.IF_ACMPEQ:      case Opcodes.IF_ACMPNE:      case Opcodes.LRETURN:      case Opcodes.DRETURN:        pop(2);        break;      case Opcodes.DUP:        abstractType1 = pop();        push(abstractType1);        push(abstractType1);        break;      case Opcodes.DUP_X1:        abstractType1 = pop();        abstractType2 = pop();        push(abstractType1);        push(abstractType2);        push(abstractType1);        break;      case Opcodes.DUP_X2:        abstractType1 = pop();        abstractType2 = pop();        abstractType3 = pop();        push(abstractType1);        push(abstractType3);        push(abstractType2);        push(abstractType1);        break;      case Opcodes.DUP2:        abstractType1 = pop();        abstractType2 = pop();        push(abstractType2);        push(abstractType1);        push(abstractType2);        push(abstractType1);        break;      case Opcodes.DUP2_X1:        abstractType1 = pop();        abstractType2 = pop();        abstractType3 = pop();        push(abstractType2);        push(abstractType1);        push(abstractType3);        push(abstractType2);        push(abstractType1);        break;      case Opcodes.DUP2_X2:        abstractType1 = pop();        abstractType2 = pop();        abstractType3 = pop();        abstractType4 = pop();        push(abstractType2);        push(abstractType1);        push(abstractType4);        push(abstractType3);        push(abstractType2);        push(abstractType1);        break;      case Opcodes.SWAP:        abstractType1 = pop();        abstractType2 = pop();        push(abstractType1);        push(abstractType2);        break;      case Opcodes.IALOAD:      case Opcodes.BALOAD:      case Opcodes.CALOAD:      case Opcodes.SALOAD:      case Opcodes.IADD:      case Opcodes.ISUB:      case Opcodes.IMUL:      case Opcodes.IDIV:      case Opcodes.IREM:      case Opcodes.IAND:      case Opcodes.IOR:      case Opcodes.IXOR:      case Opcodes.ISHL:      case Opcodes.ISHR:      case Opcodes.IUSHR:      case Opcodes.L2I:      case Opcodes.D2I:      case Opcodes.FCMPL:      case Opcodes.FCMPG:        pop(2);        push(INTEGER);        break;      case Opcodes.LADD:      case Opcodes.LSUB:      case Opcodes.LMUL:      case Opcodes.LDIV:      case Opcodes.LREM:      case Opcodes.LAND:      case Opcodes.LOR:      case Opcodes.LXOR:        pop(4);        push(LONG);        push(TOP);        break;      case Opcodes.FALOAD:      case Opcodes.FADD:      case Opcodes.FSUB:      case Opcodes.FMUL:      case Opcodes.FDIV:      case Opcodes.FREM:      case Opcodes.L2F:      case Opcodes.D2F:        pop(2);        push(FLOAT);        break;      case Opcodes.DADD:      case Opcodes.DSUB:      case Opcodes.DMUL:      case Opcodes.DDIV:      case Opcodes.DREM:        pop(4);        push(DOUBLE);        push(TOP);        break;      case Opcodes.LSHL:      case Opcodes.LSHR:      case Opcodes.LUSHR:        pop(3);        push(LONG);        push(TOP);        break;      case Opcodes.IINC:        setLocal(arg, INTEGER);        break;      case Opcodes.I2L:      case Opcodes.F2L:        pop(1);        push(LONG);        push(TOP);        break;      case Opcodes.I2F:        pop(1);        push(FLOAT);        break;      case Opcodes.I2D:      case Opcodes.F2D:        pop(1);        push(DOUBLE);        push(TOP);        break;      case Opcodes.F2I:      case Opcodes.ARRAYLENGTH:      case Opcodes.INSTANCEOF:        pop(1);        push(INTEGER);        break;      case Opcodes.LCMP:      case Opcodes.DCMPL:      case Opcodes.DCMPG:        pop(4);        push(INTEGER);        break;      case Opcodes.JSR:      case Opcodes.RET:        throw new IllegalArgumentException("JSR/RET are not supported with computeFrames option");      case Opcodes.GETSTATIC:        push(symbolTable, argSymbol.value);        break;      case Opcodes.PUTSTATIC:        pop(argSymbol.value);        break;      case Opcodes.GETFIELD:        pop(1);        push(symbolTable, argSymbol.value);        break;      case Opcodes.PUTFIELD:        pop(argSymbol.value);        pop();        break;      case Opcodes.INVOKEVIRTUAL:      case Opcodes.INVOKESPECIAL:      case Opcodes.INVOKESTATIC:      case Opcodes.INVOKEINTERFACE:        pop(argSymbol.value);        if (opcode != Opcodes.INVOKESTATIC) {          abstractType1 = pop();          if (opcode == Opcodes.INVOKESPECIAL && argSymbol.name.charAt(0) == '<') {            addInitializedType(abstractType1);          }        }        push(symbolTable, argSymbol.value);        break;      case Opcodes.INVOKEDYNAMIC:        pop(argSymbol.value);        push(symbolTable, argSymbol.value);        break;      case Opcodes.NEW:        push(UNINITIALIZED_KIND | symbolTable.addUninitializedType(argSymbol.value, arg));        break;      case Opcodes.NEWARRAY:        pop();        switch (arg) {          case Opcodes.T_BOOLEAN:            push(ARRAY_OF | BOOLEAN);            break;          case Opcodes.T_CHAR:            push(ARRAY_OF | CHAR);            break;          case Opcodes.T_BYTE:            push(ARRAY_OF | BYTE);            break;          case Opcodes.T_SHORT:            push(ARRAY_OF | SHORT);            break;          case Opcodes.T_INT:            push(ARRAY_OF | INTEGER);            break;          case Opcodes.T_FLOAT:            push(ARRAY_OF | FLOAT);            break;          case Opcodes.T_DOUBLE:            push(ARRAY_OF | DOUBLE);            break;          case Opcodes.T_LONG:            push(ARRAY_OF | LONG);            break;          default:            throw new IllegalArgumentException();        }        break;      case Opcodes.ANEWARRAY:        String arrayElementType = argSymbol.value;        pop();        if (arrayElementType.charAt(0) == '[') {          push(symbolTable, '[' + arrayElementType);        } else {          push(ARRAY_OF | REFERENCE_KIND | symbolTable.addType(arrayElementType));        }        break;      case Opcodes.CHECKCAST:        String castType = argSymbol.value;        pop();        if (castType.charAt(0) == '[') {          push(symbolTable, castType);        } else {          push(REFERENCE_KIND | symbolTable.addType(castType));        }        break;      case Opcodes.MULTIANEWARRAY:        pop(arg);        push(symbolTable, argSymbol.value);        break;      default:        throw new IllegalArgumentException();    }  }
private static boolean merge(      final SymbolTable symbolTable,      final int sourceType,      final int[] dstTypes,      final int dstIndex) {    int dstType = dstTypes[dstIndex];    if (dstType == sourceType) {      // If the types are equal, merge(sourceType, dstType) = dstType, so there is no change.      return false;    }    int srcType = sourceType;    if ((sourceType & ~DIM_MASK) == NULL) {      if (dstType == NULL) {        return false;      }      srcType = NULL;    }    if (dstType == 0) {      // If dstTypes[dstIndex] has never been assigned, merge(srcType, dstType) = srcType.      dstTypes[dstIndex] = srcType;      return true;    }    int mergedType;    if ((dstType & DIM_MASK) != 0 || (dstType & KIND_MASK) == REFERENCE_KIND) {      // If dstType is a reference type of any array dimension.      if (srcType == NULL) {        // If srcType is the NULL type, merge(srcType, dstType) = dstType, so there is no change.        return false;      } else if ((srcType & (DIM_MASK | KIND_MASK)) == (dstType & (DIM_MASK | KIND_MASK))) {        // If srcType has the same array dimension and the same kind as dstType.        if ((dstType & KIND_MASK) == REFERENCE_KIND) {          // If srcType and dstType are reference types with the same array dimension,          // merge(srcType, dstType) = dim(srcType) | common super class of srcType and dstType.          mergedType =              (srcType & DIM_MASK)                  | REFERENCE_KIND                  | symbolTable.addMergedType(srcType & VALUE_MASK, dstType & VALUE_MASK);        } else {          // If srcType and dstType are array types of equal dimension but different element types,          // merge(srcType, dstType) = dim(srcType) - 1 | java/lang/Object.          int mergedDim = ELEMENT_OF + (srcType & DIM_MASK);          mergedType = mergedDim | REFERENCE_KIND | symbolTable.addType("java/lang/Object");        }      } else if ((srcType & DIM_MASK) != 0 || (srcType & KIND_MASK) == REFERENCE_KIND) {        // If srcType is any other reference or array type,        // merge(srcType, dstType) = min(srcDdim, dstDim) | java/lang/Object        // where srcDim is the array dimension of srcType, minus 1 if srcType is an array type        // with a non reference element type (and similarly for dstDim).        int srcDim = srcType & DIM_MASK;        if (srcDim != 0 && (srcType & KIND_MASK) != REFERENCE_KIND) {          srcDim = ELEMENT_OF + srcDim;        }        int dstDim = dstType & DIM_MASK;        if (dstDim != 0 && (dstType & KIND_MASK) != REFERENCE_KIND) {          dstDim = ELEMENT_OF + dstDim;        }        mergedType =            Math.min(srcDim, dstDim) | REFERENCE_KIND | symbolTable.addType("java/lang/Object");      } else {        // If srcType is any other type, merge(srcType, dstType) = TOP.        mergedType = TOP;      }    } else if (dstType == NULL) {      // If dstType is the NULL type, merge(srcType, dstType) = srcType, or TOP if srcType is not a      // an array type or a reference type.      mergedType =          (srcType & DIM_MASK) != 0 || (srcType & KIND_MASK) == REFERENCE_KIND ? srcType : TOP;    } else {      // If dstType is any other type, merge(srcType, dstType) = TOP whatever srcType.      mergedType = TOP;    }    if (mergedType != dstType) {      dstTypes[dstIndex] = mergedType;      return true;    }    return false;  }
final void accept(final MethodWriter methodWriter) {    // Compute the number of locals, ignoring TOP types that are just after a LONG or a DOUBLE, and    // all trailing TOP types.    int[] localTypes = inputLocals;    int numLocal = 0;    int numTrailingTop = 0;    int i = 0;    while (i < localTypes.length) {      int localType = localTypes[i];      i += (localType == LONG || localType == DOUBLE) ? 2 : 1;      if (localType == TOP) {        numTrailingTop++;      } else {        numLocal += numTrailingTop + 1;        numTrailingTop = 0;      }    }    // Compute the stack size, ignoring TOP types that are just after a LONG or a DOUBLE.    int[] stackTypes = inputStack;    int numStack = 0;    i = 0;    while (i < stackTypes.length) {      int stackType = stackTypes[i];      i += (stackType == LONG || stackType == DOUBLE) ? 2 : 1;      numStack++;    }    // Visit the frame and its content.    int frameIndex = methodWriter.visitFrameStart(owner.bytecodeOffset, numLocal, numStack);    i = 0;    while (numLocal-- > 0) {      int localType = localTypes[i];      i += (localType == LONG || localType == DOUBLE) ? 2 : 1;      methodWriter.visitAbstractType(frameIndex++, localType);    }    i = 0;    while (numStack-- > 0) {      int stackType = stackTypes[i];      i += (stackType == LONG || stackType == DOUBLE) ? 2 : 1;      methodWriter.visitAbstractType(frameIndex++, stackType);    }    methodWriter.visitFrameEnd();  }
static void putAbstractType(      final SymbolTable symbolTable, final int abstractType, final ByteVector output) {    int arrayDimensions = (abstractType & Frame.DIM_MASK) >> DIM_SHIFT;    if (arrayDimensions == 0) {      int typeValue = abstractType & VALUE_MASK;      switch (abstractType & KIND_MASK) {        case CONSTANT_KIND:          output.putByte(typeValue);          break;        case REFERENCE_KIND:          output              .putByte(ITEM_OBJECT)              .putShort(symbolTable.addConstantClass(symbolTable.getType(typeValue).value).index);          break;        case UNINITIALIZED_KIND:          output.putByte(ITEM_UNINITIALIZED).putShort((int) symbolTable.getType(typeValue).data);          break;        default:          throw new AssertionError();      }    } else {      // Case of an array type, we need to build its descriptor first.      StringBuilder typeDescriptor = new StringBuilder();      while (arrayDimensions-- > 0) {        typeDescriptor.append('[');      }      if ((abstractType & KIND_MASK) == REFERENCE_KIND) {        typeDescriptor            .append('L')            .append(symbolTable.getType(abstractType & VALUE_MASK).value)            .append(';');      } else {        switch (abstractType & VALUE_MASK) {          case Frame.ITEM_ASM_BOOLEAN:            typeDescriptor.append('Z');            break;          case Frame.ITEM_ASM_BYTE:            typeDescriptor.append('B');            break;          case Frame.ITEM_ASM_CHAR:            typeDescriptor.append('C');            break;          case Frame.ITEM_ASM_SHORT:            typeDescriptor.append('S');            break;          case Frame.ITEM_INTEGER:            typeDescriptor.append('I');            break;          case Frame.ITEM_FLOAT:            typeDescriptor.append('F');            break;          case Frame.ITEM_LONG:            typeDescriptor.append('J');            break;          case Frame.ITEM_DOUBLE:            typeDescriptor.append('D');            break;          default:            throw new AssertionError();        }      }      output          .putByte(ITEM_OBJECT)          .putShort(symbolTable.addConstantClass(typeDescriptor.toString()).index);    }  }
@Override	protected int pruneCache() {        int count = 0;		Iterator<CacheObject<K,V>> values = cacheMap.values().iterator();		while (values.hasNext()) {			CacheObject co = values.next();			if (co.isExpired()) {				values.remove();				count++;			}		}		return count;	}
public void schedulePrune(final long delay) {		if (pruneTimer != null) {			pruneTimer.cancel();		}		pruneTimer = new Timer();		pruneTimer.schedule(				new TimerTask() {					@Override					public void run() {						prune();					}				}, delay, delay		);	}
public ModuleVisitor visitModule(final String name, final int access, final String version) {    if (api < Opcodes.ASM6) {      throw new UnsupportedOperationException("This feature requires ASM6");    }    if (cv != null) {      return cv.visitModule(name, access, version);    }    return null;  }
public void visitNestHost(final String nestHost) {    if (api < Opcodes.ASM7) {      throw new UnsupportedOperationException("This feature requires ASM7");    }    if (cv != null) {      cv.visitNestHost(nestHost);    }  }
public void visitOuterClass(final String owner, final String name, final String descriptor) {    if (cv != null) {      cv.visitOuterClass(owner, name, descriptor);    }  }
public AnnotationVisitor visitAnnotation(final String descriptor, final boolean visible) {    if (cv != null) {      return cv.visitAnnotation(descriptor, visible);    }    return null;  }
public void visitNestMember(final String nestMember) {    if (api < Opcodes.ASM7) {      throw new UnsupportedOperationException("This feature requires ASM7");    }    if (cv != null) {      cv.visitNestMember(nestMember);    }  }
public void visitInnerClass(      final String name, final String outerName, final String innerName, final int access) {    if (cv != null) {      cv.visitInnerClass(name, outerName, innerName, access);    }  }
public FieldVisitor visitField(      final int access,      final String name,      final String descriptor,      final String signature,      final Object value) {    if (cv != null) {      return cv.visitField(access, name, descriptor, signature, value);    }    return null;  }
@Override	public synchronized void init() {		try {			Class.forName(driverClass);		} catch (ClassNotFoundException cnfex) {			throw new DbSqlException("JDBC driver not found: " + driverClass, cnfex);		}	}
public static DbThreadSession getThreadSession() {		DbThreadSession session = (DbThreadSession) ThreadDbSessionHolder.get();		if (session == null) {			session = new DbThreadSession();		}		return session;	}
public static void closeThreadSession() {		DbThreadSession session = (DbThreadSession) ThreadDbSessionHolder.get();		if (session != null) {			session.closeSession();		}	}
protected ActionWrapper[] createExecutionArray() {		int totalInterceptors = (this.actionRuntime.getInterceptors() != null ? this.actionRuntime.getInterceptors().length : 0);		int totalFilters = (this.actionRuntime.getFilters() != null ? this.actionRuntime.getFilters().length : 0);		ActionWrapper[] executionArray = new ActionWrapper[totalFilters + 1 + totalInterceptors + 1];		// filters		int index = 0;		if (totalFilters > 0) {			System.arraycopy(actionRuntime.getFilters(), 0, executionArray, index, totalFilters);			index += totalFilters;		}		// result is executed AFTER the action AND interceptors		executionArray[index++] = actionRequest -> {			Object actionResult = actionRequest.invoke();			ActionRequest.this.madvocController.render(ActionRequest.this, actionResult);			return actionResult;		};		// interceptors		if (totalInterceptors > 0) {			System.arraycopy(actionRuntime.getInterceptors(), 0, executionArray, index, totalInterceptors);			index += totalInterceptors;		}		// action		executionArray[index] = actionRequest -> {			actionResult = invokeActionMethod();			return actionResult;		};		return executionArray;	}
protected Object invokeActionMethod() throws Exception {		if (actionRuntime.isActionHandlerDefined()) {			actionRuntime.getActionHandler().handle(this);			return null;		}		final Object[] params = targets.extractParametersValues();		try {			return actionRuntime.getActionClassMethod().invoke(action, params);		} catch(InvocationTargetException itex) {			throw wrapToException(unwrapThrowable(itex));		}	}
public String readRequestBody() {		if (requestBody == null) {			try {				requestBody = ServletUtil.readRequestBodyFromStream(getHttpServletRequest());			} catch (IOException ioex) {				requestBody = StringPool.EMPTY;			}		}		return requestBody;	}
public static int calcFirstItemIndexOfPage(int page, final int pageSize, final int total) {		if (total == 0) {			return 0;		}		if (page < 1) {			page = 1;		}		int first = (page - 1) * pageSize;		if (first >= total) {			first = ((total - 1) / pageSize) * pageSize;	// first item on the last page		}		return first;	}
public static int calcFirstItemIndexOfPage(final PageRequest pageRequest, final int total) {		return calcFirstItemIndexOfPage(pageRequest.getPage(), pageRequest.getSize(), total);	}
protected int parseInt(final String value) {		try {			return Integer.parseInt(value);		} catch (NumberFormatException nfex) {			throw new CSSellyException(nfex);		}	}
public boolean match(final int value) {		if (a == 0) {			return value == b;		}		if (a > 0) {			if (value < b) {				return false;			}			return (value - b) % a == 0;		}		if (value > b) {			return false;		}		return (b - value) % (-a) == 0;	}
public static byte[] toRawByteArray(final char[] carr) {		byte[] barr = new byte[carr.length << 1];		for (int i = 0, bpos = 0; i < carr.length; i++) {			char c = carr[i];			barr[bpos++] = (byte) ((c & 0xFF00) >> 8);			barr[bpos++] = (byte) (c & 0x00FF);		}		return barr;	}
public static int findFirstDiff(final char[] source, final int index, final char[] match) {		for (int i = index; i < source.length; i++) {			if (!equalsOne(source[i], match)) {				return i;			}		}		return -1;	}
protected String resolveNodeName(final Node node) {		switch (tagCase) {			case DEFAULT: return node.getNodeName();			case RAW: return node.getNodeRawName();			case LOWERCASE: return node.getNodeRawName().toLowerCase();			case UPPERCASE: return node.getNodeRawName().toUpperCase();		}		return null;	}
protected String resolveAttributeName(final Node node, final Attribute attribute) {		switch (attributeCase) {			case DEFAULT: return attribute.getName();			case RAW: return attribute.getRawName();			case LOWERCASE: return attribute.getRawName().toLowerCase();			case UPPERCASE: return attribute.getRawName().toUpperCase();		}		return null;	}
protected void renderAttribute(final Node node, final Attribute attribute, final Appendable appendable) throws IOException {		String name = resolveAttributeName(node, attribute);		String value = attribute.getValue();		appendable.append(name);		if (value != null) {			appendable.append('=');			appendable.append('\"');			appendable.append(HtmlEncoder.attributeDoubleQuoted(value));			appendable.append('\"');		}	}
public Props load(final File file) throws IOException {		final String extension = FileNameUtil.getExtension(file.getAbsolutePath());		final String data;		if (extension.equalsIgnoreCase("properties")) {			data = FileUtil.readString(file, StringPool.ISO_8859_1);		} else {			data = FileUtil.readString(file);		}		parse(data);		return this;	}
public Props load(final File file, final String encoding) throws IOException {		parse(FileUtil.readString(file, encoding));		return this;	}
public Props load(final InputStream in) throws IOException {		final Writer out = new FastCharArrayWriter();		StreamUtil.copy(in, out);		parse(out.toString());		return this;	}
public Props load(final Map<?, ?> p) {		for (final Map.Entry<?, ?> entry : p.entrySet()) {			final String name = entry.getKey().toString();			final Object value = entry.getValue();			if (value == null) {				continue;			}			data.putBaseProperty(name, value.toString(), false);		}		return this;	}
@SuppressWarnings("unchecked")	public Props load(final Map<?, ?> map, final String prefix) {		String realPrefix = prefix;		realPrefix += '.';		for (final Map.Entry entry : map.entrySet()) {			final String name = entry.getKey().toString();			final Object value = entry.getValue();			if (value == null) {				continue;			}			data.putBaseProperty(realPrefix + name, value.toString(), false);		}		return this;	}
public Props loadSystemProperties(final String prefix) {		final Properties environmentProperties = System.getProperties();		load(environmentProperties, prefix);		return this;	}
public Props loadEnvironment(final String prefix) {		final Map<String, String> environmentMap = System.getenv();		load(environmentMap, prefix);		return this;	}
public Props loadFromClasspath(final String... patterns) {		ClassScanner.create()			.registerEntryConsumer(entryData -> {				String usedEncoding = JoddCore.encoding;				if (StringUtil.endsWithIgnoreCase(entryData.name(), ".properties")) {					usedEncoding = StringPool.ISO_8859_1;				}				final String encoding = usedEncoding;				UncheckedException.runAndWrapException(() -> load(entryData.openInputStream(), encoding));			})			.includeResources(true)			.ignoreException(true)			.excludeCommonJars()			.excludeAllEntries(true)			.includeEntries(patterns)			.scanDefaultClasspath()			.start();		return this;	}
public String getValueOrDefault(final String key, final String defaultValue) {		initialize();		final String value = data.lookupValue(key, activeProfiles);		if (value == null) {			return defaultValue;		}		return value;	}
public Double getDoubleValue(final String key) {		final String value = getValue(key);		if (value == null) {			return null;		}		return Double.valueOf(value);	}
public String getValue(final String key, final String... profiles) {		initialize();		return data.lookupValue(key, profiles);	}
public void setValue(final String key, final String value, final String profile) {		if (profile == null) {			data.putBaseProperty(key, value, false);		} else {			data.putProfileProperty(key, value, profile, false);		}		initialized = false;	}
public void extractProps(final Map target) {		initialize();		data.extract(target, activeProfiles, null, null);	}
public void extractProps(final Map target, final String... profiles) {		initialize();		data.extract(target, profiles, null, null);	}
public void extractSubProps(final Map target, final String... wildcardPatterns) {		initialize();		data.extract(target, activeProfiles, wildcardPatterns, null);	}
@SuppressWarnings("unchecked")	public Map<String, Object> innerMap(final String prefix) {		initialize();		return data.extract(null, activeProfiles, null, prefix);	}
public void addInnerMap(String prefix, final Map<?, ?> map, final String profile) {		if (!StringUtil.endsWithChar(prefix, '.')) {			prefix += StringPool.DOT;		}		for (Map.Entry<?, ?> entry : map.entrySet()) {			String key = entry.getKey().toString();			key = prefix + key;			setValue(key, entry.getValue().toString(), profile);		}	}
protected void resolveActiveProfiles() {		if (activeProfilesProp == null) {			activeProfiles = null;			return;		}		final PropsEntry pv = data.getBaseProperty(activeProfilesProp);		if (pv == null) {			// no active profile set as the property, exit			return;		}		final String value = pv.getValue();		if (StringUtil.isBlank(value)) {			activeProfiles = null;			return;		}		activeProfiles = StringUtil.splitc(value, ',');		StringUtil.trimAll(activeProfiles);	}
public String[] getAllProfiles() {		String[] profiles = new String[data.profileProperties.size()];		int index = 0;		for (String profileName : data.profileProperties.keySet()) {			profiles[index] = profileName;			index++;		}		return profiles;	}
public String[] getProfilesFor(final String propKeyNameWildcard) {		HashSet<String> profiles = new HashSet<>();		profile:		for (Map.Entry<String, Map<String, PropsEntry>> entries : data.profileProperties.entrySet()) {			String profileName = entries.getKey();			Map<String, PropsEntry> value = entries.getValue();			for (String propKeyName : value.keySet()) {				if (Wildcard.equalsOrMatch(propKeyName, propKeyNameWildcard)) {					profiles.add(profileName);					continue profile;				}			}		}		return profiles.toArray(new String[0]);	}
protected void addPropertyInjectionPoint(final PropertyInjectionPoint pip) {		if (properties == null) {			properties = new PropertyInjectionPoint[1];			properties[0] = pip;		} else {			properties = ArraysUtil.append(properties, pip);		}	}
protected void addSetInjectionPoint(final SetInjectionPoint sip) {		if (sets == null) {			sets = new SetInjectionPoint[1];			sets[0] = sip;		} else {			sets = ArraysUtil.append(sets, sip);		}	}
protected void addMethodInjectionPoint(final MethodInjectionPoint mip) {		if (methods == null) {			methods = new MethodInjectionPoint[1];			methods[0] = mip;		} else {			methods = ArraysUtil.append(methods, mip);		}	}
protected void addInitMethodPoints(final InitMethodPoint[] methods) {		if (initMethods == null) {			initMethods = methods;		} else {			initMethods = ArraysUtil.join(initMethods, methods);		}	}
protected void addDestroyMethodPoints(final DestroyMethodPoint[] methods) {		if (destroyMethods == null) {			destroyMethods = methods;		} else {			destroyMethods = ArraysUtil.join(destroyMethods, methods);		}	}
public static Class resolveTargetClass(final Class proxy) {		final String name = proxy.getName();		if (name.endsWith(ProxettaNames.proxyClassNameSuffix)) {			return proxy.getSuperclass();		}		if (name.endsWith(ProxettaNames.wrapperClassNameSuffix)) {			return getTargetWrapperType(proxy);		}		return proxy;	}
public static void injectTargetIntoWrapper(final Object target, final Object wrapper, final String targetFieldName) {		try {			final Field field = wrapper.getClass().getField(targetFieldName);			field.setAccessible(true);			field.set(wrapper, target);		} catch (Exception ex) {			throw new ProxettaException(ex);		}	}
public static void injectTargetIntoWrapper(final Object target, final Object wrapper) {		injectTargetIntoWrapper(target, wrapper, ProxettaNames.wrapperTargetFieldName);	}
public static Class getTargetWrapperType(final Class wrapperClass) {		try {			final Field field = wrapperClass.getDeclaredField(ProxettaNames.wrapperTargetFieldName);			return field.getType();		} catch (NoSuchFieldException nsfex) {			throw new ProxettaException(nsfex);		}	}
@Override	protected int pruneCache() {        int count = 0;		CacheObject<K,V> comin = null;		// remove expired items and find cached object with minimal access count		Iterator<CacheObject<K,V>> values = cacheMap.values().iterator();		while (values.hasNext()) {			CacheObject<K,V> co = values.next();			if (co.isExpired()) {				values.remove();				onRemove(co.key, co.cachedObject);				count++;				continue;			}						if (comin == null) {				comin = co;			} else {				if (co.accessCount < comin.accessCount) {					comin = co;				}			}		}		if (!isFull()) {			return count;		}		// decrease access count to all cached objects		if (comin != null) {			long minAccessCount = comin.accessCount;			values = cacheMap.values().iterator();			while (values.hasNext()) {				CacheObject<K, V> co = values.next();				co.accessCount -= minAccessCount;				if (co.accessCount <= 0) {					values.remove();					onRemove(co.key, co.cachedObject);					count++;									}			}		}		return count;	}
protected FieldDescriptor findField(final String fieldName) {		FieldDescriptor fieldDescriptor = classDescriptor.getFieldDescriptor(fieldName, true);		if (fieldDescriptor != null) {			return fieldDescriptor;		}		// field descriptor not found in this class		// try to locate it in the superclasses		Class[] superclasses = classDescriptor.getAllSuperclasses();		for (Class superclass : superclasses) {			ClassDescriptor classDescriptor = ClassIntrospector.get().lookup(superclass);			fieldDescriptor = classDescriptor.getFieldDescriptor(fieldName, true);			if (fieldDescriptor != null) {				return fieldDescriptor;			}		}		// nothing found		return null;	}
public Class getType() {		if (type == null) {			if (fieldDescriptor != null) {				type = fieldDescriptor.getRawType();			}			else if (readMethodDescriptor != null) {				type = getGetter(true).getGetterRawType();				//type = readMethodDescriptor.getGetterRawType();			}			else if (writeMethodDescriptor != null) {				type = getSetter(true).getSetterRawType();				//type = writeMethodDescriptor.getSetterRawType();			}		}		return type;	}
public Getter getGetter(final boolean declared) {		if (getters == null) {			getters = new Getter[] {					createGetter(false),					createGetter(true),			};		}		return getters[declared ? 1 : 0];	}
protected Getter createGetter(final boolean declared) {		if (readMethodDescriptor != null) {			if (readMethodDescriptor.matchDeclared(declared)) {				return Getter.of(readMethodDescriptor);			}		}		if (fieldDescriptor != null) {			if (fieldDescriptor.matchDeclared(declared)) {				return Getter.of(fieldDescriptor);			}		}		return null;	}
public Setter getSetter(final boolean declared) {		if (setters == null) {			setters = new Setter[] {					createSetter(false),					createSetter(true),			};		}		return setters[declared ? 1 : 0];	}
protected Setter createSetter(final boolean declared) {		if (writeMethodDescriptor != null) {			if (writeMethodDescriptor.matchDeclared(declared)) {				return Setter.of(writeMethodDescriptor);			}		}		if (fieldDescriptor != null) {			if (fieldDescriptor.matchDeclared(declared)) {				return Setter.of(fieldDescriptor);			}		}		return null;	}
public Class resolveKeyType(final boolean declared) {		Class keyType = null;		Getter getter = getGetter(declared);		if (getter != null) {			keyType = getter.getGetterRawKeyComponentType();		}		if (keyType == null) {			FieldDescriptor fieldDescriptor = getFieldDescriptor();			if (fieldDescriptor != null) {				keyType = fieldDescriptor.getRawKeyComponentType();			}		}		return keyType;	}
public Class resolveComponentType(final boolean declared) {		Class componentType = null;		Getter getter = getGetter(declared);		if (getter != null) {			componentType = getter.getGetterRawComponentType();		}		if (componentType == null) {			FieldDescriptor fieldDescriptor = getFieldDescriptor();			if (fieldDescriptor != null) {				componentType = fieldDescriptor.getRawComponentType();			}		}		return componentType;	}
protected String nosep(final String in) {		if (in.endsWith(File.separator)) {			return in.substring(0, in.length() - 1);		}		return in;	}
public static JsonResult of(final Object object) {		final String json = JsonSerializer.create().deep(true).serialize(object);		return new JsonResult(json);	}
public static JsonResult of(final Exception exception) {		final HashMap<String, Object> errorMap = new HashMap<>();		errorMap.put("message", ExceptionUtil.message(exception));		errorMap.put("error", exception.getClass().getName());		errorMap.put("cause", exception.getCause() != null ? exception.getCause().getClass().getName() : null);		final ArrayList<String> details = new ArrayList<>();		final StackTraceElement[] ste = ExceptionUtil.getStackTrace(exception, null, null);		for (StackTraceElement stackTraceElement : ste) {			details.add(stackTraceElement.toString());		}		errorMap.put("details", details);		final String json = JsonSerializer.create().deep(true).serialize(errorMap);		return new JsonResult(json).status(HttpStatus.error500().internalError());	}
protected String resolveHttpMethodFromMethodName(final String methodName) {		int i = 0;		while (i < methodName.length()) {			if (CharUtil.isUppercaseAlpha(methodName.charAt(i))) {				break;			}			i++;		}		final String name = methodName.substring(0, i).toUpperCase();		for (final HttpMethod httpMethod : HttpMethod.values()) {			if (httpMethod.equalsName(name)) {				return httpMethod.name();			}		}		return null;	}
public static boolean equalsOrMatch(final CharSequence string, final CharSequence pattern) {		if (string.equals(pattern)) {			return true;		}		return match(string, pattern, 0, 0);	}
private static boolean match(final CharSequence string, final CharSequence pattern, int sNdx, int pNdx) {		int pLen = pattern.length();		if (pLen == 1) {			if (pattern.charAt(0) == '*') {     // speed-up				return true;			}		}		int sLen = string.length();		boolean nextIsNotWildcard = false;		while (true) {			// check if end of string and/or pattern occurred			if ((sNdx >= sLen)) {		// end of string still may have pending '*' in pattern				while ((pNdx < pLen) && (pattern.charAt(pNdx) == '*')) {					pNdx++;				}				return pNdx >= pLen;			}			if (pNdx >= pLen) {					// end of pattern, but not end of the string				return false;			}			char p = pattern.charAt(pNdx);		// pattern char			// perform logic			if (!nextIsNotWildcard) {				if (p == '\\') {					pNdx++;					nextIsNotWildcard =  true;					continue;				}				if (p == '?') {					sNdx++; pNdx++;					continue;				}				if (p == '*') {					char pNext = 0;						// next pattern char					if (pNdx + 1 < pLen) {						pNext = pattern.charAt(pNdx + 1);					}					if (pNext == '*') {					// double '*' have the same effect as one '*'						pNdx++;						continue;					}					int i;					pNdx++;					// find recursively if there is any substring from the end of the					// line that matches the rest of the pattern !!!					for (i = string.length(); i >= sNdx; i--) {						if (match(string, pattern, i, pNdx)) {							return true;						}					}					return false;				}			} else {				nextIsNotWildcard = false;			}			// check if pattern char and string char are equals			if (p != string.charAt(sNdx)) {				return false;			}			// everything matches for now, continue			sNdx++; pNdx++;		}	}
public static int matchOne(final String src, final String... patterns) {		for (int i = 0; i < patterns.length; i++) {			if (match(src, patterns[i])) {				return i;			}		}		return -1;	}
public static boolean matchPath(final String path, final String pattern) {		String[] pathElements = StringUtil.splitc(path, PATH_SEPARATORS);		String[] patternElements = StringUtil.splitc(pattern, PATH_SEPARATORS);		return matchTokens(pathElements, patternElements);	}
protected boolean isMatchingRules(final String name, final String... rules) {		for (String rule : rules) {			if (Wildcard.equalsOrMatch(name, rule)) {				return true;			}		}		return false;	}
protected Loading resolveLoading(final boolean parentFirstStrategy, final String className) {		boolean withParent = true;		boolean withLoader = true;		if (parentFirstStrategy) {			if (isMatchingRules(className, loaderOnlyRules)) {				withParent = false;			}			else if (isMatchingRules(className, parentOnlyRules)) {				withLoader = false;			}		}		else {			if (isMatchingRules(className, parentOnlyRules)) {				withLoader = false;			}			else if (isMatchingRules(className, loaderOnlyRules)) {				withParent = false;			}		}		return new Loading(withParent, withLoader);	}
protected Loading resolveResourceLoading(final boolean parentFirstStrategy, String resourceName) {		if (matchResourcesAsPackages) {			resourceName = StringUtil.replaceChar(resourceName, '/', '.');		}		return resolveLoading(parentFirstStrategy, resourceName);	}
@Override	protected synchronized Class<?> loadClass(final String className, final boolean resolve) throws ClassNotFoundException {		// check first if the class has already been loaded		Class<?> c = findLoadedClass(className);		if (c != null) {			if (resolve) {				resolveClass(c);			}			return c;		}		// class not loaded yet		Loading loading = resolveLoading(parentFirst, className);		if (parentFirst) {			// PARENT FIRST			if (loading.withParent) {				try {					c = parentClassLoader.loadClass(className);				}				catch (ClassNotFoundException ignore) {				}			}			if (c == null) {				if (loading.withLoader) {					c = this.findClass(className);				}				else {					throw new ClassNotFoundException("Class not found: " + className);				}			}		} else {			// THIS FIRST			if (loading.withLoader) {				try {					c = this.findClass(className);				}				catch (ClassNotFoundException ignore) {				}			}			if (c == null) {				if (loading.withParent) {					c = parentClassLoader.loadClass(className);				}				else {					throw new ClassNotFoundException("Class not found: " + className);				}			}		}		if (resolve) {			resolveClass(c);		}		return c;	}
@Override	public URL getResource(final String resourceName) {		URL url = null;		Loading loading = resolveResourceLoading(parentFirst, resourceName);		if (parentFirst) {			// PARENT FIRST			if (loading.withParent) {				url = parentClassLoader.getResource(resourceName);			}			if (url == null) {				if (loading.withLoader) {					url = this.findResource(resourceName);				}			}		} else {			// THIS FIRST			if (loading.withLoader) {				url = this.findResource(resourceName);			}			if (url == null) {				if (loading.withParent) {					url = parentClassLoader.getResource(resourceName);				}			}		}		return url;	}
public void waitFor() {		try {			synchronized (lock) {				if (!end) {					lock.wait();				}			}		}		catch (InterruptedException ignore) {			Thread.currentThread().interrupt();		}	}
public Class<? extends Annotation> detectAnnotationType(final Annotation[] annotations) {		for (final Annotation annotation : annotations) {			if (annotation instanceof In) {				return annotation.annotationType();			}			else if (annotation instanceof Out) {				return annotation.annotationType();			}		}		return null;	}
public ScopeData inspectMethodParameterScopes(final String name, final Class type, final Annotation[] annotations) {		In in = null;		Out out = null;		for (final Annotation annotation : annotations) {			if (annotation instanceof In) {				in = (In) annotation;			} else if (annotation instanceof Out) {				out = (Out) annotation;			}		}		final Class<? extends MadvocScope> scope = resolveScopeClassFromAnnotations(annotations);		int count = 0;		InjectionPoint[] ins = null;		InjectionPoint[] outs = null;		if (in != null) {			final InjectionPoint scopeDataIn = buildInjectionPoint(in.value(), name, type, scope);			if (scopeDataIn != null) {				count++;				ins = new InjectionPoint[]{scopeDataIn};			}		}		if (out != null) {			final InjectionPoint scopeDataOut = buildInjectionPoint(out.value(), name, type, scope);			if (scopeDataOut != null) {				count++;				outs = new InjectionPoint[]{scopeDataOut};			}		}		if (count == 0) {			return NO_SCOPE_DATA;		}		return new ScopeData(this, ins, outs);	}
protected InjectionPoint buildInjectionPoint(			final String annotationValue,			final String propertyName,			final Class propertyType,			final Class<? extends MadvocScope> scope) {		final String value = annotationValue.trim();		final String name, targetName;		if (StringUtil.isNotBlank(value)) {			name = value;			targetName = propertyName;		}		else {			name = propertyName;			targetName = null;		}		return new InjectionPoint(propertyType, name, targetName, scopeResolver.defaultOrScopeType(scope));	}
public ScopeData inspectClassScopes(final Class actionClass) {		ClassDescriptor cd = ClassIntrospector.get().lookup(actionClass);		PropertyDescriptor[] allProperties = cd.getAllPropertyDescriptors();		List<InjectionPoint> listIn = new ArrayList<>(allProperties.length);		List<InjectionPoint> listOut = new ArrayList<>(allProperties.length);		for (PropertyDescriptor pd : allProperties) {			// collect annotations			Class<? extends MadvocScope> scope = null;			In in = null;			Out out = null;			if (pd.getFieldDescriptor() != null) {				Field field = pd.getFieldDescriptor().getField();				in = field.getAnnotation(In.class);				out = field.getAnnotation(Out.class);				scope = resolveScopeClassFromAnnotations(field.getAnnotations());			}			if (pd.getWriteMethodDescriptor() != null) {				Method method = pd.getWriteMethodDescriptor().getMethod();				if (in == null) {					in = method.getAnnotation(In.class);				}				if (out == null) {					out = method.getAnnotation(Out.class);				}				if (scope == null) {					scope = resolveScopeClassFromAnnotations(method.getAnnotations());				}			}			if (pd.getReadMethodDescriptor() != null) {				Method method = pd.getReadMethodDescriptor().getMethod();				if (in == null) {					in = method.getAnnotation(In.class);				}				if (out == null) {					out = method.getAnnotation(Out.class);				}				if (scope == null) {					scope = resolveScopeClassFromAnnotations(method.getAnnotations());				}			}			// inspect all			final InjectionPoint ii = in == null ? null : buildInjectionPoint(in.value(), pd.getName(), pd.getType(), scope);			if (ii != null) {				listIn.add(ii);			}			final InjectionPoint oi = out == null ? null : buildInjectionPoint(out.value(), pd.getName(), pd.getType(), scope);			if (oi != null) {				listOut.add(oi);			}		}		if ((listIn.isEmpty()) && (listOut.isEmpty())) {			return NO_SCOPE_DATA;		}		InjectionPoint[] in = null;		InjectionPoint[] out = null;		if (!listIn.isEmpty()) {			in = listIn.toArray(new InjectionPoint[0]);		}		if (!listOut.isEmpty()) {			out = listOut.toArray(new InjectionPoint[0]);		}		return new ScopeData(this, in, out);	}
public void visit() {		ClassDescriptor classDescriptor = ClassIntrospector.get().lookup(type);		if (classMetadataName != null) {			// process first 'meta' fields 'class'			onProperty(classMetadataName, null, false);		}		PropertyDescriptor[] propertyDescriptors = classDescriptor.getAllPropertyDescriptors();		for (PropertyDescriptor propertyDescriptor : propertyDescriptors) {			Getter getter = propertyDescriptor.getGetter(declared);			if (getter != null) {				String propertyName = propertyDescriptor.getName();				boolean isTransient = false;				// check for transient flag				FieldDescriptor fieldDescriptor = propertyDescriptor.getFieldDescriptor();				if (fieldDescriptor != null) {					isTransient = Modifier.isTransient(fieldDescriptor.getField().getModifiers());				}				onProperty(propertyName, propertyDescriptor, isTransient);			}		}	}
protected void onProperty(		String propertyName,		final PropertyDescriptor propertyDescriptor,		final boolean isTransient) {		Class propertyType = propertyDescriptor == null ?  null : propertyDescriptor.getType();		Path currentPath = jsonContext.path;		currentPath.push(propertyName);		// change name for properties		if (propertyType != null) {			propertyName = typeData.resolveJsonName(propertyName);		}		// determine if name should be included/excluded		boolean include = !typeData.strict;		// + don't include transient fields		if (isTransient) {			include = false;		}		// + all collections are not serialized by default		include = jsonContext.matchIgnoredPropertyTypes(propertyType, true, include);		// + annotations		include = typeData.rules.apply(propertyName, true, include);		// + path queries: excludes/includes		include = jsonContext.matchPathToQueries(include);		// done		if (!include) {			currentPath.pop();			return;		}		onSerializableProperty(propertyName, propertyDescriptor);		currentPath.pop();	}
public static URL[] of(ClassLoader classLoader, Class clazz) {		if (clazz == null) {			clazz = ClassPathURLs.class;		}		if (classLoader == null) {			classLoader = clazz.getClassLoader();		}		final Set<URL> urls = new LinkedHashSet<>();		while (classLoader != null) {			if (classLoader instanceof URLClassLoader) {				final URLClassLoader urlClassLoader = (URLClassLoader) classLoader;				return urlClassLoader.getURLs();			}			final URL url = classModuleUrl(classLoader, clazz);			if (url != null) {				urls.add(url);			}			classLoader = classLoader.getParent();		}		return urls.toArray(new URL[0]);	}
private void setBean(final Object bean) {		this.bean = bean;		this.cd = (bean == null ? null : introspector.lookup(bean.getClass()));		this.first = false;		this.updateProperty = true;	}
public void updateBean(final Object bean) {		this.setBean(bean);		if (this.cd != null && this.cd.isSupplier()) {			final Object newBean = ((Supplier)this.bean).get();			setBean(newBean);		}	}
private void loadPropertyDescriptor() {		if (updateProperty) {			if (cd == null) {				propertyDescriptor = null;			} else {				propertyDescriptor = cd.getPropertyDescriptor(name, true);			}			updateProperty = false;		}	}
public Getter getGetter(final boolean declared) {		loadPropertyDescriptor();		return propertyDescriptor != null ? propertyDescriptor.getGetter(declared) : null;	}
public Setter getSetter(final boolean declared) {		loadPropertyDescriptor();		return propertyDescriptor != null ? propertyDescriptor.getSetter(declared) : null;	}
public DbOom connect() {		connectionProvider.init();		final DbDetector dbDetector = new DbDetector();		dbDetector.detectDatabaseAndConfigureDbOom(connectionProvider, dbOomConfig);		return this;	}
public void add(final Iterator<T> iterator) {		if (allIterators.contains(iterator)) {			throw new IllegalArgumentException("Duplicate iterator");		}		allIterators.add(iterator);	}
@Override	public boolean hasNext() {		if (currentIterator == -1) {			currentIterator = 0;		}		for (int i = currentIterator; i < allIterators.size(); i++) {			Iterator iterator = allIterators.get(i);			if (iterator.hasNext()) {				currentIterator = i;				return true;			}		}		return false;	}
@Override	public <E> E readValue(final ResultSet rs, final int index, final Class<E> destinationType, final int dbSqlType) throws SQLException {		T t = get(rs, index, dbSqlType);		if ((t == null) || (rs.wasNull())) {			return null;		}		return prepareGetValue(t, destinationType);	}
@Override	public void storeValue(final PreparedStatement st, final int index, final Object value, final int dbSqlType) throws SQLException {		if (value == null) {			st.setNull(index, dbSqlType);			return;		}		super.storeValue(st, index, value, dbSqlType);	}
public JoddJoyRuntime start(final ServletContext servletContext) {		LoggerProvider loggerProvider = null;		if (loggerProviderSupplier != null) {			loggerProvider = loggerProviderSupplier.get();		}		if (loggerProvider == null) {			loggerProvider = SimpleLogger.PROVIDER;		}		LoggerFactory.setLoggerProvider(loggerProvider);		log = LoggerFactory.getLogger(JoddJoy.class);		printLogo();		log.info("Ah, Joy!");		log.info("Logging using: " + loggerProvider.getClass().getSimpleName());		joyPropsConsumers.accept(joyProps);		joyProxettaConsumers.accept(joyProxetta);		joyDbConsumers.accept(joyDb);		joyPetiteConsumers.accept(joyPetite);		try {			joyPaths.start();			joyProps.start();			joyProxetta.start();			joyScanner.start();			joyPetite.start();			joyPetite.getPetiteContainer().addBean(appName + ".core",  this);			joyPetite.getPetiteContainer().addBean(appName + ".scanner", joyScanner);			joyDb.start();			joyMadvoc.setServletContext(servletContext);			joyMadvoc.start();			runJoyInitBeans();			// cleanup things we will not use			joyScanner.stop();		}		catch (Exception ex) {			if (log != null) {				log.error(ex.toString(), ex);			} else {				System.out.println(ex.toString());				ex.printStackTrace();			}			stop();			throw ex;		}		joyPetite.printBeans(100);		joyDb.printEntities(100);		joyMadvoc.printRoutes(100);		System.out.println(Chalk256.chalk().yellow().on("Joy") + " is up. Enjoy!");		log.info("Joy is up. Enjoy!");		if (joyDb.isDatabaseEnabled()) {			return new JoddJoyRuntime(				appName,				joyPaths.getAppDir(),				joyProps.getProps(),				joyProxetta.getProxetta(),				joyPetite.getPetiteContainer(),				joyMadvoc.getWebApp(),				joyDb.isDatabaseEnabled(),				joyDb.getConnectionProvider(),				joyDb.getJtxManager()			);		}		else {			return new JoddJoyRuntime(				appName,				joyPaths.getAppDir(),				joyProps.getProps(),				joyProxetta.getProxetta(),				joyPetite.getPetiteContainer(),				joyMadvoc.getWebApp()			);		}	}
private void printLogo() {		System.out.println(Chalk256.chalk().yellow().on(Jodd.JODD));	}
public void stop() {		joyProps.stop();		try {			joyDb.stop();			joyPetite.stop();		}		catch (Exception ignore) {		}		if (log != null) {			log.info("Joy is down. Bye, bye!");		}	}
@Override	public HttpConnection createHttpConnection(final HttpRequest httpRequest) throws IOException {		final SocketHttpConnection httpConnection;		final boolean https = httpRequest.protocol().equalsIgnoreCase("https");		if (https) {			SSLSocket sslSocket = createSSLSocket(				httpRequest.host(),				httpRequest.port(),				httpRequest.connectionTimeout(),				httpRequest.trustAllCertificates(),				httpRequest.verifyHttpsHost()			);			httpConnection = new SocketHttpSecureConnection(sslSocket);		}		else {			Socket socket = createSocket(httpRequest.host(), httpRequest.port(), httpRequest.connectionTimeout());			httpConnection = new SocketHttpConnection(socket);		}		// prepare connection config		httpConnection.setTimeout(httpRequest.timeout());		try {			// additional socket initialization			httpConnection.init();		}		catch (Throwable throwable) {  			// @wjw_add			httpConnection.close();			throw new HttpException(throwable);		}		return httpConnection;	}
protected Socket createSocket(final String host, final int port, final int connectionTimeout) throws IOException {		final SocketFactory socketFactory = getSocketFactory(proxy, false, false, connectionTimeout);		if (connectionTimeout < 0) {			return socketFactory.createSocket(host, port);		}		else {			// creates unconnected socket			Socket socket = socketFactory.createSocket();			socket.connect(new InetSocketAddress(host, port), connectionTimeout);			return socket;		}	}
protected SSLSocket createSSLSocket(		final String host, final int port, final int connectionTimeout,		final boolean trustAll, final boolean verifyHttpsHost) throws IOException {		final SocketFactory socketFactory = getSocketFactory(proxy, true, trustAll, connectionTimeout);		final Socket socket;		if (connectionTimeout < 0) {			socket = socketFactory.createSocket(host, port);		}		else {			// creates unconnected socket			// unfortunately, this does not work always//			sslSocket = (SSLSocket) socketFactory.createSocket();//			sslSocket.connect(new InetSocketAddress(host, port), connectionTimeout);			//			// Note: SSLSocketFactory has several create() methods.			// Those that take arguments all connect immediately			// and have no options for specifying a connection timeout.			//			// So, we have to create a socket and connect it (with a			// connection timeout), then have the SSLSocketFactory wrap			// the already-connected socket.			//			socket = Sockets.connect(host, port, connectionTimeout);			//sock.setSoTimeout(readTimeout);			//socket.connect(new InetSocketAddress(host, port), connectionTimeout);			// continue to wrap this plain socket with ssl socket...		}		// wrap plain socket in an SSL socket		SSLSocket sslSocket;		if (socket instanceof SSLSocket) {			sslSocket = (SSLSocket) socket;		}		else {			if (socketFactory instanceof SSLSocketFactory) {				sslSocket = (SSLSocket) ((SSLSocketFactory)socketFactory).createSocket(socket, host, port, true);			}			else {				sslSocket = (SSLSocket) (getDefaultSSLSocketFactory(trustAll)).createSocket(socket, host, port, true);			}		}		// sslSocket is now ready		if (secureEnabledProtocols != null) {			final String[] values = StringUtil.splitc(secureEnabledProtocols, ',');			StringUtil.trimAll(values);			sslSocket.setEnabledProtocols(values);		}		// set SSL parameters to allow host name verifier		if (verifyHttpsHost) {			final SSLParameters sslParams = new SSLParameters();			sslParams.setEndpointIdentificationAlgorithm("HTTPS");			sslSocket.setSSLParameters(sslParams);		}		return sslSocket;	}
protected SSLSocketFactory getDefaultSSLSocketFactory(final boolean trustAllCertificates) throws IOException {		if (trustAllCertificates) {			try {				SSLContext sc = SSLContext.getInstance(sslProtocol);				sc.init(null, TrustManagers.TRUST_ALL_CERTS, new java.security.SecureRandom());				return sc.getSocketFactory();			}			catch (NoSuchAlgorithmException | KeyManagementException e) {				throw new IOException(e);			}		} else {			return (SSLSocketFactory) SSLSocketFactory.getDefault();		}	}
protected SocketFactory getSocketFactory(			final ProxyInfo proxy,			final boolean ssl,			final boolean trustAllCertificates,			final int connectionTimeout) throws IOException {		switch (proxy.getProxyType()) {			case NONE:				if (ssl) {					return getDefaultSSLSocketFactory(trustAllCertificates);				}				else {					return SocketFactory.getDefault();				}			case HTTP:				return new HTTPProxySocketFactory(proxy, connectionTimeout);			case SOCKS4:				return new Socks4ProxySocketFactory(proxy, connectionTimeout);			case SOCKS5:				return new Socks5ProxySocketFactory(proxy, connectionTimeout);			default:				return null;		}	}
public String random(int count, final char[] chars) {		if (count == 0) {			return StringPool.EMPTY;		}		final char[] result = new char[count];		while (count-- > 0) {			result[count] = chars[rnd.nextInt(chars.length)];		}		return new String(result);	}
public String random(int count, final char start, final char end) {		if (count == 0) {			return StringPool.EMPTY;		}		final char[] result = new char[count];		final int len = end - start + 1;		while (count-- > 0) {			result[count] = (char) (rnd.nextInt(len) + start);		}		return new String(result);	}
public String randomRanges(int count, final char... ranges) {		if (count == 0) {			return StringPool.EMPTY;		}		int i = 0;		int len = 0;		final int[] lens = new int[ranges.length];		while (i < ranges.length) {			int gap = ranges[i + 1] - ranges[i] + 1;			len += gap;			lens[i] = len;			i += 2;		}		final char[] result = new char[count];		while (count-- > 0) {			char c = 0;			int r = rnd.nextInt(len);			for (i = 0; i < ranges.length; i += 2) {				if (r < lens[i]) {					r += ranges[i];					if (i != 0) {						r -= lens[i - 2];					}					c = (char) r;					break;				}			}			result[count] = c;		}		return new String(result);	}
public ReceivedEmail parse(final String emlContent, final String charset) throws			UnsupportedEncodingException, MessagingException {		final byte[] bytes = emlContent.getBytes(charset);		return parse(bytes);	}
public ReceivedEmail parse(final String emlContent) throws MessagingException {		try {			return parse(emlContent, JoddCore.encoding);		} catch (final UnsupportedEncodingException ignore) {			return null;		}	}
public ReceivedEmail parse(final File emlFile) throws FileNotFoundException, MessagingException {		final FileInputStream fileInputStream = new FileInputStream(emlFile);		try {			return parse(fileInputStream);		} finally {			StreamUtil.close(fileInputStream);		}	}
protected ReceivedEmail parse(final InputStream emlContentInputStream) throws MessagingException {		if (getSession() == null) {			createSession(getProperties());		}		try {			final MimeMessage message = new MimeMessage(getSession(), emlContentInputStream);			return new ReceivedEmail(message, false, null);		} finally {			StreamUtil.close(emlContentInputStream);		}	}
@SuppressWarnings("unchecked")	protected Collection<Object> newArrayInstance(final Class targetType) {		if (targetType == null ||			targetType == List.class ||			targetType == Collection.class ||			targetType.isArray()) {			return listSupplier.get();		}		if (targetType == Set.class) {			return new HashSet<>();		}		try {			return (Collection<Object>) targetType.getDeclaredConstructor().newInstance();		} catch (Exception e) {			throw new JsonException(e);		}	}
protected Object newObjectInstance(final Class targetType) {		if (targetType == null ||			targetType == Map.class) {			return mapSupplier.get();		}		final ClassDescriptor cd = ClassIntrospector.get().lookup(targetType);		final CtorDescriptor ctorDescriptor = cd.getDefaultCtorDescriptor(true);		if (ctorDescriptor == null) {			throw new JsonException("Default ctor not found for: " + targetType.getName());		}		try {//			return ClassUtil.newInstance(targetType);			return ctorDescriptor.getConstructor().newInstance();		} catch (Exception e) {			throw new JsonException(e);		}	}
protected void injectValueIntoObject(final Object target, final PropertyDescriptor pd, final Object value) {		Object convertedValue = value;		if (value != null) {			Class targetClass = pd.getType();			convertedValue = convertType(value, targetClass);		}		try {			Setter setter = pd.getSetter(true);			if (setter != null) {				setter.invokeSetter(target, convertedValue);			}		} catch (Exception ex) {			throw new JsonException(ex);		}	}
protected Object convertType(final Object value, final Class targetType) {		final Class valueClass = value.getClass();		if (valueClass == targetType) {			return value;		}		try {			return TypeConverterManager.get().convertType(value, targetType);		}		catch (Exception ex) {			if (!strictTypes) {				return null;			}			throw new JsonException("Type conversion failed", ex);		}	}
public void visitProvide(final String service, final String... providers) {    if (mv != null) {      mv.visitProvide(service, providers);    }  }
@Override	public Short get(final ResultSet rs, final int index, final int dbSqlType) throws SQLException {		return Short.valueOf(rs.getShort(index));	}
@Override	public void set(final PreparedStatement st, final int index, final Short value, final int dbSqlType) throws SQLException {		st.setShort(index, value.shortValue());	}
@Override	public void visit(final int version, final int access, final String name, final String signature, final String superName, final String[] interfaces) {		wd.init(name, superName, suffix, reqProxyClassName);		// write destination class		final int v = ProxettaAsmUtil.resolveJavaVersion(version);		super.visit(v, access, wd.thisReference, signature, wd.superName, interfaces);	}
@SuppressWarnings("unchecked")	public static <A> TypeCache<A> createDefault() {		return (TypeCache<A>)Defaults.implementation.get();	}
public T put(final Class<?> type, final T value) {		return map.put(type, value);	}
public T get(final Class<?> key, final Supplier<T> valueSupplier) {		return map.computeIfAbsent(key, aClass -> valueSupplier.get());	}
@Override	public Long get(final ResultSet rs, final int index, final int dbSqlType) throws SQLException {		return Long.valueOf(rs.getLong(index));	}
@Override	public void set(final PreparedStatement st, final int index, final Long value, final int dbSqlType) throws SQLException {		st.setLong(index, value.longValue());	}
protected HashMap<String, MethodDescriptor[]> inspectMethods() {		boolean scanAccessible = classDescriptor.isScanAccessible();		if (classDescriptor.isSystemClass()) {			scanAccessible = false;		}		final Class type = classDescriptor.getType();		final Method[] methods = scanAccessible ? ClassUtil.getAccessibleMethods(type) : ClassUtil.getSupportedMethods(type);		final HashMap<String, MethodDescriptor[]> map = new HashMap<>(methods.length);		for (final Method method : methods) {			final String methodName = method.getName();			MethodDescriptor[] mds = map.get(methodName);			if (mds == null) {				mds = new MethodDescriptor[1];			} else {				mds = ArraysUtil.resize(mds, mds.length + 1);			}			map.put(methodName, mds);			mds[mds.length - 1] = createMethodDescriptor(method);		}		return map;	}
public MethodDescriptor getMethodDescriptor(final String name, final Class[] paramTypes) {		final MethodDescriptor[] methodDescriptors = methodsMap.get(name);		if (methodDescriptors == null) {			return null;		}		for (MethodDescriptor methodDescriptor : methodDescriptors) {			final Method m = methodDescriptor.getMethod();			if (ClassUtil.compareParameters(m.getParameterTypes(), paramTypes)) {				return methodDescriptor;			}		}		return null;	}
public MethodDescriptor getMethodDescriptor(final String name) {		final MethodDescriptor[] methodDescriptors = methodsMap.get(name);		if (methodDescriptors == null) {			return null;		}		if (methodDescriptors.length != 1) {			throw new IllegalArgumentException("Method name not unique: " + name);		}		return methodDescriptors[0];	}
public MethodDescriptor[] getAllMethodDescriptors() {		if (allMethods == null) {			final List<MethodDescriptor> allMethodsList = new ArrayList<>();			for (MethodDescriptor[] methodDescriptors : methodsMap.values()) {				Collections.addAll(allMethodsList, methodDescriptors);			}			final MethodDescriptor[] allMethods = allMethodsList.toArray(new MethodDescriptor[0]);			Arrays.sort(allMethods, Comparator.comparing(md -> md.getMethod().getName()));			this.allMethods = allMethods;		}		return allMethods;	}
public static String resolveIpAddress(final String hostname) {		try {			InetAddress netAddress;			if (hostname == null || hostname.equalsIgnoreCase(LOCAL_HOST)) {				netAddress = InetAddress.getLocalHost();			} else {				netAddress = Inet4Address.getByName(hostname);			}			return netAddress.getHostAddress();		} catch (UnknownHostException ignore) {			return null;		}	}
public static int getIpAsInt(final String ipAddress) {		int ipIntValue = 0;		String[] tokens = StringUtil.splitc(ipAddress, '.');		for (String token : tokens) {			if (ipIntValue > 0) {				ipIntValue <<= 8;			}			ipIntValue += Integer.parseInt(token);		}		return ipIntValue;	}
public static boolean validateAgaintIPAdressV4Format(final String input) {		if (input == null) {			return false;		}		int hitDots = 0;		char[] data = input.toCharArray();		for (int i = 0; i < data.length; i++) {			char c = data[i];			int b = 0;			do {				if (c < '0' || c > '9') {					return false;				}				b = (b * 10 + c) - 48;				if (++i >= data.length) {					break;				}				c = data[i];			} while (c != '.');			if (b > 255) {				return false;			}			hitDots++;		}		return hitDots == 4;	}
public static String resolveHostName(final byte[] ip) {		try {			InetAddress address = InetAddress.getByAddress(ip);			return address.getHostName();		} catch (UnknownHostException ignore) {			return null;		}	}
public static byte[] downloadBytes(final String url) throws IOException {		try (InputStream inputStream = new URL(url).openStream()) {			return StreamUtil.readBytes(inputStream);		}	}
public static String downloadString(final String url, final String encoding) throws IOException {		try (InputStream inputStream = new URL(url).openStream()) {			return new String(StreamUtil.readChars(inputStream, encoding));		}	}
public static void downloadFile(final String url, final File file) throws IOException {		try (			InputStream inputStream = new URL(url).openStream();			ReadableByteChannel rbc = Channels.newChannel(inputStream);			FileChannel fileChannel = FileChannel.open(				file.toPath(),				StandardOpenOption.CREATE,				StandardOpenOption.TRUNCATE_EXISTING,				StandardOpenOption.WRITE)		) {			fileChannel.transferFrom(rbc, 0, Long.MAX_VALUE);		}	}
@Override	public void doFilter(final ServletRequest servletRequest, final ServletResponse servletResponse, final FilterChain filterChain) throws IOException, ServletException {		HttpServletRequest request = (HttpServletRequest) servletRequest;		HttpServletResponse response = (HttpServletResponse) servletResponse;		String actionPath = DispatcherUtil.getServletPath(request);		if (processActionPath(request, response, actionPath)) {			return;		}		if (!acceptActionPath(request, actionPath)) {			filterChain.doFilter(servletRequest, servletResponse);			return;		}		BufferResponseWrapper wrapper = new BufferResponseWrapper(response);		filterChain.doFilter(servletRequest, wrapper);		// reset servlet response content length AFTER the chain, since		// servlet container may set it and we are changing the content.		servletResponse.setContentLength(-1);		char[] content = wrapper.getBufferContentAsChars();		if ((content != null) && (content.length != 0)) {			if (log.isDebugEnabled()) {				log.debug("Lagarto is about to parse: " + actionPath);			}			try {				content = parse(content, request);			} catch (Exception ex) {				log.error("Error parsing", ex);				throw new ServletException(ex);			}			wrapper.writeContentToResponse(content);		}	}
protected boolean acceptActionPath(final HttpServletRequest request, final String actionPath) {		String extension = FileNameUtil.getExtension(actionPath);		if (extension.length() == 0) {			return true;		}		if (extension.equals("html") || extension.equals("htm")) {			return true;		}		return false;	}
@Override	public void render(final ActionRequest actionRequest, final Object resultValue) {		final Chain chainResult;		if (resultValue == null) {			chainResult = Chain.to(StringPool.EMPTY);		} else {			if (resultValue instanceof String) {				chainResult = Chain.to((String)resultValue);			}			else {				chainResult = (Chain) resultValue;			}		}		final String resultBasePath = actionRequest.getActionRuntime().getResultBasePath();		final String resultPath = resultMapper.resolveResultPathString(resultBasePath, chainResult.path());		actionRequest.setNextActionPath(resultPath);	}
@Override	public Object intercept(final ActionRequest actionRequest) throws Exception {		HttpServletRequest servletRequest = actionRequest.getHttpServletRequest();		// detect multipart request		if (ServletUtil.isMultipartRequest(servletRequest)) {			servletRequest = new MultipartRequestWrapper(servletRequest, fileUploader.get(), madvocEncoding.getEncoding());			actionRequest.bind(servletRequest);		}		// do it		inject(actionRequest);		final Object result = actionRequest.invoke();		outject(actionRequest);		return result;	}
protected void inject(final ActionRequest actionRequest) {		final Targets targets = actionRequest.getTargets();		final ServletContext servletContext = actionRequest.getHttpServletRequest().getServletContext();		scopeResolver.forEachScope(madvocScope -> madvocScope.inject(servletContext, targets));		scopeResolver.forEachScope(madvocScope -> madvocScope.inject(actionRequest, targets));	}
protected void outject(final ActionRequest actionRequest) {		final Targets targets = actionRequest.getTargets();		scopeResolver.forEachScope(madvocScope -> madvocScope.outject(actionRequest, targets));	}
public static Socket connect(final String hostname, final int port) throws IOException {		final Socket socket = new Socket();		socket.connect(new InetSocketAddress(hostname, port));		return socket;	}
public static Socket connect(final String hostname, final int port, final int connectionTimeout) throws IOException {		final Socket socket = new Socket();		if (connectionTimeout <= 0) {			socket.connect(new InetSocketAddress(hostname, port));		}		else {			socket.connect(new InetSocketAddress(hostname, port), connectionTimeout);		}		return socket;	}
public static String prepareArrayClassnameForLoading(String className) {		int bracketCount = StringUtil.count(className, '[');		if (bracketCount == 0) {			// not an array			return null;		}		String brackets = StringUtil.repeat('[', bracketCount);		int bracketIndex = className.indexOf('[');		className = className.substring(0, bracketIndex);		int primitiveNdx = getPrimitiveClassNameIndex(className);		if (primitiveNdx >= 0) {			className = String.valueOf(PRIMITIVE_BYTECODE_NAME[primitiveNdx]);			return brackets + className;		} else {			return brackets + 'L' + className + ';';		}	}
private static int getPrimitiveClassNameIndex(final String className) {		int dotIndex = className.indexOf('.');		if (dotIndex != -1) {			return -1;		}		return Arrays.binarySearch(PRIMITIVE_TYPE_NAMES, className);	}
@Override	public Class loadClass(final String className, final ClassLoader classLoader) throws ClassNotFoundException {		String arrayClassName = prepareArrayClassnameForLoading(className);		if ((className.indexOf('.') == -1) && (arrayClassName == null)) {			// maybe a primitive			int primitiveNdx = getPrimitiveClassNameIndex(className);			if (primitiveNdx >= 0) {				return PRIMITIVE_TYPES[primitiveNdx];			}		}		// try #1 - using provided class loader		if (classLoader != null) {			Class klass = loadClass(className, arrayClassName, classLoader);			if (klass != null) {				return klass;			}		}		// try #2 - using thread class loader		ClassLoader currentThreadClassLoader = Thread.currentThread().getContextClassLoader();		if ((currentThreadClassLoader != null) && (currentThreadClassLoader != classLoader)) {			Class klass = loadClass(className, arrayClassName, currentThreadClassLoader);			if (klass != null) {				return klass;			}		}		// try #3 - using caller classloader, similar as Class.forName()		//Class callerClass = ReflectUtil.getCallerClass(2);		Class callerClass = ClassUtil.getCallerClass();		ClassLoader callerClassLoader = callerClass.getClassLoader();		if ((callerClassLoader != classLoader) && (callerClassLoader != currentThreadClassLoader)) {			Class klass = loadClass(className, arrayClassName, callerClassLoader);			if (klass != null) {				return klass;			}		}		// try #4 - everything failed, try alternative array loader		if (arrayClassName != null) {			try {				return loadArrayClassByComponentType(className, classLoader);			} catch (ClassNotFoundException ignore) {			}		}		throw new ClassNotFoundException("Class not found: " + className);	}
protected Class loadClass(final String className, final String arrayClassName, final ClassLoader classLoader) {		if (arrayClassName != null) {			try {				if (loadArrayClassByComponentTypes) {					return loadArrayClassByComponentType(className, classLoader);				} else {					return Class.forName(arrayClassName, true, classLoader);				}			} catch (ClassNotFoundException ignore) {			}		}		try {			return classLoader.loadClass(className);		} catch (ClassNotFoundException ignore) {		}		return null;	}
protected Class loadArrayClassByComponentType(final String className, final ClassLoader classLoader) throws ClassNotFoundException {		int ndx = className.indexOf('[');		int multi = StringUtil.count(className, '[');		String componentTypeName = className.substring(0, ndx);		Class componentType = loadClass(componentTypeName, classLoader);		if (multi == 1) {			return Array.newInstance(componentType, 0).getClass();		}		int[] multiSizes;		if (multi == 2) {			multiSizes = new int[] {0, 0};		} else if (multi == 3) {			multiSizes = new int[] {0, 0, 0};		} else {			multiSizes = (int[]) Array.newInstance(int.class, multi);		}		return Array.newInstance(componentType, multiSizes).getClass();	}
@Override	public void shutdown() {		for (final BeanData beanData : instances.values()) {			beanData.callDestroyMethods();		}		instances.clear();	}
public static <T extends Comparable> BinarySearch<T> forArray(final T[] array) {		return new BinarySearch<T>() {			@Override			@SuppressWarnings( {"unchecked"})			protected int compare(final int index, final T element) {				return array[index].compareTo(element);			}			@Override			protected int getLastIndex() {				return array.length - 1;			}		};	}
public static <T> BinarySearch<T> forArray(final T[] array, final Comparator<T> comparator) {		return new BinarySearch<T>() {			@Override			@SuppressWarnings( {"unchecked"})			protected int compare(final int index, final T element) {				return comparator.compare(array[index], element);			}			@Override			protected int getLastIndex() {				return array.length - 1;			}		};	}
public int find(final E element, int low, int high) {		while (low <= high) {			int mid = (low + high) >>> 1;			int delta = compare(mid, element);			if (delta < 0) {				low = mid + 1;			} else if (delta > 0) {				high = mid - 1;			} else {				return mid;			}		}		// not found		return -(low + 1);	}
public T exclude(final String... excludes) {		for (String ex : excludes) {			rules.exclude(ex);		}		return _this();	}
public T include(final String... includes) {		for (String in : includes) {			rules.include(in);		}		return _this();	}
public T includeAs(final Class template) {		blacklist = false;		String[] properties = getAllBeanPropertyNames(template, false);		include(properties);		return _this();	}
public void start(final int startIndex) {		this.tagStartIndex = startIndex;		this.name = null;		this.idNdx = -1;		this.attributesCount = 0;		this.tagLength = 0;		this.modified = false;		this.type = TagType.START;		this.rawTag = false;	}
@Override	public boolean nameEquals(final CharSequence charSequence) {		return caseSensitive ? CharSequenceUtil.equals(name, charSequence) : CharSequenceUtil.equalsIgnoreCase(name, charSequence);	}
private void ensureLength() {		if (attributesCount + 1 >= attrNames.length) {			attrNames = ArraysUtil.resize(attrNames, attributesCount * 2);			attrValues = ArraysUtil.resize(attrValues, attributesCount * 2);		}	}
private void appendTo(final Appendable out) {		try {			out.append(type.getStartString());			out.append(name);			if (attributesCount > 0) {				for (int i = 0; i < attributesCount; i++) {					out.append(' ');					out.append(attrNames[i]);					final CharSequence value = attrValues[i];					if (value != null) {						out.append('=').append('"');						out.append(HtmlEncoder.attributeDoubleQuoted(value));						out.append('"');					}				}			}			out.append(type.getEndString());		} catch (IOException ioex) {			throw new LagartoException(ioex);		}	}
public void registerComponent(final Class component) {		String name = resolveBaseComponentName(component);		registerComponent(name, component);	}
public <T> void registerComponent(final String name, final Class<T> component, final Consumer<T> consumer) {		log.debug(() -> "Madvoc WebApp component: [" + name + "] --> " + component.getName());		madpc.removeBean(name);		madpc.registerPetiteBean(component, name, null, null, false, consumer);	}
public void registerComponentInstance(final Object componentInstance) {		Class component = componentInstance.getClass();		String name = resolveBaseComponentName(component);		registerComponentInstance(name, componentInstance);	}
public void registerComponentInstance(final String name, final Object componentInstance) {		log.debug(() -> "Madvoc WebApp component: [" + name + "] --> " + componentInstance.getClass().getName());		madpc.removeBean(name);		madpc.addBean(name, componentInstance);	}
public void fireEvent(final Class listenerType) {		final Set<String> existing = new HashSet<>();		while (true) {			MutableInteger newCount = MutableInteger.of(0);			madpc.forEachBeanType(listenerType, name -> {				if (existing.add(name)) {					// name not found, fire!					newCount.value++;					Object listener = lookupComponent(name);					if (listener != null) {						MadvocComponentLifecycle.invoke(listener, listenerType);					}				}			});			if (newCount.value == 0) {				break;			}		}	}
@SuppressWarnings({"unchecked"})	public <T> T lookupComponent(final Class<T> component) {		String name = resolveBaseComponentName(component);		return (T) madpc.getBean(name);	}
public <T> T requestComponent(final Class<T> component) {		T existingComponent = lookupComponent(component);		if (existingComponent == null) {			throw new MadvocException("Madvoc component not found: " + component.getName());		}		return existingComponent;	}
public <T> T requestComponent(final String componentName) {		T existingComponent = (T) lookupComponent(componentName);		if (existingComponent == null) {			throw new MadvocException("Madvoc component not found: " + componentName);		}		return existingComponent;	}
private String resolveBaseComponentName(Class component) {		Class lastComponent = component;		while (true) {			Class superClass = component.getSuperclass();			if (superClass.equals(Object.class)) {				break;			}			component = superClass;			if (!Modifier.isAbstract(component.getModifiers())) {				lastComponent = component;			}		}		return madpc.resolveBeanName(lastComponent);	}
@Override	protected void prepareQuery() {		super.prepareQuery();		if (sqlgen == null) {			return;		}		if (hints == null) {			String[] joinHints = sqlgen.getJoinHints();			if (joinHints != null) {				withHints(joinHints);			}		}		// insert parameters		Map<String, ParameterValue> parameters = sqlgen.getQueryParameters();		if (parameters == null) {			return;		}		for (Map.Entry<String, ParameterValue> entry : parameters.entrySet()) {			String paramName = entry.getKey();			ParameterValue param = entry.getValue();			DbEntityColumnDescriptor dec = param.getColumnDescriptor();			if (dec == null) {				setObject(paramName, param.getValue());			} else {				resolveColumnDbSqlType(connection, dec);				setObject(paramName, param.getValue(), dec.getSqlTypeClass(), dec.getDbSqlType());			}		}	}
protected void resolveColumnDbSqlType(final Connection connection, final DbEntityColumnDescriptor dec) {		if (dec.dbSqlType != SqlType.DB_SQLTYPE_UNKNOWN) {			return;		}		ResultSet rs = null;		DbEntityDescriptor ded = dec.getDbEntityDescriptor();		try {			DatabaseMetaData dmd = connection.getMetaData();			rs = dmd.getColumns(null, ded.getSchemaName(), ded.getTableName(), dec.getColumnName());			if (rs.next()) {				dec.dbSqlType = rs.getInt("DATA_TYPE");			} else {				dec.dbSqlType = SqlType.DB_SQLTYPE_NOT_AVAILABLE;				if (log.isWarnEnabled()) {					log.warn("Column SQL type not available: " + ded.toString() + '.' + dec.getColumnName());				}			}		} catch (SQLException sex) {			dec.dbSqlType = SqlType.DB_SQLTYPE_NOT_AVAILABLE;			if (log.isWarnEnabled()) {				log.warn("Column SQL type not resolved: " + ded.toString() + '.' + dec.getColumnName(), sex);			}		} finally {			DbUtil.close(rs);		}	}
protected String preprocessSql(String sqlString) {		// detects callable statement		if (sqlString.charAt(0) == '{') {			return sqlString;		}		// quickly detect if SQL string is a key		if (!CharUtil.isAlpha(sqlString.charAt(0))) {			sqlString = sqlString.substring(1);		}		else if (sqlString.indexOf(' ') != -1) {			return sqlString;		}		final String sqlFromMap = dbOom.queryMap().getQuery(sqlString);		if (sqlFromMap != null) {			sqlString = sqlFromMap.trim();		}		return sqlString;	}
protected Object resolveRowResults(Object[] row) {		if (hintResolver == null) {			hintResolver = new JoinHintResolver();		}		row = hintResolver.join(row, hints);		return row.length == 1 ? row[0] : row;	}
protected ResultSetMapper createResultSetMapper(final ResultSet resultSet) {		final Map<String, ColumnData> columnAliases = sqlgen != null ? sqlgen.getColumnData() : null;		return new DefaultResultSetMapper(dbOom, resultSet, columnAliases, cacheEntities, this);	}
public <T> T findGeneratedKey(final Class<T> type) {		return find(new Class[] {type}, false, getGeneratedColumns());	}
public void populateGeneratedKeys(final Object entity) {		final String[] generatedColumns = getGeneratedColumnNames();		if (generatedColumns == null) {			return;		}		DbEntityDescriptor ded = dbOom.entityManager().lookupType(entity.getClass());		// prepare key types		Class[] keyTypes = new Class[generatedColumns.length];		String[] properties = new String[generatedColumns.length];		for (int i = 0; i < generatedColumns.length; i++) {			String column = generatedColumns[i];			DbEntityColumnDescriptor decd = ded.findByColumnName(column);			if (decd != null) {				keyTypes[i] = decd.getPropertyType();				properties[i] = decd.getPropertyName();			}		}		final Object keyValues = findGeneratedColumns(keyTypes);		if (!keyValues.getClass().isArray()) {			BeanUtil.declared.setProperty(entity, properties[0], keyValues);		} else {			for (int i = 0; i < properties.length; i++) {				BeanUtil.declared.setProperty(entity, properties[i], ((Object[]) keyValues)[i]);			}		}	}
@Override	protected <R extends ActionInterceptor> R createWrapper(final Class<R> wrapperClass) {		return petiteContainer.createBean(wrapperClass);	}
public Q clearParameters() {		init();		if (preparedStatement == null) {			return _this();		}		try {			preparedStatement.clearParameters();		} catch (SQLException sex) {			throw new DbSqlException(sex);		}		return _this();	}
public Q setNull(final int index, final int type) {		initPrepared();		try {			preparedStatement.setNull(index, type);		} catch (SQLException sex) {			throw new DbSqlException(this, "Failed to set null to parameter: " + index, sex);		}		return _this();	}
public Q setInteger(final int index, final int value) {		initPrepared();		try {			preparedStatement.setInt(index, value);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setInteger(final int index, final Number value) {		if (value == null) {			setNull(index, Types.INTEGER);		}		else {			setInteger(index, value.intValue());		}		return _this();	}
public Q setBoolean(final int index, final Boolean value) {		if (value == null) {			setNull(index, Types.BOOLEAN);		}		else {			setBoolean(index, value.booleanValue());		}		return _this();	}
public Q setLong(final int index, final Number value) {		if (value == null) {			setNull(index, Types.BIGINT);		}		else {			setLong(index, value.longValue());		}		return _this();	}
public Q setByte(final int index, final Number value) {		if (value == null) {			setNull(index, Types.SMALLINT);		}		else {			setByte(index, value.byteValue());		}		return _this();	}
public Q setDouble(final int index, final double value) {		initPrepared();		try {			preparedStatement.setDouble(index, value);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setDouble(final int index, final Number value) {		if (value == null) {			setNull(index, Types.DOUBLE);		}		else {			setDouble(index, value.doubleValue());		}		return _this();	}
public Q setFloat(final int index, final Number value) {		if (value == null) {			setNull(index, Types.FLOAT);		}		else {			setFloat(index, value.floatValue());		}		return _this();	}
public Q setShort(final int index, final Number value) {		if (value == null) {			setNull(index, Types.SMALLINT);		}		else {			setShort(index, value.shortValue());		}		return _this();	}
public Q setString(final int index, final String value) {		initPrepared();		try {			preparedStatement.setString(index, value);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setDate(final int index, final Date value) {		initPrepared();		try {			preparedStatement.setDate(index, value);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setTime(final int index, final Time value) {		initPrepared();		try {			preparedStatement.setTime(index, value);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setTimestamp(final int index, final Timestamp value) {		initPrepared();		try {			preparedStatement.setTimestamp(index, value);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setBigDecimal(final int index, final BigDecimal value) {		initPrepared();		try {			preparedStatement.setBigDecimal(index, value);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setBigInteger(final int index, final BigInteger value) {		if (value == null) {			setNull(index, Types.NUMERIC);		}		else {			setLong(index, value.longValue());		}		return _this();	}
public Q setURL(final int index, final URL value) {		initPrepared();		try {			preparedStatement.setURL(index, value);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setBlob(final int index, final Blob value) {		initPrepared();		try {			preparedStatement.setBlob(index, value);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setClob(final int index, final Clob value) {		initPrepared();		try {			preparedStatement.setClob(index, value);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setArray(final int index, final Array value) {		initPrepared();		try {			preparedStatement.setArray(index, value);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setRef(final int index, final Ref value) {		initPrepared();		try {			preparedStatement.setRef(index, value);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setAsciiStream(final int index, final InputStream stream) {		initPrepared();		try {			preparedStatement.setAsciiStream(index, stream, stream.available());		} catch (IOException | SQLException ioex) {			throwSetParamError(index, ioex);		}		return _this();	}
public Q setBean(final String beanName, final Object bean) {		if (bean == null) {			return _this();		}		init();		final String beanNamePrefix = beanName + '.';		query.forEachNamedParameter(p -> {			final String paramName = p.name;			if (paramName.startsWith(beanNamePrefix)) {				final String propertyName = paramName.substring(beanNamePrefix.length());				if (BeanUtil.declared.hasRootProperty(bean, propertyName)) {					final Object value = BeanUtil.declared.getProperty(bean, propertyName);					setObject(paramName, value);				}			}		});		return _this();	}
public Q setMap(final Map parameters) {		if (parameters == null) {			return _this();		}		init();		query.forEachNamedParameter(p -> {			final String paramName = p.name;			setObject(paramName, parameters.get(paramName));		});		return _this();	}
public Q setObject(final int index, final Object object, final int targetSqlType) {		initPrepared();		try {			preparedStatement.setObject(index, object, targetSqlType);		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setObject(final String param, final Object object, final int targetSqlType) {		initPrepared();		final int[] positions = query.getNamedParameterIndices(param);		try {			for (final int position : positions) {				preparedStatement.setObject(position, object, targetSqlType);			}		} catch (SQLException sex) {			throwSetParamError(param, sex);		}		return _this();	}
void setObject(final int index, final Object object, final int targetSqlType, final int scale) {		initPrepared();	    try {		    preparedStatement.setObject(index, object, targetSqlType, scale);	    } catch (SQLException sex) {			throwSetParamError(index, sex);	    }    }
@SuppressWarnings({"unchecked"})	public Q setObject(final int index, final Object value, final Class<? extends SqlType> sqlTypeClass, final int dbSqlType) {		init();		if (value == null) {			setNull(index, Types.NULL);			return _this();		}		final SqlType sqlType;		if (sqlTypeClass != null) {			sqlType = SqlTypeManager.get().lookupSqlType(sqlTypeClass);		} else {			sqlType = SqlTypeManager.get().lookup(value.getClass());		}		try {			if ((sqlType != null) && (dbSqlType != SqlType.DB_SQLTYPE_NOT_AVAILABLE)) {				sqlType.storeValue(preparedStatement, index, value, dbSqlType);			} else {				DbUtil.setPreparedStatementObject(preparedStatement, index, value, dbSqlType);			}		} catch (SQLException sex) {			throwSetParamError(index, sex);		}		return _this();	}
public Q setObjects(final Object... objects) {		int index = 1;		for (final Object object : objects) {			setObject(index++, object);		}		return _this();	}
public Q setObjects(final String[] names, final Object[] values) {		init();		if (names.length != values.length) {			throw new DbSqlException(this, "Different number of parameter names and values");		}		for (int i = 0; i < names.length; i++) {			setObject(names[i], values[i]);		}		return _this();	}
public Q setBatch(final String name, final int[] array, int startingIndex) {		init();		final int batchSize = query.getBatchParameterSize(name);		for (int i = 1; i <= batchSize; i++) {			final String paramName = name + '.' + i;			if (startingIndex < array.length) {				setInteger(paramName, array[startingIndex]);			} else {				setNull(paramName, Types.INTEGER);			}			startingIndex++;		}		return _this();	}
public Q setBatch(final String name, final Object[] array, int startingIndex) {		init();		final int batchSize = query.getBatchParameterSize(name);		for (int i = 1; i <= batchSize; i++) {			final String paramName = name + '.' + i;			if (startingIndex < array.length) {				setObject(paramName, array[startingIndex]);			} else {				setObject(paramName, null);			}			startingIndex++;		}		return _this();	}
public void insertChunkAfter(final SqlChunk previous) {		SqlChunk next = previous.nextChunk;		previous.nextChunk = this;		this.previousChunk = previous;		if (next != null) {			next.previousChunk = this;			this.nextChunk = next;		}	}
protected DbEntityDescriptor lookupName(final String entityName) {		DbEntityDescriptor ded = dbEntityManager.lookupName(entityName);		if (ded == null) {			throw new DbSqlBuilderException("Entity name not registered: " + entityName);		}		return ded;	}
protected DbEntityDescriptor lookupType(final Class entity) {		final DbEntityDescriptor ded = dbEntityManager.lookupType(entity);		if (ded == null) {			throw new DbSqlBuilderException("Invalid or not-persistent entity: " + entity.getName());		}		return ded;	}
protected DbEntityDescriptor findColumnRef(final String columnRef) {		DbEntityDescriptor ded = templateData.findTableDescriptorByColumnRef(columnRef);		if (ded == null) {			throw new DbSqlBuilderException("Invalid column reference: [" + columnRef + "]");		}		return ded;	}
protected String resolveTable(final String tableRef, final DbEntityDescriptor ded) {		String tableAlias = templateData.getTableAlias(tableRef);		if (tableAlias != null) {			return tableAlias;		}		return ded.getTableNameForQuery();	}
protected void defineParameter(final StringBuilder query, String name, final Object value, final DbEntityColumnDescriptor dec) {		if (name == null) {			name = templateData.getNextParameterName();		}		query.append(':').append(name);		templateData.addParameter(name, value, dec);	}
protected static Class resolveClass(final Object object) {		Class type = object.getClass();		return type == Class.class ? (Class) object : type;	}
protected boolean isEmptyColumnValue(final DbEntityColumnDescriptor dec, final Object value) {		if (value == null) {			return true;		}		// special case for ID column		if (dec.isId() && value instanceof Number) {			final double d = ((Number) value).doubleValue();			if (d == 0.0d) {				return true;			}		}		// special case for primitives		if (dec.getPropertyType().isPrimitive()) {			if (char.class == dec.getPropertyType()) {				final Character c = ((Character) value);				if ('\u0000' == c.charValue()) {					return true;				}			} else {				final double d = ((Number) value).doubleValue();				if (d == 0) {					return true;				}			}		}		// special case for strings		if (value instanceof CharSequence) {			if (StringUtil.isBlank((CharSequence) value)) {				return true;			}		}		return false;	}
protected void appendMissingSpace(final StringBuilder out) {		int len = out.length();		if (len == 0) {			return;		}		len--;		if (!CharUtil.isWhitespace(out.charAt(len))) {			out.append(' ');		}	}
public boolean isValid(final ValidationConstraintContext vcc, final Object value) {		return validate(vcc.getTarget(), value, fieldName);	}
@Override	public Connection getConnection() {		PooledConnection pconn;		try {			pconn = cpds.getPooledConnection();		} catch (SQLException sex) {			throw new DbSqlException("Invalid pooled connection", sex);		}		try {			return pconn.getConnection();		} catch (SQLException sex) {			throw new DbSqlException("Invalid pooled connection", sex);		}	}
public Enumeration<String> getFileParameterNames() {		if (mreq == null) {			return null;		}		return Collections.enumeration(mreq.getFileParameterNames());	}
public FileUpload[] getFiles(final String fieldName) {		if (mreq == null) {			return null;		}		return mreq.getFiles(fieldName);	}
@Override	public int compareTo(final MutableLong other) {		return value < other.value ? -1 : (value == other.value ? 0 : 1);	}
public static boolean include(final ServletRequest request, final ServletResponse response, final String page) throws IOException, ServletException {		RequestDispatcher dispatcher = request.getRequestDispatcher(page);		if (dispatcher != null) {			dispatcher.include(request, response);			return true;		}		return false;	}
public static boolean includeNamed(final HttpServletRequest request, final ServletResponse response, final String resource) throws IOException, ServletException {		return includeNamed(request.getServletContext(), request, response, resource);	}
public static boolean includeNamed(final ServletContext context, final ServletRequest request, final ServletResponse response, final String page) throws IOException, ServletException {		RequestDispatcher dispatcher = context.getNamedDispatcher(page);		if (dispatcher != null) {			dispatcher.include(request, response);			return true;		}		return false;	}
public static boolean includeAbsolute(final HttpServletRequest request, final HttpServletResponse response, final String page) throws IOException, ServletException {		return includeAbsolute(request.getServletContext(), request, response, page);	}
public static boolean includeAbsolute(final ServletContext context, final ServletRequest request, final HttpServletResponse response, final String page) throws IOException, ServletException {		RequestDispatcher dispatcher = context.getRequestDispatcher(page);		if (dispatcher != null) {			dispatcher.include(request, response);			return true;		}		return false;	}
public static boolean forwardAbsolute(final HttpServletRequest request, final ServletResponse response, final String page) throws IOException, ServletException {		return forwardAbsolute(request.getServletContext(), request, response, page);	}
public static boolean forwardAbsolute(final ServletContext context, final ServletRequest request, final ServletResponse response, final String resource) throws IOException, ServletException {		RequestDispatcher dispatcher = context.getRequestDispatcher(resource);		if (dispatcher != null) {			dispatcher.forward(request, response);			return true;		}		return false;	}
public static void redirect(final HttpServletRequest request, final HttpServletResponse response, String url) throws IOException {		if (url.startsWith(StringPool.SLASH)) {			url = ServletUtil.getContextPath(request) + url;		}		response.sendRedirect(response.encodeRedirectURL(url));	}
public static void redirectPermanent(final HttpServletRequest request, final HttpServletResponse response, String url) {		if (url.startsWith(StringPool.SLASH)) {			url = ServletUtil.getContextPath(request) + url;		}		response.setStatus(HttpServletResponse.SC_MOVED_PERMANENTLY);		response.setHeader("Location", url);	}
public static String getFullUrl(final HttpServletRequest request) {		String url = request.getRequestURI();		String query = request.getQueryString();		if ((query != null) && (query.length() != 0)) {			url += '?' + query;		}		return url;	}
public static String getUrl(final HttpServletRequest request) {		String servletPath = request.getServletPath();		String query = request.getQueryString();		if ((query != null) && (query.length() != 0)) {			servletPath += '?' + query;		}		return servletPath;	}
public static boolean isPageIncluded(final HttpServletRequest request, final HttpServletResponse response) {		return (response.isCommitted() || (getIncludeServletPath(request) != null));	}
public static String getBaseRequestUri(final HttpServletRequest request) {		String result = getForwardRequestUri(request);		if (result == null) {			result = request.getRequestURI();		}		return result;	}
public static String getRequestUri(final HttpServletRequest request) {		String result = getIncludeRequestUri(request);		if (result == null) {			result = request.getRequestURI();		}		return result;	}
public String[] resolveParamNames(final Method actionClassMethod) {		MethodParameter[] methodParameters = Paramo.resolveParameters(actionClassMethod);		String[] names = new String[methodParameters.length];		for (int i = 0; i < methodParameters.length; i++) {			names[i] = methodParameters[i].getName();		}		return names;	}
public PathMacros buildActionPathMacros(final String actionPath) {		if (actionPath.isEmpty()) {			return null;		}		PathMacros pathMacros = createPathMacroInstance();		if (!pathMacros.init(actionPath, actionsManager.getPathMacroSeparators())) {			return null;		}		return pathMacros;	}
private PathMacros createPathMacroInstance() {		try {			return ClassUtil.newInstance(actionsManager.getPathMacroClass());		} catch (Exception ex) {			throw new MadvocException(ex);		}	}
@Override	public void start() {		initLogger();		log.info("PETITE start  ----------");		petiteContainer = createPetiteContainer();		if (externalsCache) {			petiteContainer.setExternalsCache(TypeCache.createDefault());		}		log.info("Web application? " + isWebApplication);		if (!isWebApplication) {			// make session scope to act as singleton scope			// if this is not a web application (and http session is not available).			petiteContainer.registerScope(SessionScope.class, new SingletonScope(petiteContainer));		}		// load parameters from properties files		petiteContainer.defineParameters(joyPropsSupplier.get().getProps());		// automagic configuration		if (autoConfiguration) {			final AutomagicPetiteConfigurator automagicPetiteConfigurator =				new AutomagicPetiteConfigurator(petiteContainer);			automagicPetiteConfigurator.registerAsConsumer(joyScannerSupplier.get().getClassScanner());		}		petiteContainerConsumers.accept(this.petiteContainer);		log.info("PETITE OK!");	}
@Override	public void stop() {		if (log != null) {			log.info("PETITE stop");		}		if (petiteContainer != null) {			petiteContainer.shutdown();		}		petiteContainer = null;	}
public void printBeans(final int width) {		final Print print = new Print();		print.line("Beans", width);		final List<BeanDefinition> beanDefinitionList = new ArrayList<>();		final String appName = appNameSupplier.get();		final String prefix = appName + ".";		petiteContainer.forEachBean(beanDefinitionList::add);		beanDefinitionList.stream()			.sorted((bd1, bd2) -> {				if (bd1.name().startsWith(prefix)) {					if (bd2.name().startsWith(prefix)) {						return bd1.name().compareTo(bd2.name());					}					return 1;				}				if (bd2.name().startsWith(prefix)) {					if (bd1.name().startsWith(prefix)) {						return bd1.name().compareTo(bd2.name());					}					return -1;				}				return bd1.name().compareTo(bd2.name());			})			.forEach(beanDefinition -> {				print.out(Chalk256.chalk().yellow(), scopeName(beanDefinition), 10);				print.space();				print.outLeftRightNewLine(					Chalk256.chalk().green(), beanDefinition.name(),					Chalk256.chalk().blue(), ClassUtil.getShortClassName(beanDefinition.type(), 2),					width - 10 - 1				);			});		print.line(width);	}
@Override  void execute(      final int opcode, final int arg, final Symbol symbolArg, final SymbolTable symbolTable) {    super.execute(opcode, arg, symbolArg, symbolTable);    Frame successor = new Frame(null);    merge(symbolTable, successor, 0);    copyFrom(successor);  }
public EmailFilter subject(final String subject) {		final SearchTerm subjectTerm = new SubjectTerm(subject);		concat(subjectTerm);		return this;	}
public EmailFilter messageId(final String messageId) {		final SearchTerm msgIdTerm = new MessageIDTerm(messageId);		concat(msgIdTerm);		return this;	}
public EmailFilter from(final String fromAddress) {		final SearchTerm fromTerm = new FromStringTerm(fromAddress);		concat(fromTerm);		return this;	}
public EmailFilter to(final String toAddress) {		final SearchTerm toTerm = new RecipientStringTerm(RecipientType.TO, toAddress);		concat(toTerm);		return this;	}
public EmailFilter cc(final String ccAddress) {		final SearchTerm toTerm = new RecipientStringTerm(RecipientType.CC, ccAddress);		concat(toTerm);		return this;	}
public EmailFilter bcc(final String bccAddress) {		final SearchTerm toTerm = new RecipientStringTerm(RecipientType.BCC, bccAddress);		concat(toTerm);		return this;	}
public EmailFilter flags(final Flags flags, final boolean value) {		final SearchTerm flagTerm = new FlagTerm(flags, value);		concat(flagTerm);		return this;	}
public EmailFilter flag(final Flag flag, final boolean value) {		final Flags flags = new Flags();		flags.add(flag);		return flags(flags, value);	}
public EmailFilter receivedDate(final Operator operator, final long milliseconds) {		final SearchTerm term = new ReceivedDateTerm(operator.value, new Date(milliseconds));		concat(term);		return this;	}
public EmailFilter sentDate(final Operator operator, final long milliseconds) {		final SearchTerm term = new SentDateTerm(operator.value, new Date(milliseconds));		concat(term);		return this;	}
public EmailFilter text(final String pattern) {		final SearchTerm term = new BodyTerm(pattern);		concat(term);		return this;	}
public EmailFilter header(final String headerName, final String pattern) {		final SearchTerm term = new HeaderTerm(headerName, pattern);		concat(term);		return this;	}
public EmailFilter size(final Operator comparison, final int size) {		final SearchTerm term = new SizeTerm(comparison.value, size);		concat(term);		return this;	}
public EmailFilter and(final EmailFilter... emailFilters) {		final SearchTerm[] searchTerms = new SearchTerm[emailFilters.length];		for (int i = 0; i < emailFilters.length; i++) {			searchTerms[i] = emailFilters[i].searchTerm;		}		concat(new AndTerm(searchTerms));		return this;	}
public EmailFilter or(final EmailFilter... emailFilters) {		final SearchTerm[] searchTerms = new SearchTerm[emailFilters.length];		for (int i = 0; i < emailFilters.length; i++) {			searchTerms[i] = emailFilters[i].searchTerm;		}		concat(new OrTerm(searchTerms));		return this;	}
public EmailFilter not(final EmailFilter emailFilter) {		final SearchTerm searchTerm = new NotTerm(emailFilter.searchTerm);		concat(searchTerm);		return this;	}
protected void concat(SearchTerm searchTerm) {		if (nextIsNot) {			searchTerm = new NotTerm(searchTerm);			nextIsNot = false;		}		if (operatorAnd) {			and(searchTerm);		} else {			or(searchTerm);		}	}
protected void and(final SearchTerm searchTerm) {		if (this.searchTerm == null) {			this.searchTerm = searchTerm;			return;		}		this.searchTerm = new AndTerm(this.searchTerm, searchTerm);	}
protected void or(final SearchTerm searchTerm) {		if (this.searchTerm == null) {			this.searchTerm = searchTerm;			return;		}		this.searchTerm = new OrTerm(this.searchTerm, searchTerm);	}
public static String encode(final byte[] bytes) {		StringBuilder base32 = new StringBuilder((bytes.length * 8 + 4) / 5);		int currByte, digit, i = 0;		while (i < bytes.length) {			// STEP 0; insert new 5 bits, leave 3 bits			currByte = bytes[i++] & 255;			base32.append(CHARS[currByte >> 3]);			digit = (currByte & 7) << 2;			if (i >= bytes.length) {				base32.append(CHARS[digit]);				break;			}			// STEP 3: insert 2 new bits, then 5 bits, leave 1 bit			currByte = bytes[i++] & 255;			base32.append(CHARS[digit | (currByte >> 6)]);			base32.append(CHARS[(currByte >> 1) & 31]);			digit = (currByte & 1) << 4;			if (i >= bytes.length) {				base32.append(CHARS[digit]);				break;			}			// STEP 1: insert 4 new bits, leave 4 bit			currByte = bytes[i++] & 255;			base32.append(CHARS[digit | (currByte >> 4)]);			digit = (currByte & 15) << 1;			if (i >= bytes.length) {				base32.append(CHARS[digit]);				break;			}			// STEP 4: insert 1 new bit, then 5 bits, leave 2 bits			currByte = bytes[i++] & 255;			base32.append(CHARS[digit | (currByte >> 7)]);			base32.append(CHARS[(currByte >> 2) & 31]);			digit = (currByte & 3) << 3;			if (i >= bytes.length) {				base32.append(CHARS[digit]);				break;			}			// STEP 2: insert 3 new bits, then 5 bits, leave 0 bit			currByte = bytes[i++] & 255;			base32.append(CHARS[digit | (currByte >> 5)]);			base32.append(CHARS[currByte & 31]);		}		return base32.toString();	}
public static byte[] decode(final String base32) throws IllegalArgumentException {		switch (base32.length() % 8) {			case 1:			case 3:			case 6:				throw new IllegalArgumentException(ERR_CANONICAL_LEN);		}		byte[] bytes = new byte[base32.length() * 5 / 8];		int offset = 0, i = 0, lookup;		byte nextByte, digit;		while (i < base32.length()) {			lookup = base32.charAt(i++) - '2';			if (lookup < 0 || lookup >= LOOKUP.length) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			digit = LOOKUP[lookup];			if (digit == -1) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			// STEP n = 0: leave 5 bits			nextByte = (byte) (digit << 3);			lookup = base32.charAt(i++) - '2';			if (lookup < 0 || lookup >= LOOKUP.length) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			digit = LOOKUP[lookup];			if (digit == -1) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			// STEP n = 5: insert 3 bits, leave 2 bits			bytes[offset++] = (byte) (nextByte | (digit >> 2));			nextByte = (byte) ((digit & 3) << 6);			if (i >= base32.length()) {				if (nextByte != (byte) 0) {					throw new IllegalArgumentException(ERR_CANONICAL_END);				}				break;			}			lookup = base32.charAt(i++) - '2';			if (lookup < 0 || lookup >= LOOKUP.length) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			digit = LOOKUP[lookup];			if (digit == -1) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			// STEP n = 2: leave 7 bits			nextByte |= (byte) (digit << 1);			lookup = base32.charAt(i++) - '2';			if (lookup < 0 || lookup >= LOOKUP.length) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			digit = LOOKUP[lookup];			if (digit == -1) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			// STEP n = 7: insert 1 bit, leave 4 bits			bytes[offset++] = (byte) (nextByte | (digit >> 4));			nextByte = (byte) ((digit & 15) << 4);			if (i >= base32.length()) {				if (nextByte != (byte) 0) {					throw new IllegalArgumentException(ERR_CANONICAL_END);				}				break;			}			lookup = base32.charAt(i++) - '2';			if (lookup < 0 || lookup >= LOOKUP.length) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			digit = LOOKUP[lookup];			if (digit == -1) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			// STEP n = 4: insert 4 bits, leave 1 bit			bytes[offset++] = (byte) (nextByte | (digit >> 1));			nextByte = (byte) ((digit & 1) << 7);			if (i >= base32.length()) {				if (nextByte != (byte) 0) {					throw new IllegalArgumentException(ERR_CANONICAL_END);				}				break;			}			lookup = base32.charAt(i++) - '2';			if (lookup < 0 || lookup >= LOOKUP.length) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			digit = LOOKUP[lookup];			if (digit == -1) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			// STEP n = 1: leave 6 bits			nextByte |= (byte) (digit << 2);			lookup = base32.charAt(i++) - '2';			if (lookup < 0 || lookup >= LOOKUP.length) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			digit = LOOKUP[lookup];			if (digit == -1) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			// STEP n = 6: insert 2 bits, leave 3 bits			bytes[offset++] = (byte) (nextByte | (digit >> 3));			nextByte = (byte) ((digit & 7) << 5);			if (i >= base32.length()) {				if (nextByte != (byte) 0) {					throw new IllegalArgumentException(ERR_CANONICAL_END);				}				break;			}			lookup = base32.charAt(i++) - '2';			if (lookup < 0 || lookup >= LOOKUP.length) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			digit = LOOKUP[lookup];			if (digit == -1) {				throw new IllegalArgumentException(ERR_INVALID_CHARS);			}			// STEP n = 3: insert 5 bits, leave 0 bit			bytes[offset++] = (byte) (nextByte | digit);		}		return bytes;	}
protected byte[] convertValueToArray(final Object value) {		if (value instanceof Blob) {			final Blob blob = (Blob) value;			try {				final long length = blob.length();				if (length > Integer.MAX_VALUE) {					throw new TypeConversionException("Blob is too big.");				}				return blob.getBytes(1, (int) length);			} catch (SQLException sex) {				throw new TypeConversionException(value, sex);			}		}		if (value instanceof File) {			try {				return FileUtil.readBytes((File) value);			} catch (IOException ioex) {				throw new TypeConversionException(value, ioex);			}		}		if (value instanceof Collection) {			final Collection collection = (Collection) value;			final byte[] target = new byte[collection.size()];			int i = 0;			for (final Object element : collection) {				target[i] = convertType(element);				i++;			}			return target;		}		if (value instanceof Iterable) {			final Iterable iterable = (Iterable) value;			final ArrayList<Byte> byteArrayList = new ArrayList<>();			for (final Object element : iterable) {				final byte convertedValue = convertType(element);				byteArrayList.add(Byte.valueOf(convertedValue));			}			final byte[] array = new byte[byteArrayList.size()];			for (int i = 0; i < byteArrayList.size(); i++) {				final Byte b = byteArrayList.get(i);				array[i] = b.byteValue();			}			return array;		}		if (value instanceof CharSequence) {			final String[] strings = StringUtil.splitc(value.toString(), ArrayConverter.NUMBER_DELIMITERS);			return convertArrayToArray(strings);		}		// everything else:		return convertToSingleElementArray(value);	}
@Override	public void doFilter(final ServletRequest request, final ServletResponse response, final FilterChain chain) throws ServletException, IOException {		HttpServletRequest req = (HttpServletRequest) request;		HttpServletResponse res = (HttpServletResponse) response;		if (				(threshold == 0) ||				(!ServletUtil.isGzipSupported(req)) ||				(!isGzipEligible(req))		) {			chain.doFilter(request, response);			return;		}		GzipResponseWrapper wrappedResponse = new GzipResponseWrapper(res);		wrappedResponse.setCompressionThreshold(threshold);		try {			chain.doFilter(request, wrappedResponse);		} finally {			wrappedResponse.finishResponse();		}	}
@Override	public void init(final FilterConfig config) {		try {			wildcards = Converter.get().toBooleanValue(config.getInitParameter("wildcards"), false);		} catch (TypeConversionException ignore) {			wildcards = false;		}		// min size		try {			threshold = Converter.get().toIntValue(config.getInitParameter("threshold"), 0);		} catch (TypeConversionException ignore) {			threshold = 0;		}		// match string		String uriMatch = config.getInitParameter("match");		if ((uriMatch != null) && (!uriMatch.equals(StringPool.STAR))) {			matches = StringUtil.splitc(uriMatch, ',');			for (int i = 0; i < matches.length; i++) {				matches[i] = matches[i].trim();			}		}		// exclude string		String uriExclude = config.getInitParameter("exclude");		if (uriExclude != null) {			excludes = StringUtil.splitc(uriExclude, ',');			for (int i = 0; i < excludes.length; i++) {				excludes[i] = excludes[i].trim();			}		}		// request parameter name		requestParameterName = config.getInitParameter("requestParameterName");		if (requestParameterName == null) {			requestParameterName = "gzip";		}		requestParameterName = requestParameterName.trim();		// allowed extensions		String urlExtensions = config.getInitParameter("extensions");		if (urlExtensions != null) {			if (urlExtensions.equals(StringPool.STAR)) {				extensions = null;			} else {				extensions = StringUtil.splitc(urlExtensions, ", ");			}		} else {			extensions = new String[] {"html", "htm", "js", "css"};		}	}
protected boolean isGzipEligible(final HttpServletRequest request) {		// request parameter name		if (requestParameterName.length() != 0) {			String forceGzipString = request.getParameter(requestParameterName);			if (forceGzipString != null) {				return Converter.get().toBooleanValue(forceGzipString, false);			}		}		// extract uri		String uri = request.getRequestURI();		if (uri == null) {			return false;		}		uri = uri.toLowerCase();		boolean result = false;		// check uri		if (matches == null) {					// match == *			if (extensions == null) {			// extensions == *				return true;			}			// extension			String extension = FileNameUtil.getExtension(uri);			if (extension.length() > 0) {				extension = extension.toLowerCase();				if (StringUtil.equalsOne(extension, extensions) != -1) {					result = true;				}			}		} else {			if (wildcards) {				result = Wildcard.matchPathOne(uri, matches) != -1;			} else {				for (String match : matches) {					if (uri.contains(match)) {						result = true;						break;					}				}			}		}		if ((result) && (excludes != null)) {			if (wildcards) {				if (Wildcard.matchPathOne(uri, excludes) != -1) {					result = false;				}			} else {				for (String exclude : excludes) {					if (uri.contains(exclude)) {						result = false;						// excludes founded						break;					}				}			}		}		return result;	}
public void addViolation(final Violation v) {		if (v == null) {			return;		}		if (violations == null) {			violations = new ArrayList<>();		}		violations.add(v);	}
public List<Violation> validate(final Object target) {		return validate(ValidationContext.resolveFor(target.getClass()), target);	}
public List<Violation> validate(final ValidationContext ctx, final Object target, final String targetName) {		for (Map.Entry<String, List<Check>> entry : ctx.map.entrySet()) {			String name = entry.getKey();			Object value = BeanUtil.declaredSilent.getProperty(target, name);			String valueName = targetName != null ? (targetName + '.' + name) : name;		// move up			ValidationConstraintContext vcc = new ValidationConstraintContext(this, target, valueName);						for (Check check : entry.getValue()) {				String[] checkProfiles = check.getProfiles();				if (!matchProfiles(checkProfiles)) {					continue;				}				if (check.getSeverity() < severity) {					continue;				}				ValidationConstraint constraint = check.getConstraint();				if (!constraint.isValid(vcc, value)) {					addViolation(new Violation(valueName, target, value, check));				}			}		}		return getViolations();	}
public void useProfile(final String profile) {		if (profile == null) {			return;		}		if (this.enabledProfiles == null) {			this.enabledProfiles = new HashSet<>();		}		this.enabledProfiles.add(profile);	}
public void useProfiles(final String... enabledProfiles) {		if (enabledProfiles == null) {			return;		}		if (this.enabledProfiles == null) {			this.enabledProfiles = new HashSet<>();		}		Collections.addAll(this.enabledProfiles, enabledProfiles);	}
protected boolean matchProfiles(final String[] checkProfiles) {		// test for all profiles		if ((checkProfiles != null) && (checkProfiles.length == 1) && checkProfiles[0].equals(ALL_PROFILES)) {			return true;		}		if (enabledProfiles == null || enabledProfiles.isEmpty()) {			if (validateAllProfilesByDefault) {				return true;	// all profiles are considered as enabled			}			// only default profile is enabled			if ((checkProfiles == null) || (checkProfiles.length == 0)) {				return true;			}			for (String profile : checkProfiles) {				if (StringUtil.isEmpty(profile)) {					return true;	// default profile				}				if (profile.equals(DEFAULT_PROFILE)) {					return true;				}			}			return false;		}		// there are enabled profiles		if ((checkProfiles == null) || (checkProfiles.length == 0)) {			return enabledProfiles.contains(DEFAULT_PROFILE);		}		boolean result = false;		for (String profile : checkProfiles) {			boolean b = true;			boolean must = false;			if (StringUtil.isEmpty(profile)) {				profile = DEFAULT_PROFILE;			} else if (profile.charAt(0) == '-') {				profile = profile.substring(1);				b = false;			} else if (profile.charAt(0) == '+') {				profile = profile.substring(1);				must = true;			}			if (enabledProfiles.contains(profile)) {				if (!b) {					return false;				}				result = true;			} else {				if (must) {					return false;				}			}		}		return result;	}
protected Object parseRequestBody(final String body, final Class targetType) {		return JsonParser.create().parse(body, targetType);	}
public long toMilliseconds() {		double then = (fraction - JD_1970.fraction) * MILLIS_IN_DAY;		then += (integer - JD_1970.integer) * MILLIS_IN_DAY;		then += then > 0 ? 1.0e-6 : -1.0e-6;		return (long) then;	}
public JulianDate add(final JulianDate jds) {		int i = this.integer + jds.integer;		double f = this.fraction + jds.fraction;		return new JulianDate(i, f);	}
public JulianDate sub(final JulianDate jds) {		int i = this.integer - jds.integer;		double f = this.fraction -jds.fraction;		return new JulianDate(i, f);	}
private void set(final int i, double f) {		integer = i;		int fi = (int) f;		f -= fi;		integer += fi;		if (f < 0) {			f += 1;			integer--;		}		this.fraction = f;	}
public int daysSpan(final JulianDate otherDate) {		int now = getJulianDayNumber();		int then = otherDate.getJulianDayNumber();		return now - then;	}
public Chalk256 standard(final int index) {		startSequence(FG_CODES[index(index, 0, 8)]);		endSequence(RESET);		return _this();	}
public Chalk256 rgb(final int r, final int b, final int g) {		startSequence(FG_CODES[index(36*r + 6*g + b,16, 232)]);		endSequence(RESET);		return _this();	}
public Chalk256 bgStandard(final int index) {		startSequence(BG_CODES[index(index, 0, 8)]);		endSequence(RESET);		return _this();	}
public Chalk256 bgRgb(final int r, final int b, final int g) {		startSequence(BG_CODES[index(36*r + 6*g + b,16, 232)]);		endSequence(RESET);		return _this();	}
private int index(int index, final int from, final int to) {		index += from;		if ((index < from) || (index >= to)) {			throw new IllegalArgumentException("Color index not in range: [0, " + (to - from) + "]");		}		return index;	}
@Override	protected void initialize(final char[] input) {		super.initialize(input);		this.tag = new ParsedTag();		this.doctype = new ParsedDoctype();		this.text = new char[1024];		this.textLen = 0;		this.parsingTime = -1;	}
public void parse(final TagVisitor visitor) {		tag.init(config.caseSensitive);		this.parsingTime = System.currentTimeMillis();		this.visitor = visitor;		visitor.start();		parsing = true;		while (parsing) {			state.parse();		}		emitText();		visitor.end();		this.parsingTime = System.currentTimeMillis() - parsingTime;	}
protected void emitComment(final int from, final int to) {		if (config.enableConditionalComments) {			// CC: downlevel-hidden starting			if (match(CC_IF, from)) {				int endBracketNdx = find(']', from + 3, to);				CharSequence expression = charSequence(from + 1, endBracketNdx);				ndx = endBracketNdx + 1;				char c = input[ndx];				if (c != '>') {					errorInvalidToken();				}				visitor.condComment(expression, true, true, false);				state = DATA_STATE;				return;			}			if (to > CC_ENDIF2.length && match(CC_ENDIF2, to - CC_ENDIF2.length)) {				// CC: downlevel-hidden ending				visitor.condComment(_ENDIF, false, true, true);				state = DATA_STATE;				return;			}		}		CharSequence comment = charSequence(from, to);		visitor.comment(comment);		commentStart = -1;	}
protected void _error(String message) {		if (config.calculatePosition) {			Position currentPosition = position(ndx);			message = message					.concat(StringPool.SPACE)					.concat(currentPosition.toString());		} else {			message = message					.concat(" [@")					.concat(Integer.toString(ndx))					.concat(StringPool.RIGHT_SQ_BRACKET);		}		visitor.error(message);	}
private boolean isAppropriateTagName(final char[] lowerCaseNameToMatch, final int from, final int to) {		final int len = to - from;		if (len != lowerCaseNameToMatch.length) {			return false;		}		for (int i = from, k = 0; i < to; i++, k++) {			char c = input[i];			c = CharUtil.toLowerAscii(c);			if (c != lowerCaseNameToMatch[k]) {				return false;			}		}		return true;	}
public String createHash(final char[] password) {		// Generate a random salt		SecureRandom random = new SecureRandom();		byte[] salt = new byte[saltBytes];		random.nextBytes(salt);		// Hash the password		byte[] hash = pbkdf2(password, salt, pbkdf2Iterations, hashBytes);		// format iterations:salt:hash		return pbkdf2Iterations + ":" + StringUtil.toHexString(salt) + ":" + StringUtil.toHexString(hash);	}
private static byte[] pbkdf2(final char[] password, final byte[] salt, final int iterations, final int bytes) {		PBEKeySpec spec = new PBEKeySpec(password, salt, iterations, bytes * 8);		try {			SecretKeyFactory skf = SecretKeyFactory.getInstance(PBKDF2_ALGORITHM);			return skf.generateSecret(spec).getEncoded();		}		catch (NoSuchAlgorithmException ignore) {			return null;		}		catch (InvalidKeySpecException e) {			throw new IllegalArgumentException(e);		}	}
private static byte[] fromHex(final String hex) {		final byte[] binary = new byte[hex.length() / 2];		for (int i = 0; i < binary.length; i++) {			binary[i] = (byte) Integer.parseInt(hex.substring(2 * i, 2 * i + 2), 16);		}		return binary;	}
public ProviderDefinition[] resolveProviderDefinitions(final Class type, final String name) {		return providerResolver.resolve(type, name);	}
public EmailAttachmentBuilder name(final String name) {		if (name != null && !name.trim().isEmpty()) {			this.name = name;		}		return this;	}
public <T extends DataSource> EmailAttachmentBuilder content(final T dataSource) {		this.dataSource = dataSource;		name(dataSource.getName());		return this;	}
public EmailAttachmentBuilder content(final InputStream inputStream, final String contentType)		throws IOException {		return content(new ByteArrayDataSource(inputStream, resolveContentType(contentType)));	}
public EmailAttachmentBuilder content(final byte[] bytes, final String contentType) {		return content(new ByteArrayDataSource(bytes, resolveContentType(contentType)));	}
public EmailAttachment<ByteArrayDataSource> buildByteArrayDataSource() throws MailException {		try {			final ByteArrayDataSource bads;			if (dataSource instanceof ByteArrayDataSource) {				bads = (ByteArrayDataSource) dataSource;			} else {				bads = new ByteArrayDataSource(dataSource.getInputStream(), dataSource.getContentType());			}			checkDataSource();			return new EmailAttachment<>(name, contentId, isInline, bads).setEmbeddedMessage(targetMessage);		} catch (final IOException ioexc) {			throw new MailException(ioexc);		}	}
public EmailAttachment<FileDataSource> buildFileDataSource(final String messageId, final File attachmentStorage) throws MailException {		try {			final FileDataSource fds;			if (dataSource instanceof FileDataSource) {				fds = (FileDataSource) dataSource;			} else {				final File file = new File(attachmentStorage, messageId);				FileUtil.writeStream(file, dataSource.getInputStream());				fds = new FileDataSource(file);			}			checkDataSource();			return new EmailAttachment<>(name, contentId, isInline, fds).setEmbeddedMessage(targetMessage);		} catch (final IOException ioexc) {			throw new MailException(ioexc);		}	}
protected EmailAttachmentBuilder setContentIdFromNameIfMissing() {		if (contentId == null) {			if (name != null) {				contentId(FileNameUtil.getName(name));			} else {				contentId(NO_NAME);			}		}		return this;	}
protected String resolveContentType(final String contentType) {		if (contentType != null) {			return contentType;		}		if (name == null) {			return MimeTypes.MIME_APPLICATION_OCTET_STREAM;		}		final String extension = FileNameUtil.getExtension(name);		return MimeTypes.getMimeType(extension);	}
public void accept(final SignatureVisitor signatureVistor) {    String signature = this.signatureValue;    int length = signature.length();    int offset; // Current offset in the parsed signature (parsed from left to right).    char currentChar; // The signature character at 'offset', or just before.    // If the signature starts with '<', it starts with TypeParameters, i.e. a formal type parameter    // identifier, followed by one or more pair ':',ReferenceTypeSignature (for its class bound and    // interface bounds).    if (signature.charAt(0) == '<') {      // Invariant: offset points to the second character of a formal type parameter name at the      // beginning of each iteration of the loop below.      offset = 2;      do {        // The formal type parameter name is everything between offset - 1 and the first ':'.        int classBoundStartOffset = signature.indexOf(':', offset);        signatureVistor.visitFormalTypeParameter(            signature.substring(offset - 1, classBoundStartOffset));        // If the character after the ':' class bound marker is not the start of a        // ReferenceTypeSignature, it means the class bound is empty (which is a valid case).        offset = classBoundStartOffset + 1;        currentChar = signature.charAt(offset);        if (currentChar == 'L' || currentChar == '[' || currentChar == 'T') {          offset = parseType(signature, offset, signatureVistor.visitClassBound());        }        // While the character after the class bound or after the last parsed interface bound        // is ':', we need to parse another interface bound.        while ((currentChar = signature.charAt(offset++)) == ':') {          offset = parseType(signature, offset, signatureVistor.visitInterfaceBound());        }        // At this point a TypeParameter has been fully parsed, and we need to parse the next one        // (note that currentChar is now the first character of the next TypeParameter, and that        // offset points to the second character), unless the character just after this        // TypeParameter signals the end of the TypeParameters.      } while (currentChar != '>');    } else {      offset = 0;    }    // If the (optional) TypeParameters is followed by '(' this means we are parsing a    // MethodSignature, which has JavaTypeSignature type inside parentheses, followed by a Result    // type and optional ThrowsSignature types.    if (signature.charAt(offset) == '(') {      offset++;      while (signature.charAt(offset) != ')') {        offset = parseType(signature, offset, signatureVistor.visitParameterType());      }      // Use offset + 1 to skip ')'.      offset = parseType(signature, offset + 1, signatureVistor.visitReturnType());      while (offset < length) {        // Use offset + 1 to skip the first character of a ThrowsSignature, i.e. '^'.        offset = parseType(signature, offset + 1, signatureVistor.visitExceptionType());      }    } else {      // Otherwise we are parsing a ClassSignature (by hypothesis on the method input), which has      // one or more ClassTypeSignature for the super class and the implemented interfaces.      offset = parseType(signature, offset, signatureVistor.visitSuperclass());      while (offset < length) {        offset = parseType(signature, offset, signatureVistor.visitInterface());      }    }  }
private static int parseType(      final String signature, final int startOffset, final SignatureVisitor signatureVisitor) {    int offset = startOffset; // Current offset in the parsed signature.    char currentChar = signature.charAt(offset++); // The signature character at 'offset'.    // Switch based on the first character of the JavaTypeSignature, which indicates its kind.    switch (currentChar) {      case 'Z':      case 'C':      case 'B':      case 'S':      case 'I':      case 'F':      case 'J':      case 'D':      case 'V':        // Case of a BaseType or a VoidDescriptor.        signatureVisitor.visitBaseType(currentChar);        return offset;      case '[':        // Case of an ArrayTypeSignature, a '[' followed by a JavaTypeSignature.        return parseType(signature, offset, signatureVisitor.visitArrayType());      case 'T':        // Case of TypeVariableSignature, an identifier between 'T' and ';'.        int endOffset = signature.indexOf(';', offset);        signatureVisitor.visitTypeVariable(signature.substring(offset, endOffset));        return endOffset + 1;      case 'L':        // Case of a ClassTypeSignature, which ends with ';'.        // These signatures have a main class type followed by zero or more inner class types        // (separated by '.'). Each can have type arguments, inside '<' and '>'.        int start = offset; // The start offset of the currently parsed main or inner class name.        boolean visited = false; // Whether the currently parsed class name has been visited.        boolean inner = false; // Whether we are currently parsing an inner class type.        // Parses the signature, one character at a time.        while (true) {          currentChar = signature.charAt(offset++);          if (currentChar == '.' || currentChar == ';') {            // If a '.' or ';' is encountered, this means we have fully parsed the main class name            // or an inner class name. This name may already have been visited it is was followed by            // type arguments between '<' and '>'. If not, we need to visit it here.            if (!visited) {              String name = signature.substring(start, offset - 1);              if (inner) {                signatureVisitor.visitInnerClassType(name);              } else {                signatureVisitor.visitClassType(name);              }            }            // If we reached the end of the ClassTypeSignature return, otherwise start the parsing            // of a new class name, which is necessarily an inner class name.            if (currentChar == ';') {              signatureVisitor.visitEnd();              break;            }            start = offset;            visited = false;            inner = true;          } else if (currentChar == '<') {            // If a '<' is encountered, this means we have fully parsed the main class name or an            // inner class name, and that we now need to parse TypeArguments. First, we need to            // visit the parsed class name.            String name = signature.substring(start, offset - 1);            if (inner) {              signatureVisitor.visitInnerClassType(name);            } else {              signatureVisitor.visitClassType(name);            }            visited = true;            // Now, parse the TypeArgument(s), one at a time.            while ((currentChar = signature.charAt(offset)) != '>') {              switch (currentChar) {                case '*':                  // Unbounded TypeArgument.                  ++offset;                  signatureVisitor.visitTypeArgument();                  break;                case '+':                case '-':                  // Extends or Super TypeArgument. Use offset + 1 to skip the '+' or '-'.                  offset =                      parseType(                          signature, offset + 1, signatureVisitor.visitTypeArgument(currentChar));                  break;                default:                  // Instanceof TypeArgument. The '=' is implicit.                  offset = parseType(signature, offset, signatureVisitor.visitTypeArgument('='));                  break;              }            }          }        }        return offset;      default:        throw new IllegalArgumentException();    }  }
int computeAttributesSize() {    symbolTable.addConstantUtf8(Constants.MODULE);    // 6 attribute header bytes, 6 bytes for name, flags and version, and 5 * 2 bytes for counts.    int size =        22 + requires.length + exports.length + opens.length + usesIndex.length + provides.length;    if (packageCount > 0) {      symbolTable.addConstantUtf8(Constants.MODULE_PACKAGES);      // 6 attribute header bytes, and 2 bytes for package_count.      size += 8 + packageIndex.length;    }    if (mainClassIndex > 0) {      symbolTable.addConstantUtf8(Constants.MODULE_MAIN_CLASS);      // 6 attribute header bytes, and 2 bytes for main_class_index.      size += 8;    }    return size;  }
void putAttributes(final ByteVector output) {    // 6 bytes for name, flags and version, and 5 * 2 bytes for counts.    int moduleAttributeLength =        16 + requires.length + exports.length + opens.length + usesIndex.length + provides.length;    output        .putShort(symbolTable.addConstantUtf8(Constants.MODULE))        .putInt(moduleAttributeLength)        .putShort(moduleNameIndex)        .putShort(moduleFlags)        .putShort(moduleVersionIndex)        .putShort(requiresCount)        .putByteArray(requires.data, 0, requires.length)        .putShort(exportsCount)        .putByteArray(exports.data, 0, exports.length)        .putShort(opensCount)        .putByteArray(opens.data, 0, opens.length)        .putShort(usesCount)        .putByteArray(usesIndex.data, 0, usesIndex.length)        .putShort(providesCount)        .putByteArray(provides.data, 0, provides.length);    if (packageCount > 0) {      output          .putShort(symbolTable.addConstantUtf8(Constants.MODULE_PACKAGES))          .putInt(2 + packageIndex.length)          .putShort(packageCount)          .putByteArray(packageIndex.data, 0, packageIndex.length);    }    if (mainClassIndex > 0) {      output          .putShort(symbolTable.addConstantUtf8(Constants.MODULE_MAIN_CLASS))          .putInt(2)          .putShort(mainClassIndex);    }  }
public static String decode(final String source, final String encoding) {		return decode(source, encoding, false);	}
public static String decodeQuery(final String source, final String encoding) {		return decode(source, encoding, true);	}
@Override	@SuppressWarnings("unchecked")	public void start() {		initLogger();		if (!databaseEnabled) {			log.info("DB not enabled.");			return;		}		log.info("DB start ----------");		final PetiteContainer petiteContainer = joyPetiteSupplier.get().getPetiteContainer();		// connection pool		connectionProvider = createConnectionProviderIfNotSupplied();		petiteContainer.addBean(beanNamePrefix() + "pool", connectionProvider);		if (connectionProvider instanceof CoreConnectionPool) {			final CoreConnectionPool pool = (CoreConnectionPool) connectionProvider;			if (pool.getDriver() == null) {				databaseEnabled = false;				log.warn("DB configuration not set (" + beanNamePrefix() + "pool.*). DB will be disabled.");				return;			}		}		connectionProvider.init();		checkConnectionProvider();		// transactions manager		jtxManager = createJtxTransactionManager(connectionProvider);		jtxManager.setValidateExistingTransaction(true);		final AnnotationTxAdviceManager annTxAdviceManager = new AnnotationTxAdviceManager(new LeanJtxWorker(jtxManager), jtxScopePattern);		AnnotationTxAdviceSupport.manager = annTxAdviceManager;		// create proxy		joyProxettaSupplier.get().getProxetta().withAspect(createTxProxyAspects(annTxAdviceManager.getAnnotations()));		final DbSessionProvider sessionProvider = new DbJtxSessionProvider(jtxManager);		// querymap		final long startTime = System.currentTimeMillis();		final QueryMap queryMap = new DbPropsQueryMap();		log.debug("Queries loaded in " + (System.currentTimeMillis() - startTime) + "ms.");		log.debug("Total queries: " + queryMap.size());		// dboom		dbOom = DbOom.create()			.withConnectionProvider(connectionProvider)			.withSessionProvider(sessionProvider)			.withQueryMap(queryMap)			.get();		dbOom.connect();		final DbEntityManager dbEntityManager = dbOom.entityManager();		dbEntityManager.reset();		petiteContainer.addBean(beanNamePrefix() + "query", dbOom.queryConfig());		petiteContainer.addBean(beanNamePrefix() + "oom", dbOom.config());		// automatic configuration		if (autoConfiguration) {			final AutomagicDbOomConfigurator automagicDbOomConfigurator =				new AutomagicDbOomConfigurator(dbEntityManager, true);			automagicDbOomConfigurator.registerAsConsumer(				joyScannerSupplier.get().getClassScanner());		}		dbEntityManagerConsumers.accept(dbEntityManager);		log.info("DB OK!");	}
protected void checkConnectionProvider() {		final Connection connection = connectionProvider.getConnection();		try {			final DatabaseMetaData databaseMetaData = connection.getMetaData();			String name = databaseMetaData.getDatabaseProductName();			String version = databaseMetaData.getDatabaseProductVersion();			if (log.isInfoEnabled()) {				log.info("Connected to database: " + name + " v" + version);			}		} catch (SQLException sex) {			log.error("DB connection failed: ", sex);		} finally {			connectionProvider.closeConnection(connection);		}	}
public void printEntities(final int width) {		if (!databaseEnabled) {			return;		}		final List<DbEntityDescriptor> list = new ArrayList<>();		dbOom.entityManager().forEachEntity(list::add);		if (list.isEmpty()) {			return;		}		final Print print = new Print();		print.line("Entities", width);		list.stream()			.sorted(Comparator.comparing(DbEntityDescriptor::getEntityName))			.forEach(ded -> print.outLeftRightNewLine(				Chalk256.chalk().yellow(), ded.getTableName(),				Chalk256.chalk().blue(),   ClassUtil.getShortClassName(ded.getType(), 2),				width));		print.line(width);	}
public MethodSignatureVisitor lookupMethodSignatureVisitor(final int access, final String name, final String desc, final String className) {		String key = ProxettaAsmUtil.createMethodSignaturesKey(access, name, desc, className);		return methodSignatures.get(key);	}
@Override	public void visit(final int version, final int access, final String name, final String signature, final String superName, final String[] interfaces) {		final int lastSlash = name.lastIndexOf('/');		this.thisReference = name;		this.superName = superName;		this.nextSupername = superName;		this.targetPackage = lastSlash == -1 ? StringPool.EMPTY : name.substring(0, lastSlash).replace('/', '.');		this.targetClassname = name.substring(lastSlash + 1);		this.isTargetInterface = (access & AsmUtil.ACC_INTERFACE) != 0;		if (this.isTargetInterface) {			nextInterfaces = new HashSet<>();			if (interfaces != null) {				Collections.addAll(nextInterfaces, interfaces);			}		}		generics = new GenericsReader().parseSignatureForGenerics(signature, isTargetInterface);	}
@Override	public MethodVisitor visitMethod(final int access, final String name, final String desc, final String signature, final String[] exceptions) {//		if ((access & AsmUtil.ACC_FINAL) != 0) {//			return null;	// skip finals//		}		MethodSignatureVisitor msign = createMethodSignature(access, name, desc, signature, exceptions, thisReference, this.generics);		String key = ProxettaAsmUtil.createMethodSignaturesKey(access, name, desc, thisReference);		methodSignatures.put(key, msign);		allMethodSignatures.add(msign.getCleanSignature());		return new MethodAnnotationReader(msign);	}
@Override	public void visitEnd() {		// prepare class annotations		if (classAnnotations != null) {			annotations = classAnnotations.toArray(new AnnotationInfo[0]);			classAnnotations = null;		}		List<String> superList = new ArrayList<>();		Set<String> allInterfaces = new HashSet<>();		if (nextInterfaces != null) {			allInterfaces.addAll(nextInterfaces);		}		// check all public super methods that are not overridden in superclass		while (nextSupername != null) {			InputStream inputStream = null;			ClassReader cr;			try {				inputStream = ClassLoaderUtil.getClassAsStream(nextSupername, classLoader);				cr = new ClassReader(inputStream);			} catch (IOException ioex) {				throw new ProxettaException("Unable to inspect super class: " + nextSupername, ioex);			} finally {				StreamUtil.close(inputStream);			}			superList.add(nextSupername);			superClassReaders.add(cr);	// remember the super class reader			cr.accept(new SuperClassVisitor(), 0);			if (cr.getInterfaces() != null) {				Collections.addAll(allInterfaces, cr.getInterfaces());			}		}		superClasses = superList.toArray(new String[0]);		// check all interface methods that are not overridden in super-interface		Set<String> todoInterfaces = new HashSet<>(allInterfaces);		Set<String> newCollectedInterfaces = new HashSet<>();		while (true) {			for (String next : todoInterfaces) {				InputStream inputStream = null;				ClassReader cr;				try {					inputStream = ClassLoaderUtil.getClassAsStream(next, classLoader);					cr = new ClassReader(inputStream);				}				catch (IOException ioex) {					throw new ProxettaException("Unable to inspect super interface: " + next, ioex);				}				finally {					StreamUtil.close(inputStream);				}				superClassReaders.add(cr);				// remember the super class reader				cr.accept(new SuperClassVisitor(), 0);				if (cr.getInterfaces() != null) {					for (String newInterface : cr.getInterfaces()) {						if (!allInterfaces.contains(newInterface) && !todoInterfaces.contains(newInterface)) {							// new interface found							newCollectedInterfaces.add(newInterface);						}					}				}			}			// perform collection			allInterfaces.addAll(todoInterfaces);			if (newCollectedInterfaces.isEmpty()) {				// no new interface found				break;			}			todoInterfaces.clear();			todoInterfaces.addAll(newCollectedInterfaces);			newCollectedInterfaces.clear();		}	}
protected MethodSignatureVisitor createMethodSignature(			final int access,			final String methodName,			final String description,			final String signature,			final String[] exceptions,			final String classname,			final Map<String, String> declaredTypeGenerics) {		MethodSignatureVisitor v = new MethodSignatureVisitor(methodName, access, classname, description, exceptions, signature, declaredTypeGenerics, this);		new SignatureReader(signature != null ? signature : description).accept(v);		return v;	}
public static String toCsvString(final Object... elements) {		StringBuilder line = new StringBuilder();		int last = elements.length -1;		for (int i = 0; i < elements.length; i++) {			if (elements[i] == null) {				if (i != last) {					line.append(FIELD_SEPARATOR);				}				continue;			}			String field = elements[i].toString();			// check for special cases			int ndx = field.indexOf(FIELD_SEPARATOR);			if (ndx == -1) {				ndx = field.indexOf(FIELD_QUOTE);			}			if (ndx == -1) {				if (field.startsWith(StringPool.SPACE) || field.endsWith(StringPool.SPACE)) {					ndx = 1;				}			}			if (ndx == -1) {				ndx = StringUtil.indexOfChars(field, SPECIAL_CHARS);			}			// add field			if (ndx != -1) {				line.append(FIELD_QUOTE);			}			field = StringUtil.replace(field, StringPool.QUOTE, DOUBLE_QUOTE);			line.append(field);			if (ndx != -1) {				line.append(FIELD_QUOTE);			}			// last			if (i != last) {				line.append(FIELD_SEPARATOR);			}		}		return line.toString();	}
public static String[] toStringArray(final String line) {		List<String> row = new ArrayList<>();        boolean inQuotedField = false;        int fieldStart = 0;        final int len = line.length();        for (int i = 0; i < len; i++) {            char c = line.charAt(i);            if (c == FIELD_SEPARATOR) {                if (!inQuotedField) {	// ignore we are quoting                    addField(row, line, fieldStart, i, inQuotedField);                    fieldStart = i + 1;                }            } else if (c == FIELD_QUOTE) {                if (inQuotedField) {                    if (i + 1 == len || line.charAt(i + 1) == FIELD_SEPARATOR) {	// we are already quoting - peek to see if this is the end of the field                        addField(row, line, fieldStart, i, inQuotedField);                        fieldStart = i + 2;                        i++; // and skip the comma                        inQuotedField = false;                    }                } else if (fieldStart == i) {                    inQuotedField = true;	// this is a beginning of a quote                    fieldStart++;			// move field start                }            }        }        // add last field - but only if string was not empty        if (len > 0 && fieldStart <= len) {            addField(row, line, fieldStart, len, inQuotedField);        }        return row.toArray(new String[0]);	}
public CtorInjectionPoint resolve(final Class type, final boolean useAnnotation) {		// lookup methods		ClassDescriptor cd = ClassIntrospector.get().lookup(type);		CtorDescriptor[] allCtors = cd.getAllCtorDescriptors();		Constructor foundedCtor = null;		Constructor defaultCtor = null;		BeanReferences[] references = null;		for (CtorDescriptor ctorDescriptor : allCtors) {			Constructor<?> ctor = ctorDescriptor.getConstructor();			Class<?>[] paramTypes = ctor.getParameterTypes();			if (paramTypes.length == 0) {				defaultCtor = ctor;     // detects default ctors			}			if (!useAnnotation) {				continue;			}			BeanReferences[] ctorReferences = referencesResolver.readAllReferencesFromAnnotation(ctor);			if (ctorReferences == null) {				continue;			}			if (foundedCtor != null) {				throw new PetiteException("Two or more constructors are annotated as injection points in the bean: " + type.getName());			}			foundedCtor = ctor;			references = ctorReferences;		}		if (foundedCtor == null) {			// there is no annotated constructor			if (allCtors.length == 1) {				foundedCtor = allCtors[0].getConstructor();			} else {				foundedCtor = defaultCtor;			}			if (foundedCtor == null) {				// no matching ctor found				// still this is not an error if bean is already instantiated.				return CtorInjectionPoint.EMPTY;			}			references = referencesResolver.readAllReferencesFromAnnotation(foundedCtor);			if (references == null) {				references = new BeanReferences[0];			}		}		return new CtorInjectionPoint(foundedCtor, references);	}
private ClassReader createAdviceClassReader(final Class<? extends ProxyAdvice> advice) {		InputStream inputStream = null;		try {			inputStream = ClassLoaderUtil.getClassAsStream(advice);			return new ClassReader(inputStream);		} catch (IOException ioex) {			throw new ProxettaException(ioex);		} finally {			StreamUtil.close(inputStream);		}	}
private ClassReader getCachedAdviceClassReader(final Class<? extends ProxyAdvice> advice) {		if (adviceClassReaderCache == null) {			adviceClassReaderCache = TypeCache.createDefault();		}		ClassReader adviceReader = adviceClassReaderCache.get(advice);		if (adviceReader == null) {			adviceReader = createAdviceClassReader(advice);			adviceClassReaderCache.put(advice, adviceReader);		}		return adviceReader;	}
private void readAdviceData() {		if (ready) {			return;		}		adviceClassReader.accept(new EmptyClassVisitor() {			/**			 * Stores advice reference.			 */			@Override			public void visit(final int version, final int access, final String name, final String signature, final String superName, final String[] interfaces) {				adviceReference = name;				super.visit(version, access, name, signature, superName, interfaces);			}			/**			 * Prevents advice to have inner classes.			 */			@Override			public void visitInnerClass(final String name, final String outerName, final String innerName, final int access) {				if (outerName.equals(adviceReference)) {					throw new ProxettaException("Proxetta doesn't allow inner classes in/for advice: " + advice.getName());				}				super.visitInnerClass(name, outerName, innerName, access);			}			/**			 * Clones advices fields to destination.			 */			@Override			public FieldVisitor visitField(final int access, final String name, final String desc, final String signature, final Object value) {				wd.dest.visitField(access, adviceFieldName(name, aspectIndex), desc, signature, value);     // [A5]				return super.visitField(access, name, desc, signature, value);			}			/**			 * Copies advices methods to destination.			 */			@Override			public MethodVisitor visitMethod(int access, String name, final String desc, final String signature, final String[] exceptions) {				if (name.equals(CLINIT)) {              // [A6]					if (!desc.equals(DESC_VOID)) {						throw new ProxettaException("Invalid static initialization block description for advice: " + advice.getName());					}					name = ProxettaNames.clinitMethodName + ProxettaNames.methodDivider + aspectIndex;					access |= AsmUtil.ACC_PRIVATE | AsmUtil.ACC_FINAL;					wd.addAdviceClinitMethod(name);					return new MethodAdapter(wd.dest.visitMethod(access, name, desc, signature, exceptions)) {						@Override						public void visitLocalVariable(final String name, final String desc, final String signature, final Label start, final Label end, final int index) {						}						@Override						public void visitLineNumber(final int line, final Label start) {						}						@Override						public void visitMethodInsn(final int opcode, String owner, String name, final String desc, final boolean isInterface) {							if (opcode == INVOKESTATIC) {								if (owner.equals(adviceReference)) {									owner = wd.thisReference;									name = adviceMethodName(name, aspectIndex);								}							}							super.visitMethodInsn(opcode, owner, name, desc, isInterface);						}						@Override						public void visitFieldInsn(final int opcode, String owner, String name, final String desc) { // [F6]							if (owner.equals(adviceReference)) {								owner = wd.thisReference;              // [F5]								name = adviceFieldName(name, aspectIndex);							}							super.visitFieldInsn(opcode, owner, name, desc);						}					};				} else				if (name.equals(INIT)) { // [A7]					if (!desc.equals(DESC_VOID)) {						throw new ProxettaException("Advices can have only default constructors. Invalid advice: " + advice.getName());					}					name = ProxettaNames.initMethodName + ProxettaNames.methodDivider + aspectIndex;					access = ProxettaAsmUtil.makePrivateFinalAccess(access);					wd.addAdviceInitMethod(name);					return new MethodAdapter(wd.dest.visitMethod(access, name, desc, signature, exceptions)) {						@Override						public void visitLocalVariable(final String name, final String desc, final String signature, final Label start, final Label end, final int index) {						}						@Override						public void visitLineNumber(final int line, final Label start) {						}						int state; // used to detect and to ignore the first super call()						@Override						public void visitVarInsn(final int opcode, final int var) {                      // [F7]							if ((state == 0) && (opcode == ALOAD) && (var == 0)) {								state++;								return;							}							super.visitVarInsn(opcode, var);						}						@Override						public void visitMethodInsn(final int opcode, String owner, String name, final String desc, final boolean isInterface) {							if ((state == 1) && (opcode == INVOKESPECIAL)) {							    state++;								return;							}							if ((opcode == INVOKEVIRTUAL) || (opcode == INVOKEINTERFACE)) {								if (owner.equals(adviceReference)) {									owner = wd.thisReference;									name = adviceMethodName(name, aspectIndex);								}							} else							if (opcode == INVOKESTATIC) {								if (owner.equals(adviceReference)) {									owner = wd.thisReference;									name = adviceMethodName(name, aspectIndex);								}							}							super.visitMethodInsn(opcode, owner, name, desc, isInterface);						}						@Override						public void visitFieldInsn(final int opcode, String owner, String name, final String desc) { // [F7]							if (owner.equals(adviceReference)) {								owner = wd.thisReference;              // [F5]								name = adviceFieldName(name, aspectIndex);							}							super.visitFieldInsn(opcode, owner, name, desc);						}					};				} else				// other methods				if (!name.equals(ProxettaNames.executeMethodName)) {					name = adviceMethodName(name, aspectIndex);					return new MethodAdapter(wd.dest.visitMethod(access, name, desc, signature, exceptions)) {						@Override						public void visitLocalVariable(final String name, final String desc, final String signature, final Label start, final Label end, final int index) {						}						@Override						public void visitLineNumber(final int line, final Label start) {						}						@Override						public void visitMethodInsn(final int opcode, String owner, String name, final String desc, final boolean isInterface) {							if ((opcode == INVOKEVIRTUAL) || (opcode == INVOKEINTERFACE)) {								if (owner.equals(adviceReference)) {									owner = wd.thisReference;									name = adviceMethodName(name, aspectIndex);								}							} else							if (opcode == INVOKESTATIC || opcode == INVOKESPECIAL) {								if (owner.equals(adviceReference)) {									owner = wd.thisReference;									name = adviceMethodName(name, aspectIndex);								}							}							super.visitMethodInsn(opcode, owner, name, desc, isInterface);						}						@Override						public void visitFieldInsn(final int opcode, String owner, String name, final String desc) {        // replace field references							if (owner.equals(adviceReference)) {								owner = wd.thisReference;								name = adviceFieldName(name, aspectIndex);							}							super.visitFieldInsn(opcode, owner, name, desc);						}					};				}				// Parse EXECUTE method, just to gather some info, real parsing will come later				//return new MethodAdapter(new EmptyMethodVisitor()) {		// toask may we replace this with the following code?				return new EmptyMethodVisitor() {					@Override					public void visitVarInsn(final int opcode, final int var) {						if (isStoreOpcode(opcode)) {							if (var > maxLocalVarOffset) {								maxLocalVarOffset = var;          // find max local var offset							}						}						super.visitVarInsn(opcode, var);					}				};//					return super.visitMethod(access, name, desc, signature, exceptions);			}		}, 0);		maxLocalVarOffset += 2;       // increment offset by 2 because var on last index may be a dword value		ready = true;	}
public String encrypt(final String str) {		try {			byte[] utf8 = StringUtil.getBytes(str);		// encode the string into bytes using utf-8			byte[] enc = ecipher.doFinal(utf8); 	// encrypt			return Base64.encodeToString(enc);		// encode bytes to base64 to get a string		} catch (Throwable ignore) {			return null;		}	}
public String decrypt(String str) {		try {			str = StringUtil.replaceChar(str, ' ', '+');	// replace spaces with chars.			byte[] dec = Base64.decode(str);    	// decode base64 to get bytes			byte[] utf8 = dcipher.doFinal(dec);     // decrypt			return new String(utf8, UTF_8);			// decode using utf-8		} catch (Throwable ignore) {			return null;		}	}
public static void setLoggerProvider(final LoggerProvider loggerProvider) {		LoggerFactory.loggerProvider = loggerProvider::createLogger;		if (loggers != null) {			loggers.clear();		}	}
public static Logger getLogger(final String name) {		if (loggers == null) {			return loggerProvider.apply(name);		}		return loggers.computeIfAbsent(name, loggerProvider);	}
private void setName(final String name) {		if (name.contains(";") || name.contains(",") || name.startsWith("$")) {			throw new IllegalArgumentException("Invalid cookie name:" + name);		}		for (int n = 0; n < name.length(); n++) {			char c = name.charAt(n);			if (c <= 0x20 || c >= 0x7f) {				throw new IllegalArgumentException("Invalid cookie name:" + name);			}		}		this.name = name;	}
public String invoke(String actionPath, final HttpServletRequest servletRequest, final HttpServletResponse servletResponse) throws Exception {		final String originalActionPath = actionPath;		boolean characterEncodingSet = false;		while (actionPath != null) {			// build action path			final String httpMethod = servletRequest.getMethod().toUpperCase();			if (log.isDebugEnabled()) {				log.debug("Action path: " + httpMethod + " " + actionPath);			}			actionPath = actionPathRewriter.rewrite(servletRequest, actionPath, httpMethod);			String[] actionPathChunks = MadvocUtil.splitPathToChunks(actionPath);			// resolve action runtime			ActionRuntime actionRuntime = actionsManager.lookup(httpMethod, actionPathChunks);			if (actionRuntime == null) {				// special case!				if (actionPath.endsWith(welcomeFile)) {					actionPath = actionPath.substring(0, actionPath.length() - (welcomeFile.length() - 1));					actionPathChunks = MadvocUtil.splitPathToChunks(actionPath);					actionRuntime = actionsManager.lookup(httpMethod, actionPathChunks);				}				if (actionRuntime == null) {					return originalActionPath;				}			}			if (log.isDebugEnabled()) {				log.debug("Invoke action for '" + actionPath + "' using " + actionRuntime.createActionString());			}			// set character encoding			if (!characterEncodingSet && applyCharacterEncoding) {				final String encoding = madvocEncoding.getEncoding();				if (encoding != null) {					servletRequest.setCharacterEncoding(encoding);					servletResponse.setCharacterEncoding(encoding);				}				characterEncodingSet = true;			}			// create action object			final Object action;			if (actionRuntime.isActionHandlerDefined()) {				action = actionRuntime.getActionHandler();			}			else {				action = createAction(actionRuntime.getActionClass());			}			final ActionRequest actionRequest = createActionRequest(				actionPath,				actionPathChunks,				actionRuntime,				action,				servletRequest,				servletResponse);			// invoke and render			if (actionRuntime.isAsync()) {				asyncActionExecutor.invoke(actionRequest);			} else {				actionRequest.invoke();			}			actionPath = actionRequest.getNextActionPath();		}		return null;	}
@SuppressWarnings("unchecked")	public void render(final ActionRequest actionRequest, final Object resultObject) throws Exception {		final ActionResult actionResult = resultsManager.lookup(actionRequest, resultObject);		if (actionResult == null) {			throw new MadvocException("Action result not found");		}		if (preventCaching) {			ServletUtil.preventCaching(actionRequest.getHttpServletResponse());		}		log.debug(() -> "Result type: " + actionResult.getClass().getSimpleName());		actionResult.render(actionRequest, actionRequest.getActionResult());	}
protected Object createAction(final Class actionClass) {		try {			return ClassUtil.newInstance(actionClass);		} catch (Exception ex) {			throw new MadvocException("Invalid Madvoc action", ex);		}	}
protected ActionRequest createActionRequest(		final String actionPath,		final String[] actionPathChunks,		final ActionRuntime actionRuntime,		final Object action,		final HttpServletRequest servletRequest,		final HttpServletResponse servletResponse) {		return new ActionRequest(this, actionPath, actionPathChunks, actionRuntime, action, servletRequest, servletResponse);	}
@Override	protected <R extends ActionFilter> R createWrapper(final Class<R> wrapperClass) {		return petiteContainer.createBean(wrapperClass);	}
protected boolean isBeanDestroyable(final BeanData beanData) {		DestroyMethodPoint[] dmp = beanData.definition().destroyMethodPoints();		return dmp != null && dmp.length != 0;	}
protected void registerDestroyableBeans(final BeanData beanData) {		if (!isBeanDestroyable(beanData)) {			return;		}		if (destroyableBeans == null) {			destroyableBeans = new ArrayList<>();		}		destroyableBeans.add(beanData);	}
protected void destroyBean(final BeanData beanData) {		if (destroyableBeans == null) {			return;		}		if (!isBeanDestroyable(beanData)) {			return;		}		if (destroyableBeans.remove(beanData)) {			beanData.callDestroyMethods();		}	}
@Override	public void shutdown() {		if (destroyableBeans == null) {			return;		}		for (final BeanData destroyableBean : destroyableBeans) {			destroyableBean.callDestroyMethods();		}		destroyableBeans.clear();	}
protected Properties createSessionProperties() {		final Properties props = new Properties();		props.putAll(customProperties);		if (debugMode) {			props.put(MAIL_DEBUG, "true");		}		if (!strictAddress) {			props.put(MAIL_MIME_ADDRESS_STRICT, "false");		}		return props;	}
public ReceivedEmail[] get() {		if (fromFolder != null) {			session.useFolder(fromFolder);		}		return session.receiveMessages(filter, flagsToSet, flagsToUnset, envelopeOnly, messages -> {			if (targetFolder != null) {				try {					session.folder.copyMessages(messages, session.getFolder(targetFolder));				} catch (MessagingException e) {					throw new MailException("Copying messages failed");				}			}		});	}
public UnsafeBuffer[] duplicateTermBuffers()    {        final UnsafeBuffer[] buffers = new UnsafeBuffer[PARTITION_COUNT];        for (int i = 0; i < PARTITION_COUNT; i++)        {            buffers[i] = new UnsafeBuffer(termBuffers[i].duplicate().order(ByteOrder.LITTLE_ENDIAN));        }        return buffers;    }
public static void main(final String[] args)    {        loadPropertiesFiles(args);        try (ClusteredServiceContainer container = launch())        {            container.context().shutdownSignalBarrier().await();            System.out.println("Shutdown ClusteredServiceContainer...");        }    }
public static AtomicCounter allocate(        final MutableDirectBuffer tempBuffer,        final String name,        final CountersManager countersManager,        final long registrationId,        final int sessionId,        final int streamId,        final String channel)    {        final int counterId = StreamCounter.allocateCounterId(            tempBuffer, name, PER_IMAGE_TYPE_ID, countersManager, registrationId, sessionId, streamId, channel);        return new AtomicCounter(countersManager.valuesBuffer(), counterId, countersManager);    }
public void run()    {        do        {            LockSupport.parkNanos(parkNs);            final long currentTotalMessages = totalMessages;            final long currentTotalBytes = totalBytes;            final long currentTimestamp = System.nanoTime();            final long timeSpanNs = currentTimestamp - lastTimestamp;            final double messagesPerSec =                ((currentTotalMessages - lastTotalMessages) * (double)reportIntervalNs) / (double)timeSpanNs;            final double bytesPerSec =                ((currentTotalBytes - lastTotalBytes) * (double)reportIntervalNs) / (double)timeSpanNs;            reportingFunc.onReport(messagesPerSec, bytesPerSec, currentTotalMessages, currentTotalBytes);            lastTotalBytes = currentTotalBytes;            lastTotalMessages = currentTotalMessages;            lastTimestamp = currentTimestamp;        }        while (!halt);    }
public static FragmentHandler rateReporterHandler(final RateReporter reporter)    {        return (buffer, offset, length, header) -> reporter.onMessage(1, length);    }
@SuppressWarnings("unused")    public static void printError(        final String channel,        final int streamId,        final int sessionId,        final String message,        final HeaderFlyweight cause)    {        System.out.println(message);    }
public static void printRate(        final double messagesPerSec,        final double bytesPerSec,        final long totalMessages,        final long totalBytes)    {        System.out.println(String.format(            "%.02g msgs/sec, %.02g payload bytes/sec, totals %d messages %d MB",            messagesPerSec, bytesPerSec, totalMessages, totalBytes / (1024 * 1024)));    }
public static MappedByteBuffer mapExistingFileReadOnly(final File location)    {        if (!location.exists())        {            final String msg = "file not found: " + location.getAbsolutePath();            throw new IllegalStateException(msg);        }        MappedByteBuffer mappedByteBuffer = null;        try (RandomAccessFile file = new RandomAccessFile(location, "r");            FileChannel channel = file.getChannel())        {            mappedByteBuffer = channel.map(READ_ONLY, 0, channel.size());        }        catch (final IOException ex)        {            LangUtil.rethrowUnchecked(ex);        }        return mappedByteBuffer;    }
public void close()    {        final State state = this.state;        if (State.CLOSED != state)        {            if (isReplayActive)            {                isReplayActive = false;                archive.stopReplay(replaySessionId);            }            if (State.MERGED != state)            {                subscription.removeDestination(replayDestination);            }            state(State.CLOSED);        }    }
public int doWork()    {        int workCount = 0;        switch (state)        {            case AWAIT_INITIAL_RECORDING_POSITION:                workCount += awaitInitialRecordingPosition();                break;            case AWAIT_REPLAY:                workCount += awaitReplay();                break;            case AWAIT_CATCH_UP:                workCount += awaitCatchUp();                break;            case AWAIT_CURRENT_RECORDING_POSITION:                workCount += awaitUpdatedRecordingPosition();                break;            case AWAIT_STOP_REPLAY:                workCount += awaitStopReplay();                break;        }        return workCount;    }
public int poll(final FragmentHandler fragmentHandler, final int fragmentLimit)    {        doWork();        return null == image ? 0 : image.poll(fragmentHandler, fragmentLimit);    }
public long position()    {        if (isClosed)        {            return CLOSED;        }        final long rawTail = rawTailVolatile(logMetaDataBuffer);        final int termOffset = termOffset(rawTail, termBufferLength);        return computePosition(termId(rawTail), termOffset, positionBitsToShift, initialTermId);    }
public final long offer(final DirectBuffer buffer, final int offset, final int length)    {        return offer(buffer, offset, length, null);    }
public final long offer(        final DirectBuffer bufferOne,        final int offsetOne,        final int lengthOne,        final DirectBuffer bufferTwo,        final int offsetTwo,        final int lengthTwo)    {        return offer(bufferOne, offsetOne, lengthOne, bufferTwo, offsetTwo, lengthTwo, null);    }
public long offer(        final DirectBuffer buffer,        final int offset,        final int length,        final ReservedValueSupplier reservedValueSupplier)    {        long newPosition = CLOSED;        if (!isClosed)        {            final long limit = positionLimit.getVolatile();            final ExclusiveTermAppender termAppender = termAppenders[activePartitionIndex];            final long position = termBeginPosition + termOffset;            if (position < limit)            {                final int result;                if (length <= maxPayloadLength)                {                    checkPositiveLength(length);                    result = termAppender.appendUnfragmentedMessage(                        termId, termOffset, headerWriter, buffer, offset, length, reservedValueSupplier);                }                else                {                    checkMaxMessageLength(length);                    result = termAppender.appendFragmentedMessage(                        termId,                        termOffset,                        headerWriter,                        buffer,                        offset,                        length,                        maxPayloadLength,                        reservedValueSupplier);                }                newPosition = newPosition(result);            }            else            {                newPosition = backPressureStatus(position, length);            }        }        return newPosition;    }
public long offer(        final DirectBuffer bufferOne,        final int offsetOne,        final int lengthOne,        final DirectBuffer bufferTwo,        final int offsetTwo,        final int lengthTwo,        final ReservedValueSupplier reservedValueSupplier)    {        long newPosition = CLOSED;        if (!isClosed)        {            final long limit = positionLimit.getVolatile();            final ExclusiveTermAppender termAppender = termAppenders[activePartitionIndex];            final long position = termBeginPosition + termOffset;            final int length = validateAndComputeLength(lengthOne, lengthTwo);            if (position < limit)            {                final int result;                if (length <= maxPayloadLength)                {                    checkPositiveLength(length);                    result = termAppender.appendUnfragmentedMessage(                        termId,                        termOffset,                        headerWriter,                        bufferOne, offsetOne, lengthOne,                        bufferTwo, offsetTwo, lengthTwo,                        reservedValueSupplier);                }                else                {                    checkMaxMessageLength(length);                    result = termAppender.appendFragmentedMessage(                        termId,                        termOffset,                        headerWriter,                        bufferOne, offsetOne, lengthOne,                        bufferTwo, offsetTwo, lengthTwo,                        maxPayloadLength,                        reservedValueSupplier);                }                newPosition = newPosition(result);            }            else            {                newPosition = backPressureStatus(position, length);            }        }        return newPosition;    }
public long offer(final DirectBufferVector[] vectors, final ReservedValueSupplier reservedValueSupplier)    {        final int length = DirectBufferVector.validateAndComputeLength(vectors);        long newPosition = CLOSED;        if (!isClosed)        {            final long limit = positionLimit.getVolatile();            final ExclusiveTermAppender termAppender = termAppenders[activePartitionIndex];            final long position = termBeginPosition + termOffset;            if (position < limit)            {                final int result;                if (length <= maxPayloadLength)                {                    result = termAppender.appendUnfragmentedMessage(                        termId, termOffset, headerWriter, vectors, length, reservedValueSupplier);                }                else                {                    checkMaxMessageLength(length);                    result = termAppender.appendFragmentedMessage(                        termId,                        termOffset,                        headerWriter,                        vectors,                        length,                        maxPayloadLength,                        reservedValueSupplier);                }                newPosition = newPosition(result);            }            else            {                newPosition = backPressureStatus(position, length);            }        }        return newPosition;    }
public long tryClaim(final int length, final BufferClaim bufferClaim)    {        checkPayloadLength(length);        long newPosition = CLOSED;        if (!isClosed)        {            final long limit = positionLimit.getVolatile();            final ExclusiveTermAppender termAppender = termAppenders[activePartitionIndex];            final long position = termBeginPosition + termOffset;            if (position < limit)            {                final int result = termAppender.claim(termId, termOffset, headerWriter, length, bufferClaim);                newPosition = newPosition(result);            }            else            {                newPosition = backPressureStatus(position, length);            }        }        return newPosition;    }
public long appendPadding(final int length)    {        checkMaxMessageLength(length);        long newPosition = CLOSED;        if (!isClosed)        {            final long limit = positionLimit.getVolatile();            final ExclusiveTermAppender termAppender = termAppenders[activePartitionIndex];            final long position = termBeginPosition + termOffset;            if (position < limit)            {                checkPositiveLength(length);                final int result = termAppender.appendPadding(termId, termOffset, headerWriter, length);                newPosition = newPosition(result);            }            else            {                newPosition = backPressureStatus(position, length);            }        }        return newPosition;    }
public DestinationMessageFlyweight channel(final String channel)    {        lengthOfChannel = buffer.putStringAscii(offset + CHANNEL_OFFSET, channel);        return this;    }
public void close()    {        lock.lock();        try        {            if (!isClosed)            {                isClosed = true;                archiveProxy.closeSession(controlSessionId);                if (!context.ownsAeronClient())                {                    CloseHelper.close(controlResponsePoller.subscription());                    CloseHelper.close(archiveProxy.publication());                }                context.close();            }        }        finally        {            lock.unlock();        }    }
public static AeronArchive connect(final Context ctx)    {        Subscription subscription = null;        Publication publication = null;        AsyncConnect asyncConnect = null;        try        {            ctx.conclude();            final Aeron aeron = ctx.aeron();            final long messageTimeoutNs = ctx.messageTimeoutNs();            final long deadlineNs = aeron.context().nanoClock().nanoTime() + messageTimeoutNs;            subscription = aeron.addSubscription(ctx.controlResponseChannel(), ctx.controlResponseStreamId());            final ControlResponsePoller controlResponsePoller = new ControlResponsePoller(subscription);            publication = aeron.addExclusivePublication(ctx.controlRequestChannel(), ctx.controlRequestStreamId());            final ArchiveProxy archiveProxy = new ArchiveProxy(                publication, ctx.idleStrategy(), aeron.context().nanoClock(), messageTimeoutNs, DEFAULT_RETRY_ATTEMPTS);            asyncConnect = new AsyncConnect(ctx, controlResponsePoller, archiveProxy, deadlineNs);            final IdleStrategy idleStrategy = ctx.idleStrategy();            final AgentInvoker aeronClientInvoker = aeron.conductorAgentInvoker();            AeronArchive aeronArchive;            while (null == (aeronArchive = asyncConnect.poll()))            {                if (null != aeronClientInvoker)                {                    aeronClientInvoker.invoke();                }                idleStrategy.idle();            }            return aeronArchive;        }        catch (final Exception ex)        {            if (!ctx.ownsAeronClient())            {                CloseHelper.quietClose(subscription);                CloseHelper.quietClose(publication);            }            CloseHelper.quietClose(asyncConnect);            ctx.close();            throw ex;        }    }
public static AsyncConnect asyncConnect(final Context ctx)    {        Subscription subscription = null;        Publication publication = null;        try        {            ctx.conclude();            final Aeron aeron = ctx.aeron();            final long messageTimeoutNs = ctx.messageTimeoutNs();            final long deadlineNs = aeron.context().nanoClock().nanoTime() + messageTimeoutNs;            subscription = aeron.addSubscription(ctx.controlResponseChannel(), ctx.controlResponseStreamId());            final ControlResponsePoller controlResponsePoller = new ControlResponsePoller(subscription);            publication = aeron.addExclusivePublication(ctx.controlRequestChannel(), ctx.controlRequestStreamId());            final ArchiveProxy archiveProxy = new ArchiveProxy(                publication, ctx.idleStrategy(), aeron.context().nanoClock(), messageTimeoutNs, DEFAULT_RETRY_ATTEMPTS);            return new AsyncConnect(ctx, controlResponsePoller, archiveProxy, deadlineNs);        }        catch (final Exception ex)        {            if (!ctx.ownsAeronClient())            {                CloseHelper.quietClose(subscription);                CloseHelper.quietClose(publication);            }            ctx.close();            throw ex;        }    }
public String pollForErrorResponse()    {        lock.lock();        try        {            ensureOpen();            if (controlResponsePoller.poll() != 0 && controlResponsePoller.isPollComplete())            {                if (controlResponsePoller.controlSessionId() == controlSessionId &&                    controlResponsePoller.templateId() == ControlResponseDecoder.TEMPLATE_ID &&                    controlResponsePoller.code() == ControlResponseCode.ERROR)                {                    return controlResponsePoller.errorMessage();                }            }            return null;        }        finally        {            lock.unlock();        }    }
public void checkForErrorResponse()    {        lock.lock();        try        {            ensureOpen();            if (controlResponsePoller.poll() != 0 && controlResponsePoller.isPollComplete())            {                if (controlResponsePoller.controlSessionId() == controlSessionId &&                    controlResponsePoller.templateId() == ControlResponseDecoder.TEMPLATE_ID &&                    controlResponsePoller.code() == ControlResponseCode.ERROR)                {                    final ArchiveException ex = new ArchiveException(                        controlResponsePoller.errorMessage(), (int)controlResponsePoller.relevantId());                    if (null != context.errorHandler())                    {                        context.errorHandler().onError(ex);                    }                    else                    {                        throw ex;                    }                }            }        }        finally        {            lock.unlock();        }    }
public Publication addRecordedPublication(final String channel, final int streamId)    {        Publication publication = null;        lock.lock();        try        {            ensureOpen();            publication = aeron.addPublication(channel, streamId);            if (!publication.isOriginal())            {                throw new ArchiveException(                    "publication already added for channel=" + channel + " streamId=" + streamId);            }            startRecording(ChannelUri.addSessionId(channel, publication.sessionId()), streamId, SourceLocation.LOCAL);        }        catch (final RuntimeException ex)        {            CloseHelper.quietClose(publication);            throw ex;        }        finally        {            lock.unlock();        }        return publication;    }
public ExclusivePublication addRecordedExclusivePublication(final String channel, final int streamId)    {        ExclusivePublication publication = null;        lock.lock();        try        {            ensureOpen();            publication = aeron.addExclusivePublication(channel, streamId);            startRecording(ChannelUri.addSessionId(channel, publication.sessionId()), streamId, SourceLocation.LOCAL);        }        catch (final RuntimeException ex)        {            CloseHelper.quietClose(publication);            throw ex;        }        finally        {            lock.unlock();        }        return publication;    }
public long startRecording(final String channel, final int streamId, final SourceLocation sourceLocation)    {        lock.lock();        try        {            ensureOpen();            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.startRecording(channel, streamId, sourceLocation, correlationId, controlSessionId))            {                throw new ArchiveException("failed to send start recording request");            }            return pollForResponse(correlationId);        }        finally        {            lock.unlock();        }    }
public void stopRecording(final String channel, final int streamId)    {        lock.lock();        try        {            ensureOpen();            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.stopRecording(channel, streamId, correlationId, controlSessionId))            {                throw new ArchiveException("failed to send stop recording request");            }            pollForResponse(correlationId);        }        finally        {            lock.unlock();        }    }
public void stopRecording(final Publication publication)    {        final String recordingChannel = ChannelUri.addSessionId(publication.channel(), publication.sessionId());        stopRecording(recordingChannel, publication.streamId());    }
public void stopRecording(final long subscriptionId)    {        lock.lock();        try        {            ensureOpen();            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.stopRecording(subscriptionId, correlationId, controlSessionId))            {                throw new ArchiveException("failed to send stop recording request");            }            pollForResponse(correlationId);        }        finally        {            lock.unlock();        }    }
public long startReplay(        final long recordingId,        final long position,        final long length,        final String replayChannel,        final int replayStreamId)    {        lock.lock();        try        {            ensureOpen();            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.replay(                recordingId,                position,                length,                replayChannel,                replayStreamId,                correlationId,                controlSessionId))            {                throw new ArchiveException("failed to send replay request");            }            return pollForResponse(correlationId);        }        finally        {            lock.unlock();        }    }
public void stopReplay(final long replaySessionId)    {        lock.lock();        try        {            ensureOpen();            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.stopReplay(replaySessionId, correlationId, controlSessionId))            {                throw new ArchiveException("failed to send stop replay request");            }            pollForResponse(correlationId);        }        finally        {            lock.unlock();        }    }
public Subscription replay(        final long recordingId,        final long position,        final long length,        final String replayChannel,        final int replayStreamId)    {        lock.lock();        try        {            ensureOpen();            final ChannelUri replayChannelUri = ChannelUri.parse(replayChannel);            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.replay(                recordingId,                position,                length,                replayChannel,                replayStreamId,                correlationId,                controlSessionId))            {                throw new ArchiveException("failed to send replay request");            }            final int replaySessionId = (int)pollForResponse(correlationId);            replayChannelUri.put(CommonContext.SESSION_ID_PARAM_NAME, Integer.toString(replaySessionId));            return aeron.addSubscription(replayChannelUri.toString(), replayStreamId);        }        finally        {            lock.unlock();        }    }
public int listRecordings(        final long fromRecordingId, final int recordCount, final RecordingDescriptorConsumer consumer)    {        lock.lock();        try        {            ensureOpen();            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.listRecordings(fromRecordingId, recordCount, correlationId, controlSessionId))            {                throw new ArchiveException("failed to send list recordings request");            }            return pollForDescriptors(correlationId, recordCount, consumer);        }        finally        {            lock.unlock();        }    }
public int listRecordingsForUri(        final long fromRecordingId,        final int recordCount,        final String channelFragment,        final int streamId,        final RecordingDescriptorConsumer consumer)    {        lock.lock();        try        {            ensureOpen();            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.listRecordingsForUri(                fromRecordingId,                recordCount,                channelFragment,                streamId,                correlationId,                controlSessionId))            {                throw new ArchiveException("failed to send list recordings request");            }            return pollForDescriptors(correlationId, recordCount, consumer);        }        finally        {            lock.unlock();        }    }
public int listRecording(final long recordingId, final RecordingDescriptorConsumer consumer)    {        lock.lock();        try        {            ensureOpen();            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.listRecording(recordingId, correlationId, controlSessionId))            {                throw new ArchiveException("failed to send list recording request");            }            return pollForDescriptors(correlationId, 1, consumer);        }        finally        {            lock.unlock();        }    }
public long getRecordingPosition(final long recordingId)    {        lock.lock();        try        {            ensureOpen();            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.getRecordingPosition(recordingId, correlationId, controlSessionId))            {                throw new ArchiveException("failed to send get recording position request");            }            return pollForResponse(correlationId);        }        finally        {            lock.unlock();        }    }
public long findLastMatchingRecording(        final long minRecordingId, final String channelFragment, final int streamId, final int sessionId)    {        lock.lock();        try        {            ensureOpen();            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.findLastMatchingRecording(                minRecordingId, channelFragment, streamId, sessionId, correlationId, controlSessionId))            {                throw new ArchiveException("failed to send find last matching recording request");            }            return pollForResponse(correlationId);        }        finally        {            lock.unlock();        }    }
public void truncateRecording(final long recordingId, final long position)    {        lock.lock();        try        {            ensureOpen();            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.truncateRecording(recordingId, position, correlationId, controlSessionId))            {                throw new ArchiveException("failed to send truncate recording request");            }            pollForResponse(correlationId);        }        finally        {            lock.unlock();        }    }
public int listRecordingSubscriptions(        final int pseudoIndex,        final int subscriptionCount,        final String channelFragment,        final int streamId,        final boolean applyStreamId,        final RecordingSubscriptionDescriptorConsumer consumer)    {        lock.lock();        try        {            ensureOpen();            final long correlationId = aeron.nextCorrelationId();            if (!archiveProxy.listRecordingSubscriptions(                pseudoIndex,                subscriptionCount,                channelFragment,                streamId,                applyStreamId,                correlationId,                controlSessionId))            {                throw new ArchiveException("failed to send list recording subscriptions request");            }            return pollForSubscriptionDescriptors(correlationId, subscriptionCount, consumer);        }        finally        {            lock.unlock();        }    }
public static void dumpSegment(final PrintStream out, final int messageDumpLimit, final UnsafeBuffer buffer)    {        final DataHeaderFlyweight dataHeaderFlyweight = new DataHeaderFlyweight();        final int length = buffer.capacity();        int offset = 0;        while (offset < length)        {            dataHeaderFlyweight.wrap(buffer, offset, length - offset);            out.println(offset + ": " + dataHeaderFlyweight.toString());            final int frameLength = dataHeaderFlyweight.frameLength();            if (frameLength < DataHeaderFlyweight.HEADER_LENGTH)            {                break;            }            final int limit = min(frameLength - HEADER_LENGTH, messageDumpLimit);            out.println(LogInspector.formatBytes(buffer, offset + HEADER_LENGTH, limit));            offset += BitUtil.align(frameLength, FrameDescriptor.FRAME_ALIGNMENT);        }    }
public static void eventAvailableImage(final Image image)    {        final Subscription subscription = image.subscription();        System.out.format(            "new image on %s streamId %x sessionId %x from %s%n",            subscription.channel(), subscription.streamId(), image.sessionId(), image.sourceIdentity());    }
public static void eventUnavailableImage(final Image image)    {        final Subscription subscription = image.subscription();        System.out.format(            "inactive image on %s streamId %d sessionId %x%n",            subscription.channel(), subscription.streamId(), image.sessionId());    }
public static FragmentHandler reassembledStringMessage1(final int streamId)    {        return (buffer, offset, length, header) ->        {            final byte[] data = new byte[length];            buffer.getBytes(offset, data);            System.out.format(                "message to stream %d from session %x term id %x term offset %d (%d@%d)%n",                streamId, header.sessionId(), header.termId(), header.termOffset(), length, offset);            if (length != 10000)            {                System.out.format(                    "Received message was not assembled properly;" +                    " received length was %d, but was expecting 10000%n",                    length);            }        };    }
public static StatusIndicator controllableIdleStrategy(final CountersReader countersReader)    {        StatusIndicator statusIndicator = null;        final MutableInteger id = new MutableInteger(-1);        countersReader.forEach(            (counterId, label) ->            {                if (counterId == SystemCounterDescriptor.CONTROLLABLE_IDLE_STRATEGY.id() &&                    label.equals(SystemCounterDescriptor.CONTROLLABLE_IDLE_STRATEGY.label()))                {                    id.value = counterId;                }            });        if (Aeron.NULL_VALUE != id.value)        {            statusIndicator = new UnsafeBufferStatusIndicator(countersReader.valuesBuffer(), id.value);        }        return statusIndicator;    }
public static StatusIndicatorReader sendChannelStatus(final CountersReader countersReader, final String channel)    {        StatusIndicatorReader statusReader = null;        final MutableInteger id = new MutableInteger(-1);        countersReader.forEach(            (counterId, typeId, keyBuffer, label) ->            {                if (typeId == SendChannelStatus.SEND_CHANNEL_STATUS_TYPE_ID)                {                    if (channel.startsWith(keyBuffer.getStringAscii(ChannelEndpointStatus.CHANNEL_OFFSET)))                    {                        id.value = counterId;                    }                }            });        if (Aeron.NULL_VALUE != id.value)        {            statusReader = new UnsafeBufferStatusIndicator(countersReader.valuesBuffer(), id.value);        }        return statusReader;    }
public static StatusIndicatorReader receiveChannelStatus(final CountersReader countersReader, final String channel)    {        StatusIndicatorReader statusReader = null;        final MutableInteger id = new MutableInteger(-1);        countersReader.forEach(            (counterId, typeId, keyBuffer, label) ->            {                if (typeId == ReceiveChannelStatus.RECEIVE_CHANNEL_STATUS_TYPE_ID)                {                    if (channel.startsWith(keyBuffer.getStringAscii(ChannelEndpointStatus.CHANNEL_OFFSET)))                    {                        id.value = counterId;                    }                }            });        if (Aeron.NULL_VALUE != id.value)        {            statusReader = new UnsafeBufferStatusIndicator(countersReader.valuesBuffer(), id.value);        }        return statusReader;    }
public void limit(final int limit)    {        if (limit < 0 || limit >= buffer.capacity())        {            throw new IllegalArgumentException(                "limit outside range: capacity=" + buffer.capacity() + " limit=" + limit);        }        this.limit = limit;    }
public BufferBuilder append(final DirectBuffer srcBuffer, final int srcOffset, final int length)    {        ensureCapacity(length);        buffer.putBytes(limit, srcBuffer, srcOffset, length);        limit += length;        return this;    }
public int poll()    {        controlSessionId = -1;        correlationId = -1;        relevantId = -1;        templateId = -1;        errorMessage = null;        pollComplete = false;        return subscription.controlledPoll(fragmentAssembler, fragmentLimit);    }
public static MappedByteBuffer mapLossReport(final String aeronDirectoryName, final int reportFileLength)    {        return mapNewFile(file(aeronDirectoryName), reportFileLength, false);    }
public Action onFragment(final DirectBuffer buffer, final int offset, final int length, final Header header)    {        final byte flags = header.flags();        Action action = Action.CONTINUE;        if ((flags & UNFRAGMENTED) == UNFRAGMENTED)        {            action = delegate.onFragment(buffer, offset, length, header);        }        else        {            if ((flags & BEGIN_FRAG_FLAG) == BEGIN_FRAG_FLAG)            {                builder.reset().append(buffer, offset, length);            }            else            {                final int limit = builder.limit();                builder.append(buffer, offset, length);                if ((flags & END_FRAG_FLAG) == END_FRAG_FLAG)                {                    final int msgLength = builder.limit();                    action = delegate.onFragment(builder.buffer(), 0, msgLength, header);                    if (Action.ABORT == action)                    {                        builder.limit(limit);                    }                    else                    {                        builder.reset();                    }                }            }        }        return action;    }
public Map<StreamCompositeKey, List<StreamPosition>> snapshot()    {        final Map<StreamCompositeKey, List<StreamPosition>> streams = new HashMap<>();        counters.forEach(            (counterId, typeId, keyBuffer, label) ->            {                if ((typeId >= PUBLISHER_LIMIT_TYPE_ID && typeId <= RECEIVER_POS_TYPE_ID) ||                    typeId == SENDER_LIMIT_TYPE_ID || typeId == PER_IMAGE_TYPE_ID || typeId == PUBLISHER_POS_TYPE_ID)                {                    final StreamCompositeKey key = new StreamCompositeKey(                        keyBuffer.getInt(SESSION_ID_OFFSET),                        keyBuffer.getInt(STREAM_ID_OFFSET),                        keyBuffer.getStringAscii(CHANNEL_OFFSET));                    final StreamPosition position = new StreamPosition(                        keyBuffer.getLong(REGISTRATION_ID_OFFSET),                        counters.getCounterValue(counterId),                        typeId);                    streams                        .computeIfAbsent(key, (ignore) -> new ArrayList<>())                        .add(position);                }            });        return streams;    }
public int print(final PrintStream out)    {        final Map<StreamCompositeKey, List<StreamPosition>> streams = snapshot();        final StringBuilder builder = new StringBuilder();        for (final Map.Entry<StreamCompositeKey, List<StreamPosition>> entry : streams.entrySet())        {            builder.setLength(0);            final StreamCompositeKey key = entry.getKey();            builder                .append("sessionId=").append(key.sessionId())                .append(" streamId=").append(key.streamId())                .append(" channel=").append(key.channel())                .append(" :");            for (final StreamPosition streamPosition : entry.getValue())            {                builder                    .append(' ')                    .append(labelName(streamPosition.typeId()))                    .append(':').append(streamPosition.id())                    .append(':').append(streamPosition.value());            }            out.println(builder);        }        return streams.size();    }
public double generateNewOptimalDelay()    {        final double x = uniformRandom(randMax) + baseX;        return constantT * Math.log(x * factorT);    }
public long onStatusMessage(        final StatusMessageFlyweight flyweight,        final InetSocketAddress receiverAddress,        final long senderLimit,        final int initialTermId,        final int positionBitsToShift,        final long timeNs)    {        final long position = computePosition(            flyweight.consumptionTermId(),            flyweight.consumptionTermOffset(),            positionBitsToShift,            initialTermId);        lastPosition = Math.max(lastPosition, position);        timeOfLastStatusMessage = timeNs;        return Math.max(senderLimit, position + flyweight.receiverWindowLength());    }
public long onIdle(final long timeNs, final long senderLimit, final long senderPosition, final boolean isEos)    {        if (isEos && shouldLinger)        {            if (lastPosition >= senderPosition || ((timeOfLastStatusMessage + RECEIVER_TIMEOUT_NS) - timeNs < 0))            {                shouldLinger = false;            }        }        return senderLimit;    }
public void reset(final long correlationId, final int recordCount, final RecordingDescriptorConsumer consumer)    {        this.correlationId = correlationId;        this.consumer = consumer;        this.remainingRecordCount = recordCount;        isDispatchComplete = false;    }
public static int read(final AtomicBuffer buffer, final EntryConsumer entryConsumer)    {        final int capacity = buffer.capacity();        int recordsRead = 0;        int offset = 0;        while (offset < capacity)        {            final long observationCount = buffer.getLongVolatile(offset + OBSERVATION_COUNT_OFFSET);            if (observationCount <= 0)            {                break;            }            ++recordsRead;            final String channel = buffer.getStringAscii(offset + CHANNEL_OFFSET);            final String source = buffer.getStringAscii(offset + CHANNEL_OFFSET + SIZE_OF_INT + channel.length());            entryConsumer.accept(                observationCount,                buffer.getLong(offset + TOTAL_BYTES_LOST_OFFSET),                buffer.getLong(offset + FIRST_OBSERVATION_OFFSET),                buffer.getLong(offset + LAST_OBSERVATION_OFFSET),                buffer.getInt(offset + SESSION_ID_OFFSET),                buffer.getInt(offset + STREAM_ID_OFFSET),                channel,                source);            final int recordLength = CHANNEL_OFFSET + (SIZE_OF_INT * 2) + channel.length() + source.length();            offset += BitUtil.align(recordLength, ENTRY_ALIGNMENT);        }        return recordsRead;    }
public static UnsafeBuffer createDefaultHeader(final int sessionId, final int streamId, final int termId)    {        final UnsafeBuffer buffer = new UnsafeBuffer(            BufferUtil.allocateDirectAligned(HEADER_LENGTH, CACHE_LINE_LENGTH));        buffer.putByte(VERSION_FIELD_OFFSET, CURRENT_VERSION);        buffer.putByte(FLAGS_FIELD_OFFSET, (byte)BEGIN_AND_END_FLAGS);        buffer.putShort(TYPE_FIELD_OFFSET, (short)HDR_TYPE_DATA, LITTLE_ENDIAN);        buffer.putInt(SESSION_ID_FIELD_OFFSET, sessionId, LITTLE_ENDIAN);        buffer.putInt(STREAM_ID_FIELD_OFFSET, streamId, LITTLE_ENDIAN);        buffer.putInt(TERM_ID_FIELD_OFFSET, termId, LITTLE_ENDIAN);        buffer.putLong(RESERVED_VALUE_OFFSET, DEFAULT_RESERVE_VALUE);        return buffer;    }
public CounterMessageFlyweight keyBuffer(final DirectBuffer keyBuffer, final int keyOffset, final int keyLength)    {        buffer.putInt(KEY_LENGTH_OFFSET, keyLength);        if (null != keyBuffer && keyLength > 0)        {            buffer.putBytes(keyBufferOffset(), keyBuffer, keyOffset, keyLength);        }        return this;    }
public CounterMessageFlyweight labelBuffer(        final DirectBuffer labelBuffer, final int labelOffset, final int labelLength)    {        buffer.putInt(labelOffset(), labelLength);        buffer.putBytes(labelBufferOffset(), labelBuffer, labelOffset, labelLength);        return this;    }
public int poll(final FragmentHandler fragmentHandler, final int fragmentLimit)    {        final Image[] images = this.images;        final int length = images.length;        int fragmentsRead = 0;        int startingIndex = roundRobinIndex++;        if (startingIndex >= length)        {            roundRobinIndex = startingIndex = 0;        }        for (int i = startingIndex; i < length && fragmentsRead < fragmentLimit; i++)        {            fragmentsRead += images[i].poll(fragmentHandler, fragmentLimit - fragmentsRead);        }        for (int i = 0; i < startingIndex && fragmentsRead < fragmentLimit; i++)        {            fragmentsRead += images[i].poll(fragmentHandler, fragmentLimit - fragmentsRead);        }        return fragmentsRead;    }
public int controlledPoll(final ControlledFragmentHandler fragmentHandler, final int fragmentLimit)    {        final Image[] images = this.images;        final int length = images.length;        int fragmentsRead = 0;        int startingIndex = roundRobinIndex++;        if (startingIndex >= length)        {            roundRobinIndex = startingIndex = 0;        }        for (int i = startingIndex; i < length && fragmentsRead < fragmentLimit; i++)        {            fragmentsRead += images[i].controlledPoll(fragmentHandler, fragmentLimit - fragmentsRead);        }        for (int i = 0; i < startingIndex && fragmentsRead < fragmentLimit; i++)        {            fragmentsRead += images[i].controlledPoll(fragmentHandler, fragmentLimit - fragmentsRead);        }        return fragmentsRead;    }
public long blockPoll(final BlockHandler blockHandler, final int blockLengthLimit)    {        long bytesConsumed = 0;        for (final Image image : images)        {            bytesConsumed += image.blockPoll(blockHandler, blockLengthLimit);        }        return bytesConsumed;    }
public long rawPoll(final RawBlockHandler rawBlockHandler, final int blockLengthLimit)    {        long bytesConsumed = 0;        for (final Image image : images)        {            bytesConsumed += image.rawPoll(rawBlockHandler, blockLengthLimit);        }        return bytesConsumed;    }
public Image imageBySessionId(final int sessionId)    {        Image result = null;        for (final Image image : images)        {            if (sessionId == image.sessionId())            {                result = image;                break;            }        }        return result;    }
public void forEachImage(final Consumer<Image> consumer)    {        for (final Image image : images)        {            consumer.accept(image);        }    }
public static ArchivingMediaDriver launch(final MediaDriver.Context driverCtx, final Archive.Context archiveCtx)    {        final MediaDriver driver = MediaDriver.launch(driverCtx);        final Archive archive = Archive.launch(archiveCtx            .mediaDriverAgentInvoker(driver.sharedAgentInvoker())            .errorHandler(driverCtx.errorHandler())            .errorCounter(driverCtx.systemCounters().get(SystemCounterDescriptor.ERRORS)));        return new ArchivingMediaDriver(driver, archive);    }
public static boolean originalChannelContains(        final RecordingDescriptorDecoder descriptorDecoder, final byte[] channelFragment)    {        final int fragmentLength = channelFragment.length;        if (fragmentLength == 0)        {            return true;        }        final int limit = descriptorDecoder.limit();        final int strippedChannelLength = descriptorDecoder.strippedChannelLength();        final int originalChannelOffset = limit +            RecordingDescriptorDecoder.strippedChannelHeaderLength() + strippedChannelLength;        descriptorDecoder.limit(originalChannelOffset);        final int channelLength = descriptorDecoder.originalChannelLength();        descriptorDecoder.limit(limit);        final DirectBuffer buffer = descriptorDecoder.buffer();        int offset = descriptorDecoder.offset() + descriptorDecoder.sbeBlockLength() +            RecordingDescriptorDecoder.strippedChannelHeaderLength() + strippedChannelLength +            RecordingDescriptorDecoder.originalChannelHeaderLength();        nextChar:        for (int end = offset + (channelLength - fragmentLength); offset <= end; offset++)        {            for (int i = 0; i < fragmentLength; i++)            {                if (buffer.getByte(offset + i) != channelFragment[i])                {                    continue nextChar;                }            }            return true;        }        return false;    }
private void refreshCatalog(final boolean fixOnRefresh)    {        if (fixOnRefresh)        {            forEach(this::refreshAndFixDescriptor);        }        else        {            forEach(((headerEncoder, headerDecoder, descriptorEncoder, descriptorDecoder) -> nextRecordingId++));        }    }
public int claim(        final HeaderWriter header,        final int length,        final BufferClaim bufferClaim,        final int activeTermId)    {        final int frameLength = length + HEADER_LENGTH;        final int alignedLength = align(frameLength, FRAME_ALIGNMENT);        final UnsafeBuffer termBuffer = this.termBuffer;        final int termLength = termBuffer.capacity();        final long rawTail = getAndAddRawTail(alignedLength);        final int termId = termId(rawTail);        final long termOffset = rawTail & 0xFFFF_FFFFL;        checkTerm(activeTermId, termId);        long resultingOffset = termOffset + alignedLength;        if (resultingOffset > termLength)        {            resultingOffset = handleEndOfLogCondition(termBuffer, termOffset, header, termLength, termId);        }        else        {            final int frameOffset = (int)termOffset;            header.write(termBuffer, frameOffset, frameLength, termId);            bufferClaim.wrap(termBuffer, frameOffset, frameLength);        }        return (int)resultingOffset;    }
public int appendUnfragmentedMessage(        final HeaderWriter header,        final DirectBuffer bufferOne,        final int offsetOne,        final int lengthOne,        final DirectBuffer bufferTwo,        final int offsetTwo,        final int lengthTwo,        final ReservedValueSupplier reservedValueSupplier,        final int activeTermId)    {        final int frameLength = lengthOne + lengthTwo + HEADER_LENGTH;        final int alignedLength = align(frameLength, FRAME_ALIGNMENT);        final UnsafeBuffer termBuffer = this.termBuffer;        final int termLength = termBuffer.capacity();        final long rawTail = getAndAddRawTail(alignedLength);        final int termId = termId(rawTail);        final long termOffset = rawTail & 0xFFFF_FFFFL;        checkTerm(activeTermId, termId);        long resultingOffset = termOffset + alignedLength;        if (resultingOffset > termLength)        {            resultingOffset = handleEndOfLogCondition(termBuffer, termOffset, header, termLength, termId);        }        else        {            final int frameOffset = (int)termOffset;            header.write(termBuffer, frameOffset, frameLength, termId);            termBuffer.putBytes(frameOffset + HEADER_LENGTH, bufferOne, offsetOne, lengthOne);            termBuffer.putBytes(frameOffset + HEADER_LENGTH + lengthOne, bufferTwo, offsetTwo, lengthTwo);            if (null != reservedValueSupplier)            {                final long reservedValue = reservedValueSupplier.get(termBuffer, frameOffset, frameLength);                termBuffer.putLong(frameOffset + RESERVED_VALUE_OFFSET, reservedValue, LITTLE_ENDIAN);            }            frameLengthOrdered(termBuffer, frameOffset, frameLength);        }        return (int)resultingOffset;    }
public int appendUnfragmentedMessage(        final HeaderWriter header,        final DirectBuffer buffer,        final int offset,        final int length,        final ReservedValueSupplier reservedValueSupplier,        final int activeTermId)    {        final int frameLength = length + HEADER_LENGTH;        final int alignedLength = align(frameLength, FRAME_ALIGNMENT);        final UnsafeBuffer termBuffer = this.termBuffer;        final int termLength = termBuffer.capacity();        final long rawTail = getAndAddRawTail(alignedLength);        final int termId = termId(rawTail);        final long termOffset = rawTail & 0xFFFF_FFFFL;        checkTerm(activeTermId, termId);        long resultingOffset = termOffset + alignedLength;        if (resultingOffset > termLength)        {            resultingOffset = handleEndOfLogCondition(termBuffer, termOffset, header, termLength, termId);        }        else        {            final int frameOffset = (int)termOffset;            header.write(termBuffer, frameOffset, frameLength, termId);            termBuffer.putBytes(frameOffset + HEADER_LENGTH, buffer, offset, length);            if (null != reservedValueSupplier)            {                final long reservedValue = reservedValueSupplier.get(termBuffer, frameOffset, frameLength);                termBuffer.putLong(frameOffset + RESERVED_VALUE_OFFSET, reservedValue, LITTLE_ENDIAN);            }            frameLengthOrdered(termBuffer, frameOffset, frameLength);        }        return (int)resultingOffset;    }
public int appendFragmentedMessage(        final HeaderWriter header,        final DirectBuffer bufferOne,        final int offsetOne,        final int lengthOne,        final DirectBuffer bufferTwo,        final int offsetTwo,        final int lengthTwo,        final int maxPayloadLength,        final ReservedValueSupplier reservedValueSupplier,        final int activeTermId)    {        final int length = lengthOne + lengthTwo;        final int numMaxPayloads = length / maxPayloadLength;        final int remainingPayload = length % maxPayloadLength;        final int lastFrameLength = remainingPayload > 0 ? align(remainingPayload + HEADER_LENGTH, FRAME_ALIGNMENT) : 0;        final int requiredLength = (numMaxPayloads * (maxPayloadLength + HEADER_LENGTH)) + lastFrameLength;        final UnsafeBuffer termBuffer = this.termBuffer;        final int termLength = termBuffer.capacity();        final long rawTail = getAndAddRawTail(requiredLength);        final int termId = termId(rawTail);        final long termOffset = rawTail & 0xFFFF_FFFFL;        checkTerm(activeTermId, termId);        long resultingOffset = termOffset + requiredLength;        if (resultingOffset > termLength)        {            resultingOffset = handleEndOfLogCondition(termBuffer, termOffset, header, termLength, termId);        }        else        {            int frameOffset = (int)termOffset;            byte flags = BEGIN_FRAG_FLAG;            int remaining = length;            int positionOne = 0;            int positionTwo = 0;            do            {                final int bytesToWrite = Math.min(remaining, maxPayloadLength);                final int frameLength = bytesToWrite + HEADER_LENGTH;                final int alignedLength = align(frameLength, FRAME_ALIGNMENT);                header.write(termBuffer, frameOffset, frameLength, termId);                int bytesWritten = 0;                int payloadOffset = frameOffset + HEADER_LENGTH;                do                {                    final int remainingOne = lengthOne - positionOne;                    if (remainingOne > 0)                    {                        final int numBytes = Math.min(bytesToWrite - bytesWritten, remainingOne);                        termBuffer.putBytes(payloadOffset, bufferOne, offsetOne + positionOne, numBytes);                        bytesWritten += numBytes;                        payloadOffset += numBytes;                        positionOne += numBytes;                    }                    else                    {                        final int numBytes = Math.min(bytesToWrite - bytesWritten, lengthTwo - positionTwo);                        termBuffer.putBytes(payloadOffset, bufferTwo, offsetTwo + positionTwo, numBytes);                        bytesWritten += numBytes;                        payloadOffset += numBytes;                        positionTwo += numBytes;                    }                }                while (bytesWritten < bytesToWrite);                if (remaining <= maxPayloadLength)                {                    flags |= END_FRAG_FLAG;                }                frameFlags(termBuffer, frameOffset, flags);                if (null != reservedValueSupplier)                {                    final long reservedValue = reservedValueSupplier.get(termBuffer, frameOffset, frameLength);                    termBuffer.putLong(frameOffset + RESERVED_VALUE_OFFSET, reservedValue, LITTLE_ENDIAN);                }                frameLengthOrdered(termBuffer, frameOffset, frameLength);                flags = 0;                frameOffset += alignedLength;                remaining -= bytesToWrite;            }            while (remaining > 0);        }        return (int)resultingOffset;    }
public boolean connect(final String responseChannel, final int responseStreamId, final long correlationId)    {        connectRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .correlationId(correlationId)            .responseStreamId(responseStreamId)            .version(AeronArchive.Configuration.SEMANTIC_VERSION)            .responseChannel(responseChannel);        return offerWithTimeout(connectRequestEncoder.encodedLength(), null);    }
public boolean tryConnect(final String responseChannel, final int responseStreamId, final long correlationId)    {        connectRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .correlationId(correlationId)            .responseStreamId(responseStreamId)            .version(AeronArchive.Configuration.SEMANTIC_VERSION)            .responseChannel(responseChannel);        final int length = MessageHeaderEncoder.ENCODED_LENGTH + connectRequestEncoder.encodedLength();        return publication.offer(buffer, 0, length) > 0;    }
public boolean closeSession(final long controlSessionId)    {        closeSessionRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId);        return offer(closeSessionRequestEncoder.encodedLength());    }
public boolean startRecording(        final String channel,        final int streamId,        final SourceLocation sourceLocation,        final long correlationId,        final long controlSessionId)    {        startRecordingRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .streamId(streamId)            .sourceLocation(sourceLocation)            .channel(channel);        return offer(startRecordingRequestEncoder.encodedLength());    }
public boolean stopRecording(        final String channel,        final int streamId,        final long correlationId,        final long controlSessionId)    {        stopRecordingRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .streamId(streamId)            .channel(channel);        return offer(stopRecordingRequestEncoder.encodedLength());    }
public boolean stopRecording(        final long subscriptionId,        final long correlationId,        final long controlSessionId)    {        stopRecordingSubscriptionRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .subscriptionId(subscriptionId);        return offer(stopRecordingSubscriptionRequestEncoder.encodedLength());    }
public boolean replay(        final long recordingId,        final long position,        final long length,        final String replayChannel,        final int replayStreamId,        final long correlationId,        final long controlSessionId)    {        replayRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .recordingId(recordingId)            .position(position)            .length(length)            .replayStreamId(replayStreamId)            .replayChannel(replayChannel);        return offer(replayRequestEncoder.encodedLength());    }
public boolean stopReplay(final long replaySessionId, final long correlationId, final long controlSessionId)    {        stopReplayRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .replaySessionId(replaySessionId);        return offer(replayRequestEncoder.encodedLength());    }
public boolean listRecordings(        final long fromRecordingId, final int recordCount, final long correlationId, final long controlSessionId)    {        listRecordingsRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .fromRecordingId(fromRecordingId)            .recordCount(recordCount);        return offer(listRecordingsRequestEncoder.encodedLength());    }
public boolean listRecordingsForUri(        final long fromRecordingId,        final int recordCount,        final String channelFragment,        final int streamId,        final long correlationId,        final long controlSessionId)    {        listRecordingsForUriRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .fromRecordingId(fromRecordingId)            .recordCount(recordCount)            .streamId(streamId)            .channel(channelFragment);        return offer(listRecordingsForUriRequestEncoder.encodedLength());    }
public boolean listRecording(final long recordingId, final long correlationId, final long controlSessionId)    {        listRecordingRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .recordingId(recordingId);        return offer(listRecordingRequestEncoder.encodedLength());    }
public boolean extendRecording(        final String channel,        final int streamId,        final SourceLocation sourceLocation,        final long recordingId,        final long correlationId,        final long controlSessionId)    {        extendRecordingRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .recordingId(recordingId)            .streamId(streamId)            .sourceLocation(sourceLocation)            .channel(channel);        return offer(extendRecordingRequestEncoder.encodedLength());    }
public boolean getRecordingPosition(final long recordingId, final long correlationId, final long controlSessionId)    {        recordingPositionRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .recordingId(recordingId);        return offer(recordingPositionRequestEncoder.encodedLength());    }
public boolean truncateRecording(        final long recordingId, final long position, final long correlationId, final long controlSessionId)    {        truncateRecordingRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .recordingId(recordingId)            .position(position);        return offer(truncateRecordingRequestEncoder.encodedLength());    }
public boolean getStopPosition(final long recordingId, final long correlationId, final long controlSessionId)    {        stopPositionRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .recordingId(recordingId);        return offer(stopPositionRequestEncoder.encodedLength());    }
public boolean findLastMatchingRecording(        final long minRecordingId,        final String channelFragment,        final int streamId,        final int sessionId,        final long correlationId,        final long controlSessionId)    {        findLastMatchingRecordingRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .minRecordingId(minRecordingId)            .sessionId(sessionId)            .streamId(streamId)            .channel(channelFragment);        return offer(findLastMatchingRecordingRequestEncoder.encodedLength());    }
public boolean listRecordingSubscriptions(        final int pseudoIndex,        final int subscriptionCount,        final String channelFragment,        final int streamId,        final boolean applyStreamId,        final long correlationId,        final long controlSessionId)    {        listRecordingSubscriptionsRequestEncoder            .wrapAndApplyHeader(buffer, 0, messageHeaderEncoder)            .controlSessionId(controlSessionId)            .correlationId(correlationId)            .pseudoIndex(pseudoIndex)            .subscriptionCount(subscriptionCount)            .applyStreamId(applyStreamId ? BooleanType.TRUE : BooleanType.FALSE)            .streamId(streamId)            .channel(channelFragment);        return offer(listRecordingSubscriptionsRequestEncoder.encodedLength());    }
@SuppressWarnings("MethodLength")    public static UdpChannel parse(final String channelUriString)    {        try        {            final ChannelUri channelUri = ChannelUri.parse(channelUriString);            validateConfiguration(channelUri);            InetSocketAddress endpointAddress = getEndpointAddress(channelUri);            final InetSocketAddress explicitControlAddress = getExplicitControlAddress(channelUri);            final String tagIdStr = channelUri.channelTag();            final String controlMode = channelUri.get(CommonContext.MDC_CONTROL_MODE_PARAM_NAME);            final boolean hasNoDistinguishingCharacteristic =                null == endpointAddress && null == explicitControlAddress && null == tagIdStr;            if (hasNoDistinguishingCharacteristic && null == controlMode)            {                throw new IllegalArgumentException(                    "Aeron URIs for UDP must specify an endpoint address, control address, tag-id, or control-mode");            }            if (null != endpointAddress && endpointAddress.isUnresolved())            {                throw new UnknownHostException("could not resolve endpoint address: " + endpointAddress);            }            if (null != explicitControlAddress && explicitControlAddress.isUnresolved())            {                throw new UnknownHostException("could not resolve control address: " + explicitControlAddress);            }            final Context context = new Context()                .uriStr(channelUriString)                .channelUri(channelUri)                .hasNoDistinguishingCharacteristic(hasNoDistinguishingCharacteristic);            if (null != tagIdStr)            {                context.hasTagId(true).tagId(Long.parseLong(tagIdStr));            }            if (null == endpointAddress)            {                endpointAddress = new InetSocketAddress("0.0.0.0", 0);            }            if (endpointAddress.getAddress().isMulticastAddress())            {                final InetSocketAddress controlAddress = getMulticastControlAddress(endpointAddress);                final InterfaceSearchAddress searchAddress = getInterfaceSearchAddress(channelUri);                final NetworkInterface localInterface = findInterface(searchAddress);                final InetSocketAddress resolvedAddress = resolveToAddressOfInterface(localInterface, searchAddress);                context                    .isMulticast(true)                    .localControlAddress(resolvedAddress)                    .remoteControlAddress(controlAddress)                    .localDataAddress(resolvedAddress)                    .remoteDataAddress(endpointAddress)                    .localInterface(localInterface)                    .protocolFamily(getProtocolFamily(endpointAddress.getAddress()))                    .canonicalForm(canonicalise(resolvedAddress, endpointAddress));                final String ttlValue = channelUri.get(CommonContext.TTL_PARAM_NAME);                if (null != ttlValue)                {                    context.hasMulticastTtl(true).multicastTtl(Integer.parseInt(ttlValue));                }            }            else if (null != explicitControlAddress)            {                context                    .hasExplicitControl(true)                    .remoteControlAddress(endpointAddress)                    .remoteDataAddress(endpointAddress)                    .localControlAddress(explicitControlAddress)                    .localDataAddress(explicitControlAddress)                    .protocolFamily(getProtocolFamily(endpointAddress.getAddress()))                    .canonicalForm(canonicalise(explicitControlAddress, endpointAddress));            }            else            {                final InterfaceSearchAddress searchAddress = getInterfaceSearchAddress(channelUri);                final InetSocketAddress localAddress = searchAddress.getInetAddress().isAnyLocalAddress() ?                    searchAddress.getAddress() :                    resolveToAddressOfInterface(findInterface(searchAddress), searchAddress);                final String uniqueCanonicalFormSuffix = hasNoDistinguishingCharacteristic ?                    ("-" + UNIQUE_CANONICAL_FORM_VALUE.getAndAdd(1)) : "";                context                    .remoteControlAddress(endpointAddress)                    .remoteDataAddress(endpointAddress)                    .localControlAddress(localAddress)                    .localDataAddress(localAddress)                    .protocolFamily(getProtocolFamily(endpointAddress.getAddress()))                    .canonicalForm(canonicalise(localAddress, endpointAddress) + uniqueCanonicalFormSuffix);            }            return new UdpChannel(context);        }        catch (final Exception ex)        {            throw new InvalidChannelException(ErrorCode.INVALID_CHANNEL, ex);        }    }
public static String canonicalise(final InetSocketAddress localData, final InetSocketAddress remoteData)    {        final StringBuilder builder = new StringBuilder(48);        builder.append("UDP-");        toHex(builder, localData.getAddress().getAddress())            .append('-')            .append(localData.getPort());        builder.append('-');        toHex(builder, remoteData.getAddress().getAddress())            .append('-')            .append(remoteData.getPort());        return builder.toString();    }
public boolean matchesTag(final UdpChannel udpChannel)    {        if (!hasTag || !udpChannel.hasTag() || tag != udpChannel.tag())        {            return false;        }        if (udpChannel.remoteData().getAddress().isAnyLocalAddress() &&            udpChannel.remoteData().getPort() == 0 &&            udpChannel.localData().getAddress().isAnyLocalAddress() &&            udpChannel.localData().getPort() == 0)        {            return true;        }        throw new IllegalArgumentException("matching tag has set endpoint or control address");    }
public static InetSocketAddress destinationAddress(final ChannelUri uri)    {        try        {            validateConfiguration(uri);            return getEndpointAddress(uri);        }        catch (final Exception ex)        {            throw new InvalidChannelException(ErrorCode.INVALID_CHANNEL, ex);        }    }
public String description()    {        final StringBuilder builder = new StringBuilder("UdpChannel - ");        if (null != localInterface)        {            builder                .append("interface: ")                .append(localInterface.getDisplayName())                .append(", ");        }        builder            .append("localData: ").append(localData)            .append(", remoteData: ").append(remoteData)            .append(", ttl: ").append(multicastTtl);        return builder.toString();    }
public void close()    {        hwmPosition.close();        rebuildPosition.close();        for (final ReadablePosition position : subscriberPositions)        {            position.close();        }        for (int i = 0, size = untetheredSubscriptions.size(); i < size; i++)        {            final UntetheredSubscription untetheredSubscription = untetheredSubscriptions.get(i);            if (UntetheredSubscription.RESTING == untetheredSubscription.state)            {                untetheredSubscription.position.close();            }        }        congestionControl.close();        rawLog.close();    }
public void addSubscriber(final SubscriptionLink subscriptionLink, final ReadablePosition subscriberPosition)    {        subscriberPositions = ArrayUtil.add(subscriberPositions, subscriberPosition);        if (!subscriptionLink.isTether())        {            untetheredSubscriptions.add(new UntetheredSubscription(                subscriptionLink, subscriberPosition, timeOfLastStatusMessageScheduleNs));        }    }
public void removeSubscriber(final SubscriptionLink subscriptionLink, final ReadablePosition subscriberPosition)    {        subscriberPositions = ArrayUtil.remove(subscriberPositions, subscriberPosition);        subscriberPosition.close();        if (!subscriptionLink.isTether())        {            for (int lastIndex = untetheredSubscriptions.size() - 1, i = lastIndex; i >= 0; i--)            {                if (untetheredSubscriptions.get(i).subscriptionLink == subscriptionLink)                {                    ArrayListUtil.fastUnorderedRemove(untetheredSubscriptions, i, lastIndex);                    break;                }            }        }    }
public void onGapDetected(final int termId, final int termOffset, final int length)    {        final long changeNumber = beginLossChange + 1;        beginLossChange = changeNumber;        lossTermId = termId;        lossTermOffset = termOffset;        lossLength = length;        endLossChange = changeNumber;        if (null != reportEntry)        {            reportEntry.recordObservation(length, cachedEpochClock.time());        }        else if (null != lossReport)        {            reportEntry = lossReport.createEntry(                length, cachedEpochClock.time(), sessionId, streamId, channel(), sourceAddress.toString());            if (null == reportEntry)            {                lossReport = null;            }        }    }
void addDestination(final int transportIndex, final ReceiveDestinationUdpTransport transport)    {        imageConnections = ArrayUtil.ensureCapacity(imageConnections, transportIndex + 1);        if (transport.isMulticast())        {            imageConnections[transportIndex] = new ImageConnection(                cachedNanoClock.nanoTime(), transport.udpChannel().remoteControl());        }        else if (transport.hasExplicitControl())        {            imageConnections[transportIndex] = new ImageConnection(                cachedNanoClock.nanoTime(), transport.explicitControlAddress());        }    }
final void trackRebuild(final long nowNs, final long statusMessageTimeoutNs)    {        long minSubscriberPosition = Long.MAX_VALUE;        long maxSubscriberPosition = Long.MIN_VALUE;        for (final ReadablePosition subscriberPosition : subscriberPositions)        {            final long position = subscriberPosition.getVolatile();            minSubscriberPosition = Math.min(minSubscriberPosition, position);            maxSubscriberPosition = Math.max(maxSubscriberPosition, position);        }        final long rebuildPosition = Math.max(this.rebuildPosition.get(), maxSubscriberPosition);        final long hwmPosition = this.hwmPosition.getVolatile();        final long scanOutcome = lossDetector.scan(            termBuffers[indexByPosition(rebuildPosition, positionBitsToShift)],            rebuildPosition,            hwmPosition,            nowNs,            termLengthMask,            positionBitsToShift,            initialTermId);        final int rebuildTermOffset = (int)rebuildPosition & termLengthMask;        final long newRebuildPosition = (rebuildPosition - rebuildTermOffset) + rebuildOffset(scanOutcome);        this.rebuildPosition.proposeMaxOrdered(newRebuildPosition);        final long ccOutcome = congestionControl.onTrackRebuild(            nowNs,            minSubscriberPosition,            nextSmPosition,            hwmPosition,            rebuildPosition,            newRebuildPosition,            lossFound(scanOutcome));        final int windowLength = CongestionControl.receiverWindowLength(ccOutcome);        final int threshold = CongestionControl.threshold(windowLength);        if (CongestionControl.shouldForceStatusMessage(ccOutcome) ||            ((timeOfLastStatusMessageScheduleNs + statusMessageTimeoutNs) - nowNs < 0) ||            (minSubscriberPosition > (nextSmPosition + threshold)))        {            scheduleStatusMessage(nowNs, minSubscriberPosition, windowLength);            cleanBufferTo(minSubscriberPosition - (termLengthMask + 1));        }    }
int insertPacket(        final int termId,        final int termOffset,        final UnsafeBuffer buffer,        final int length,        final int transportIndex,        final InetSocketAddress srcAddress)    {        final boolean isHeartbeat = DataHeaderFlyweight.isHeartbeat(buffer, length);        final long packetPosition = computePosition(termId, termOffset, positionBitsToShift, initialTermId);        final long proposedPosition = isHeartbeat ? packetPosition : packetPosition + length;        if (!isFlowControlUnderRun(packetPosition) && !isFlowControlOverRun(proposedPosition))        {            trackConnection(transportIndex, srcAddress, lastPacketTimestampNs);            if (isHeartbeat)            {                if (DataHeaderFlyweight.isEndOfStream(buffer) && !isEndOfStream && allEos(transportIndex))                {                    LogBufferDescriptor.endOfStreamPosition(rawLog.metaData(), proposedPosition);                    isEndOfStream = true;                }                heartbeatsReceived.incrementOrdered();            }            else            {                final UnsafeBuffer termBuffer = termBuffers[indexByPosition(packetPosition, positionBitsToShift)];                TermRebuilder.insert(termBuffer, termOffset, buffer, length);            }            lastPacketTimestampNs = cachedNanoClock.nanoTime();            hwmPosition.proposeMaxOrdered(proposedPosition);        }        return length;    }
boolean hasActivityAndNotEndOfStream(final long nowNs)    {        boolean isActive = true;        if (((lastPacketTimestampNs + imageLivenessTimeoutNs) - nowNs < 0) ||            (isEndOfStream && rebuildPosition.getVolatile() >= hwmPosition.get()))        {            isActive = false;        }        return isActive;    }
int sendPendingStatusMessage()    {        int workCount = 0;        if (ACTIVE == state)        {            final long changeNumber = endSmChange;            if (changeNumber != lastSmChangeNumber)            {                final long smPosition = nextSmPosition;                final int receiverWindowLength = nextSmReceiverWindowLength;                UNSAFE.loadFence();                if (changeNumber == beginSmChange)                {                    final int termId = computeTermIdFromPosition(smPosition, positionBitsToShift, initialTermId);                    final int termOffset = (int)smPosition & termLengthMask;                    channelEndpoint.sendStatusMessage(                        imageConnections, sessionId, streamId, termId, termOffset, receiverWindowLength, (byte)0);                    statusMessagesSent.incrementOrdered();                    lastSmPosition = smPosition;                    lastSmWindowLimit = smPosition + receiverWindowLength;                    lastSmChangeNumber = changeNumber;                }                workCount = 1;            }        }        return workCount;    }
int processPendingLoss()    {        int workCount = 0;        final long changeNumber = endLossChange;        if (changeNumber != lastLossChangeNumber)        {            final int termId = lossTermId;            final int termOffset = lossTermOffset;            final int length = lossLength;            UNSAFE.loadFence();            if (changeNumber == beginLossChange)            {                if (isReliable)                {                    channelEndpoint.sendNakMessage(imageConnections, sessionId, streamId, termId, termOffset, length);                    nakMessagesSent.incrementOrdered();                }                else                {                    final UnsafeBuffer termBuffer = termBuffers[indexByTerm(initialTermId, termId)];                    if (tryFillGap(rawLog.metaData(), termBuffer, termId, termOffset, length))                    {                        lossGapFills.incrementOrdered();                    }                }                lastLossChangeNumber = changeNumber;            }            workCount = 1;        }        return workCount;    }
int initiateAnyRttMeasurements(final long nowNs)    {        int workCount = 0;        if (congestionControl.shouldMeasureRtt(nowNs))        {            final long preciseTimeNs = nanoClock.nanoTime();            channelEndpoint.sendRttMeasurement(imageConnections, sessionId, streamId, preciseTimeNs, 0, true);            congestionControl.onRttMeasurementSent(preciseTimeNs);            workCount = 1;        }        return workCount;    }
void onRttMeasurement(        final RttMeasurementFlyweight header,        @SuppressWarnings("unused") final int transportIndex,        final InetSocketAddress srcAddress)    {        final long nowNs = nanoClock.nanoTime();        final long rttInNs = nowNs - header.echoTimestampNs() - header.receptionDelta();        congestionControl.onRttMeasurement(nowNs, rttInNs, srcAddress);    }
public void onTimeEvent(final long timeNs, final long timesMs, final DriverConductor conductor)    {        switch (state)        {            case ACTIVE:                checkUntetheredSubscriptions(timeNs, conductor);                break;            case INACTIVE:                if (isDrained())                {                    state = State.LINGER;                    timeOfLastStateChangeNs = timeNs;                    conductor.transitionToLinger(this);                }                isTrackingRebuild = false;                break;            case LINGER:                if ((timeOfLastStateChangeNs + imageLivenessTimeoutNs) - timeNs < 0)                {                    state = State.DONE;                    conductor.cleanupImage(this);                }                break;        }    }
public static CountersReader mapCounters(final File cncFile)    {        final MappedByteBuffer cncByteBuffer = IoUtil.mapExistingFile(cncFile, "cnc");        final DirectBuffer cncMetaData = createMetaDataBuffer(cncByteBuffer);        final int cncVersion = cncMetaData.getInt(cncVersionOffset(0));        if (CncFileDescriptor.CNC_VERSION != cncVersion)        {            throw new AeronException(                "Aeron CnC version does not match: version=" + cncVersion + " required=" + CNC_VERSION);        }        return new CountersReader(            createCountersMetaDataBuffer(cncByteBuffer, cncMetaData),            createCountersValuesBuffer(cncByteBuffer, cncMetaData),            StandardCharsets.US_ASCII);    }
public static AtomicCounter findControlToggle(final CountersReader counters)    {        final AtomicBuffer buffer = counters.metaDataBuffer();        for (int i = 0, size = counters.maxCounterId(); i < size; i++)        {            final int recordOffset = CountersReader.metaDataOffset(i);            if (counters.getCounterState(i) == RECORD_ALLOCATED &&                buffer.getInt(recordOffset + TYPE_ID_OFFSET) == CONTROL_TOGGLE_TYPE_ID)            {                return new AtomicCounter(counters.valuesBuffer(), i, null);            }        }        return null;    }
public String put(final String key, final String value)    {        return params.put(key, value);    }
public String channelTag()    {        return (null != tags && tags.length > CHANNEL_TAG_INDEX) ? tags[CHANNEL_TAG_INDEX] : null;    }
public String entityTag()    {        return (null != tags && tags.length > ENTITY_TAG_INDEX) ? tags[ENTITY_TAG_INDEX] : null;    }
public void initialPosition(final long position, final int initialTermId, final int termLength)    {        if (position < 0 || 0 != (position & (FRAME_ALIGNMENT - 1)))        {            throw new IllegalArgumentException("invalid position: " + position);        }        final int bitsToShift = LogBufferDescriptor.positionBitsToShift(termLength);        final int termId = LogBufferDescriptor.computeTermIdFromPosition(position, bitsToShift, initialTermId);        final int termOffset = (int)(position & (termLength - 1));        put(INITIAL_TERM_ID_PARAM_NAME, Integer.toString(initialTermId));        put(TERM_ID_PARAM_NAME, Integer.toString(termId));        put(TERM_OFFSET_PARAM_NAME, Integer.toString(termOffset));        put(TERM_LENGTH_PARAM_NAME, Integer.toString(termLength));    }
public static ChannelUri parse(final CharSequence cs)    {        int position = 0;        final String prefix;        if (startsWith(cs, 0, SPY_PREFIX))        {            prefix = SPY_QUALIFIER;            position = SPY_PREFIX.length();        }        else        {            prefix = "";        }        if (!startsWith(cs, position, AERON_PREFIX))        {            throw new IllegalArgumentException("Aeron URIs must start with 'aeron:', found: '" + cs + "'");        }        else        {            position += AERON_PREFIX.length();        }        final StringBuilder builder = new StringBuilder();        final Map<String, String> params = new Object2ObjectHashMap<>();        String media = null;        String key = null;        State state = State.MEDIA;        for (int i = position; i < cs.length(); i++)        {            final char c = cs.charAt(i);            switch (state)            {                case MEDIA:                    switch (c)                    {                        case '?':                            media = builder.toString();                            builder.setLength(0);                            state = State.PARAMS_KEY;                            break;                        case ':':                            throw new IllegalArgumentException("encountered ':' within media definition");                        default:                            builder.append(c);                    }                    break;                case PARAMS_KEY:                    if (c == '=')                    {                        key = builder.toString();                        builder.setLength(0);                        state = State.PARAMS_VALUE;                    }                    else                    {                        builder.append(c);                    }                    break;                case PARAMS_VALUE:                    if (c == '|')                    {                        params.put(key, builder.toString());                        builder.setLength(0);                        state = State.PARAMS_KEY;                    }                    else                    {                        builder.append(c);                    }                    break;                default:                    throw new IllegalStateException("unexpected state=" + state);            }        }        switch (state)        {            case MEDIA:                media = builder.toString();                break;            case PARAMS_VALUE:                params.put(key, builder.toString());                break;            default:                throw new IllegalArgumentException("no more input found, state=" + state);        }        return new ChannelUri(prefix, media, params);    }
public static String addSessionId(final String channel, final int sessionId)    {        final ChannelUri channelUri = ChannelUri.parse(channel);        channelUri.put(CommonContext.SESSION_ID_PARAM_NAME, Integer.toString(sessionId));        return channelUri.toString();    }
public static long getTag(final String paramValue)    {        return isTagged(paramValue) ?            AsciiEncoding.parseLongAscii(paramValue, 4, paramValue.length() - 4) : INVALID_TAG;    }
public int claim(        final int termId,        final int termOffset,        final HeaderWriter header,        final int length,        final BufferClaim bufferClaim)    {        final int frameLength = length + HEADER_LENGTH;        final int alignedLength = align(frameLength, FRAME_ALIGNMENT);        final UnsafeBuffer termBuffer = this.termBuffer;        final int termLength = termBuffer.capacity();        int resultingOffset = termOffset + alignedLength;        putRawTailOrdered(termId, resultingOffset);        if (resultingOffset > termLength)        {            resultingOffset = handleEndOfLogCondition(termBuffer, termOffset, header, termLength, termId);        }        else        {            header.write(termBuffer, termOffset, frameLength, termId);            bufferClaim.wrap(termBuffer, termOffset, frameLength);        }        return resultingOffset;    }
public int appendPadding(        final int termId,        final int termOffset,        final HeaderWriter header,        final int length)    {        final int frameLength = length + HEADER_LENGTH;        final int alignedLength = align(frameLength, FRAME_ALIGNMENT);        final UnsafeBuffer termBuffer = this.termBuffer;        final int termLength = termBuffer.capacity();        int resultingOffset = termOffset + alignedLength;        putRawTailOrdered(termId, resultingOffset);        if (resultingOffset > termLength)        {            resultingOffset = handleEndOfLogCondition(termBuffer, termOffset, header, termLength, termId);        }        else        {            header.write(termBuffer, termOffset, frameLength, termId);            frameType(termBuffer, termOffset, PADDING_FRAME_TYPE);            frameLengthOrdered(termBuffer, termOffset, frameLength);        }        return resultingOffset;    }
public int appendUnfragmentedMessage(        final int termId,        final int termOffset,        final HeaderWriter header,        final DirectBuffer srcBuffer,        final int srcOffset,        final int length,        final ReservedValueSupplier reservedValueSupplier)    {        final int frameLength = length + HEADER_LENGTH;        final int alignedLength = align(frameLength, FRAME_ALIGNMENT);        final UnsafeBuffer termBuffer = this.termBuffer;        final int termLength = termBuffer.capacity();        int resultingOffset = termOffset + alignedLength;        putRawTailOrdered(termId, resultingOffset);        if (resultingOffset > termLength)        {            resultingOffset = handleEndOfLogCondition(termBuffer, termOffset, header, termLength, termId);        }        else        {            header.write(termBuffer, termOffset, frameLength, termId);            termBuffer.putBytes(termOffset + HEADER_LENGTH, srcBuffer, srcOffset, length);            if (null != reservedValueSupplier)            {                final long reservedValue = reservedValueSupplier.get(termBuffer, termOffset, frameLength);                termBuffer.putLong(termOffset + RESERVED_VALUE_OFFSET, reservedValue, LITTLE_ENDIAN);            }            frameLengthOrdered(termBuffer, termOffset, frameLength);        }        return resultingOffset;    }
public int appendFragmentedMessage(        final int termId,        final int termOffset,        final HeaderWriter header,        final DirectBufferVector[] vectors,        final int length,        final int maxPayloadLength,        final ReservedValueSupplier reservedValueSupplier)    {        final int numMaxPayloads = length / maxPayloadLength;        final int remainingPayload = length % maxPayloadLength;        final int lastFrameLength = remainingPayload > 0 ? align(remainingPayload + HEADER_LENGTH, FRAME_ALIGNMENT) : 0;        final int requiredLength = (numMaxPayloads * (maxPayloadLength + HEADER_LENGTH)) + lastFrameLength;        final UnsafeBuffer termBuffer = this.termBuffer;        final int termLength = termBuffer.capacity();        int resultingOffset = termOffset + requiredLength;        putRawTailOrdered(termId, resultingOffset);        if (resultingOffset > termLength)        {            resultingOffset = handleEndOfLogCondition(termBuffer, termOffset, header, termLength, termId);        }        else        {            int frameOffset = termOffset;            byte flags = BEGIN_FRAG_FLAG;            int remaining = length;            int vectorIndex = 0;            int vectorOffset = 0;            do            {                final int bytesToWrite = Math.min(remaining, maxPayloadLength);                final int frameLength = bytesToWrite + HEADER_LENGTH;                final int alignedLength = align(frameLength, FRAME_ALIGNMENT);                header.write(termBuffer, frameOffset, frameLength, termId);                int bytesWritten = 0;                int payloadOffset = frameOffset + HEADER_LENGTH;                do                {                    final DirectBufferVector vector = vectors[vectorIndex];                    final int vectorRemaining = vector.length - vectorOffset;                    final int numBytes = Math.min(bytesToWrite - bytesWritten, vectorRemaining);                    termBuffer.putBytes(payloadOffset, vector.buffer, vector.offset + vectorOffset, numBytes);                    bytesWritten += numBytes;                    payloadOffset += numBytes;                    vectorOffset += numBytes;                    if (vectorRemaining <= numBytes)                    {                        vectorIndex++;                        vectorOffset = 0;                    }                }                while (bytesWritten < bytesToWrite);                if (remaining <= maxPayloadLength)                {                    flags |= END_FRAG_FLAG;                }                frameFlags(termBuffer, frameOffset, flags);                if (null != reservedValueSupplier)                {                    final long reservedValue = reservedValueSupplier.get(termBuffer, frameOffset, frameLength);                    termBuffer.putLong(frameOffset + RESERVED_VALUE_OFFSET, reservedValue, LITTLE_ENDIAN);                }                frameLengthOrdered(termBuffer, frameOffset, frameLength);                flags = 0;                frameOffset += alignedLength;                remaining -= bytesToWrite;            }            while (remaining > 0);        }        return resultingOffset;    }
final int updatePublisherLimit()    {        int workCount = 0;        final long senderPosition = this.senderPosition.getVolatile();        if (hasReceivers || (spiesSimulateConnection && spyPositions.length > 0))        {            long minConsumerPosition = senderPosition;            for (final ReadablePosition spyPosition : spyPositions)            {                minConsumerPosition = Math.min(minConsumerPosition, spyPosition.getVolatile());            }            final long proposedPublisherLimit = minConsumerPosition + termWindowLength;            if (publisherLimit.proposeMaxOrdered(proposedPublisherLimit))            {                cleanBuffer(proposedPublisherLimit);                workCount = 1;            }        }        else if (publisherLimit.get() > senderPosition)        {            publisherLimit.setOrdered(senderPosition);        }        return workCount;    }
public static NetworkInterface[] filterBySubnet(final InetAddress address, final int subnetPrefix)        throws SocketException    {        return filterBySubnet(NetworkInterfaceShim.DEFAULT, address, subnetPrefix);    }
public static ByteBuffer allocateDirectAlignedAndPadded(final int capacity, final int alignment)    {        final ByteBuffer buffer = BufferUtil.allocateDirectAligned(capacity + alignment, alignment);        buffer.limit(buffer.limit() - alignment);        return buffer.slice();    }
public static UnsafeBufferPosition allocate(        final MutableDirectBuffer tempBuffer,        final String name,        final int typeId,        final CountersManager countersManager,        final long registrationId,        final int sessionId,        final int streamId,        final String channel)    {        return new UnsafeBufferPosition(            (UnsafeBuffer)countersManager.valuesBuffer(),            allocateCounterId(tempBuffer, name, typeId, countersManager, registrationId, sessionId, streamId, channel),            countersManager);    }
public static String labelName(final int typeId)    {        switch (typeId)        {            case PublisherLimit.PUBLISHER_LIMIT_TYPE_ID:                return PublisherLimit.NAME;            case SenderPos.SENDER_POSITION_TYPE_ID:                return SenderPos.NAME;            case ReceiverHwm.RECEIVER_HWM_TYPE_ID:                return ReceiverHwm.NAME;            case SubscriberPos.SUBSCRIBER_POSITION_TYPE_ID:                return SubscriberPos.NAME;            case ReceiverPos.RECEIVER_POS_TYPE_ID:                return ReceiverPos.NAME;            case SenderLimit.SENDER_LIMIT_TYPE_ID:                return SenderLimit.NAME;            case PublisherPos.PUBLISHER_POS_TYPE_ID:                return PublisherPos.NAME;            case SenderBpe.SENDER_BPE_TYPE_ID:                return SenderBpe.NAME;            default:                return "<unknown>";        }    }
public static long scanForAvailability(final UnsafeBuffer termBuffer, final int offset, final int maxLength)    {        final int limit = Math.min(maxLength, termBuffer.capacity() - offset);        int available = 0;        int padding = 0;        do        {            final int termOffset = offset + available;            final int frameLength = frameLengthVolatile(termBuffer, termOffset);            if (frameLength <= 0)            {                break;            }            int alignedFrameLength = align(frameLength, FRAME_ALIGNMENT);            if (isPaddingFrame(termBuffer, termOffset))            {                padding = alignedFrameLength - HEADER_LENGTH;                alignedFrameLength = HEADER_LENGTH;            }            available += alignedFrameLength;            if (available > limit)            {                available -= alignedFrameLength;                padding = 0;                break;            }        }        while (0 == padding && available < limit);        return pack(padding, available);    }
public ChannelUriStringBuilder clear()    {        prefix = null;        media = null;        endpoint = null;        networkInterface = null;        controlEndpoint = null;        controlMode = null;        tags = null;        alias = null;        reliable = null;        ttl = null;        mtu = null;        termLength = null;        initialTermId = null;        termId = null;        termOffset = null;        sessionId = null;        linger = null;        sparse = null;        eos = null;        tether = null;        isSessionIdTagged = false;        return this;    }
public ChannelUriStringBuilder validate()    {        if (null == media)        {            throw new IllegalStateException("media type is mandatory");        }        if (CommonContext.UDP_MEDIA.equals(media) && (null == endpoint && null == controlEndpoint))        {            throw new IllegalStateException("either 'endpoint' or 'control' must be specified for UDP.");        }        int count = 0;        count += null == initialTermId ? 0 : 1;        count += null == termId ? 0 : 1;        count += null == termOffset ? 0 : 1;        if (count > 0)        {            if (count < 3)            {                throw new IllegalStateException(                    "if any of then a complete set of 'initialTermId', 'termId', and 'termOffset' must be provided");            }            if (termId - initialTermId < 0) // lgtm [java/dereferenced-value-may-be-null]            {                throw new IllegalStateException(                    "difference greater than 2^31 - 1: termId=" + termId + " - initialTermId=" + initialTermId);            }            if (null != termLength && termOffset > termLength) // lgtm [java/dereferenced-value-may-be-null]            {                throw new IllegalStateException("termOffset=" + termOffset + " > termLength=" + termLength);            }        }        return this;    }
public ChannelUriStringBuilder prefix(final String prefix)    {        if (null != prefix && !prefix.equals("") && !prefix.equals(SPY_QUALIFIER))        {            throw new IllegalArgumentException("invalid prefix: " + prefix);        }        this.prefix = prefix;        return this;    }
public ChannelUriStringBuilder media(final String media)    {        switch (media)        {            case CommonContext.UDP_MEDIA:            case CommonContext.IPC_MEDIA:                break;            default:                throw new IllegalArgumentException("invalid media: " + media);        }        this.media = media;        return this;    }
public ChannelUriStringBuilder controlMode(final String controlMode)    {        if (null != controlMode &&            !controlMode.equals(CommonContext.MDC_CONTROL_MODE_MANUAL) &&            !controlMode.equals(CommonContext.MDC_CONTROL_MODE_DYNAMIC))        {            throw new IllegalArgumentException("invalid control mode: " + controlMode);        }        this.controlMode = controlMode;        return this;    }
public ChannelUriStringBuilder ttl(final Integer ttl)    {        if (null != ttl && (ttl < 0 || ttl > 255))        {            throw new IllegalArgumentException("TTL not in range 0-255: " + ttl);        }        this.ttl = ttl;        return this;    }
public ChannelUriStringBuilder mtu(final Integer mtu)    {        if (null != mtu)        {            if (mtu < 32 || mtu > 65504)            {                throw new IllegalArgumentException("MTU not in range 32-65504: " + mtu);            }            if ((mtu & (FRAME_ALIGNMENT - 1)) != 0)            {                throw new IllegalArgumentException("MTU not a multiple of FRAME_ALIGNMENT: mtu=" + mtu);            }        }        this.mtu = mtu;        return this;    }
public ChannelUriStringBuilder termLength(final Integer termLength)    {        if (null != termLength)        {            LogBufferDescriptor.checkTermLength(termLength);        }        this.termLength = termLength;        return this;    }
public ChannelUriStringBuilder termOffset(final Integer termOffset)    {        if (null != termOffset)        {            if ((termOffset < 0 || termOffset > LogBufferDescriptor.TERM_MAX_LENGTH))            {                throw new IllegalArgumentException("term offset not in range 0-1g: " + termOffset);            }            if (0 != (termOffset & (FRAME_ALIGNMENT - 1)))            {                throw new IllegalArgumentException("term offset not multiple of FRAME_ALIGNMENT: " + termOffset);            }        }        this.termOffset = termOffset;        return this;    }
public ChannelUriStringBuilder linger(final Long lingerNs)    {        if (null != lingerNs && lingerNs < 0)        {            throw new IllegalArgumentException("linger value cannot be negative: " + lingerNs);        }        this.linger = lingerNs;        return this;    }
public ChannelUriStringBuilder initialPosition(final long position, final int initialTermId, final int termLength)    {        if (position < 0 || 0 != (position & (FRAME_ALIGNMENT - 1)))        {            throw new IllegalArgumentException("invalid position: " + position);        }        final int bitsToShift = LogBufferDescriptor.positionBitsToShift(termLength);        this.initialTermId = initialTermId;        this.termId = LogBufferDescriptor.computeTermIdFromPosition(position, bitsToShift, initialTermId);        this.termOffset = (int)(position & (termLength - 1));        this.termLength = termLength;        return this;    }
@SuppressWarnings("MethodLength")    public String build()    {        sb.setLength(0);        if (null != prefix && !"".equals(prefix))        {            sb.append(prefix).append(':');        }        sb.append(ChannelUri.AERON_SCHEME).append(':').append(media).append('?');        if (null != tags)        {            sb.append(TAGS_PARAM_NAME).append('=').append(tags).append('|');        }        if (null != endpoint)        {            sb.append(ENDPOINT_PARAM_NAME).append('=').append(endpoint).append('|');        }        if (null != networkInterface)        {            sb.append(INTERFACE_PARAM_NAME).append('=').append(networkInterface).append('|');        }        if (null != controlEndpoint)        {            sb.append(MDC_CONTROL_PARAM_NAME).append('=').append(controlEndpoint).append('|');        }        if (null != controlMode)        {            sb.append(MDC_CONTROL_MODE_PARAM_NAME).append('=').append(controlMode).append('|');        }        if (null != mtu)        {            sb.append(MTU_LENGTH_PARAM_NAME).append('=').append(mtu.intValue()).append('|');        }        if (null != termLength)        {            sb.append(TERM_LENGTH_PARAM_NAME).append('=').append(termLength.intValue()).append('|');        }        if (null != initialTermId)        {            sb.append(INITIAL_TERM_ID_PARAM_NAME).append('=').append(initialTermId.intValue()).append('|');        }        if (null != termId)        {            sb.append(TERM_ID_PARAM_NAME).append('=').append(termId.intValue()).append('|');        }        if (null != termOffset)        {            sb.append(TERM_OFFSET_PARAM_NAME).append('=').append(termOffset.intValue()).append('|');        }        if (null != sessionId)        {            sb.append(SESSION_ID_PARAM_NAME).append('=').append(prefixTag(isSessionIdTagged, sessionId)).append('|');        }        if (null != ttl)        {            sb.append(TTL_PARAM_NAME).append('=').append(ttl.intValue()).append('|');        }        if (null != reliable)        {            sb.append(RELIABLE_STREAM_PARAM_NAME).append('=').append(reliable).append('|');        }        if (null != linger)        {            sb.append(LINGER_PARAM_NAME).append('=').append(linger.intValue()).append('|');        }        if (null != alias)        {            sb.append(ALIAS_PARAM_NAME).append('=').append(alias).append('|');        }        if (null != sparse)        {            sb.append(SPARSE_PARAM_NAME).append('=').append(sparse).append('|');        }        if (null != eos)        {            sb.append(EOS_PARAM_NAME).append('=').append(eos).append('|');        }        if (null != tether)        {            sb.append(TETHER_PARAM_NAME).append('=').append(tether).append('|');        }        final char lastChar = sb.charAt(sb.length() - 1);        if (lastChar == '|' || lastChar == '?')        {            sb.setLength(sb.length() - 1);        }        return sb.toString();    }
public static void sendError(final int bytesToSend, final IOException ex, final InetSocketAddress destination)    {        throw new AeronException("failed to send packet of " + bytesToSend + " bytes to " + destination, ex);    }
public void openDatagramChannel(final AtomicCounter statusIndicator)    {        try        {            sendDatagramChannel = DatagramChannel.open(udpChannel.protocolFamily());            receiveDatagramChannel = sendDatagramChannel;            if (udpChannel.isMulticast())            {                if (null != connectAddress)                {                    receiveDatagramChannel = DatagramChannel.open(udpChannel.protocolFamily());                }                receiveDatagramChannel.setOption(StandardSocketOptions.SO_REUSEADDR, true);                receiveDatagramChannel.bind(new InetSocketAddress(endPointAddress.getPort()));                receiveDatagramChannel.join(endPointAddress.getAddress(), udpChannel.localInterface());                sendDatagramChannel.setOption(StandardSocketOptions.IP_MULTICAST_IF, udpChannel.localInterface());                if (udpChannel.isHasMulticastTtl())                {                    sendDatagramChannel.setOption(StandardSocketOptions.IP_MULTICAST_TTL, udpChannel.multicastTtl());                    multicastTtl = sendDatagramChannel.getOption(StandardSocketOptions.IP_MULTICAST_TTL);                }                else if (context.socketMulticastTtl() != 0)                {                    sendDatagramChannel.setOption(StandardSocketOptions.IP_MULTICAST_TTL, context.socketMulticastTtl());                    multicastTtl = sendDatagramChannel.getOption(StandardSocketOptions.IP_MULTICAST_TTL);                }            }            else            {                sendDatagramChannel.bind(bindAddress);            }            if (null != connectAddress)            {                sendDatagramChannel.connect(connectAddress);            }            if (0 != context.socketSndbufLength())            {                sendDatagramChannel.setOption(SO_SNDBUF, context.socketSndbufLength());            }            if (0 != context.socketRcvbufLength())            {                receiveDatagramChannel.setOption(SO_RCVBUF, context.socketRcvbufLength());            }            sendDatagramChannel.configureBlocking(false);            receiveDatagramChannel.configureBlocking(false);        }        catch (final IOException ex)        {            if (null != statusIndicator)            {                statusIndicator.setOrdered(ChannelEndpointStatus.ERRORED);            }            CloseHelper.quietClose(sendDatagramChannel);            if (receiveDatagramChannel != sendDatagramChannel)            {                CloseHelper.quietClose(receiveDatagramChannel);            }            sendDatagramChannel = null;            receiveDatagramChannel = null;            throw new AeronException(                "channel error - " + ex.getMessage() +                " (at " + ex.getStackTrace()[0].toString() + "): " +                udpChannel.originalUriString(), ex);        }    }
public void close()    {        if (!isClosed)        {            isClosed = true;            try            {                if (null != selectionKey)                {                    selectionKey.cancel();                }                if (null != transportPoller)                {                    transportPoller.cancelRead(this);                    transportPoller.selectNowWithoutProcessing();                }                if (null != sendDatagramChannel)                {                    sendDatagramChannel.close();                }                if (receiveDatagramChannel != sendDatagramChannel && null != receiveDatagramChannel)                {                    receiveDatagramChannel.close();                }                if (null != transportPoller)                {                    transportPoller.selectNowWithoutProcessing();                }            }            catch (final IOException ex)            {                errorLog.record(ex);            }        }    }
public boolean isValidFrame(final UnsafeBuffer buffer, final int length)    {        boolean isFrameValid = true;        if (frameVersion(buffer, 0) != HeaderFlyweight.CURRENT_VERSION)        {            isFrameValid = false;            invalidPackets.increment();        }        else if (length < HeaderFlyweight.MIN_HEADER_LENGTH)        {            isFrameValid = false;            invalidPackets.increment();        }        return isFrameValid;    }
public InetSocketAddress receive(final ByteBuffer buffer)    {        buffer.clear();        InetSocketAddress address = null;        try        {            if (receiveDatagramChannel.isOpen())            {                address = (InetSocketAddress)receiveDatagramChannel.receive(buffer);            }        }        catch (final PortUnreachableException ignored)        {        }        catch (final Exception ex)        {            LangUtil.rethrowUnchecked(ex);        }        return address;    }
public void onNak(        final int termId,        final int termOffset,        final int length,        final int termLength,        final RetransmitSender retransmitSender)    {        if (!isInvalid(termOffset, termLength))        {            if (null == activeRetransmitsMap.get(termId, termOffset) &&                activeRetransmitsMap.size() < MAX_RETRANSMITS_DEFAULT)            {                final RetransmitAction action = assignRetransmitAction();                action.termId = termId;                action.termOffset = termOffset;                action.length = Math.min(length, termLength - termOffset);                final long delay = delayGenerator.generateDelay();                if (0 == delay)                {                    retransmitSender.resend(termId, termOffset, action.length);                    action.linger(lingerTimeoutGenerator.generateDelay(), nanoClock.nanoTime());                }                else                {                    action.delay(delay, nanoClock.nanoTime());                }                activeRetransmitsMap.put(termId, termOffset, action);            }        }    }
public void onRetransmitReceived(final int termId, final int termOffset)    {        final RetransmitAction action = activeRetransmitsMap.get(termId, termOffset);        if (null != action && DELAYED == action.state)        {            activeRetransmitsMap.remove(termId, termOffset);            action.cancel();            // do not go into linger        }    }
public void processTimeouts(final long nowNs, final RetransmitSender retransmitSender)    {        if (activeRetransmitsMap.size() > 0)        {            for (final RetransmitAction action : retransmitActionPool)            {                if (DELAYED == action.state && (action.expireNs - nowNs < 0))                {                    retransmitSender.resend(action.termId, action.termOffset, action.length);                    action.linger(lingerTimeoutGenerator.generateDelay(), nanoClock.nanoTime());                }                else if (LINGERING == action.state && (action.expireNs - nowNs < 0))                {                    action.cancel();                    activeRetransmitsMap.remove(action.termId, action.termOffset);                }            }        }    }
public void reset(        final long correlationId, final int subscriptionCount, final RecordingSubscriptionDescriptorConsumer consumer)    {        this.correlationId = correlationId;        this.consumer = consumer;        this.remainingSubscriptionCount = subscriptionCount;        isDispatchComplete = false;    }
public Action onFragment(final DirectBuffer buffer, final int offset, final int length, final Header header)    {        final byte flags = header.flags();        Action action = Action.CONTINUE;        if ((flags & UNFRAGMENTED) == UNFRAGMENTED)        {            action = delegate.onFragment(buffer, offset, length, header);        }        else        {            if ((flags & BEGIN_FRAG_FLAG) == BEGIN_FRAG_FLAG)            {                final BufferBuilder builder = getBufferBuilder(header.sessionId());                builder.reset().append(buffer, offset, length);            }            else            {                final BufferBuilder builder = builderBySessionIdMap.get(header.sessionId());                if (null != builder && builder.limit() != 0)                {                    final int limit = builder.limit();                    builder.append(buffer, offset, length);                    if ((flags & END_FRAG_FLAG) == END_FRAG_FLAG)                    {                        final int msgLength = builder.limit();                        action = delegate.onFragment(builder.buffer(), 0, msgLength, header);                        if (Action.ABORT == action)                        {                            builder.limit(limit);                        }                        else                        {                            builder.reset();                        }                    }                }            }        }        return action;    }
public static String status(final long status)    {        if (INITIALIZING == status)        {            return "INITIALIZING";        }        if (ERRORED == status)        {            return "ERRORED";        }        if (ACTIVE == status)        {            return "ACTIVE";        }        if (CLOSING == status)        {            return "CLOSING";        }        return "unknown id=" + status;    }
public static AtomicCounter allocate(        final MutableDirectBuffer tempBuffer,        final String name,        final int typeId,        final CountersManager countersManager,        final String channel)    {        final int keyLength = tempBuffer.putStringWithoutLengthAscii(            CHANNEL_OFFSET + SIZE_OF_INT, channel, 0, MAX_CHANNEL_LENGTH);        tempBuffer.putInt(CHANNEL_OFFSET, keyLength);        int labelLength = 0;        labelLength += tempBuffer.putStringWithoutLengthAscii(keyLength + labelLength, name);        labelLength += tempBuffer.putStringWithoutLengthAscii(keyLength + labelLength, ": ");        labelLength += tempBuffer.putStringWithoutLengthAscii(            keyLength + labelLength, channel, 0, MAX_LABEL_LENGTH - labelLength);        return countersManager.newCounter(typeId, tempBuffer, 0, keyLength, tempBuffer, keyLength, labelLength);    }
public void onFragment(final DirectBuffer buffer, final int offset, final int length, final Header header)    {        final byte flags = header.flags();        if ((flags & UNFRAGMENTED) == UNFRAGMENTED)        {            delegate.onFragment(buffer, offset, length, header);        }        else        {            handleFragment(buffer, offset, length, header, flags);        }    }
public DirectBufferVector reset(final DirectBuffer buffer, final int offset, final int length)    {        this.buffer = buffer;        this.offset = offset;        this.length = length;        return this;    }
public DirectBufferVector validate()    {        final int capacity = buffer.capacity();        if (offset < 0 || offset >= capacity)        {            throw new IllegalArgumentException("offset=" + offset + " capacity=" + capacity);        }        if (length < 0 || length > (capacity - offset))        {            throw new IllegalArgumentException("offset=" + offset + " capacity=" + capacity + " length=" + length);        }        return this;    }
public static int validateAndComputeLength(final DirectBufferVector[] vectors)    {        int messageLength = 0;        for (final DirectBufferVector vector : vectors)        {            vector.validate();            messageLength += vector.length;            if (messageLength < 0)            {                throw new IllegalStateException("length overflow: " + Arrays.toString(vectors));            }        }        return messageLength;    }
public static int producerWindowLength(final int termBufferLength, final int defaultTermWindowLength)    {        int termWindowLength = termBufferLength / 2;        if (0 != defaultTermWindowLength)        {            termWindowLength = Math.min(defaultTermWindowLength, termWindowLength);        }        return termWindowLength;    }
public static IdleStrategy agentIdleStrategy(final String strategyName, final StatusIndicator controllableStatus)    {        IdleStrategy idleStrategy = null;        switch (strategyName)        {            case DEFAULT_IDLE_STRATEGY:                idleStrategy = new BackoffIdleStrategy(                    IDLE_MAX_SPINS, IDLE_MAX_YIELDS, IDLE_MIN_PARK_NS, IDLE_MAX_PARK_NS);                break;            case CONTROLLABLE_IDLE_STRATEGY:                idleStrategy = new ControllableIdleStrategy(controllableStatus);                controllableStatus.setOrdered(ControllableIdleStrategy.PARK);                break;            default:                try                {                    idleStrategy = (IdleStrategy)Class.forName(strategyName).getConstructor().newInstance();                }                catch (final Exception ex)                {                    LangUtil.rethrowUnchecked(ex);                }                break;        }        return idleStrategy;    }
public static SendChannelEndpointSupplier sendChannelEndpointSupplier()    {        SendChannelEndpointSupplier supplier = null;        try        {            final String className = getProperty(SEND_CHANNEL_ENDPOINT_SUPPLIER_PROP_NAME);            if (null == className)            {                return new DefaultSendChannelEndpointSupplier();            }            supplier = (SendChannelEndpointSupplier)Class.forName(className).getConstructor().newInstance();        }        catch (final Exception ex)        {            LangUtil.rethrowUnchecked(ex);        }        return supplier;    }
public static ReceiveChannelEndpointSupplier receiveChannelEndpointSupplier()    {        ReceiveChannelEndpointSupplier supplier = null;        try        {            final String className = getProperty(RECEIVE_CHANNEL_ENDPOINT_SUPPLIER_PROP_NAME);            if (null == className)            {                return new DefaultReceiveChannelEndpointSupplier();            }            supplier = (ReceiveChannelEndpointSupplier)Class.forName(className).getConstructor().newInstance();        }        catch (final Exception ex)        {            LangUtil.rethrowUnchecked(ex);        }        return supplier;    }
public static FlowControlSupplier unicastFlowControlSupplier()    {        FlowControlSupplier supplier = null;        try        {            final String className = getProperty(UNICAST_FLOW_CONTROL_STRATEGY_SUPPLIER_PROP_NAME);            if (null == className)            {                return new DefaultUnicastFlowControlSupplier();            }            supplier = (FlowControlSupplier)Class.forName(className).getConstructor().newInstance();        }        catch (final Exception ex)        {            LangUtil.rethrowUnchecked(ex);        }        return supplier;    }
public static FlowControlSupplier multicastFlowControlSupplier()    {        FlowControlSupplier supplier = null;        try        {            final String className = getProperty(MULTICAST_FLOW_CONTROL_STRATEGY_SUPPLIER_PROP_NAME);            if (null == className)            {                return new DefaultMulticastFlowControlSupplier();            }            supplier = (FlowControlSupplier)Class.forName(className).getConstructor().newInstance();        }        catch (final Exception ex)        {            LangUtil.rethrowUnchecked(ex);        }        return supplier;    }
public static CongestionControlSupplier congestionControlSupplier()    {        CongestionControlSupplier supplier = null;        try        {            final String className = getProperty(CONGESTION_CONTROL_STRATEGY_SUPPLIER_PROP_NAME);            if (null == className)            {                return new DefaultCongestionControlSupplier();            }            supplier = (CongestionControlSupplier)Class.forName(className).getConstructor().newInstance();        }        catch (final Exception ex)        {            LangUtil.rethrowUnchecked(ex);        }        return supplier;    }
public static void validateMtuLength(final int mtuLength)    {        if (mtuLength < DataHeaderFlyweight.HEADER_LENGTH || mtuLength > MAX_UDP_PAYLOAD_LENGTH)        {            throw new ConfigurationException(                "mtuLength must be a >= HEADER_LENGTH and <= MAX_UDP_PAYLOAD_LENGTH: " + mtuLength);        }        if ((mtuLength & (FrameDescriptor.FRAME_ALIGNMENT - 1)) != 0)        {            throw new ConfigurationException("mtuLength must be a multiple of FRAME_ALIGNMENT: " + mtuLength);        }    }
public static TerminationValidator terminationValidator()    {        TerminationValidator validator = null;        try        {            final String className = getProperty(TERMINATION_VALIDATOR_PROP_NAME);            if (null == className)            {                return new DefaultDenyTerminationValidator();            }            validator = (TerminationValidator)Class.forName(className).getConstructor().newInstance();        }        catch (final Exception ex)        {            LangUtil.rethrowUnchecked(ex);        }        return validator;    }
public static void validateSocketBufferLengths(final MediaDriver.Context ctx)    {        try (DatagramChannel probe = DatagramChannel.open())        {            final int defaultSoSndBuf = probe.getOption(StandardSocketOptions.SO_SNDBUF);            probe.setOption(StandardSocketOptions.SO_SNDBUF, Integer.MAX_VALUE);            final int maxSoSndBuf = probe.getOption(StandardSocketOptions.SO_SNDBUF);            if (maxSoSndBuf < ctx.socketSndbufLength())            {                System.err.format(                    "WARNING: Could not get desired SO_SNDBUF, adjust OS to allow %s: attempted=%d, actual=%d%n",                    SOCKET_SNDBUF_LENGTH_PROP_NAME,                    ctx.socketSndbufLength(),                    maxSoSndBuf);            }            probe.setOption(StandardSocketOptions.SO_RCVBUF, Integer.MAX_VALUE);            final int maxSoRcvBuf = probe.getOption(StandardSocketOptions.SO_RCVBUF);            if (maxSoRcvBuf < ctx.socketRcvbufLength())            {                System.err.format(                    "WARNING: Could not get desired SO_RCVBUF, adjust OS to allow %s: attempted=%d, actual=%d%n",                    SOCKET_RCVBUF_LENGTH_PROP_NAME,                    ctx.socketRcvbufLength(),                    maxSoRcvBuf);            }            final int soSndBuf = 0 == ctx.socketSndbufLength() ? defaultSoSndBuf : ctx.socketSndbufLength();            if (ctx.mtuLength() > soSndBuf)            {                throw new ConfigurationException(String.format(                    "MTU greater than socket SO_SNDBUF, adjust %s to match MTU: mtuLength=%d, SO_SNDBUF=%d",                    SOCKET_SNDBUF_LENGTH_PROP_NAME,                    ctx.mtuLength(),                    soSndBuf));            }            if (ctx.initialWindowLength() > maxSoRcvBuf)            {                throw new ConfigurationException("window length greater than socket SO_RCVBUF, increase '" +                    Configuration.INITIAL_WINDOW_LENGTH_PROP_NAME +                    "' to match window: windowLength=" + ctx.initialWindowLength() + ", SO_RCVBUF=" + maxSoRcvBuf);            }        }        catch (final IOException ex)        {            throw new AeronException("probe socket: " + ex.toString(), ex);        }    }
public static void validatePageSize(final int pageSize)    {        if (pageSize < PAGE_MIN_SIZE)        {            throw new ConfigurationException(                "page size less than min size of " + PAGE_MIN_SIZE + ": " + pageSize);        }        if (pageSize > PAGE_MAX_SIZE)        {            throw new ConfigurationException(                "page size greater than max size of " + PAGE_MAX_SIZE + ": " + pageSize);        }        if (!BitUtil.isPowerOfTwo(pageSize))        {            throw new ConfigurationException("page size not a power of 2: " + pageSize);        }    }
public static void validateSessionIdRange(final int low, final int high)    {        if (low > high)        {            throw new ConfigurationException("low session id value " + low + " must be <= high value " + high);        }        if (Math.abs((long)high - low) > Integer.MAX_VALUE)        {            throw new ConfigurationException("reserved range to too large");        }    }
public static void validateUnblockTimeout(        final long publicationUnblockTimeoutNs, final long clientLivenessTimeoutNs, final long timerIntervalNs)    {        if (publicationUnblockTimeoutNs <= clientLivenessTimeoutNs)        {            throw new ConfigurationException(                "publicationUnblockTimeoutNs=" + publicationUnblockTimeoutNs +                " <= clientLivenessTimeoutNs=" + clientLivenessTimeoutNs);        }        if (clientLivenessTimeoutNs <= timerIntervalNs)        {            throw new ConfigurationException(                "clientLivenessTimeoutNs=" + clientLivenessTimeoutNs +                " <= timerIntervalNs=" + timerIntervalNs);        }    }
public ErrorResponseFlyweight errorCode(final ErrorCode code)    {        buffer.putInt(offset + ERROR_CODE_OFFSET, code.value());        return this;    }
static Set<ClusterEventCode> getEnabledClusterEventCodes(final String enabledClusterEventCodes)    {        if (null == enabledClusterEventCodes || "".equals(enabledClusterEventCodes))        {            return EnumSet.noneOf(ClusterEventCode.class);        }        final Function<Integer, ClusterEventCode> eventCodeById = ClusterEventCode::get;        final Function<String, ClusterEventCode> eventCodeByName = ClusterEventCode::valueOf;        final EnumSet<ClusterEventCode> allEventsSet = EnumSet.allOf(ClusterEventCode.class);        return parseEventCodes(enabledClusterEventCodes, eventCodeById, eventCodeByName, allEventsSet);    }
static Set<ArchiveEventCode> getEnabledArchiveEventCodes(final String enabledArchiveEventCodes)    {        if (null == enabledArchiveEventCodes || "".equals(enabledArchiveEventCodes))        {            return EnumSet.noneOf(ArchiveEventCode.class);        }        final Function<Integer, ArchiveEventCode> eventCodeById = ArchiveEventCode::get;        final Function<String, ArchiveEventCode> eventCodeByName = ArchiveEventCode::valueOf;        final EnumSet<ArchiveEventCode> allEventsSet = EnumSet.allOf(ArchiveEventCode.class);        return parseEventCodes(enabledArchiveEventCodes, eventCodeById, eventCodeByName, allEventsSet);    }
static Set<DriverEventCode> getEnabledDriverEventCodes(final String enabledLoggerEventCodes)    {        if (null == enabledLoggerEventCodes || "".equals(enabledLoggerEventCodes))        {            return EnumSet.noneOf(DriverEventCode.class);        }        final Set<DriverEventCode> eventCodeSet = new HashSet<>();        final String[] codeIds = enabledLoggerEventCodes.split(",");        for (final String codeId : codeIds)        {            switch (codeId)            {                case "all":                    eventCodeSet.addAll(ALL_LOGGER_EVENT_CODES);                    break;                case "admin":                    eventCodeSet.addAll(ADMIN_ONLY_EVENT_CODES);                    break;                default:                {                    DriverEventCode code = null;                    try                    {                        code = DriverEventCode.valueOf(codeId);                    }                    catch (final IllegalArgumentException ignore)                    {                    }                    if (null == code)                    {                        try                        {                            code = DriverEventCode.get(Integer.parseInt(codeId));                        }                        catch (final IllegalArgumentException ignore)                        {                        }                    }                    if (null != code)                    {                        eventCodeSet.add(code);                    }                    else                    {                        System.err.println("unknown event code: " + codeId);                    }                }            }        }        return eventCodeSet;    }
public void reset()    {        isBallotSent = false;        isLeader = false;        hasRequestedJoin = false;        hasSentTerminationAck = false;        vote = null;        candidateTermId = Aeron.NULL_VALUE;        leadershipTermId = Aeron.NULL_VALUE;        logPosition = NULL_POSITION;    }
public static ClusterMember[] parse(final String value)    {        if (null == value || value.length() == 0)        {            return ClusterMember.EMPTY_CLUSTER_MEMBER_ARRAY;        }        final String[] memberValues = value.split("\\|");        final int length = memberValues.length;        final ClusterMember[] members = new ClusterMember[length];        for (int i = 0; i < length; i++)        {            final String endpointsDetail = memberValues[i];            final String[] memberAttributes = endpointsDetail.split(",");            if (memberAttributes.length != 6)            {                throw new ClusterException("invalid member value: " + endpointsDetail + " within: " + value);            }            final String justEndpoints = String.join(                ",",                memberAttributes[1],                memberAttributes[2],                memberAttributes[3],                memberAttributes[4],                memberAttributes[5]);            members[i] = new ClusterMember(                Integer.parseInt(memberAttributes[0]),                memberAttributes[1],                memberAttributes[2],                memberAttributes[3],                memberAttributes[4],                memberAttributes[5],                justEndpoints);        }        return members;    }
public static String encodeAsString(final ClusterMember[] clusterMembers)    {        final StringBuilder builder = new StringBuilder();        for (int i = 0, length = clusterMembers.length; i < length; i++)        {            final ClusterMember member = clusterMembers[i];            builder                .append(member.id())                .append(',')                .append(member.endpointsDetail());            if ((length - 1) != i)            {                builder.append('|');            }        }        return builder.toString();    }
public static void addMemberStatusPublications(        final ClusterMember[] members,        final ClusterMember exclude,        final ChannelUri channelUri,        final int streamId,        final Aeron aeron)    {        for (final ClusterMember member : members)        {            if (member != exclude)            {                channelUri.put(ENDPOINT_PARAM_NAME, member.memberFacingEndpoint());                member.publication = aeron.addExclusivePublication(channelUri.toString(), streamId);            }        }    }
public static void closeMemberPublications(final ClusterMember[] clusterMembers)    {        for (final ClusterMember member : clusterMembers)        {            CloseHelper.close(member.publication);        }    }
public static void addMemberStatusPublication(        final ClusterMember member, final ChannelUri channelUri, final int streamId, final Aeron aeron)    {        channelUri.put(ENDPOINT_PARAM_NAME, member.memberFacingEndpoint());        member.publication = aeron.addExclusivePublication(channelUri.toString(), streamId);    }
public static void addClusterMemberIds(        final ClusterMember[] clusterMembers, final Int2ObjectHashMap<ClusterMember> clusterMemberByIdMap)    {        for (final ClusterMember member : clusterMembers)        {            clusterMemberByIdMap.put(member.id(), member);        }    }
public static boolean hasActiveQuorum(        final ClusterMember[] clusterMembers, final long nowMs, final long timeoutMs)    {        int threshold = quorumThreshold(clusterMembers.length);        for (final ClusterMember member : clusterMembers)        {            if (member.isLeader() || nowMs <= (member.timeOfLastAppendPositionMs() + timeoutMs))            {                if (--threshold <= 0)                {                    return true;                }            }        }        return false;    }
public static long quorumPosition(final ClusterMember[] members, final long[] rankedPositions)    {        final int length = rankedPositions.length;        for (int i = 0; i < length; i++)        {            rankedPositions[i] = 0;        }        for (final ClusterMember member : members)        {            long newPosition = member.logPosition;            for (int i = 0; i < length; i++)            {                final long rankedPosition = rankedPositions[i];                if (newPosition > rankedPosition)                {                    rankedPositions[i] = newPosition;                    newPosition = rankedPosition;                }            }        }        return rankedPositions[length - 1];    }
public static void resetLogPositions(final ClusterMember[] clusterMembers, final long logPosition)    {        for (final ClusterMember member : clusterMembers)        {            member.logPosition(logPosition);        }    }
public static boolean haveVotersReachedPosition(        final ClusterMember[] clusterMembers, final long position, final long leadershipTermId)    {        for (final ClusterMember member : clusterMembers)        {            if (member.vote != null && (member.logPosition < position || member.leadershipTermId != leadershipTermId))            {                return false;            }        }        return true;    }
public static void becomeCandidate(        final ClusterMember[] members, final long candidateTermId, final int candidateMemberId)    {        for (final ClusterMember member : members)        {            if (member.id == candidateMemberId)            {                member.vote(Boolean.TRUE)                    .candidateTermId(candidateTermId)                    .isBallotSent(true);            }            else            {                member.vote(null)                    .candidateTermId(Aeron.NULL_VALUE)                    .isBallotSent(false);            }        }    }
public static boolean hasWonVoteOnFullCount(final ClusterMember[] members, final long candidateTermId)    {        int votes = 0;        for (final ClusterMember member : members)        {            if (null == member.vote || member.candidateTermId != candidateTermId)            {                return false;            }            votes += member.vote ? 1 : 0;        }        return votes >= ClusterMember.quorumThreshold(members.length);    }
public static boolean hasMajorityVoteWithCanvassMembers(final ClusterMember[] members, final long candidateTermId)    {        int votes = 0;        for (final ClusterMember member : members)        {            if (NULL_POSITION != member.logPosition && null == member.vote)            {                return false;            }            if (Boolean.TRUE.equals(member.vote) && member.candidateTermId == candidateTermId)            {                ++votes;            }        }        return votes >= ClusterMember.quorumThreshold(members.length);    }
public static boolean hasMajorityVote(final ClusterMember[] clusterMembers, final long candidateTermId)    {        int votes = 0;        for (final ClusterMember member : clusterMembers)        {            if (Boolean.TRUE.equals(member.vote) && member.candidateTermId == candidateTermId)            {                ++votes;            }        }        return votes >= ClusterMember.quorumThreshold(clusterMembers.length);    }
public static ClusterMember determineMember(        final ClusterMember[] clusterMembers, final int memberId, final String memberEndpoints)    {        ClusterMember member = NULL_VALUE != memberId ? ClusterMember.findMember(clusterMembers, memberId) : null;        if ((null == clusterMembers || 0 == clusterMembers.length) && null == member)        {            member = ClusterMember.parseEndpoints(NULL_VALUE, memberEndpoints);        }        else        {            if (null == member)            {                throw new ClusterException("memberId=" + memberId + " not found in clusterMembers");            }            if (!"".equals(memberEndpoints))            {                ClusterMember.validateMemberEndpoints(member, memberEndpoints);            }        }        return member;    }
public static void validateMemberEndpoints(final ClusterMember member, final String memberEndpoints)    {        final ClusterMember endpointMember = ClusterMember.parseEndpoints(Aeron.NULL_VALUE, memberEndpoints);        if (!areSameEndpoints(member, endpointMember))        {            throw new ClusterException(                "clusterMembers and memberEndpoints differ: " + member.endpointsDetail() + " != " + memberEndpoints);        }    }
public static boolean areSameEndpoints(final ClusterMember lhs, final ClusterMember rhs)    {        return lhs.clientFacingEndpoint().equals(rhs.clientFacingEndpoint()) &&            lhs.memberFacingEndpoint().equals(rhs.memberFacingEndpoint()) &&            lhs.logEndpoint().equals(rhs.logEndpoint()) &&            lhs.transferEndpoint().equals(rhs.transferEndpoint()) &&            lhs.archiveEndpoint().equals(rhs.archiveEndpoint());    }
public static boolean isUnanimousCandidate(final ClusterMember[] clusterMembers, final ClusterMember candidate)    {        for (final ClusterMember member : clusterMembers)        {            if (NULL_POSITION == member.logPosition || compareLog(candidate, member) < 0)            {                return false;            }        }        return true;    }
public static boolean isQuorumCandidate(final ClusterMember[] clusterMembers, final ClusterMember candidate)    {        int possibleVotes = 0;        for (final ClusterMember member : clusterMembers)        {            if (NULL_POSITION == member.logPosition || compareLog(candidate, member) < 0)            {                continue;            }            ++possibleVotes;        }        return possibleVotes >= ClusterMember.quorumThreshold(clusterMembers.length);    }
public static int compareLog(        final long lhsLogLeadershipTermId,        final long lhsLogPosition,        final long rhsLogLeadershipTermId,        final long rhsLogPosition)    {        if (lhsLogLeadershipTermId > rhsLogLeadershipTermId)        {            return 1;        }        else if (lhsLogLeadershipTermId < rhsLogLeadershipTermId)        {            return -1;        }        else if (lhsLogPosition > rhsLogPosition)        {            return 1;        }        else if (lhsLogPosition < rhsLogPosition)        {            return -1;        }        return 0;    }
public static int compareLog(final ClusterMember lhs, final ClusterMember rhs)    {        return compareLog(lhs.leadershipTermId, lhs.logPosition, rhs.leadershipTermId, rhs.logPosition);    }
public static boolean isNotDuplicateEndpoints(final ClusterMember[] members, final String memberEndpoints)    {        for (final ClusterMember member : members)        {            if (member.endpointsDetail().equals(memberEndpoints))            {                return false;            }        }        return true;    }
public static int findMemberIndex(final ClusterMember[] clusterMembers, final int memberId)    {        final int length = clusterMembers.length;        int index = ArrayUtil.UNKNOWN_INDEX;        for (int i = 0; i < length; i++)        {            if (clusterMembers[i].id() == memberId)            {                index = i;            }        }        return index;    }
public static ClusterMember findMember(final ClusterMember[] clusterMembers, final int memberId)    {        for (final ClusterMember member : clusterMembers)        {            if (member.id() == memberId)            {                return member;            }        }        return null;    }
public static ClusterMember[] addMember(final ClusterMember[] oldMembers, final ClusterMember newMember)    {        return ArrayUtil.add(oldMembers, newMember);    }
public static ClusterMember[] removeMember(final ClusterMember[] oldMembers, final int memberId)    {        return ArrayUtil.remove(oldMembers, findMemberIndex(oldMembers, memberId));    }
public static int highMemberId(final ClusterMember[] clusterMembers)    {        int highId = Aeron.NULL_VALUE;        for (final ClusterMember member : clusterMembers)        {            highId = Math.max(highId, member.id());        }        return highId;    }
public static String clientFacingEndpoints(final ClusterMember[] members)    {        final StringBuilder builder = new StringBuilder(100);        for (int i = 0, length = members.length; i < length; i++)        {            if (0 != i)            {                builder.append(',');            }            final ClusterMember member = members[i];            builder.append(member.id()).append('=').append(member.clientFacingEndpoint());        }        return builder.toString();    }
public long onIdle(final long timeNs, final long senderLimit, final long senderPosition, final boolean isEos)    {        long minPosition = Long.MAX_VALUE;        long minLimitPosition = Long.MAX_VALUE;        final ArrayList<Receiver> receiverList = this.receiverList;        for (int lastIndex = receiverList.size() - 1, i = lastIndex; i >= 0; i--)        {            final Receiver receiver = receiverList.get(i);            if ((receiver.timeOfLastStatusMessageNs + RECEIVER_TIMEOUT) - timeNs < 0)            {                ArrayListUtil.fastUnorderedRemove(receiverList, i, lastIndex--);            }            else            {                minPosition = Math.min(minPosition, receiver.lastPosition);                minLimitPosition = Math.min(minLimitPosition, receiver.lastPositionPlusWindow);            }        }        if (isEos && shouldLinger)        {            if (0 == receiverList.size() || minPosition >= senderPosition)            {                shouldLinger = false;            }        }        return receiverList.size() > 0 ? minLimitPosition : senderLimit;    }
public static Status unblock(        final UnsafeBuffer logMetaDataBuffer,        final UnsafeBuffer termBuffer,        final int blockedOffset,        final int tailOffset,        final int termId)    {        Status status = NO_ACTION;        int frameLength = frameLengthVolatile(termBuffer, blockedOffset);        if (frameLength < 0)        {            resetHeader(logMetaDataBuffer, termBuffer, blockedOffset, termId, -frameLength);            status = UNBLOCKED;        }        else if (0 == frameLength)        {            int currentOffset = blockedOffset + FRAME_ALIGNMENT;            while (currentOffset < tailOffset)            {                frameLength = frameLengthVolatile(termBuffer, currentOffset);                if (frameLength != 0)                {                    if (scanBackToConfirmZeroed(termBuffer, currentOffset, blockedOffset))                    {                        final int length = currentOffset - blockedOffset;                        resetHeader(logMetaDataBuffer, termBuffer, blockedOffset, termId, length);                        status = UNBLOCKED;                    }                    break;                }                currentOffset += FRAME_ALIGNMENT;            }            if (currentOffset == termBuffer.capacity())            {                if (0 == frameLengthVolatile(termBuffer, blockedOffset))                {                    final int length = currentOffset - blockedOffset;                    resetHeader(logMetaDataBuffer, termBuffer, blockedOffset, termId, length);                    status = UNBLOCKED_TO_END;                }            }        }        return status;    }
public MappedByteBuffer mapExistingCncFile(final Consumer<String> logger)    {        final File cncFile = new File(aeronDirectory, CncFileDescriptor.CNC_FILE);        if (cncFile.exists() && cncFile.length() > 0)        {            if (null != logger)            {                logger.accept("INFO: Aeron CnC file exists: " + cncFile);            }            return IoUtil.mapExistingFile(cncFile, CncFileDescriptor.CNC_FILE);        }        return null;    }
public static boolean isDriverActive(        final File directory, final long driverTimeoutMs, final Consumer<String> logger)    {        final File cncFile = new File(directory, CncFileDescriptor.CNC_FILE);        if (cncFile.exists() && cncFile.length() > 0)        {            logger.accept("INFO: Aeron CnC file exists: " + cncFile);            final MappedByteBuffer cncByteBuffer = IoUtil.mapExistingFile(cncFile, "CnC file");            try            {                return isDriverActive(driverTimeoutMs, logger, cncByteBuffer);            }            finally            {                IoUtil.unmap(cncByteBuffer);            }        }        return false;    }
public boolean isDriverActive(final long driverTimeoutMs, final Consumer<String> logger)    {        final MappedByteBuffer cncByteBuffer = mapExistingCncFile(logger);        try        {            return isDriverActive(driverTimeoutMs, logger, cncByteBuffer);        }        finally        {            IoUtil.unmap(cncByteBuffer);        }    }
public static boolean isDriverActive(        final long driverTimeoutMs, final Consumer<String> logger, final ByteBuffer cncByteBuffer)    {        if (null == cncByteBuffer)        {            return false;        }        final UnsafeBuffer cncMetaDataBuffer = CncFileDescriptor.createMetaDataBuffer(cncByteBuffer);        final long startTimeMs = System.currentTimeMillis();        int cncVersion;        while (0 == (cncVersion = cncMetaDataBuffer.getIntVolatile(CncFileDescriptor.cncVersionOffset(0))))        {            if (System.currentTimeMillis() > (startTimeMs + driverTimeoutMs))            {                throw new DriverTimeoutException("CnC file is created but not initialised.");            }            sleep(1);        }        if (CNC_VERSION != cncVersion)        {            throw new AeronException(                "Aeron CnC version does not match: required=" + CNC_VERSION + " version=" + cncVersion);        }        final ManyToOneRingBuffer toDriverBuffer = new ManyToOneRingBuffer(            CncFileDescriptor.createToDriverBuffer(cncByteBuffer, cncMetaDataBuffer));        final long timestamp = toDriverBuffer.consumerHeartbeatTime();        final long now = System.currentTimeMillis();        final long timestampAge = now - timestamp;        logger.accept("INFO: Aeron toDriver consumer heartbeat is (ms): " + timestampAge);        return timestampAge <= driverTimeoutMs;    }
public static boolean requestDriverTermination(        final File directory,        final DirectBuffer tokenBuffer,        final int tokenOffset,        final int tokenLength)    {        final File cncFile = new File(directory, CncFileDescriptor.CNC_FILE);        if (cncFile.exists() && cncFile.length() > 0)        {            final MappedByteBuffer cncByteBuffer = IoUtil.mapExistingFile(cncFile, "CnC file");            try            {                final UnsafeBuffer cncMetaDataBuffer = CncFileDescriptor.createMetaDataBuffer(cncByteBuffer);                final int cncVersion = cncMetaDataBuffer.getIntVolatile(cncVersionOffset(0));                if (CncFileDescriptor.CNC_VERSION != cncVersion)                {                    throw new AeronException(                        "Aeron CnC version does not match: required=" + CNC_VERSION + " version=" + cncVersion);                }                final ManyToOneRingBuffer toDriverBuffer = new ManyToOneRingBuffer(                    CncFileDescriptor.createToDriverBuffer(cncByteBuffer, cncMetaDataBuffer));                final long clientId = toDriverBuffer.nextCorrelationId();                final DriverProxy driverProxy = new DriverProxy(toDriverBuffer, clientId);                return driverProxy.terminateDriver(tokenBuffer, tokenOffset, tokenLength);            }            finally            {                IoUtil.unmap(cncByteBuffer);            }        }        return false;    }
public int saveErrorLog(final PrintStream out)    {        final MappedByteBuffer cncByteBuffer = mapExistingCncFile(null);        try        {            return saveErrorLog(out, cncByteBuffer);        }        finally        {            IoUtil.unmap(cncByteBuffer);        }    }
public int saveErrorLog(final PrintStream out, final ByteBuffer cncByteBuffer)    {        if (null == cncByteBuffer)        {            return 0;        }        final UnsafeBuffer cncMetaDataBuffer = CncFileDescriptor.createMetaDataBuffer(cncByteBuffer);        final int cncVersion = cncMetaDataBuffer.getInt(CncFileDescriptor.cncVersionOffset(0));        if (CNC_VERSION != cncVersion)        {            throw new AeronException(                "Aeron CnC version does not match: required=" + CNC_VERSION + " version=" + cncVersion);        }        int distinctErrorCount = 0;        final AtomicBuffer buffer = CncFileDescriptor.createErrorLogBuffer(cncByteBuffer, cncMetaDataBuffer);        if (ErrorLogReader.hasErrors(buffer))        {            final SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss.SSSZ");            final ErrorConsumer errorConsumer = (count, firstTimestamp, lastTimestamp, ex) ->                formatError(out, dateFormat, count, firstTimestamp, lastTimestamp, ex);            distinctErrorCount = ErrorLogReader.read(buffer, errorConsumer);        }        out.println();        out.println(distinctErrorCount + " distinct errors observed.");        return distinctErrorCount;    }
public static int frameLengthVolatile(final UnsafeBuffer buffer, final int termOffset)    {        int frameLength = buffer.getIntVolatile(termOffset);        if (ByteOrder.nativeOrder() != LITTLE_ENDIAN)        {            frameLength = Integer.reverseBytes(frameLength);        }        return frameLength;    }
public static void frameLengthOrdered(final UnsafeBuffer buffer, final int termOffset, final int frameLength)    {        int length = frameLength;        if (ByteOrder.nativeOrder() != LITTLE_ENDIAN)        {            length = Integer.reverseBytes(frameLength);        }        buffer.putIntOrdered(termOffset, length);    }
public static void frameType(final UnsafeBuffer buffer, final int termOffset, final int type)    {        buffer.putShort(typeOffset(termOffset), (short)type, LITTLE_ENDIAN);    }
public static void frameFlags(final UnsafeBuffer buffer, final int termOffset, final byte flags)    {        buffer.putByte(flagsOffset(termOffset), flags);    }
public static void frameTermOffset(final UnsafeBuffer buffer, final int termOffset)    {        buffer.putInt(termOffsetOffset(termOffset), termOffset, LITTLE_ENDIAN);    }
public static void frameTermId(final UnsafeBuffer buffer, final int termOffset, final int termId)    {        buffer.putInt(termIdOffset(termOffset), termId, LITTLE_ENDIAN);    }
public void registerForSend(final NetworkPublication publication)    {        publicationBySessionAndStreamId.put(publication.sessionId(), publication.streamId(), publication);    }
public int send(final ByteBuffer buffer)    {        int bytesSent = 0;        if (null != sendDatagramChannel)        {            final int bytesToSend = buffer.remaining();            if (null == multiDestination)            {                try                {                    sendHook(buffer, connectAddress);                    if (sendDatagramChannel.isConnected())                    {                        bytesSent = sendDatagramChannel.write(buffer);                    }                }                catch (final PortUnreachableException ignore)                {                }                catch (final IOException ex)                {                    sendError(bytesToSend, ex, connectAddress);                }            }            else            {                bytesSent = multiDestination.send(sendDatagramChannel, buffer, this, bytesToSend);            }        }        return bytesSent;    }
public static int findCounterIdByRecording(final CountersReader countersReader, final long recordingId)    {        final DirectBuffer buffer = countersReader.metaDataBuffer();        for (int i = 0, size = countersReader.maxCounterId(); i < size; i++)        {            if (countersReader.getCounterState(i) == RECORD_ALLOCATED)            {                final int recordOffset = CountersReader.metaDataOffset(i);                if (buffer.getInt(recordOffset + TYPE_ID_OFFSET) == RECORDING_POSITION_TYPE_ID &&                    buffer.getLong(recordOffset + KEY_OFFSET + RECORDING_ID_OFFSET) == recordingId)                {                    return i;                }            }        }        return NULL_COUNTER_ID;    }
public static int findCounterIdBySession(final CountersReader countersReader, final int sessionId)    {        final DirectBuffer buffer = countersReader.metaDataBuffer();        for (int i = 0, size = countersReader.maxCounterId(); i < size; i++)        {            if (countersReader.getCounterState(i) == RECORD_ALLOCATED)            {                final int recordOffset = CountersReader.metaDataOffset(i);                if (buffer.getInt(recordOffset + TYPE_ID_OFFSET) == RECORDING_POSITION_TYPE_ID &&                    buffer.getInt(recordOffset + KEY_OFFSET + SESSION_ID_OFFSET) == sessionId)                {                    return i;                }            }        }        return NULL_COUNTER_ID;    }
public static long getRecordingId(final CountersReader countersReader, final int counterId)    {        final DirectBuffer buffer = countersReader.metaDataBuffer();        if (countersReader.getCounterState(counterId) == RECORD_ALLOCATED)        {            final int recordOffset = CountersReader.metaDataOffset(counterId);            if (buffer.getInt(recordOffset + TYPE_ID_OFFSET) == RECORDING_POSITION_TYPE_ID)            {                return buffer.getLong(recordOffset + KEY_OFFSET + RECORDING_ID_OFFSET);            }        }        return NULL_RECORDING_ID;    }
public static String getSourceIdentity(final CountersReader countersReader, final int counterId)    {        final DirectBuffer buffer = countersReader.metaDataBuffer();        if (countersReader.getCounterState(counterId) == RECORD_ALLOCATED)        {            final int recordOffset = CountersReader.metaDataOffset(counterId);            if (buffer.getInt(recordOffset + TYPE_ID_OFFSET) == RECORDING_POSITION_TYPE_ID)            {                return buffer.getStringAscii(recordOffset + KEY_OFFSET + SOURCE_IDENTITY_LENGTH_OFFSET);            }        }        return null;    }
public static boolean isActive(final CountersReader countersReader, final int counterId, final long recordingId)    {        final DirectBuffer buffer = countersReader.metaDataBuffer();        if (countersReader.getCounterState(counterId) == RECORD_ALLOCATED)        {            final int recordOffset = CountersReader.metaDataOffset(counterId);            return                buffer.getInt(recordOffset + TYPE_ID_OFFSET) == RECORDING_POSITION_TYPE_ID &&                buffer.getLong(recordOffset + KEY_OFFSET + RECORDING_ID_OFFSET) == recordingId;        }        return false;    }
static InetSocketAddress parse(final CharSequence cs)    {        if (null == cs || cs.length() == 0)        {            throw new NullPointerException("Input string must not be null or empty");        }        InetSocketAddress address = tryParseIpV4(cs);        if (null == address)        {            address = tryParseIpV6(cs);        }        if (null == address)        {            throw new IllegalArgumentException("Invalid format: " + cs);        }        return address;    }
public long onStatusMessage(        final StatusMessageFlyweight flyweight,        final InetSocketAddress receiverAddress,        final long senderLimit,        final int initialTermId,        final int positionBitsToShift,        final long timeNs)    {        final long position = computePosition(            flyweight.consumptionTermId(),            flyweight.consumptionTermOffset(),            positionBitsToShift,            initialTermId);        final long windowLength = flyweight.receiverWindowLength();        final long receiverId = flyweight.receiverId();        final boolean isFromPreferred = isFromPreferred(flyweight);        final long lastPositionPlusWindow = position + windowLength;        boolean isExisting = false;        long minPosition = Long.MAX_VALUE;        final ArrayList<Receiver> receiverList = this.receiverList;        for (int i = 0, size = receiverList.size(); i < size; i++)        {            final Receiver receiver = receiverList.get(i);            if (isFromPreferred && receiverId == receiver.receiverId)            {                receiver.lastPosition = Math.max(position, receiver.lastPosition);                receiver.lastPositionPlusWindow = lastPositionPlusWindow;                receiver.timeOfLastStatusMessageNs = timeNs;                isExisting = true;            }            minPosition = Math.min(minPosition, receiver.lastPositionPlusWindow);        }        if (isFromPreferred && !isExisting)        {            receiverList.add(new Receiver(position, lastPositionPlusWindow, timeNs, receiverId, receiverAddress));            minPosition = Math.min(minPosition, lastPositionPlusWindow);        }        return receiverList.size() > 0 ?            Math.max(senderLimit, minPosition) :            Math.max(senderLimit, lastPositionPlusWindow);    }
public static int scanForGap(        final UnsafeBuffer termBuffer,        final int termId,        final int termOffset,        final int limitOffset,        final GapHandler handler)    {        int offset = termOffset;        do        {            final int frameLength = frameLengthVolatile(termBuffer, offset);            if (frameLength <= 0)            {                break;            }            offset += align(frameLength, FRAME_ALIGNMENT);        }        while (offset < limitOffset);        final int gapBeginOffset = offset;        if (offset < limitOffset)        {            final int limit = limitOffset - ALIGNED_HEADER_LENGTH;            while (offset < limit)            {                offset += FRAME_ALIGNMENT;                if (0 != termBuffer.getIntVolatile(offset))                {                    offset -= ALIGNED_HEADER_LENGTH;                    break;                }            }            final int gapLength = (offset - gapBeginOffset) + ALIGNED_HEADER_LENGTH;            handler.onGap(termId, gapBeginOffset, gapLength);        }        return gapBeginOffset;    }
public static ClusteredMediaDriver launch(        final MediaDriver.Context driverCtx,        final Archive.Context archiveCtx,        final ConsensusModule.Context consensusModuleCtx)    {        final MediaDriver driver = MediaDriver.launch(driverCtx            .spiesSimulateConnection(true));        final Archive archive = Archive.launch(archiveCtx            .mediaDriverAgentInvoker(driver.sharedAgentInvoker())            .errorHandler(driverCtx.errorHandler())            .errorCounter(driverCtx.systemCounters().get(SystemCounterDescriptor.ERRORS)));        final ConsensusModule consensusModule = ConsensusModule.launch(consensusModuleCtx);        return new ClusteredMediaDriver(driver, archive, consensusModule);    }
public long receiverId()    {        final long value;        if (ByteOrder.nativeOrder() == LITTLE_ENDIAN)        {            value =                (                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 7)) << 56) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 6) & 0xFF) << 48) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 5) & 0xFF) << 40) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 4) & 0xFF) << 32) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 3) & 0xFF) << 24) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 2) & 0xFF) << 16) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 1) & 0xFF) << 8) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 0) & 0xFF))                );        }        else        {            value =                (                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 0)) << 56) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 1) & 0xFF) << 48) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 2) & 0xFF) << 40) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 3) & 0xFF) << 32) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 4) & 0xFF) << 24) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 5) & 0xFF) << 16) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 6) & 0xFF) << 8) |                    (((long)getByte(RECEIVER_ID_FIELD_OFFSET + 7) & 0xFF))                );        }        return value;    }
public StatusMessageFlyweight receiverId(final long id)    {        if (ByteOrder.nativeOrder() == LITTLE_ENDIAN)        {            putByte(RECEIVER_ID_FIELD_OFFSET + 7, (byte)(id >> 56));            putByte(RECEIVER_ID_FIELD_OFFSET + 6, (byte)(id >> 48));            putByte(RECEIVER_ID_FIELD_OFFSET + 5, (byte)(id >> 40));            putByte(RECEIVER_ID_FIELD_OFFSET + 4, (byte)(id >> 32));            putByte(RECEIVER_ID_FIELD_OFFSET + 3, (byte)(id >> 24));            putByte(RECEIVER_ID_FIELD_OFFSET + 2, (byte)(id >> 16));            putByte(RECEIVER_ID_FIELD_OFFSET + 1, (byte)(id >> 8));            putByte(RECEIVER_ID_FIELD_OFFSET + 0, (byte)(id));        }        else        {            putByte(RECEIVER_ID_FIELD_OFFSET + 0, (byte)(id >> 56));            putByte(RECEIVER_ID_FIELD_OFFSET + 1, (byte)(id >> 48));            putByte(RECEIVER_ID_FIELD_OFFSET + 2, (byte)(id >> 40));            putByte(RECEIVER_ID_FIELD_OFFSET + 3, (byte)(id >> 32));            putByte(RECEIVER_ID_FIELD_OFFSET + 4, (byte)(id >> 24));            putByte(RECEIVER_ID_FIELD_OFFSET + 5, (byte)(id >> 16));            putByte(RECEIVER_ID_FIELD_OFFSET + 6, (byte)(id >> 8));            putByte(RECEIVER_ID_FIELD_OFFSET + 7, (byte)(id));        }        return this;    }
public int applicationSpecificFeedback(final byte[] destination)    {        final int frameLength = frameLength();        int result = 0;        if (frameLength > HEADER_LENGTH)        {            if (frameLength > capacity())            {                throw new AeronException(String.format(                    "SM application specific feedback (%d) is truncated (%d)",                    frameLength - HEADER_LENGTH,                    capacity() - HEADER_LENGTH));            }            final int copyLength = Math.min(destination.length, frameLength - HEADER_LENGTH);            getBytes(APP_SPECIFIC_FEEDBACK_FIELD_OFFSET, destination, 0, copyLength);            result = copyLength;        }        return result;    }
public StatusMessageFlyweight applicationSpecificFeedback(final byte[] source, final int offset, final int length)    {        frameLength(HEADER_LENGTH + length);        putBytes(APP_SPECIFIC_FEEDBACK_FIELD_OFFSET, source, offset, length);        return this;    }
public void reload()    {        entries.clear();        indexByLeadershipTermIdMap.clear();        indexByLeadershipTermIdMap.compact();        nextEntryIndex = 0;        byteBuffer.clear();        try        {            while (true)            {                final int bytes = fileChannel.read(byteBuffer);                if (byteBuffer.remaining() == 0)                {                    byteBuffer.flip();                    captureEntriesFromBuffer(byteBuffer, buffer, entries);                    byteBuffer.clear();                }                if (-1 == bytes)                {                    if (byteBuffer.position() > 0)                    {                        byteBuffer.flip();                        captureEntriesFromBuffer(byteBuffer, buffer, entries);                        byteBuffer.clear();                    }                    break;                }            }        }        catch (final IOException ex)        {            LangUtil.rethrowUnchecked(ex);        }    }
public long findLastTermRecordingId()    {        for (int i = entries.size() - 1; i >= 0; i--)        {            final Entry entry = entries.get(i);            if (ENTRY_TYPE_TERM == entry.type)            {                return entry.recordingId;            }        }        return RecordingPos.NULL_RECORDING_ID;    }
public Entry findLastTerm()    {        for (int i = entries.size() - 1; i >= 0; i--)        {            final Entry entry = entries.get(i);            if (ENTRY_TYPE_TERM == entry.type)            {                return entry;            }        }        return null;    }
public Entry getTermEntry(final long leadershipTermId)    {        final int index = (int)indexByLeadershipTermIdMap.get(leadershipTermId);        if (NULL_VALUE == index)        {            throw new ClusterException("unknown leadershipTermId=" + leadershipTermId);        }        return entries.get(index);    }
public RecoveryPlan createRecoveryPlan(final AeronArchive archive, final int serviceCount)    {        final ArrayList<Snapshot> snapshots = new ArrayList<>();        final ArrayList<Log> logs = new ArrayList<>();        planRecovery(snapshots, logs, entries, archive, serviceCount);        long lastLeadershipTermId = NULL_VALUE;        long lastTermBaseLogPosition = 0;        long committedLogPosition = -1;        long appendedLogPosition = 0;        final int snapshotStepsSize = snapshots.size();        if (snapshotStepsSize > 0)        {            final Snapshot snapshot = snapshots.get(0);            lastLeadershipTermId = snapshot.leadershipTermId;            lastTermBaseLogPosition = snapshot.termBaseLogPosition;            appendedLogPosition = snapshot.logPosition;            committedLogPosition = snapshot.logPosition;        }        if (!logs.isEmpty())        {            final Log log = logs.get(0);            lastLeadershipTermId = log.leadershipTermId;            lastTermBaseLogPosition = log.termBaseLogPosition;            appendedLogPosition = log.stopPosition;            committedLogPosition = log.logPosition;        }        return new RecoveryPlan(            lastLeadershipTermId,            lastTermBaseLogPosition,            appendedLogPosition,            committedLogPosition,            snapshots,            logs);    }
public static RecoveryPlan createRecoveryPlan(final ArrayList<RecordingLog.Snapshot> snapshots)    {        long lastLeadershipTermId = NULL_VALUE;        long lastTermBaseLogPosition = 0;        long committedLogPosition = -1;        long appendedLogPosition = 0;        final int snapshotStepsSize = snapshots.size();        if (snapshotStepsSize > 0)        {            final Snapshot snapshot = snapshots.get(0);            lastLeadershipTermId = snapshot.leadershipTermId;            lastTermBaseLogPosition = snapshot.termBaseLogPosition;            appendedLogPosition = snapshot.logPosition;            committedLogPosition = snapshot.logPosition;        }        return new RecoveryPlan(            lastLeadershipTermId,            lastTermBaseLogPosition,            appendedLogPosition,            committedLogPosition,            snapshots,            new ArrayList<>());    }
public void appendTerm(        final long recordingId, final long leadershipTermId, final long termBaseLogPosition, final long timestamp)    {        final int size = entries.size();        if (size > 0)        {            final Entry lastEntry = entries.get(size - 1);            if (lastEntry.type != NULL_VALUE && lastEntry.leadershipTermId >= leadershipTermId)            {                throw new ClusterException("leadershipTermId out of sequence: previous " +                    lastEntry.leadershipTermId + " this " + leadershipTermId);            }        }        indexByLeadershipTermIdMap.put(leadershipTermId, nextEntryIndex);        append(            ENTRY_TYPE_TERM,            recordingId,            leadershipTermId,            termBaseLogPosition,            NULL_POSITION,            timestamp,            NULL_VALUE);    }
public void appendSnapshot(        final long recordingId,        final long leadershipTermId,        final long termBaseLogPosition,        final long logPosition,        final long timestamp,        final int serviceId)    {        final int size = entries.size();        if (size > 0)        {            final Entry entry = entries.get(size - 1);            if (entry.type == ENTRY_TYPE_TERM && entry.leadershipTermId != leadershipTermId)            {                throw new ClusterException("leadershipTermId out of sequence: previous " +                    entry.leadershipTermId + " this " + leadershipTermId);            }        }        append(            ENTRY_TYPE_SNAPSHOT,            recordingId,            leadershipTermId,            termBaseLogPosition,            logPosition,            timestamp,            serviceId);    }
public void commitLogPosition(final long leadershipTermId, final long logPosition)    {        final int index = getLeadershipTermEntryIndex(leadershipTermId);        commitEntryValue(index, logPosition, LOG_POSITION_OFFSET);        final Entry entry = entries.get(index);        entries.set(index, new Entry(            entry.recordingId,            entry.leadershipTermId,            entry.termBaseLogPosition,            logPosition,            entry.timestamp,            entry.serviceId,            entry.type,            entry.entryIndex));    }
public void tombstoneEntry(final long leadershipTermId, final int entryIndex)    {        int index = -1;        for (int i = 0, size = entries.size(); i < size; i++)        {            final Entry entry = entries.get(i);            if (entry.leadershipTermId == leadershipTermId && entry.entryIndex == entryIndex)            {                index = entry.entryIndex;                if (ENTRY_TYPE_TERM == entry.type)                {                    indexByLeadershipTermIdMap.remove(leadershipTermId);                }                break;            }        }        if (-1 == index)        {            throw new ClusterException("unknown entry index: " + entryIndex);        }        buffer.putInt(0, NULL_VALUE, LITTLE_ENDIAN);        byteBuffer.limit(SIZE_OF_INT).position(0);        final long filePosition = (index * (long)ENTRY_LENGTH) + ENTRY_TYPE_OFFSET;        try        {            if (SIZE_OF_INT != fileChannel.write(byteBuffer, filePosition))            {                throw new ClusterException("failed to write field atomically");            }        }        catch (final Exception ex)        {            LangUtil.rethrowUnchecked(ex);        }    }
public static AeronCluster connect(final AeronCluster.Context ctx)    {        Subscription subscription = null;        AsyncConnect asyncConnect = null;        try        {            ctx.conclude();            final Aeron aeron = ctx.aeron();            final long deadlineNs = aeron.context().nanoClock().nanoTime() + ctx.messageTimeoutNs();            subscription = aeron.addSubscription(ctx.egressChannel(), ctx.egressStreamId());            final IdleStrategy idleStrategy = ctx.idleStrategy();            asyncConnect = new AsyncConnect(ctx, subscription, deadlineNs);            final AgentInvoker aeronClientInvoker = aeron.conductorAgentInvoker();            AeronCluster aeronCluster;            while (null == (aeronCluster = asyncConnect.poll()))            {                if (null != aeronClientInvoker)                {                    aeronClientInvoker.invoke();                }                idleStrategy.idle();            }            return aeronCluster;        }        catch (final Exception ex)        {            if (!ctx.ownsAeronClient())            {                CloseHelper.close(subscription);                CloseHelper.close(asyncConnect);            }            ctx.close();            throw ex;        }    }
public static AsyncConnect asyncConnect(final Context ctx)    {        Subscription subscription = null;        try        {            ctx.conclude();            final long deadlineNs = ctx.aeron().context().nanoClock().nanoTime() + ctx.messageTimeoutNs();            subscription = ctx.aeron().addSubscription(ctx.egressChannel(), ctx.egressStreamId());            return new AsyncConnect(ctx, subscription, deadlineNs);        }        catch (final Exception ex)        {            if (!ctx.ownsAeronClient())            {                CloseHelper.quietClose(subscription);            }            ctx.close();            throw ex;        }    }
public void close()    {        if (null != publication && publication.isConnected())        {            closeSession();        }        if (!ctx.ownsAeronClient())        {            CloseHelper.close(subscription);            CloseHelper.close(publication);        }        ctx.close();    }
public long offer(final DirectBuffer buffer, final int offset, final int length)    {        return publication.offer(headerBuffer, 0, INGRESS_HEADER_LENGTH, buffer, offset, length, null);    }
public long offer(final DirectBufferVector[] vectors)    {        if (headerVector != vectors[0])        {            vectors[0] = headerVector;        }        return publication.offer(vectors, null);    }
public boolean sendKeepAlive()    {        idleStrategy.reset();        int attempts = SEND_ATTEMPTS;        while (true)        {            final long result = publication.offer(keepaliveMsgBuffer, 0, keepaliveMsgBuffer.capacity(), null);            if (result > 0)            {                return true;            }            if (result == Publication.NOT_CONNECTED || result == Publication.CLOSED)            {                return false;            }            if (result == Publication.MAX_POSITION_EXCEEDED)            {                throw new ClusterException("unexpected publication state: " + result);            }            if (--attempts <= 0)            {                break;            }            idleStrategy.idle();        }        return false;    }
public void onNewLeader(        final long clusterSessionId,        final long leadershipTermId,        final int leaderMemberId,        final String memberEndpoints)    {        if (clusterSessionId != this.clusterSessionId)        {            throw new ClusterException(                "invalid clusterSessionId=" + clusterSessionId + " expected " + this.clusterSessionId);        }        this.leadershipTermId = leadershipTermId;        this.leaderMemberId = leaderMemberId;        ingressMessageHeaderEncoder.leadershipTermId(leadershipTermId);        sessionKeepAliveEncoder.leadershipTermId(leadershipTermId);        if (ctx.clusterMemberEndpoints() != null)        {            CloseHelper.close(publication);            ctx.clusterMemberEndpoints(memberEndpoints);            updateMemberEndpoints(memberEndpoints, leaderMemberId);        }        fragmentAssembler.clear();        controlledFragmentAssembler.clear();        egressListener.newLeader(clusterSessionId, leadershipTermId, leaderMemberId, memberEndpoints);        controlledEgressListener.newLeader(clusterSessionId, leadershipTermId, leaderMemberId, memberEndpoints);    }
public static boolean unblock(        final UnsafeBuffer[] termBuffers,        final UnsafeBuffer logMetaDataBuffer,        final long blockedPosition,        final int termLength)    {        final int positionBitsToShift = LogBufferDescriptor.positionBitsToShift(termLength);        final int blockedTermCount = (int)(blockedPosition >> positionBitsToShift);        final int blockedOffset = (int)blockedPosition & (termLength - 1);        final int activeTermCount = activeTermCount(logMetaDataBuffer);        if (activeTermCount == (blockedTermCount - 1) && blockedOffset == 0)        {            final int currentTermId = termId(rawTailVolatile(logMetaDataBuffer, indexByTermCount(activeTermCount)));            return rotateLog(logMetaDataBuffer, activeTermCount, currentTermId);        }        final int blockedIndex = indexByTermCount(blockedTermCount);        final long rawTail = rawTailVolatile(logMetaDataBuffer, blockedIndex);        final int termId = termId(rawTail);        final int tailOffset = termOffset(rawTail, termLength);        final UnsafeBuffer termBuffer = termBuffers[blockedIndex];        switch (TermUnblocker.unblock(logMetaDataBuffer, termBuffer, blockedOffset, tailOffset, termId))        {            case UNBLOCKED_TO_END:                rotateLog(logMetaDataBuffer, blockedTermCount, termId);                // fall through            case UNBLOCKED:                return true;        }        return false;    }
public String channel()    {        final int length = buffer.getInt(offset + CHANNEL_OFFSET);        lengthOfChannel = SIZE_OF_INT + length;        return buffer.getStringAscii(offset + CHANNEL_OFFSET, length);    }
public ImageMessageFlyweight channel(final String channel)    {        lengthOfChannel = buffer.putStringAscii(offset + CHANNEL_OFFSET, channel);        return this;    }
public static void checkTermLength(final int termLength)    {        if (termLength < TERM_MIN_LENGTH)        {            throw new IllegalStateException(                "Term length less than min length of " + TERM_MIN_LENGTH + ": length=" + termLength);        }        if (termLength > TERM_MAX_LENGTH)        {            throw new IllegalStateException(                "Term length more than max length of " + TERM_MAX_LENGTH + ": length=" + termLength);        }        if (!BitUtil.isPowerOfTwo(termLength))        {            throw new IllegalStateException("Term length not a power of 2: length=" + termLength);        }    }
public static void checkPageSize(final int pageSize)    {        if (pageSize < PAGE_MIN_SIZE)        {            throw new IllegalStateException(                "Page size less than min size of " + PAGE_MIN_SIZE + ": page size=" + pageSize);        }        if (pageSize > PAGE_MAX_SIZE)        {            throw new IllegalStateException(                "Page size more than max size of " + PAGE_MAX_SIZE + ": page size=" + pageSize);        }        if (!BitUtil.isPowerOfTwo(pageSize))        {            throw new IllegalStateException("Page size not a power of 2: page size=" + pageSize);        }    }
public static boolean casActiveTermCount(        final UnsafeBuffer metadataBuffer, final int expectedTermCount, final int updateTermCount)    {        return metadataBuffer.compareAndSetInt(LOG_ACTIVE_TERM_COUNT_OFFSET, expectedTermCount, updateTermCount);    }
public static long computePosition(        final int activeTermId, final int termOffset, final int positionBitsToShift, final int initialTermId)    {        final long termCount = activeTermId - initialTermId; // copes with negative activeTermId on rollover        return (termCount << positionBitsToShift) + termOffset;    }
public static long computeLogLength(final int termLength, final int filePageSize)    {        if (termLength < (1024 * 1024 * 1024))        {            return align((termLength * PARTITION_COUNT) + LOG_META_DATA_LENGTH, filePageSize);        }        return (PARTITION_COUNT * (long)termLength) + align(LOG_META_DATA_LENGTH, filePageSize);    }
public static void storeDefaultFrameHeader(final UnsafeBuffer metadataBuffer, final DirectBuffer defaultHeader)    {        if (defaultHeader.capacity() != HEADER_LENGTH)        {            throw new IllegalArgumentException(                "Default header length not equal to HEADER_LENGTH: length=" + defaultHeader.capacity());        }        metadataBuffer.putInt(LOG_DEFAULT_FRAME_HEADER_LENGTH_OFFSET, HEADER_LENGTH);        metadataBuffer.putBytes(LOG_DEFAULT_FRAME_HEADER_OFFSET, defaultHeader, 0, HEADER_LENGTH);    }
public static void applyDefaultHeader(        final UnsafeBuffer metadataBuffer, final UnsafeBuffer termBuffer, final int termOffset)    {        termBuffer.putBytes(termOffset, metadataBuffer, LOG_DEFAULT_FRAME_HEADER_OFFSET, HEADER_LENGTH);    }
public static boolean rotateLog(final UnsafeBuffer metadataBuffer, final int termCount, final int termId)    {        final int nextTermId = termId + 1;        final int nextTermCount = termCount + 1;        final int nextIndex = indexByTermCount(nextTermCount);        final int expectedTermId = nextTermId - PARTITION_COUNT;        long rawTail;        do        {            rawTail = rawTail(metadataBuffer, nextIndex);            if (expectedTermId != termId(rawTail))            {                break;            }        }        while (!casRawTail(metadataBuffer, nextIndex, rawTail, packTail(nextTermId, 0)));        return casActiveTermCount(metadataBuffer, termCount, nextTermCount);    }
public static void initialiseTailWithTermId(        final UnsafeBuffer metadataBuffer, final int partitionIndex, final int termId)    {        metadataBuffer.putLong(TERM_TAIL_COUNTERS_OFFSET + (partitionIndex * SIZE_OF_LONG), packTail(termId, 0));    }
public static int termOffset(final long rawTail, final long termLength)    {        final long tail = rawTail & 0xFFFF_FFFFL;        return (int)Math.min(tail, termLength);    }
public static void rawTail(final UnsafeBuffer metadataBuffer, final int partitionIndex, final long rawTail)    {        metadataBuffer.putLong(TERM_TAIL_COUNTERS_OFFSET + (SIZE_OF_LONG * partitionIndex), rawTail);    }
public static void rawTailVolatile(final UnsafeBuffer metadataBuffer, final int partitionIndex, final long rawTail)    {        metadataBuffer.putLongVolatile(TERM_TAIL_COUNTERS_OFFSET + (SIZE_OF_LONG * partitionIndex), rawTail);    }
public static long rawTailVolatile(final UnsafeBuffer metadataBuffer)    {        final int partitionIndex = indexByTermCount(activeTermCount(metadataBuffer));        return metadataBuffer.getLongVolatile(TERM_TAIL_COUNTERS_OFFSET + (SIZE_OF_LONG * partitionIndex));    }
public static boolean casRawTail(        final UnsafeBuffer metadataBuffer,        final int partitionIndex,        final long expectedRawTail,        final long updateRawTail)    {        final int index = TERM_TAIL_COUNTERS_OFFSET + (SIZE_OF_LONG * partitionIndex);        return metadataBuffer.compareAndSetLong(index, expectedRawTail, updateRawTail);    }
public static void main(final String[] args)    {        loadPropertiesFiles(args);        try (Archive ignore = launch())        {            new ShutdownSignalBarrier().await();            System.out.println("Shutdown Archive...");        }    }
public TerminateDriverFlyweight tokenBuffer(        final DirectBuffer tokenBuffer, final int tokenOffset, final int tokenLength)    {        buffer.putInt(TOKEN_LENGTH_OFFSET, tokenLength);        if (null != tokenBuffer && tokenLength > 0)        {            buffer.putBytes(tokenBufferOffset(), tokenBuffer, tokenOffset, tokenLength);        }        return this;    }
public static Counter allocate(        final Aeron aeron,        final MutableDirectBuffer tempBuffer,        final long leadershipTermId,        final long logPosition,        final long timestamp,        final boolean hasReplay,        final long... snapshotRecordingIds)    {        tempBuffer.putLong(LEADERSHIP_TERM_ID_OFFSET, leadershipTermId);        tempBuffer.putLong(LOG_POSITION_OFFSET, logPosition);        tempBuffer.putLong(TIMESTAMP_OFFSET, timestamp);        tempBuffer.putInt(REPLAY_FLAG_OFFSET, hasReplay ? 1 : 0);        final int serviceCount = snapshotRecordingIds.length;        tempBuffer.putInt(SERVICE_COUNT_OFFSET, serviceCount);        final int keyLength = SNAPSHOT_RECORDING_IDS_OFFSET + (serviceCount * SIZE_OF_LONG);        if (keyLength > MAX_KEY_LENGTH)        {            throw new ClusterException(keyLength + " exceeds max key length " + MAX_KEY_LENGTH);        }        for (int i = 0; i < serviceCount; i++)        {            tempBuffer.putLong(SNAPSHOT_RECORDING_IDS_OFFSET + (i * SIZE_OF_LONG), snapshotRecordingIds[i]);        }        final int labelOffset = BitUtil.align(keyLength, SIZE_OF_INT);        int labelLength = 0;        labelLength += tempBuffer.putStringWithoutLengthAscii(labelOffset + labelLength, NAME);        labelLength += tempBuffer.putLongAscii(keyLength + labelLength, leadershipTermId);        labelLength += tempBuffer.putStringWithoutLengthAscii(labelOffset + labelLength, " logPosition=");        labelLength += tempBuffer.putLongAscii(labelOffset + labelLength, logPosition);        labelLength += tempBuffer.putStringWithoutLengthAscii(labelOffset + labelLength, " hasReplay=" + hasReplay);        return aeron.addCounter(RECOVERY_STATE_TYPE_ID, tempBuffer, 0, keyLength, tempBuffer, labelOffset, labelLength);    }
public static int findCounterId(final CountersReader counters)    {        final DirectBuffer buffer = counters.metaDataBuffer();        for (int i = 0, size = counters.maxCounterId(); i < size; i++)        {            if (counters.getCounterState(i) == RECORD_ALLOCATED)            {                final int recordOffset = CountersReader.metaDataOffset(i);                if (buffer.getInt(recordOffset + TYPE_ID_OFFSET) == RECOVERY_STATE_TYPE_ID)                {                    return i;                }            }        }        return NULL_COUNTER_ID;    }
public static long getLogPosition(final CountersReader counters, final int counterId)    {        final DirectBuffer buffer = counters.metaDataBuffer();        if (counters.getCounterState(counterId) == RECORD_ALLOCATED)        {            final int recordOffset = CountersReader.metaDataOffset(counterId);            if (buffer.getInt(recordOffset + TYPE_ID_OFFSET) == RECOVERY_STATE_TYPE_ID)            {                return buffer.getLong(recordOffset + KEY_OFFSET + LOG_POSITION_OFFSET);            }        }        return NULL_VALUE;    }
public static boolean hasReplay(final CountersReader counters, final int counterId)    {        final DirectBuffer buffer = counters.metaDataBuffer();        if (counters.getCounterState(counterId) == RECORD_ALLOCATED)        {            final int recordOffset = CountersReader.metaDataOffset(counterId);            if (buffer.getInt(recordOffset + TYPE_ID_OFFSET) == RECOVERY_STATE_TYPE_ID)            {                return buffer.getInt(recordOffset + KEY_OFFSET + REPLAY_FLAG_OFFSET) == 1;            }        }        return false;    }
public static long getSnapshotRecordingId(final CountersReader counters, final int counterId, final int serviceId)    {        final DirectBuffer buffer = counters.metaDataBuffer();        if (counters.getCounterState(counterId) == RECORD_ALLOCATED)        {            final int recordOffset = CountersReader.metaDataOffset(counterId);            if (buffer.getInt(recordOffset + TYPE_ID_OFFSET) == RECOVERY_STATE_TYPE_ID)            {                final int serviceCount = buffer.getInt(recordOffset + KEY_OFFSET + SERVICE_COUNT_OFFSET);                if (serviceId < 0 || serviceId >= serviceCount)                {                    throw new ClusterException("invalid serviceId " + serviceId + " for count of " + serviceCount);                }                return buffer.getLong(                    recordOffset + KEY_OFFSET + SNAPSHOT_RECORDING_IDS_OFFSET + (serviceId * SIZE_OF_LONG));            }        }        throw new ClusterException("Active counter not found " + counterId);    }
public static char[] flagsToChars(final short flags)    {        final char[] chars = new char[]{ '0', '0', '0', '0', '0', '0', '0', '0' };        final int length = chars.length;        short mask = (short)(1 << (length - 1));        for (int i = 0; i < length; i++)        {            if ((flags & mask) == mask)            {                chars[i] = '1';            }            mask >>= 1;        }        return chars;    }
public ReportEntry createEntry(        final long initialBytesLost,        final long timestampMs,        final int sessionId,        final int streamId,        final String channel,        final String source)    {        ReportEntry reportEntry = null;        final int requiredCapacity = CHANNEL_OFFSET + (SIZE_OF_INT * 2) + channel.length() + source.length();        if (requiredCapacity <= (buffer.capacity() - nextRecordOffset))        {            final int offset = nextRecordOffset;            buffer.putLong(offset + TOTAL_BYTES_LOST_OFFSET, initialBytesLost);            buffer.putLong(offset + FIRST_OBSERVATION_OFFSET, timestampMs);            buffer.putLong(offset + LAST_OBSERVATION_OFFSET, timestampMs);            buffer.putInt(offset + SESSION_ID_OFFSET, sessionId);            buffer.putInt(offset + STREAM_ID_OFFSET, streamId);            final int encodedChannelLength = buffer.putStringAscii(offset + CHANNEL_OFFSET, channel);            buffer.putStringAscii(offset + CHANNEL_OFFSET + encodedChannelLength, source);            buffer.putLongOrdered(offset + OBSERVATION_COUNT_OFFSET, 1);            reportEntry = new ReportEntry(buffer, offset);            nextRecordOffset += BitUtil.align(requiredCapacity, ENTRY_ALIGNMENT);        }        return reportEntry;    }
public long offer(final Publication publication, final DirectBuffer buffer, final int offset, final int length)    {        return publication.offer(headerBuffer, 0, HEADER_LENGTH, buffer, offset, length, null);    }
public PublicationMessageFlyweight channel(final String channel)    {        lengthOfChannel = buffer.putStringAscii(offset + CHANNEL_OFFSET, channel);        return this;    }
public static boolean tryFillGap(        final UnsafeBuffer logMetaDataBuffer,        final UnsafeBuffer termBuffer,        final int termId,        final int gapOffset,        final int gapLength)    {        int offset = (gapOffset + gapLength) - FRAME_ALIGNMENT;        while (offset >= gapOffset)        {            if (0 != termBuffer.getInt(offset))            {                return false;            }            offset -= FRAME_ALIGNMENT;        }        applyDefaultHeader(logMetaDataBuffer, termBuffer, gapOffset);        frameType(termBuffer, gapOffset, HDR_TYPE_PAD);        frameTermOffset(termBuffer, gapOffset);        frameTermId(termBuffer, gapOffset, termId);        frameLengthOrdered(termBuffer, gapOffset, gapLength);        return true;    }
public static int read(        final UnsafeBuffer termBuffer,        final int termOffset,        final FragmentHandler handler,        final int fragmentsLimit,        final Header header,        final ErrorHandler errorHandler,        final long currentPosition,        final Position subscriberPosition)    {        int fragmentsRead = 0;        int offset = termOffset;        final int capacity = termBuffer.capacity();        header.buffer(termBuffer);        try        {            while (fragmentsRead < fragmentsLimit && offset < capacity)            {                final int frameLength = frameLengthVolatile(termBuffer, offset);                if (frameLength <= 0)                {                    break;                }                final int frameOffset = offset;                offset += BitUtil.align(frameLength, FRAME_ALIGNMENT);                if (!isPaddingFrame(termBuffer, frameOffset))                {                    header.offset(frameOffset);                    handler.onFragment(termBuffer, frameOffset + HEADER_LENGTH, frameLength - HEADER_LENGTH, header);                    ++fragmentsRead;                }            }        }        catch (final Throwable t)        {            errorHandler.onError(t);        }        finally        {            final long newPosition = currentPosition + (offset - termOffset);            if (newPosition > currentPosition)            {                subscriberPosition.setOrdered(newPosition);            }        }        return fragmentsRead;    }
public void write(final UnsafeBuffer termBuffer, final int offset, final int length, final int termId)    {        termBuffer.putLongOrdered(offset + FRAME_LENGTH_FIELD_OFFSET, versionFlagsType | ((-length) & 0xFFFF_FFFFL));        UnsafeAccess.UNSAFE.storeFence();        termBuffer.putLong(offset + TERM_OFFSET_FIELD_OFFSET, sessionId | offset);        termBuffer.putLong(offset + STREAM_ID_FIELD_OFFSET, streamId | (((long)termId) << 32));    }
public long offer(final DirectBuffer buffer, final int offset, final int length)    {        return cluster.offer(id, responsePublication, buffer, offset, length);    }
public final void wrap(final AtomicBuffer buffer, final int offset, final int length)    {        this.buffer.wrap(buffer, offset, length);    }
public final BufferClaim putBytes(final DirectBuffer srcBuffer, final int srcIndex, final int length)    {        buffer.putBytes(HEADER_LENGTH, srcBuffer, srcIndex, length);        return this;    }
public final void commit()    {        int frameLength = buffer.capacity();        if (ByteOrder.nativeOrder() != LITTLE_ENDIAN)        {            frameLength = Integer.reverseBytes(frameLength);        }        buffer.putIntOrdered(FRAME_LENGTH_FIELD_OFFSET, frameLength);    }
public final void abort()    {        int frameLength = buffer.capacity();        if (ByteOrder.nativeOrder() != LITTLE_ENDIAN)        {            frameLength = Integer.reverseBytes(frameLength);        }        buffer.putShort(TYPE_FIELD_OFFSET, (short)HDR_TYPE_PAD, LITTLE_ENDIAN);        buffer.putIntOrdered(FRAME_LENGTH_FIELD_OFFSET, frameLength);    }
public static void main(final String[] args)    {        loadPropertiesFiles(args);        final ShutdownSignalBarrier barrier = new ShutdownSignalBarrier();        final MediaDriver.Context ctx = new MediaDriver.Context();        ctx.terminationHook(barrier::signal);        try (MediaDriver ignore = MediaDriver.launch(ctx))        {            barrier.await();            System.out.println("Shutdown Driver...");        }    }
public static MediaDriver launchEmbedded(final Context ctx)    {        if (CommonContext.AERON_DIR_PROP_DEFAULT.equals(ctx.aeronDirectoryName()))        {            ctx.aeronDirectoryName(CommonContext.generateRandomDirName());        }        return launch(ctx);    }
public void close()    {        CloseHelper.close(sharedRunner);        CloseHelper.close(sharedNetworkRunner);        CloseHelper.close(receiverRunner);        CloseHelper.close(senderRunner);        CloseHelper.close(conductorRunner);        CloseHelper.close(sharedInvoker);        if (ctx.useWindowsHighResTimer() && SystemUtil.osName().startsWith("win"))        {            if (!wasHighResTimerEnabled)            {                HighResolutionTimer.disable();            }        }    }
public int poll(final FragmentHandler fragmentHandler, final int fragmentLimit)    {        if (isClosed)        {            return 0;        }        final long position = subscriberPosition.get();        return TermReader.read(            activeTermBuffer(position),            (int)position & termLengthMask,            fragmentHandler,            fragmentLimit,            header,            errorHandler,            position,            subscriberPosition);    }
public int controlledPoll(final ControlledFragmentHandler handler, final int fragmentLimit)    {        if (isClosed)        {            return 0;        }        int fragmentsRead = 0;        long initialPosition = subscriberPosition.get();        int initialOffset = (int)initialPosition & termLengthMask;        int resultingOffset = initialOffset;        final UnsafeBuffer termBuffer = activeTermBuffer(initialPosition);        final int capacity = termBuffer.capacity();        final Header header = this.header;        header.buffer(termBuffer);        try        {            while (fragmentsRead < fragmentLimit && resultingOffset < capacity)            {                final int length = frameLengthVolatile(termBuffer, resultingOffset);                if (length <= 0)                {                    break;                }                final int frameOffset = resultingOffset;                final int alignedLength = BitUtil.align(length, FRAME_ALIGNMENT);                resultingOffset += alignedLength;                if (isPaddingFrame(termBuffer, frameOffset))                {                    continue;                }                header.offset(frameOffset);                final Action action = handler.onFragment(                    termBuffer, frameOffset + HEADER_LENGTH, length - HEADER_LENGTH, header);                if (action == ABORT)                {                    resultingOffset -= alignedLength;                    break;                }                ++fragmentsRead;                if (action == BREAK)                {                    break;                }                else if (action == COMMIT)                {                    initialPosition += (resultingOffset - initialOffset);                    initialOffset = resultingOffset;                    subscriberPosition.setOrdered(initialPosition);                }            }        }        catch (final Throwable t)        {            errorHandler.onError(t);        }        finally        {            final long resultingPosition = initialPosition + (resultingOffset - initialOffset);            if (resultingPosition > initialPosition)            {                subscriberPosition.setOrdered(resultingPosition);            }        }        return fragmentsRead;    }
public long controlledPeek(        final long initialPosition, final ControlledFragmentHandler handler, final long limitPosition)    {        if (isClosed)        {            return 0;        }        validatePosition(initialPosition);        int initialOffset = (int)initialPosition & termLengthMask;        int offset = initialOffset;        long position = initialPosition;        final UnsafeBuffer termBuffer = activeTermBuffer(initialPosition);        final int capacity = termBuffer.capacity();        final Header header = this.header;        header.buffer(termBuffer);        long resultingPosition = initialPosition;        try        {            while (position < limitPosition && offset < capacity)            {                final int length = frameLengthVolatile(termBuffer, offset);                if (length <= 0)                {                    break;                }                final int frameOffset = offset;                final int alignedLength = BitUtil.align(length, FRAME_ALIGNMENT);                offset += alignedLength;                if (isPaddingFrame(termBuffer, frameOffset))                {                    position += (offset - initialOffset);                    initialOffset = offset;                    resultingPosition = position;                    continue;                }                header.offset(frameOffset);                final Action action = handler.onFragment(                    termBuffer, frameOffset + HEADER_LENGTH, length - HEADER_LENGTH, header);                if (action == ABORT)                {                    break;                }                position += (offset - initialOffset);                initialOffset = offset;                if ((header.flags() & END_FRAG_FLAG) == END_FRAG_FLAG)                {                    resultingPosition = position;                }                if (action == BREAK)                {                    break;                }            }        }        catch (final Throwable t)        {            errorHandler.onError(t);        }        return resultingPosition;    }
public int blockPoll(final BlockHandler handler, final int blockLengthLimit)    {        if (isClosed)        {            return 0;        }        final long position = subscriberPosition.get();        final int termOffset = (int)position & termLengthMask;        final UnsafeBuffer termBuffer = activeTermBuffer(position);        final int limitOffset = Math.min(termOffset + blockLengthLimit, termBuffer.capacity());        final int resultingOffset = TermBlockScanner.scan(termBuffer, termOffset, limitOffset);        final int length = resultingOffset - termOffset;        if (resultingOffset > termOffset)        {            try            {                final int termId = termBuffer.getInt(termOffset + TERM_ID_FIELD_OFFSET, LITTLE_ENDIAN);                handler.onBlock(termBuffer, termOffset, length, sessionId, termId);            }            catch (final Throwable t)            {                errorHandler.onError(t);            }            finally            {                subscriberPosition.setOrdered(position + length);            }        }        return length;    }
public int rawPoll(final RawBlockHandler handler, final int blockLengthLimit)    {        if (isClosed)        {            return 0;        }        final long position = subscriberPosition.get();        final int termOffset = (int)position & termLengthMask;        final int activeIndex = indexByPosition(position, positionBitsToShift);        final UnsafeBuffer termBuffer = termBuffers[activeIndex];        final int capacity = termBuffer.capacity();        final int limitOffset = Math.min(termOffset + blockLengthLimit, capacity);        final int resultingOffset = TermBlockScanner.scan(termBuffer, termOffset, limitOffset);        final int length = resultingOffset - termOffset;        if (resultingOffset > termOffset)        {            try            {                final long fileOffset = ((long)capacity * activeIndex) + termOffset;                final int termId = termBuffer.getInt(termOffset + TERM_ID_FIELD_OFFSET, LITTLE_ENDIAN);                handler.onBlock(                    logBuffers.fileChannel(), fileOffset, termBuffer, termOffset, length, sessionId, termId);            }            catch (final Throwable t)            {                errorHandler.onError(t);            }            finally            {                subscriberPosition.setOrdered(position + length);            }        }        return length;    }
public final long position()    {        final int resultingOffset = BitUtil.align(termOffset() + frameLength(), FRAME_ALIGNMENT);        return computePosition(termId(), resultingOffset, positionBitsToShift, initialTermId);    }
public SubscriptionMessageFlyweight channel(final String channel)    {        lengthOfChannel = buffer.putStringAscii(offset + CHANNEL_OFFSET, channel);        return this;    }
public RawLog newPublication(        final String channel,        final int sessionId,        final int streamId,        final long correlationId,        final int termBufferLength,        final boolean useSparseFiles)    {        return newInstance(            publicationsDir, channel, sessionId, streamId, correlationId, termBufferLength, useSparseFiles);    }
public RawLog newImage(        final String channel,        final int sessionId,        final int streamId,        final long correlationId,        final int termBufferLength,        final boolean useSparseFiles)    {        return newInstance(imagesDir, channel, sessionId, streamId, correlationId, termBufferLength, useSparseFiles);    }
public static Counter allocate(        final Aeron aeron,        final MutableDirectBuffer tempBuffer,        final int serviceId)    {        tempBuffer.putInt(SERVICE_ID_OFFSET, serviceId);        final int labelOffset = BitUtil.align(KEY_LENGTH, SIZE_OF_INT);        int labelLength = 0;        labelLength += tempBuffer.putStringWithoutLengthAscii(labelOffset + labelLength, NAME);        labelLength += tempBuffer.putIntAscii(labelOffset + labelLength, serviceId);        return aeron.addCounter(            SERVICE_HEARTBEAT_TYPE_ID, tempBuffer, 0, KEY_LENGTH, tempBuffer, labelOffset, labelLength);    }
public static int findCounterId(final CountersReader counters, final int serviceId)    {        final DirectBuffer buffer = counters.metaDataBuffer();        for (int i = 0, size = counters.maxCounterId(); i < size; i++)        {            if (counters.getCounterState(i) == RECORD_ALLOCATED)            {                final int recordOffset = CountersReader.metaDataOffset(i);                if (buffer.getInt(recordOffset + TYPE_ID_OFFSET) == SERVICE_HEARTBEAT_TYPE_ID &&                    buffer.getInt(recordOffset + KEY_OFFSET + SERVICE_ID_OFFSET) == serviceId)                {                    return i;                }            }        }        return NULL_COUNTER_ID;    }
public Map<StreamCompositeKey, StreamBacklog> snapshot()    {        final Map<StreamCompositeKey, StreamBacklog> streams = new HashMap<>();        counters.forEach(            (counterId, typeId, keyBuffer, label) ->            {                if ((typeId >= PUBLISHER_LIMIT_TYPE_ID && typeId <= RECEIVER_POS_TYPE_ID) ||                    typeId == SENDER_LIMIT_TYPE_ID || typeId == PER_IMAGE_TYPE_ID || typeId == PUBLISHER_POS_TYPE_ID)                {                    final StreamCompositeKey key = new StreamCompositeKey(                        keyBuffer.getInt(SESSION_ID_OFFSET),                        keyBuffer.getInt(STREAM_ID_OFFSET),                        keyBuffer.getStringAscii(CHANNEL_OFFSET));                    final StreamBacklog streamBacklog = streams.computeIfAbsent(key, (ignore) -> new StreamBacklog());                    final long registrationId = keyBuffer.getLong(REGISTRATION_ID_OFFSET);                    final long value = counters.getCounterValue(counterId);                    switch (typeId)                    {                        case PublisherLimit.PUBLISHER_LIMIT_TYPE_ID:                            streamBacklog.createPublisherIfAbsent().registrationId(registrationId);                            streamBacklog.createPublisherIfAbsent().limit(value);                            break;                        case PublisherPos.PUBLISHER_POS_TYPE_ID:                            streamBacklog.createPublisherIfAbsent().registrationId(registrationId);                            streamBacklog.createPublisherIfAbsent().position(value);                            break;                        case SenderPos.SENDER_POSITION_TYPE_ID:                            streamBacklog.createSenderIfAbsent().registrationId(registrationId);                            streamBacklog.createSenderIfAbsent().position(value);                            break;                        case SenderLimit.SENDER_LIMIT_TYPE_ID:                            streamBacklog.createSenderIfAbsent().registrationId(registrationId);                            streamBacklog.createSenderIfAbsent().limit(value);                            break;                        case ReceiverHwm.RECEIVER_HWM_TYPE_ID:                            streamBacklog.createReceiverIfAbsent().registrationId(registrationId);                            streamBacklog.createReceiverIfAbsent().highWaterMark(value);                            break;                        case ReceiverPos.RECEIVER_POS_TYPE_ID:                            streamBacklog.createReceiverIfAbsent().registrationId(registrationId);                            streamBacklog.createReceiverIfAbsent().position(value);                            break;                        case SubscriberPos.SUBSCRIBER_POSITION_TYPE_ID:                            streamBacklog.subscriberBacklogs().put(registrationId, new Subscriber(value));                            break;                    }                }            });        return streams;    }
public void print(final PrintStream out)    {        final StringBuilder builder = new StringBuilder();        for (final Map.Entry<StreamCompositeKey, StreamBacklog> entry : snapshot().entrySet())        {            builder.setLength(0);            final StreamCompositeKey key = entry.getKey();            builder                .append("sessionId=").append(key.sessionId())                .append(" streamId=").append(key.streamId())                .append(" channel=").append(key.channel())                .append(" : ");            final StreamBacklog streamBacklog = entry.getValue();            if (streamBacklog.publisher() != null)            {                builder                    .append("\n┌─for publisher ")                    .append(streamBacklog.publisher().registrationId())                    .append(" the last sampled position is ")                    .append(streamBacklog.publisher().position())                    .append(" (~")                    .append(streamBacklog.publisher().remainingWindow())                    .append(" bytes before back-pressure)");                final Sender sender = streamBacklog.sender();                if (sender != null)                {                    final long senderBacklog = sender.backlog(streamBacklog.publisher().position());                    builder.append("\n└─sender ").append(sender.registrationId());                    if (senderBacklog >= 0)                    {                        builder.append(" has to send ").append(senderBacklog).append(" bytes");                    }                    else                    {                        builder.append(" is at position ").append(sender.position());                    }                    builder.append(" (").append(sender.window()).append(" bytes remaining in the sender window)");                }                else                {                    builder.append("\n└─no sender yet...");                }            }            if (streamBacklog.receiver() != null)            {                builder                    .append("\n┌─receiver ")                    .append(streamBacklog.receiver().registrationId())                    .append(" is at position ")                    .append(streamBacklog.receiver().position());                final Iterator<Map.Entry<Long, Subscriber>> subscriberIterator =                    streamBacklog.subscriberBacklogs().entrySet().iterator();                while (subscriberIterator.hasNext())                {                    final Map.Entry<Long, Subscriber> subscriber = subscriberIterator.next();                    builder                        .append(subscriberIterator.hasNext() ? "\n├" : "\n└")                        .append("─subscriber ")                        .append(subscriber.getKey())                        .append(" has ")                        .append(subscriber.getValue().backlog(streamBacklog.receiver().highWaterMark()))                        .append(" backlog bytes");                }            }            builder.append('\n');            out.println(builder);        }    }
public long scan(        final UnsafeBuffer termBuffer,        final long rebuildPosition,        final long hwmPosition,        final long nowNs,        final int termLengthMask,        final int positionBitsToShift,        final int initialTermId)    {        boolean lossFound = false;        int rebuildOffset = (int)rebuildPosition & termLengthMask;        if (rebuildPosition < hwmPosition)        {            final int rebuildTermCount = (int)(rebuildPosition >>> positionBitsToShift);            final int hwmTermCount = (int)(hwmPosition >>> positionBitsToShift);            final int rebuildTermId = initialTermId + rebuildTermCount;            final int hwmTermOffset = (int)hwmPosition & termLengthMask;            final int limitOffset = rebuildTermCount == hwmTermCount ? hwmTermOffset : termLengthMask + 1;            rebuildOffset = scanForGap(termBuffer, rebuildTermId, rebuildOffset, limitOffset, this);            if (rebuildOffset < limitOffset)            {                if (scannedTermOffset != activeTermOffset || scannedTermId != activeTermId)                {                    activateGap(nowNs);                    lossFound = true;                }                checkTimerExpiry(nowNs);            }        }        return pack(rebuildOffset, lossFound);    }
public long offer(        final DirectBuffer buffer,        final int offset,        final int length,        final ReservedValueSupplier reservedValueSupplier)    {        long newPosition = CLOSED;        if (!isClosed)        {            final long limit = positionLimit.getVolatile();            final int termCount = activeTermCount(logMetaDataBuffer);            final TermAppender termAppender = termAppenders[indexByTermCount(termCount)];            final long rawTail = termAppender.rawTailVolatile();            final long termOffset = rawTail & 0xFFFF_FFFFL;            final int termId = termId(rawTail);            final long position = computeTermBeginPosition(termId, positionBitsToShift, initialTermId) + termOffset;            if (termCount != (termId - initialTermId))            {                return ADMIN_ACTION;            }            if (position < limit)            {                final int resultingOffset;                if (length <= maxPayloadLength)                {                    checkPositiveLength(length);                    resultingOffset = termAppender.appendUnfragmentedMessage(                        headerWriter, buffer, offset, length, reservedValueSupplier, termId);                }                else                {                    checkMaxMessageLength(length);                    resultingOffset = termAppender.appendFragmentedMessage(                        headerWriter, buffer, offset, length, maxPayloadLength, reservedValueSupplier, termId);                }                newPosition = newPosition(termCount, (int)termOffset, termId, position, resultingOffset);            }            else            {                newPosition = backPressureStatus(position, length);            }        }        return newPosition;    }
public long offer(        final DirectBuffer bufferOne,        final int offsetOne,        final int lengthOne,        final DirectBuffer bufferTwo,        final int offsetTwo,        final int lengthTwo,        final ReservedValueSupplier reservedValueSupplier)    {        long newPosition = CLOSED;        if (!isClosed)        {            final long limit = positionLimit.getVolatile();            final int termCount = activeTermCount(logMetaDataBuffer);            final TermAppender termAppender = termAppenders[indexByTermCount(termCount)];            final long rawTail = termAppender.rawTailVolatile();            final long termOffset = rawTail & 0xFFFF_FFFFL;            final int termId = termId(rawTail);            final long position = computeTermBeginPosition(termId, positionBitsToShift, initialTermId) + termOffset;            if (termCount != (termId - initialTermId))            {                return ADMIN_ACTION;            }            final int length = validateAndComputeLength(lengthOne, lengthTwo);            if (position < limit)            {                final int resultingOffset;                if (length <= maxPayloadLength)                {                    resultingOffset = termAppender.appendUnfragmentedMessage(                        headerWriter,                        bufferOne, offsetOne, lengthOne,                        bufferTwo, offsetTwo, lengthTwo,                        reservedValueSupplier,                        termId);                }                else                {                    checkMaxMessageLength(length);                    resultingOffset = termAppender.appendFragmentedMessage(                        headerWriter,                        bufferOne, offsetOne, lengthOne,                        bufferTwo, offsetTwo, lengthTwo,                        maxPayloadLength,                        reservedValueSupplier,                        termId);                }                newPosition = newPosition(termCount, (int)termOffset, termId, position, resultingOffset);            }            else            {                newPosition = backPressureStatus(position, length);            }        }        return newPosition;    }
public long tryClaim(final int length, final BufferClaim bufferClaim)    {        checkPayloadLength(length);        long newPosition = CLOSED;        if (!isClosed)        {            final long limit = positionLimit.getVolatile();            final int termCount = activeTermCount(logMetaDataBuffer);            final TermAppender termAppender = termAppenders[indexByTermCount(termCount)];            final long rawTail = termAppender.rawTailVolatile();            final long termOffset = rawTail & 0xFFFF_FFFFL;            final int termId = termId(rawTail);            final long position = computeTermBeginPosition(termId, positionBitsToShift, initialTermId) + termOffset;            if (termCount != (termId - initialTermId))            {                return ADMIN_ACTION;            }            if (position < limit)            {                final int resultingOffset = termAppender.claim(headerWriter, length, bufferClaim, termId);                newPosition = newPosition(termCount, (int)termOffset, termId, position, resultingOffset);            }            else            {                newPosition = backPressureStatus(position, length);            }        }        return newPosition;    }
public static int scan(final UnsafeBuffer termBuffer, final int termOffset, final int limitOffset)    {        int offset = termOffset;        while (offset < limitOffset)        {            final int frameLength = frameLengthVolatile(termBuffer, offset);            if (frameLength <= 0)            {                break;            }            final int alignedFrameLength = align(frameLength, FRAME_ALIGNMENT);            if (isPaddingFrame(termBuffer, offset))            {                if (termOffset == offset)                {                    offset += alignedFrameLength;                }                break;            }            if (offset + alignedFrameLength > limitOffset)            {                break;            }            offset += alignedFrameLength;        }        return offset;    }
public static void main(final String[] args)    {        loadPropertiesFiles(args);        try (ConsensusModule consensusModule = launch())        {            consensusModule.context().shutdownSignalBarrier().await();            System.out.println("Shutdown ConsensusModule...");        }    }
public static AtomicCounter allocate(        final MutableDirectBuffer tempBuffer,        final String name,        final int typeId,        final CountersManager countersManager,        final long registrationId)    {        return new AtomicCounter(            countersManager.valuesBuffer(),            allocateCounterId(tempBuffer, name, typeId, countersManager, registrationId),            countersManager);    }
public static Aeron connect(final Context ctx)    {        try        {            final Aeron aeron = new Aeron(ctx);            if (ctx.useConductorAgentInvoker())            {                aeron.conductorInvoker.start();            }            else            {                AgentRunner.startOnThread(aeron.conductorRunner, ctx.threadFactory());            }            return aeron;        }        catch (final Exception ex)        {            ctx.close();            throw ex;        }    }
public void printCounters(final PrintStream out)    {        final CountersReader counters = countersReader();        counters.forEach((value, id, label) -> out.format("%3d: %,20d - %s%n", id, value, label));    }
public Subscription addSubscription(        final String channel,        final int streamId,        final AvailableImageHandler availableImageHandler,        final UnavailableImageHandler unavailableImageHandler)    {        return conductor.addSubscription(channel, streamId, availableImageHandler, unavailableImageHandler);    }
public Counter addCounter(        final int typeId,        final DirectBuffer keyBuffer,        final int keyOffset,        final int keyLength,        final DirectBuffer labelBuffer,        final int labelOffset,        final int labelLength)    {        return conductor.addCounter(typeId, keyBuffer, keyOffset, keyLength, labelBuffer, labelOffset, labelLength);    }
public Context conclude()        {            super.conclude();            if (null == clientLock)            {                clientLock = new ReentrantLock();            }            if (null == epochClock)            {                epochClock = new SystemEpochClock();            }            if (null == nanoClock)            {                nanoClock = new SystemNanoClock();            }            if (null == idleStrategy)            {                idleStrategy = new SleepingMillisIdleStrategy(Configuration.IDLE_SLEEP_MS);            }            if (cncFile() != null)            {                connectToDriver();            }            interServiceTimeoutNs = CncFileDescriptor.clientLivenessTimeout(cncMetaDataBuffer);            if (interServiceTimeoutNs <= keepAliveIntervalNs)            {                throw new ConfigurationException("interServiceTimeoutNs=" + interServiceTimeoutNs +                    " <= keepAliveIntervalNs=" + keepAliveIntervalNs);            }            if (null == toDriverBuffer)            {                toDriverBuffer = new ManyToOneRingBuffer(                    CncFileDescriptor.createToDriverBuffer(cncByteBuffer, cncMetaDataBuffer));            }            if (null == toClientBuffer)            {                toClientBuffer = new CopyBroadcastReceiver(new BroadcastReceiver(                    CncFileDescriptor.createToClientsBuffer(cncByteBuffer, cncMetaDataBuffer)));            }            if (countersMetaDataBuffer() == null)            {                countersMetaDataBuffer(                    CncFileDescriptor.createCountersMetaDataBuffer(cncByteBuffer, cncMetaDataBuffer));            }            if (countersValuesBuffer() == null)            {                countersValuesBuffer(CncFileDescriptor.createCountersValuesBuffer(cncByteBuffer, cncMetaDataBuffer));            }            if (null == logBuffersFactory)            {                logBuffersFactory = new MappedLogBuffersFactory();            }            if (null == errorHandler)            {                errorHandler = Configuration.DEFAULT_ERROR_HANDLER;            }            if (null == driverProxy)            {                clientId = toDriverBuffer.nextCorrelationId();                driverProxy = new DriverProxy(toDriverBuffer, clientId);            }            return this;        }
public void close()        {            final MappedByteBuffer cncByteBuffer = this.cncByteBuffer;            this.cncByteBuffer = null;            IoUtil.unmap(cncByteBuffer);            super.close();        }
public static void dispatchDescriptor(        final RecordingDescriptorDecoder decoder, final RecordingDescriptorConsumer consumer)    {        consumer.onRecordingDescriptor(            decoder.controlSessionId(),            decoder.correlationId(),            decoder.recordingId(),            decoder.startTimestamp(),            decoder.stopTimestamp(),            decoder.startPosition(),            decoder.stopPosition(),            decoder.initialTermId(),            decoder.segmentFileLength(),            decoder.termBufferLength(),            decoder.mtuLength(),            decoder.sessionId(),            decoder.streamId(),            decoder.strippedChannel(),            decoder.originalChannel(),            decoder.sourceIdentity());    }
public static void insert(        final UnsafeBuffer termBuffer, final int termOffset, final UnsafeBuffer packet, final int length)    {        if (0 == termBuffer.getInt(termOffset))        {            termBuffer.putBytes(termOffset + HEADER_LENGTH, packet, HEADER_LENGTH, length - HEADER_LENGTH);            termBuffer.putLong(termOffset + 24, packet.getLong(24));            termBuffer.putLong(termOffset + 16, packet.getLong(16));            termBuffer.putLong(termOffset + 8, packet.getLong(8));            termBuffer.putLongOrdered(termOffset, packet.getLong(0));        }    }
public static CapacityByteArrayOutputStream withTargetNumSlabs(      int minSlabSize, int maxCapacityHint, int targetNumSlabs, ByteBufferAllocator allocator) {    return new CapacityByteArrayOutputStream(        initialSlabSizeHeuristic(minSlabSize, maxCapacityHint, targetNumSlabs),        maxCapacityHint, allocator);  }
private void addSlab(int minimumSize) {    int nextSlabSize;    if (bytesUsed == 0) {      nextSlabSize = initialSlabSize;    } else if (bytesUsed > maxCapacityHint / 5) {      // to avoid an overhead of up to twice the needed size, we get linear when approaching target page size      nextSlabSize = maxCapacityHint / 5;    } else {      // double the size every time      nextSlabSize = bytesUsed;    }    if (nextSlabSize < minimumSize) {      LOG.debug("slab size {} too small for value of size {}. Bumping up slab size", nextSlabSize, minimumSize);      nextSlabSize = minimumSize;    }    LOG.debug("used {} slabs, adding new slab of size {}", slabs.size(), nextSlabSize);    this.currentSlab = allocator.allocate(nextSlabSize);    this.slabs.add(currentSlab);    this.bytesAllocated += nextSlabSize;    this.currentSlabIndex = 0;  }
public void writeTo(OutputStream out) throws IOException {    for (int i = 0; i < slabs.size() - 1; i++) {      writeToOutput(out, slabs.get(i), slabs.get(i).position());    }    writeToOutput(out, currentSlab, currentSlabIndex);  }
public void reset() {    // readjust slab size.    // 7 = 2^3 - 1 so that doubling the initial size 3 times will get to the same size    this.initialSlabSize = max(bytesUsed / 7, initialSlabSize);    LOG.debug("initial slab of size {}", initialSlabSize);    for (ByteBuffer slab : slabs) {      allocator.release(slab);    }    this.slabs.clear();    this.bytesAllocated = 0;    this.bytesUsed = 0;    this.currentSlab = EMPTY_SLAB;    this.currentSlabIndex = 0;  }
public void setByte(long index, byte value) {    checkArgument(index < bytesUsed, "Index: " + index + " is >= the current size of: " + bytesUsed);    long seen = 0;    for (int i = 0; i < slabs.size(); i++) {      ByteBuffer slab = slabs.get(i);      if (index < seen + slab.limit()) {        // ok found index        slab.put((int)(index-seen), value);        break;      }      seen += slab.limit();    }  }
public void add(Statistics<?> stats) {    if (stats.hasNonNullValue()) {      nullPages.add(false);      Object min = stats.genericGetMin();      Object max = stats.genericGetMax();      addMinMax(min, max);      pageIndexes.add(nextPageIndex);      minMaxSize += sizeOf(min);      minMaxSize += sizeOf(max);    } else {      nullPages.add(true);    }    nullCounts.add(stats.getNumNulls());    ++nextPageIndex;  }
private boolean isDescending(PrimitiveComparator<Binary> comparator) {    for (int i = 1, n = pageIndexes.size(); i < n; ++i) {      if (compareMinValues(comparator, i - 1, i) < 0 || compareMaxValues(comparator, i - 1, i) < 0) {        return false;      }    }    return true;  }
@Deprecated  public void initFromPage(int valueCount, ByteBuffer page, int offset) throws IOException {    if (offset < 0) {      throw new IllegalArgumentException("Illegal offset: " + offset);    }    actualOffset = offset;    ByteBuffer pageWithOffset = page.duplicate();    pageWithOffset.position(offset);    initFromPage(valueCount, ByteBufferInputStream.wrap(pageWithOffset));    actualOffset = -1;  }
@Deprecated  public void initFromPage(int valueCount, byte[] page, int offset) throws IOException {    this.initFromPage(valueCount, ByteBuffer.wrap(page), offset);  }
public void initFromPage(int valueCount, ByteBufferInputStream in) throws IOException {    if (actualOffset != -1) {      throw new UnsupportedOperationException(          "Either initFromPage(int, ByteBuffer, int) or initFromPage(int, ByteBufferInputStream) must be implemented in "              + getClass().getName());    }    initFromPage(valueCount, in.slice(valueCount), 0);  }
public static void setRequestedProjection(Job job, Schema requestedProjection) {    AvroReadSupport.setRequestedProjection(ContextUtil.getConfiguration(job),        requestedProjection);  }
public static void setAvroReadSchema(Job job, Schema avroReadSchema) {    AvroReadSupport.setAvroReadSchema(ContextUtil.getConfiguration(job), avroReadSchema);  }
public static void setAvroDataSupplier(Job job,      Class<? extends AvroDataSupplier> supplierClass) {    AvroReadSupport.setAvroDataSupplier(ContextUtil.getConfiguration(job), supplierClass);  }
@Override  public Converter getConverter(int fieldIndex) {    // get the real converter from the delegate    Converter delegateConverter = checkNotNull(delegate.getConverter(fieldIndex), "delegate converter");    // determine the indexFieldPath for the converter proxy we're about to make, which is    // this converter's path + the requested fieldIndex    List<Integer> newIndexFieldPath = new ArrayList<Integer>(indexFieldPath.size() + 1);    newIndexFieldPath.addAll(indexFieldPath);    newIndexFieldPath.add(fieldIndex);    if (delegateConverter.isPrimitive()) {      PrimitiveColumnIO columnIO = getColumnIO(newIndexFieldPath);      ColumnPath columnPath = ColumnPath.get(columnIO.getColumnDescriptor().getPath());      ValueInspector[] valueInspectors = getValueInspectors(columnPath);      return new FilteringPrimitiveConverter(delegateConverter.asPrimitiveConverter(), valueInspectors);    } else {      return new FilteringGroupConverter(delegateConverter.asGroupConverter(), newIndexFieldPath, valueInspectorsByColumn, columnIOsByIndexFieldPath);    }  }
public static RowRanges calculateRowRanges(FilterCompat.Filter filter, ColumnIndexStore columnIndexStore,      Set<ColumnPath> paths, long rowCount) {    return filter.accept(new FilterCompat.Visitor<RowRanges>() {      @Override      public RowRanges visit(FilterPredicateCompat filterPredicateCompat) {        try {          return filterPredicateCompat.getFilterPredicate()              .accept(new ColumnIndexFilter(columnIndexStore, paths, rowCount));        } catch (MissingOffsetIndexException e) {          LOGGER.info(e.getMessage());          return RowRanges.createSingle(rowCount);        }      }      @Override      public RowRanges visit(UnboundRecordFilterCompat unboundRecordFilterCompat) {        return RowRanges.createSingle(rowCount);      }      @Override      public RowRanges visit(NoOpFilter noOpFilter) {        return RowRanges.createSingle(rowCount);      }    });  }
public static <T> void setThriftClass(JobConf conf, Class<T> klass) {    conf.set(ThriftReadSupport.THRIFT_READ_CLASS_KEY, klass.getName());  }
private static GroupType convertArrayType(final String name, final ListTypeInfo typeInfo) {    final TypeInfo subType = typeInfo.getListElementTypeInfo();    return listWrapper(name, listType(), new GroupType(Repetition.REPEATED,        ParquetHiveSerDe.ARRAY.toString(), convertType("array_element", subType)));  }
private static GroupType convertStructType(final String name, final StructTypeInfo typeInfo) {    final List<String> columnNames = typeInfo.getAllStructFieldNames();    final List<TypeInfo> columnTypes = typeInfo.getAllStructFieldTypeInfos();    return new GroupType(Repetition.OPTIONAL, name, convertTypes(columnNames, columnTypes));  }
private static GroupType convertMapType(final String name, final MapTypeInfo typeInfo) {    final Type keyType = convertType(ParquetHiveSerDe.MAP_KEY.toString(),        typeInfo.getMapKeyTypeInfo(), Repetition.REQUIRED);    final Type valueType = convertType(ParquetHiveSerDe.MAP_VALUE.toString(),        typeInfo.getMapValueTypeInfo());    return ConversionPatterns.mapType(Repetition.OPTIONAL, name, keyType, valueType);  }
public static List<String> expand(String globPattern) {    return GlobExpanderImpl.expand(GlobParser.parse(globPattern));  }
static RowRanges createSingle(long rowCount) {    RowRanges ranges = new RowRanges();    ranges.add(new Range(0, rowCount - 1));    return ranges;  }
static RowRanges create(long rowCount, PrimitiveIterator.OfInt pageIndexes, OffsetIndex offsetIndex) {    RowRanges ranges = new RowRanges();    while (pageIndexes.hasNext()) {      int pageIndex = pageIndexes.nextInt();      ranges.add(new Range(offsetIndex.getFirstRowIndex(pageIndex), offsetIndex.getLastRowIndex(pageIndex, rowCount)));    }    return ranges;  }
static RowRanges union(RowRanges left, RowRanges right) {    RowRanges result = new RowRanges();    Iterator<Range> it1 = left.ranges.iterator();    Iterator<Range> it2 = right.ranges.iterator();    if (it2.hasNext()) {      Range range2 = it2.next();      while (it1.hasNext()) {        Range range1 = it1.next();        if (range1.isAfter(range2)) {          result.add(range2);          range2 = range1;          Iterator<Range> tmp = it1;          it1 = it2;          it2 = tmp;        } else {          result.add(range1);        }      }      result.add(range2);    } else {      it2 = it1;    }    while (it2.hasNext()) {      result.add(it2.next());    }    return result;  }
static RowRanges intersection(RowRanges left, RowRanges right) {    RowRanges result = new RowRanges();    int rightIndex = 0;    for (Range l : left.ranges) {      for (int i = rightIndex, n = right.ranges.size(); i < n; ++i) {        Range r = right.ranges.get(i);        if (l.isBefore(r)) {          break;        } else if (l.isAfter(r)) {          rightIndex = i + 1;          continue;        }        result.add(Range.intersection(l, r));      }    }    return result;  }
private void add(Range range) {    Range rangeToAdd = range;    for (int i = ranges.size() - 1; i >= 0; --i) {      Range last = ranges.get(i);      assert !last.isAfter(range);      Range u = Range.union(last, rangeToAdd);      if (u == null) {        break;      }      rangeToAdd = u;      ranges.remove(i);    }    ranges.add(rangeToAdd);  }
private int positiveLongToInt(long value) {    if (!ColumnChunkMetaData.positiveLongFitsInAnInt(value)) {      throw new IllegalArgumentException("value should be positive and fit in an int: " + value);    }    return (int)(value + Integer.MIN_VALUE);  }
public static GlobNodeSequence parse(String pattern) {    /*     * The parse algorithm works as follows, assuming we are parsing:     * "apache{one,pre{x,y}post,two}parquet{a,b}"     *     * 1) Begin scanning the string until we find the first {     *     * 2) Now that we've found the beginning of a glob group, scan forwards     *    until the end of this glob group (by counting { and } we see until we find     *    the closing } for the group we found in step 1).     *     * 3) Once the matching closing } is found we need to do two things. First, everything     *    from the end of the last group up to start of this group is an Atom, so in the example     *    above, once we've found that "{one,pre{x,y}post,two}" is the first group, we need to grab     *    "apache" and treat it as an atom and add it to our sequence.     *    Then, we parse "{one,pre{x,y}post,two}" using a similar but slightly different function (parseOneOf)     *    and add the result from that to our sequence.     *     * 4) Repeat until the end of the string -- so next we find {a,b} and add "parquet" as an Atom and parse     *    {a,b} using parseOneOf.     */    if (pattern.isEmpty() || pattern.equals("{}")) {      return new GlobNodeSequence(Arrays.<GlobNode>asList(new Atom("")));    }    // the outer parse method needs to parse the pattern into a    // GlobNodeSequence, though it may end up being a singleton sequence    List<GlobNode> children = new ArrayList<GlobNode>();    int unmatchedBraces = 0; // count of unmatched braces    int firstBrace = 0; // open brace of current group being processsed    int anchor = 0; // first un-parsed character position    for (int i = 0; i < pattern.length(); i++) {      char c = pattern.charAt(i);      switch (c) {        case ',':          if (unmatchedBraces == 0) {            // commas not allowed in the top level expression            // TODO: maybe turn this check off?            throw new GlobParseException("Unexpected comma outside of a {} group:\n"                + annotateMessage(pattern, i));          }          break;        case '{':          if (unmatchedBraces == 0) {            // this is the first brace of an outermost {} group            firstBrace = i;          }          unmatchedBraces++;          break;        case '}':          unmatchedBraces--;          if (unmatchedBraces < 0) {            throw new GlobParseException("Unexpected closing }:\n"                + annotateMessage(pattern, i));          }          if (unmatchedBraces == 0) {            // grab everything from the end of the last group up to here,            // not including the close brace, it is an Atom in our sequence            // (assuming it's not empty)            if (anchor != firstBrace) {              // not empty!              // (substring's end param is exclusive)              children.add(new Atom(pattern.substring(anchor, firstBrace)));            }            // grab the group, parse it, add it to our sequence, and then continue            // note that we skip the braces on both sides (substring's end param is exclusive)            children.add(parseOneOf(pattern.substring(firstBrace + 1, i)));            // we have now parsed all the way up to here, the next un-parsed char is i + 1            anchor = i + 1;          }          break;      }    }    if (unmatchedBraces > 0) {      throw new GlobParseException("Not enough close braces in: " + pattern);    }    if (anchor != pattern.length()) {      // either there were no {} groups, or there were some characters after the      // last }, either way whatever is left (could be the entire input) is an Atom      // in our sequence      children.add(new Atom(pattern.substring(anchor, pattern.length())));    }    return new GlobNodeSequence(children);  }
private static String annotateMessage(String message, int pos) {    StringBuilder sb = new StringBuilder(message);    sb.append('\n');    for (int i = 0; i < pos; i++) {      sb.append('-');    }    sb.append('^');    return sb.toString();  }
private void endPreviousBitPackedRun() {    if (bitPackedRunHeaderPointer == -1) {      // we're not currently in a bit-packed-run      return;    }    // create bit-packed-header, which needs to fit in 1 byte    byte bitPackHeader = (byte) ((bitPackedGroupCount << 1) | 1);    // update this byte    baos.setByte(bitPackedRunHeaderPointer, bitPackHeader);    // mark that this run is over    bitPackedRunHeaderPointer = -1;    // reset the number of groups    bitPackedGroupCount = 0;  }
@Override  public void readOne(TProtocol in, TProtocol out) throws TException {    readOneStruct(in, out);  }
public static Filter get(FilterPredicate filterPredicate) {    checkNotNull(filterPredicate, "filterPredicate");    LOG.info("Filtering using predicate: {}", filterPredicate);    // rewrite the predicate to not include the not() operator    FilterPredicate collapsedPredicate = LogicalInverseRewriter.rewrite(filterPredicate);    if (!filterPredicate.equals(collapsedPredicate)) {      LOG.info("Predicate has been collapsed to: {}", collapsedPredicate);    }    return new FilterPredicateCompat(collapsedPredicate);  }
public static Filter get(FilterPredicate filterPredicate, UnboundRecordFilter unboundRecordFilter) {    checkArgument(filterPredicate == null || unboundRecordFilter == null,        "Cannot provide both a FilterPredicate and an UnboundRecordFilter");    if (filterPredicate != null) {      return get(filterPredicate);    }    if (unboundRecordFilter != null) {      return get(unboundRecordFilter);    }    return NOOP;  }
@Deprecated  public static List<Footer> readAllFootersInParallelUsingSummaryFiles(Configuration configuration, List<FileStatus> partFiles) throws IOException {    return readAllFootersInParallelUsingSummaryFiles(configuration, partFiles, false);  }
@Deprecated  public static List<Footer> readAllFootersInParallelUsingSummaryFiles(      final Configuration configuration,      final Collection<FileStatus> partFiles,      final boolean skipRowGroups) throws IOException {    // figure out list of all parents to part files    Set<Path> parents = new HashSet<Path>();    for (FileStatus part : partFiles) {      parents.add(part.getPath().getParent());    }    // read corresponding summary files if they exist    List<Callable<Map<Path, Footer>>> summaries = new ArrayList<Callable<Map<Path, Footer>>>();    for (final Path path : parents) {      summaries.add(new Callable<Map<Path, Footer>>() {        @Override        public Map<Path, Footer> call() throws Exception {          ParquetMetadata mergedMetadata = readSummaryMetadata(configuration, path, skipRowGroups);          if (mergedMetadata != null) {            final List<Footer> footers;            if (skipRowGroups) {              footers = new ArrayList<Footer>();              for (FileStatus f : partFiles) {                footers.add(new Footer(f.getPath(), mergedMetadata));              }            } else {              footers = footersFromSummaryFile(path, mergedMetadata);            }            Map<Path, Footer> map = new HashMap<Path, Footer>();            for (Footer footer : footers) {              // the folder may have been moved              footer = new Footer(new Path(path, footer.getFile().getName()), footer.getParquetMetadata());              map.put(footer.getFile(), footer);            }            return map;          } else {            return Collections.emptyMap();          }        }      });    }    Map<Path, Footer> cache = new HashMap<Path, Footer>();    try {      List<Map<Path, Footer>> footersFromSummaries = runAllInParallel(configuration.getInt(PARQUET_READ_PARALLELISM, 5), summaries);      for (Map<Path, Footer> footers : footersFromSummaries) {        cache.putAll(footers);      }    } catch (ExecutionException e) {      throw new IOException("Error reading summaries", e);    }    // keep only footers for files actually requested and read file footer if not found in summaries    List<Footer> result = new ArrayList<Footer>(partFiles.size());    List<FileStatus> toRead = new ArrayList<FileStatus>();    for (FileStatus part : partFiles) {      Footer f = cache.get(part.getPath());      if (f != null) {        result.add(f);      } else {        toRead.add(part);      }    }    if (toRead.size() > 0) {      // read the footers of the files that did not have a summary file      LOG.info("reading another {} footers", toRead.size());      result.addAll(readAllFootersInParallel(configuration, toRead, skipRowGroups));    }    return result;  }
@Deprecated  public static List<Footer> readAllFootersInParallel(final Configuration configuration, List<FileStatus> partFiles, final boolean skipRowGroups) throws IOException {    List<Callable<Footer>> footers = new ArrayList<Callable<Footer>>();    for (final FileStatus currentFile : partFiles) {      footers.add(new Callable<Footer>() {        @Override        public Footer call() throws Exception {          try {            return new Footer(currentFile.getPath(), readFooter(configuration, currentFile, filter(skipRowGroups)));          } catch (IOException e) {            throw new IOException("Could not read footer for file " + currentFile, e);          }        }      });    }    try {      return runAllInParallel(configuration.getInt(PARQUET_READ_PARALLELISM, 5), footers);    } catch (ExecutionException e) {      throw new IOException("Could not read footer: " + e.getMessage(), e.getCause());    }  }
@Deprecated  public static List<Footer> readAllFootersInParallel(Configuration configuration, FileStatus fileStatus, boolean skipRowGroups) throws IOException {    List<FileStatus> statuses = listFiles(configuration, fileStatus);    return readAllFootersInParallel(configuration, statuses, skipRowGroups);  }
@Deprecated  public static List<Footer> readAllFootersInParallel(Configuration configuration, FileStatus fileStatus) throws IOException {    return readAllFootersInParallel(configuration, fileStatus, false);  }
@Deprecated  public static List<Footer> readFooters(Configuration configuration, FileStatus pathStatus) throws IOException {    return readFooters(configuration, pathStatus, false);  }
@Deprecated  public static List<Footer> readFooters(Configuration configuration, FileStatus pathStatus, boolean skipRowGroups) throws IOException {    List<FileStatus> files = listFiles(configuration, pathStatus);    return readAllFootersInParallelUsingSummaryFiles(configuration, files, skipRowGroups);  }
@Deprecated  public static List<Footer> readSummaryFile(Configuration configuration, FileStatus summaryStatus) throws IOException {    final Path parent = summaryStatus.getPath().getParent();    ParquetMetadata mergedFooters = readFooter(configuration, summaryStatus, filter(false));    return footersFromSummaryFile(parent, mergedFooters);  }
@Deprecated  public static final ParquetMetadata readFooter(Configuration configuration, Path file) throws IOException {    return readFooter(configuration, file, NO_FILTER);  }
public static ParquetMetadata readFooter(Configuration configuration, Path file, MetadataFilter filter) throws IOException {    return readFooter(HadoopInputFile.fromPath(file, configuration), filter);  }
@Deprecated  public static final ParquetMetadata readFooter(Configuration configuration, FileStatus file, MetadataFilter filter) throws IOException {    return readFooter(HadoopInputFile.fromStatus(file, configuration), filter);  }
@Deprecated  public static final ParquetMetadata readFooter(InputFile file, MetadataFilter filter) throws IOException {    ParquetReadOptions options;    if (file instanceof HadoopInputFile) {      options = HadoopReadOptions.builder(((HadoopInputFile) file).getConfiguration())          .withMetadataFilter(filter).build();    } else {      options = ParquetReadOptions.builder().withMetadataFilter(filter).build();    }    try (SeekableInputStream in = file.newStream()) {      return readFooter(file, options, in);    }  }
public static ParquetFileReader open(InputFile file) throws IOException {    return new ParquetFileReader(file, ParquetReadOptions.builder().build());  }
public static ParquetFileReader open(InputFile file, ParquetReadOptions options) throws IOException {    return new ParquetFileReader(file, options);  }
public PageReadStore readNextRowGroup() throws IOException {    if (currentBlock == blocks.size()) {      return null;    }    BlockMetaData block = blocks.get(currentBlock);    if (block.getRowCount() == 0) {      throw new RuntimeException("Illegal row group of 0 rows");    }    this.currentRowGroup = new ColumnChunkPageReadStore(block.getRowCount());    // prepare the list of consecutive parts to read them in one scan    List<ConsecutivePartList> allParts = new ArrayList<ConsecutivePartList>();    ConsecutivePartList currentParts = null;    for (ColumnChunkMetaData mc : block.getColumns()) {      ColumnPath pathKey = mc.getPath();      BenchmarkCounter.incrementTotalBytes(mc.getTotalSize());      ColumnDescriptor columnDescriptor = paths.get(pathKey);      if (columnDescriptor != null) {        long startingPos = mc.getStartingPos();        // first part or not consecutive => new list        if (currentParts == null || currentParts.endPos() != startingPos) {          currentParts = new ConsecutivePartList(startingPos);          allParts.add(currentParts);        }        currentParts.addChunk(new ChunkDescriptor(columnDescriptor, mc, startingPos, (int)mc.getTotalSize()));      }    }    // actually read all the chunks    ChunkListBuilder builder = new ChunkListBuilder();    for (ConsecutivePartList consecutiveChunks : allParts) {      consecutiveChunks.readAll(f, builder);    }    for (Chunk chunk : builder.build()) {      currentRowGroup.addColumn(chunk.descriptor.col, chunk.readAllPages());    }    // avoid re-reading bytes the dictionary reader is used after this call    if (nextDictionaryReader != null) {      nextDictionaryReader.setRowGroup(currentRowGroup);    }    advanceToNextBlock();    return currentRowGroup;  }
public PageReadStore readNextFilteredRowGroup() throws IOException {    if (currentBlock == blocks.size()) {      return null;    }    if (!options.useColumnIndexFilter()) {      return readNextRowGroup();    }    BlockMetaData block = blocks.get(currentBlock);    if (block.getRowCount() == 0) {      throw new RuntimeException("Illegal row group of 0 rows");    }    ColumnIndexStore ciStore = getColumnIndexStore(currentBlock);    RowRanges rowRanges = getRowRanges(currentBlock);    long rowCount = rowRanges.rowCount();    if (rowCount == 0) {      // There are no matching rows -> skipping this row-group      advanceToNextBlock();      return readNextFilteredRowGroup();    }    if (rowCount == block.getRowCount()) {      // All rows are matching -> fall back to the non-filtering path      return readNextRowGroup();    }    this.currentRowGroup = new ColumnChunkPageReadStore(rowRanges);    // prepare the list of consecutive parts to read them in one scan    ChunkListBuilder builder = new ChunkListBuilder();    List<ConsecutivePartList> allParts = new ArrayList<ConsecutivePartList>();    ConsecutivePartList currentParts = null;    for (ColumnChunkMetaData mc : block.getColumns()) {      ColumnPath pathKey = mc.getPath();      ColumnDescriptor columnDescriptor = paths.get(pathKey);      if (columnDescriptor != null) {        OffsetIndex offsetIndex = ciStore.getOffsetIndex(mc.getPath());        OffsetIndex filteredOffsetIndex = filterOffsetIndex(offsetIndex, rowRanges,            block.getRowCount());        for (OffsetRange range : calculateOffsetRanges(filteredOffsetIndex, mc, offsetIndex.getOffset(0))) {          BenchmarkCounter.incrementTotalBytes(range.getLength());          long startingPos = range.getOffset();          // first part or not consecutive => new list          if (currentParts == null || currentParts.endPos() != startingPos) {            currentParts = new ConsecutivePartList(startingPos);            allParts.add(currentParts);          }          ChunkDescriptor chunkDescriptor = new ChunkDescriptor(columnDescriptor, mc, startingPos,              (int) range.getLength());          currentParts.addChunk(chunkDescriptor);          builder.setOffsetIndex(chunkDescriptor, filteredOffsetIndex);        }      }    }    // actually read all the chunks    for (ConsecutivePartList consecutiveChunks : allParts) {      consecutiveChunks.readAll(f, builder);    }    for (Chunk chunk : builder.build()) {      currentRowGroup.addColumn(chunk.descriptor.col, chunk.readAllPages());    }    // avoid re-reading bytes the dictionary reader is used after this call    if (nextDictionaryReader != null) {      nextDictionaryReader.setRowGroup(currentRowGroup);    }    advanceToNextBlock();    return currentRowGroup;  }
public DictionaryPageReadStore getNextDictionaryReader() {    if (nextDictionaryReader == null && currentBlock < blocks.size()) {      this.nextDictionaryReader = getDictionaryReader(blocks.get(currentBlock));    }    return nextDictionaryReader;  }
DictionaryPage readDictionary(ColumnChunkMetaData meta) throws IOException {    if (!meta.getEncodings().contains(Encoding.PLAIN_DICTIONARY) &&        !meta.getEncodings().contains(Encoding.RLE_DICTIONARY)) {      return null;    }    // TODO: this should use getDictionaryPageOffset() but it isn't reliable.    if (f.getPos() != meta.getStartingPos()) {      f.seek(meta.getStartingPos());    }    PageHeader pageHeader = Util.readPageHeader(f);    if (!pageHeader.isSetDictionary_page_header()) {      return null; // TODO: should this complain?    }    DictionaryPage compressedPage = readCompressedDictionary(pageHeader, f);    BytesInputDecompressor decompressor = options.getCodecFactory().getDecompressor(meta.getCodec());    return new DictionaryPage(        decompressor.decompress(compressedPage.getBytes(), compressedPage.getUncompressedSize()),        compressedPage.getDictionarySize(),        compressedPage.getEncoding());  }
synchronized void addWriter(InternalParquetRecordWriter writer, Long allocation) {    Long oldValue = writerList.get(writer);    if (oldValue == null) {      writerList.put(writer, allocation);    } else {      throw new IllegalArgumentException("[BUG] The Parquet Memory Manager should not add an " +          "instance of InternalParquetRecordWriter more than once. The Manager already contains " +          "the writer: " + writer);    }    updateAllocation();  }
synchronized void removeWriter(InternalParquetRecordWriter writer) {    if (writerList.containsKey(writer)) {      writerList.remove(writer);    }    if (!writerList.isEmpty()) {      updateAllocation();    }  }
private void updateAllocation() {    long totalAllocations = 0;    for (Long allocation : writerList.values()) {      totalAllocations += allocation;    }    if (totalAllocations <= totalMemoryPool) {      scale = 1.0;    } else {      scale = (double) totalMemoryPool / totalAllocations;      LOG.warn(String.format(          "Total allocation exceeds %.2f%% (%,d bytes) of heap memory\n" +          "Scaling row group sizes to %.2f%% for %d writers",          100*memoryPoolRatio, totalMemoryPool, 100*scale, writerList.size()));      for (Runnable callBack : callBacks.values()) {        // we do not really want to start a new thread here.        callBack.run();      }    }    int maxColCount = 0;    for (InternalParquetRecordWriter w : writerList.keySet()) {      maxColCount = Math.max(w.getSchema().getColumns().size(), maxColCount);    }    for (Map.Entry<InternalParquetRecordWriter, Long> entry : writerList.entrySet()) {      long newSize = (long) Math.floor(entry.getValue() * scale);      if(scale < 1.0 && minMemoryAllocation > 0 && newSize < minMemoryAllocation) {          throw new ParquetRuntimeException(String.format("New Memory allocation %d bytes" +          " is smaller than the minimum allocation size of %d bytes.",              newSize, minMemoryAllocation)){};      }      entry.getKey().setRowGroupSizeThreshold(newSize);      LOG.debug(String.format("Adjust block size from %,d to %,d for writer: %s",            entry.getValue(), newSize, entry.getKey()));    }  }
public void registerScaleCallBack(String callBackName, Runnable callBack) {    Preconditions.checkNotNull(callBackName, "callBackName");    Preconditions.checkNotNull(callBack, "callBack");    if (callBacks.containsKey(callBackName)) {      throw new IllegalArgumentException("The callBackName " + callBackName +          " is duplicated and has been registered already.");    } else {      callBacks.put(callBackName, callBack);    }  }
public void start() throws IOException {    state = state.start();    LOG.debug("{}: start", out.getPos());    out.write(MAGIC);  }
public void startBlock(long recordCount) throws IOException {    state = state.startBlock();    LOG.debug("{}: start block", out.getPos());//    out.write(MAGIC); // TODO: add a magic delimiter    alignment.alignForRowGroup(out);    currentBlock = new BlockMetaData();    currentRecordCount = recordCount;    currentColumnIndexes = new ArrayList<>();    currentOffsetIndexes = new ArrayList<>();  }
public void startColumn(ColumnDescriptor descriptor,                          long valueCount,                          CompressionCodecName compressionCodecName) throws IOException {    state = state.startColumn();    encodingStatsBuilder.clear();    currentEncodings = new HashSet<Encoding>();    currentChunkPath = ColumnPath.get(descriptor.getPath());    currentChunkType = descriptor.getPrimitiveType();    currentChunkCodec = compressionCodecName;    currentChunkValueCount = valueCount;    currentChunkFirstDataPage = out.getPos();    compressedLength = 0;    uncompressedLength = 0;    // The statistics will be copied from the first one added at writeDataPage(s) so we have the correct typed one    currentStatistics = null;    columnIndexBuilder = ColumnIndexBuilder.getBuilder(currentChunkType, columnIndexTruncateLength);    offsetIndexBuilder = OffsetIndexBuilder.getBuilder();    firstPageOffset = -1;  }
public void writeDictionaryPage(DictionaryPage dictionaryPage) throws IOException {    state = state.write();    LOG.debug("{}: write dictionary page: {} values", out.getPos(), dictionaryPage.getDictionarySize());    currentChunkDictionaryPageOffset = out.getPos();    int uncompressedSize = dictionaryPage.getUncompressedSize();    int compressedPageSize = (int)dictionaryPage.getBytes().size(); // TODO: fix casts    metadataConverter.writeDictionaryPageHeader(        uncompressedSize,        compressedPageSize,        dictionaryPage.getDictionarySize(),        dictionaryPage.getEncoding(),        out);    long headerSize = out.getPos() - currentChunkDictionaryPageOffset;    this.uncompressedLength += uncompressedSize + headerSize;    this.compressedLength += compressedPageSize + headerSize;    LOG.debug("{}: write dictionary page content {}", out.getPos(), compressedPageSize);    dictionaryPage.getBytes().writeAllTo(out);    encodingStatsBuilder.addDictEncoding(dictionaryPage.getEncoding());    currentEncodings.add(dictionaryPage.getEncoding());  }
@Deprecated  public void writeDataPage(      int valueCount, int uncompressedPageSize,      BytesInput bytes,      Encoding rlEncoding,      Encoding dlEncoding,      Encoding valuesEncoding) throws IOException {    state = state.write();    // We are unable to build indexes without rowCount so skip them for this column    offsetIndexBuilder = OffsetIndexBuilder.getNoOpBuilder();    columnIndexBuilder = ColumnIndexBuilder.getNoOpBuilder();    long beforeHeader = out.getPos();    LOG.debug("{}: write data page: {} values", beforeHeader, valueCount);    int compressedPageSize = (int)bytes.size();    metadataConverter.writeDataPageV1Header(        uncompressedPageSize, compressedPageSize,        valueCount,        rlEncoding,        dlEncoding,        valuesEncoding,        out);    long headerSize = out.getPos() - beforeHeader;    this.uncompressedLength += uncompressedPageSize + headerSize;    this.compressedLength += compressedPageSize + headerSize;    LOG.debug("{}: write data page content {}", out.getPos(), compressedPageSize);    bytes.writeAllTo(out);    encodingStatsBuilder.addDataEncoding(valuesEncoding);    currentEncodings.add(rlEncoding);    currentEncodings.add(dlEncoding);    currentEncodings.add(valuesEncoding);  }
@Deprecated  public void writeDataPage(      int valueCount, int uncompressedPageSize,      BytesInput bytes,      Statistics statistics,      Encoding rlEncoding,      Encoding dlEncoding,      Encoding valuesEncoding) throws IOException {    // We are unable to build indexes without rowCount so skip them for this column    offsetIndexBuilder = OffsetIndexBuilder.getNoOpBuilder();    columnIndexBuilder = ColumnIndexBuilder.getNoOpBuilder();    innerWriteDataPage(valueCount, uncompressedPageSize, bytes, statistics, rlEncoding, dlEncoding, valuesEncoding);  }
public void writeDataPage(      int valueCount, int uncompressedPageSize,      BytesInput bytes,      Statistics statistics,      long rowCount,      Encoding rlEncoding,      Encoding dlEncoding,      Encoding valuesEncoding) throws IOException {    long beforeHeader = out.getPos();    innerWriteDataPage(valueCount, uncompressedPageSize, bytes, statistics, rlEncoding, dlEncoding, valuesEncoding);    offsetIndexBuilder.add((int) (out.getPos() - beforeHeader), rowCount);  }
void writeColumnChunk(ColumnDescriptor descriptor,      long valueCount,      CompressionCodecName compressionCodecName,      DictionaryPage dictionaryPage,      BytesInput bytes,      long uncompressedTotalPageSize,      long compressedTotalPageSize,      Statistics<?> totalStats,      ColumnIndexBuilder columnIndexBuilder,      OffsetIndexBuilder offsetIndexBuilder,      Set<Encoding> rlEncodings,      Set<Encoding> dlEncodings,      List<Encoding> dataEncodings) throws IOException {    startColumn(descriptor, valueCount, compressionCodecName);    state = state.write();    if (dictionaryPage != null) {      writeDictionaryPage(dictionaryPage);    }    LOG.debug("{}: write data pages", out.getPos());    long headersSize = bytes.size() - compressedTotalPageSize;    this.uncompressedLength += uncompressedTotalPageSize + headersSize;    this.compressedLength += compressedTotalPageSize + headersSize;    LOG.debug("{}: write data pages content", out.getPos());    firstPageOffset = out.getPos();    bytes.writeAllTo(out);    encodingStatsBuilder.addDataEncodings(dataEncodings);    if (rlEncodings.isEmpty()) {      encodingStatsBuilder.withV2Pages();    }    currentEncodings.addAll(rlEncodings);    currentEncodings.addAll(dlEncodings);    currentEncodings.addAll(dataEncodings);    currentStatistics = totalStats;    this.columnIndexBuilder = columnIndexBuilder;    this.offsetIndexBuilder = offsetIndexBuilder;    endColumn();  }
public void endColumn() throws IOException {    state = state.endColumn();    LOG.debug("{}: end column", out.getPos());    if (columnIndexBuilder.getMinMaxSize() > columnIndexBuilder.getPageCount() * MAX_STATS_SIZE) {      currentColumnIndexes.add(null);    } else {      currentColumnIndexes.add(columnIndexBuilder.build());    }    currentOffsetIndexes.add(offsetIndexBuilder.build(firstPageOffset));    currentBlock.addColumn(ColumnChunkMetaData.get(        currentChunkPath,        currentChunkType,        currentChunkCodec,        encodingStatsBuilder.build(),        currentEncodings,        currentStatistics,        currentChunkFirstDataPage,        currentChunkDictionaryPageOffset,        currentChunkValueCount,        compressedLength,        uncompressedLength));    this.currentBlock.setTotalByteSize(currentBlock.getTotalByteSize() + uncompressedLength);    this.uncompressedLength = 0;    this.compressedLength = 0;    columnIndexBuilder = null;    offsetIndexBuilder = null;  }
public void endBlock() throws IOException {    state = state.endBlock();    LOG.debug("{}: end block", out.getPos());    currentBlock.setRowCount(currentRecordCount);    blocks.add(currentBlock);    columnIndexes.add(currentColumnIndexes);    offsetIndexes.add(currentOffsetIndexes);    currentColumnIndexes = null;    currentOffsetIndexes = null;    currentBlock = null;  }
private static void copy(SeekableInputStream from, PositionOutputStream to,                           long start, long length) throws IOException{    LOG.debug("Copying {} bytes at {} to {}" ,length , start , to.getPos());    from.seek(start);    long bytesCopied = 0;    byte[] buffer = COPY_BUFFER.get();    while (bytesCopied < length) {      long bytesLeft = length - bytesCopied;      int bytesRead = from.read(buffer, 0,          (buffer.length < bytesLeft ? buffer.length : (int) bytesLeft));      if (bytesRead < 0) {        throw new IllegalArgumentException(            "Unexpected end of input file at " + start + bytesCopied);      }      to.write(buffer, 0, bytesRead);      bytesCopied += bytesRead;    }  }
public void end(Map<String, String> extraMetaData) throws IOException {    state = state.end();    serializeColumnIndexes(columnIndexes, blocks, out);    serializeOffsetIndexes(offsetIndexes, blocks, out);    LOG.debug("{}: end", out.getPos());    this.footer = new ParquetMetadata(new FileMetaData(schema, extraMetaData, Version.FULL_VERSION), blocks);    serializeFooter(footer, out);    out.close();  }
@Deprecated  public static ParquetMetadata mergeMetadataFiles(List<Path> files,  Configuration conf) throws IOException {    Preconditions.checkArgument(!files.isEmpty(), "Cannot merge an empty list of metadata");    GlobalMetaData globalMetaData = null;    List<BlockMetaData> blocks = new ArrayList<BlockMetaData>();    for (Path p : files) {      ParquetMetadata pmd = ParquetFileReader.readFooter(conf, p, ParquetMetadataConverter.NO_FILTER);      FileMetaData fmd = pmd.getFileMetaData();      globalMetaData = mergeInto(fmd, globalMetaData, true);      blocks.addAll(pmd.getBlocks());    }    // collapse GlobalMetaData into a single FileMetaData, which will throw if they are not compatible    return new ParquetMetadata(globalMetaData.merge(), blocks);  }
@Deprecated  public static void writeMergedMetadataFile(List<Path> files, Path outputPath, Configuration conf) throws IOException {    ParquetMetadata merged = mergeMetadataFiles(files, conf);    writeMetadataFile(outputPath, merged, outputPath.getFileSystem(conf));  }
@Deprecated  public static void writeMetadataFile(Configuration configuration, Path outputPath, List<Footer> footers) throws IOException {    writeMetadataFile(configuration, outputPath, footers, JobSummaryLevel.ALL);  }
@Deprecated  public static void writeMetadataFile(Configuration configuration, Path outputPath, List<Footer> footers, JobSummaryLevel level) throws IOException {    Preconditions.checkArgument(level == JobSummaryLevel.ALL || level == JobSummaryLevel.COMMON_ONLY,        "Unsupported level: " + level);    FileSystem fs = outputPath.getFileSystem(configuration);    outputPath = outputPath.makeQualified(fs);    ParquetMetadata metadataFooter = mergeFooters(outputPath, footers);    if (level == JobSummaryLevel.ALL) {      writeMetadataFile(outputPath, metadataFooter, fs, PARQUET_METADATA_FILE);    }    metadataFooter.getBlocks().clear();    writeMetadataFile(outputPath, metadataFooter, fs, PARQUET_COMMON_METADATA_FILE);  }
static GlobalMetaData mergeInto(      FileMetaData toMerge,      GlobalMetaData mergedMetadata) {    return mergeInto(toMerge, mergedMetadata, true);  }
static MessageType mergeInto(MessageType toMerge, MessageType mergedSchema) {    return mergeInto(toMerge, mergedSchema, true);  }
static MessageType mergeInto(MessageType toMerge, MessageType mergedSchema, boolean strict) {    if (mergedSchema == null) {      return toMerge;    }    return mergedSchema.union(toMerge, strict);  }
public void readValue() {    try {      if (!valueRead) {        binding.read();        valueRead = true;      }    } catch (RuntimeException e) {      if (CorruptDeltaByteArrays.requiresSequentialReads(writerVersion, currentEncoding) &&          e instanceof ArrayIndexOutOfBoundsException) {        // this is probably PARQUET-246, which may happen if reading data with        // MR because this can't be detected without reading all footers        throw new ParquetDecodingException("Read failure possibly due to " +            "PARQUET-246: try setting parquet.split.files to false",            new ParquetDecodingException(                format("Can't read value in column %s at value %d out of %d, " +                        "%d out of %d in currentPage. repetition level: " +                        "%d, definition level: %d",                    path, readValues, totalValueCount,                    readValues - (endOfPageValueCount - pageValueCount),                    pageValueCount, repetitionLevel, definitionLevel),                e));      }      throw new ParquetDecodingException(          format("Can't read value in column %s at value %d out of %d, " +                  "%d out of %d in currentPage. repetition level: " +                  "%d, definition level: %d",              path, readValues, totalValueCount,              readValues - (endOfPageValueCount - pageValueCount),              pageValueCount, repetitionLevel, definitionLevel),          e);    }  }
public static boolean nullOk(Schema schema) {    if (Schema.Type.NULL == schema.getType()) {      return true;    } else if (Schema.Type.UNION == schema.getType()) {      for (Schema possible : schema.getTypes()) {        if (nullOk(possible)) {          return true;        }      }    }    return false;  }
public static Schema merge(Iterable<Schema> schemas) {    Iterator<Schema> iter = schemas.iterator();    if (!iter.hasNext()) {      return null;    }    Schema result = iter.next();    while (iter.hasNext()) {      result = merge(result, iter.next());    }    return result;  }
public static Schema merge(Schema left, Schema right) {    Schema merged = mergeOnly(left, right);    Preconditions.checkState(merged != null,        "Cannot merge %s and %s", left, right);    return merged;  }
private static Schema mergeOrUnion(Schema left, Schema right) {    Schema merged = mergeOnly(left, right);    if (merged != null) {      return merged;    }    return union(left, right);  }
private static Schema union(Schema left, Schema right) {    if (left.getType() == Schema.Type.UNION) {      if (right.getType() == Schema.Type.UNION) {        // combine the unions by adding each type in right individually        Schema combined = left;        for (Schema type : right.getTypes()) {          combined = union(combined, type);        }        return combined;      } else {        boolean notMerged = true;        // combine a union with a non-union by checking if each type will merge        List<Schema> types = Lists.newArrayList();        Iterator<Schema> schemas = left.getTypes().iterator();        // try to merge each type and stop when one succeeds        while (schemas.hasNext()) {          Schema next = schemas.next();          Schema merged = mergeOnly(next, right);          if (merged != null) {            types.add(merged);            notMerged = false;            break;          } else {            // merge didn't work, add the type            types.add(next);          }        }        // add the remaining types from the left union        while (schemas.hasNext()) {          types.add(schemas.next());        }        if (notMerged) {          types.add(right);        }        return Schema.createUnion(types);      }    } else if (right.getType() == Schema.Type.UNION) {      return union(right, left);    }    return Schema.createUnion(ImmutableList.of(left, right));  }
private static Schema mergeOnly(Schema left, Schema right) {    if (Objects.equal(left, right)) {      return left;    }    // handle primitive type promotion; doesn't promote integers to floats    switch (left.getType()) {      case INT:        if (right.getType() == Schema.Type.LONG) {          return right;        }        break;      case LONG:        if (right.getType() == Schema.Type.INT) {          return left;        }        break;      case FLOAT:        if (right.getType() == Schema.Type.DOUBLE) {          return right;        }        break;      case DOUBLE:        if (right.getType() == Schema.Type.FLOAT) {          return left;        }    }    // any other cases where the types don't match must be combined by a union    if (left.getType() != right.getType()) {      return null;    }    switch (left.getType()) {      case UNION:        return union(left, right);      case RECORD:        if (left.getName() == null && right.getName() == null &&            fieldSimilarity(left, right) < SIMILARITY_THRESH) {          return null;        } else if (!Objects.equal(left.getName(), right.getName())) {          return null;        }        Schema combinedRecord = Schema.createRecord(            coalesce(left.getName(), right.getName()),            coalesce(left.getDoc(), right.getDoc()),            coalesce(left.getNamespace(), right.getNamespace()),            false        );        combinedRecord.setFields(mergeFields(left, right));        return combinedRecord;      case MAP:        return Schema.createMap(            mergeOrUnion(left.getValueType(), right.getValueType()));      case ARRAY:        return Schema.createArray(            mergeOrUnion(left.getElementType(), right.getElementType()));      case ENUM:        if (!Objects.equal(left.getName(), right.getName())) {          return null;        }        Set<String> symbols = Sets.newLinkedHashSet();        symbols.addAll(left.getEnumSymbols());        symbols.addAll(right.getEnumSymbols());        return Schema.createEnum(            left.getName(),            coalesce(left.getDoc(), right.getDoc()),            coalesce(left.getNamespace(), right.getNamespace()),            ImmutableList.copyOf(symbols)        );      default:        // all primitives are handled before the switch by the equality check.        // schemas that reach this point are not primitives and also not any of        // the above known types.        throw new UnsupportedOperationException(            "Unknown schema type: " + left.getType());    }  }
private static Schema nullableForDefault(Schema schema) {    if (schema.getType() == Schema.Type.NULL) {      return schema;    }    if (schema.getType() != Schema.Type.UNION) {      return Schema.createUnion(ImmutableList.of(NULL, schema));    }    if (schema.getTypes().get(0).getType() == Schema.Type.NULL) {      return schema;    }    List<Schema> types = Lists.newArrayList();    types.add(NULL);    for (Schema type : schema.getTypes()) {      if (type.getType() != Schema.Type.NULL) {        types.add(type);      }    }    return Schema.createUnion(types);  }
public static Schema.Field copy(Schema.Field field) {    return new Schema.Field(        field.name(), field.schema(), field.doc(), field.defaultValue());  }
@SafeVarargs  private static <E> E coalesce(E... objects) {    for (E object : objects) {      if (object != null) {        return object;      }    }    return null;  }
@Override  public void close(TaskAttemptContext context) throws IOException, InterruptedException {    try {      internalWriter.close();      // release after the writer closes in case it is used for a last flush    } finally {      if (codecFactory != null) {        codecFactory.release();      }      if (memoryManager != null) {        memoryManager.removeWriter(internalWriter);      }    }  }
@Override  public void write(Void key, T value) throws IOException, InterruptedException {    internalWriter.write(value);  }
private static Object makeValue(String string, Schema schema) {    if (string == null) {      return null;    }    try {      switch (schema.getType()) {        case BOOLEAN:          return Boolean.valueOf(string);        case STRING:          return string;        case FLOAT:          return Float.valueOf(string);        case DOUBLE:          return Double.valueOf(string);        case INT:          return Integer.valueOf(string);        case LONG:          return Long.valueOf(string);        case ENUM:          // TODO: translate to enum class          if (schema.hasEnumSymbol(string)) {            return string;          } else {            try {              return schema.getEnumSymbols().get(Integer.parseInt(string));            } catch (IndexOutOfBoundsException ex) {              return null;            }          }        case UNION:          Object value = null;          for (Schema possible : schema.getTypes()) {            value = makeValue(string, possible);            if (value != null) {              return value;            }          }          return null;        case NULL:          return null;        default:          // FIXED, BYTES, MAP, ARRAY, RECORD are not supported          throw new RecordException(              "Unsupported field type:" + schema.getType());      }    } catch (NumberFormatException e) {      // empty string is considered null for numeric types      if (string.isEmpty()) {        return null;      } else {        throw e;      }    }  }
public static ThriftMetaData fromExtraMetaData(      Map<String, String> extraMetaData) {    final String thriftClassName = extraMetaData.get(THRIFT_CLASS);    final String thriftDescriptorString = extraMetaData.get(THRIFT_DESCRIPTOR);    if (thriftClassName == null || thriftDescriptorString == null) {      return null;    }    final StructType descriptor = parseDescriptor(thriftDescriptorString);    return new ThriftMetaData(thriftClassName, descriptor);  }
@SuppressWarnings("unchecked")  public static ThriftMetaData fromThriftClass(Class<?> thriftClass) {    if (thriftClass != null && TBase.class.isAssignableFrom(thriftClass)) {      Class<? extends TBase<?, ?>> tClass = (Class<? extends TBase<?, ?>>) thriftClass;      StructType descriptor = new ThriftSchemaConverter().toStructType(tClass);      return new ThriftMetaData(thriftClass.getName(), descriptor);    }    return null;  }
public Map<String, String> toExtraMetaData() {    final Map<String, String> map = new HashMap<String, String>();    map.put(THRIFT_CLASS, getThriftClass().getName());    map.put(THRIFT_DESCRIPTOR, descriptor.toJSON());    return map;  }
@Override  public void writeNull(int repetitionLevel, int definitionLevel) {    if (DEBUG)      log(null, repetitionLevel, definitionLevel);    repetitionLevel(repetitionLevel);    definitionLevel(definitionLevel);    statistics.incrementNumNulls();    ++valueCount;  }
@Override  public void write(double value, int repetitionLevel, int definitionLevel) {    if (DEBUG)      log(value, repetitionLevel, definitionLevel);    repetitionLevel(repetitionLevel);    definitionLevel(definitionLevel);    dataColumn.writeDouble(value);    statistics.updateStats(value);    ++valueCount;  }
@Override  public void write(Binary value, int repetitionLevel, int definitionLevel) {    if (DEBUG)      log(value, repetitionLevel, definitionLevel);    repetitionLevel(repetitionLevel);    definitionLevel(definitionLevel);    dataColumn.writeBytes(value);    statistics.updateStats(value);    ++valueCount;  }
void finalizeColumnChunk() {    final DictionaryPage dictionaryPage = dataColumn.toDictPageAndClose();    if (dictionaryPage != null) {      if (DEBUG)        LOG.debug("write dictionary");      try {        pageWriter.writeDictionaryPage(dictionaryPage);      } catch (IOException e) {        throw new ParquetEncodingException("could not write dictionary page for " + path, e);      }      dataColumn.resetDictionary();    }  }
void writePage() {    if (valueCount == 0) {      throw new ParquetEncodingException("writing empty page");    }    this.rowsWrittenSoFar += pageRowCount;    if (DEBUG)      LOG.debug("write page");    try {      writePage(pageRowCount, valueCount, statistics, repetitionLevelColumn, definitionLevelColumn, dataColumn);    } catch (IOException e) {      throw new ParquetEncodingException("could not write page for " + path, e);    }    repetitionLevelColumn.reset();    definitionLevelColumn.reset();    dataColumn.reset();    valueCount = 0;    resetStatistics();    pageRowCount = 0;  }
static List<String> parseSemicolonDelimitedString(String columnsToKeepGlobs) {    String[] splits = columnsToKeepGlobs.split(GLOB_SEPARATOR);    List<String> globs = new ArrayList<String>();    for (String s : splits) {      if (!s.isEmpty()) {        globs.add(s);      }    }    if (globs.isEmpty()) {      throw new ThriftProjectionException(String.format("Semicolon delimited string '%s' contains 0 glob strings",          columnsToKeepGlobs));    }    return globs;  }
boolean keep(String path) {    WildcardPath match = null;    // since we have a rule of every path must match at least one column,    // we visit every single wildcard path, instead of short circuiting,    // for the case where more than one pattern matches a column. Otherwise    // we'd get a misleading exception saying a path didn't match a column,    // even though it looks like it should have (but didn't because of short circuiting).    // This also allows us log a warning when more than one glob path matches.    for (WildcardPathStatus wp : columnsToKeep) {      if (wp.matches(path)) {        if (match != null && !match.getParentGlobPath().equals(wp.getWildcardPath().getParentGlobPath())) {          String message = "Field path: '%s' matched more than one glob path pattern. First match: " +              "'%s' (when expanded to '%s') second match:'%s' (when expanded to '%s')";          warn(String.format(message,              path, match.getParentGlobPath(), match.getOriginalPattern(),              wp.getWildcardPath().getParentGlobPath(), wp.getWildcardPath().getOriginalPattern()));        } else {          match = wp.getWildcardPath();        }      }    }    return match != null;  }
public void endMessage() {    delegate.endMessage();    validateMissingFields(types.peek().asGroupType().getFieldCount());    previousField.pop();  }
public void startField(String field, int index) {    if (index <= previousField.peek()) {      throw new InvalidRecordException("fields must be added in order " + field + " index " + index + " is before previous field " + previousField.peek());    }    validateMissingFields(index);    fields.push(index);    fieldValueCount.push(0);    delegate.startField(field, index);  }
public void endField(String field, int index) {    delegate.endField(field, index);    fieldValueCount.pop();    previousField.push(fields.pop());  }
public void startGroup() {    previousField.push(-1);    types.push(types.peek().asGroupType().getType(fields.peek()));    delegate.startGroup();  }
public void endGroup() {    delegate.endGroup();    validateMissingFields(types.peek().asGroupType().getFieldCount());    types.pop();    previousField.pop();  }
public void addBinary(Binary value) {    validate(BINARY, INT96, FIXED_LEN_BYTE_ARRAY);    delegate.addBinary(value);  }
@Override  public void writeToStringBuilder(StringBuilder sb, String indent) {    sb.append(indent)        .append(getRepetition().name().toLowerCase(Locale.ENGLISH))        .append(" ")        .append(primitive.name().toLowerCase());    if (primitive == PrimitiveTypeName.FIXED_LEN_BYTE_ARRAY) {      sb.append("(" + length + ")");    }    sb.append(" ").append(getName());    if (getLogicalTypeAnnotation() != null) {      // TODO: should we print decimal metadata too?      sb.append(" (").append(getLogicalTypeAnnotation().toString()).append(")");    }    if (getId() != null) {      sb.append(" = ").append(getId());    }  }
@SuppressWarnings("unchecked")  public <T> PrimitiveComparator<T> comparator() {    return (PrimitiveComparator<T>) getPrimitiveTypeName().comparator(getLogicalTypeAnnotation());  }
@Override  public void initFromPage(int valueCount, ByteBufferInputStream stream) throws IOException {    this.in = stream;    long startPos = in.position();    this.config = DeltaBinaryPackingConfig.readConfig(in);    this.totalValueCount = BytesUtils.readUnsignedVarInt(in);    allocateValuesBuffer();    bitWidths = new int[config.miniBlockNumInABlock];    //read first value from header    valuesBuffer[valuesBuffered++] = BytesUtils.readZigZagVarLong(in);    while (valuesBuffered < totalValueCount) { //values Buffered could be more than totalValueCount, since we flush on a mini block basis      loadNewBlockToBuffer();    }    updateNextOffset((int) (in.position() - startPos));  }
private void allocateValuesBuffer() {    int totalMiniBlockCount = (int) Math.ceil((double) totalValueCount / config.miniBlockSizeInValues);    //+ 1 because first value written to header is also stored in values buffer    valuesBuffer = new long[totalMiniBlockCount * config.miniBlockSizeInValues + 1];  }
private void unpackMiniBlock(BytePackerForLong packer) throws IOException {    for (int j = 0; j < config.miniBlockSizeInValues; j += 8) {      unpack8Values(packer);    }  }
public FileMetaData merge() {    String createdByString = createdBy.size() == 1 ?      createdBy.iterator().next() :      createdBy.toString();    Map<String, String> mergedKeyValues = new HashMap<String, String>();    for (Entry<String, Set<String>> entry : keyValueMetaData.entrySet()) {      if (entry.getValue().size() > 1) {        throw new RuntimeException("could not merge metadata: key " + entry.getKey() + " has conflicting values: " + entry.getValue());      }      mergedKeyValues.put(entry.getKey(), entry.getValue().iterator().next());    }    return new FileMetaData(schema, mergedKeyValues, createdByString);  }
@InterfaceAudience.Private  public static LogicalTypeAnnotation fromOriginalType(OriginalType originalType, DecimalMetadata decimalMetadata) {    if (originalType == null) {      return null;    }    switch (originalType) {      case UTF8:        return stringType();      case MAP:        return mapType();      case DECIMAL:        int scale = (decimalMetadata == null ? 0 : decimalMetadata.getScale());        int precision = (decimalMetadata == null ? 0 : decimalMetadata.getPrecision());        return decimalType(scale, precision);      case LIST:        return listType();      case DATE:        return dateType();      case INTERVAL:        return IntervalLogicalTypeAnnotation.getInstance();      case TIMESTAMP_MILLIS:        return timestampType(true, LogicalTypeAnnotation.TimeUnit.MILLIS);      case TIMESTAMP_MICROS:        return timestampType(true, LogicalTypeAnnotation.TimeUnit.MICROS);      case TIME_MILLIS:        return timeType(true, LogicalTypeAnnotation.TimeUnit.MILLIS);      case TIME_MICROS:        return timeType(true, LogicalTypeAnnotation.TimeUnit.MICROS);      case UINT_8:        return intType(8, false);      case UINT_16:        return intType(16, false);      case UINT_32:        return intType(32, false);      case UINT_64:        return intType(64, false);      case INT_8:        return intType(8, true);      case INT_16:        return intType(16, true);      case INT_32:        return intType(32, true);      case INT_64:        return intType(64, true);      case ENUM:        return enumType();      case JSON:        return jsonType();      case BSON:        return bsonType();      case MAP_KEY_VALUE:        return MapKeyValueTypeAnnotation.getInstance();      default:        throw new RuntimeException("Can't convert original type to logical type, unknown original type " + originalType);    }  }
@Override  public OutputFormat<Void, Tuple> getOutputFormat() throws IOException {    return new ParquetOutputFormat<Tuple>(new TupleToThriftWriteSupport(className));  }
@Override  public BytesInput getBytes() {    // The Page Header should include: blockSizeInValues, numberOfMiniBlocks, totalValueCount    if (deltaValuesToFlush != 0) {      flushBlockBuffer();    }    return BytesInput.concat(            config.toBytesInput(),            BytesInput.fromUnsignedVarInt(totalValueCount),            BytesInput.fromZigZagVarLong(firstValue),            BytesInput.from(baos));  }
public static void checkArgument(boolean isValid, String message, Object... args)      throws IllegalArgumentException {    if (!isValid) {      throw new IllegalArgumentException(          String.format(String.valueOf(message), strings(args)));    }  }
public static void checkState(boolean isValid, String message, Object... args)      throws IllegalStateException {    if (!isValid) {      throw new IllegalStateException(          String.format(String.valueOf(message), strings(args)));    }  }
@Override  public void readOne(TProtocol in, TProtocol out) throws TException {    List<Action> buffer = new LinkedList<Action>();    try{        boolean hasFieldsIgnored = readOneStruct(in, buffer, thriftType);        if (hasFieldsIgnored) {          notifyRecordHasFieldIgnored();        }    } catch (Exception e) {      throw new SkippableException(error("Error while reading", buffer), e);    }    try {      for (Action a : buffer) {        a.write(out);      }    } catch (Exception e) {      throw new TException(error("Can not write record", buffer), e);    }  }
private void checkEnum(ThriftType expectedType, int i) {    if (expectedType.getType() == ThriftTypeID.ENUM) {      ThriftType.EnumType expectedEnumType = (ThriftType.EnumType)expectedType;      if (expectedEnumType.getEnumValueById(i) == null) {        throw new DecodingSchemaMismatchException("can not find index " + i + " in enum " + expectedType);      }    }  }
public static MessageType getSchemaForRead(MessageType fileMessageType, String partialReadSchemaString) {    if (partialReadSchemaString == null)      return fileMessageType;    MessageType requestedMessageType = MessageTypeParser.parseMessageType(partialReadSchemaString);    return getSchemaForRead(fileMessageType, requestedMessageType);  }
@Deprecated  public ReadContext init(          Configuration configuration,          Map<String, String> keyValueMetaData,          MessageType fileSchema) {    throw new UnsupportedOperationException("Override init(InitContext)");  }
public ReadContext init(InitContext context) {    return init(context.getConfiguration(), context.getMergedKeyValueMetaData(), context.getFileSchema());  }
@Override  public void setMinMaxFromBytes(byte[] minBytes, byte[] maxBytes) {    max = Binary.fromReusedByteArray(maxBytes);    min = Binary.fromReusedByteArray(minBytes);    this.markAsNotEmpty();  }
private void calculateBitWidthsForDeltaBlockBuffer(int miniBlocksToFlush) {    for (int miniBlockIndex = 0; miniBlockIndex < miniBlocksToFlush; miniBlockIndex++) {      int mask = 0;      int miniStart = miniBlockIndex * config.miniBlockSizeInValues;      //The end of current mini block could be the end of current block(deltaValuesToFlush) buffer when data is not aligned to mini block      int miniEnd = Math.min((miniBlockIndex + 1) * config.miniBlockSizeInValues, deltaValuesToFlush);      for (int i = miniStart; i < miniEnd; i++) {        mask |= deltaBlockBuffer[i];      }      bitWidths[miniBlockIndex] = 32 - Integer.numberOfLeadingZeros(mask);    }  }
public static final UnboundRecordFilter and( final UnboundRecordFilter filter1, final UnboundRecordFilter filter2 ) {    Preconditions.checkNotNull( filter1, "filter1" );    Preconditions.checkNotNull( filter2, "filter2" );    return new UnboundRecordFilter() {      @Override      public RecordFilter bind(Iterable<ColumnReader> readers) {        return new AndRecordFilter( filter1.bind(readers), filter2.bind( readers) );      }    };  }
@Override  public void writeToStringBuilder(StringBuilder sb, String indent) {    sb.append("message ")        .append(getName())        .append(getLogicalTypeAnnotation() == null ? "" : " (" + getLogicalTypeAnnotation().toString() +")")        .append(" {\n");    membersDisplayString(sb, "  ");    sb.append("}\n");  }
static ColumnIndexStore create(ParquetFileReader reader, BlockMetaData block, Set<ColumnPath> paths) {    try {      return new ColumnIndexStoreImpl(reader, block, paths);    } catch (MissingOffsetIndexException e) {      return EMPTY;    }  }
public static final UnboundRecordFilter not( final UnboundRecordFilter filter) {    Preconditions.checkNotNull( filter, "filter" );    return new UnboundRecordFilter() {      @Override      public RecordFilter bind(Iterable<ColumnReader> readers) {        return new NotRecordFilter( filter.bind(readers) );      }    };  }
public static <E extends Exception> void throwIfInstance(Throwable t,                                                           Class<E> excClass)      throws E {    if (excClass.isAssignableFrom(t.getClass())) {      // the throwable is already an exception, so return it      throw excClass.cast(t);    }  }
@Deprecated  public static Statistics getStatsBasedOnType(PrimitiveTypeName type) {    switch (type) {      case INT32:        return new IntStatistics();      case INT64:        return new LongStatistics();      case FLOAT:        return new FloatStatistics();      case DOUBLE:        return new DoubleStatistics();      case BOOLEAN:        return new BooleanStatistics();      case BINARY:        return new BinaryStatistics();      case INT96:        return new BinaryStatistics();      case FIXED_LEN_BYTE_ARRAY:        return new BinaryStatistics();      default:        throw new UnknownColumnTypeException(type);    }  }
public static Statistics<?> createStats(Type type) {    PrimitiveType primitive = type.asPrimitiveType();    switch (primitive.getPrimitiveTypeName()) {      case INT32:        return new IntStatistics(primitive);      case INT64:        return new LongStatistics(primitive);      case FLOAT:        return new FloatStatistics(primitive);      case DOUBLE:        return new DoubleStatistics(primitive);      case BOOLEAN:        return new BooleanStatistics(primitive);      case BINARY:      case INT96:      case FIXED_LEN_BYTE_ARRAY:        return new BinaryStatistics(primitive);      default:        throw new UnknownColumnTypeException(primitive.getPrimitiveTypeName());    }  }
public static Builder getBuilderForReading(PrimitiveType type) {    switch (type.getPrimitiveTypeName()) {      case FLOAT:        return new FloatBuilder(type);      case DOUBLE:        return new DoubleBuilder(type);      default:        return new Builder(type);    }  }
public void mergeStatistics(Statistics stats) {    if (stats.isEmpty()) return;    // Merge stats only if they have the same type    if (type.equals(stats.type)) {      incrementNumNulls(stats.getNumNulls());      if (stats.hasNonNullValue()) {        mergeStatisticsMinMax(stats);        markAsNotEmpty();      }    } else {      throw StatisticsClassException.create(this, stats);    }  }
public static Schema getNonNull(Schema schema) {    if (schema.getType().equals(Schema.Type.UNION)) {      List<Schema> schemas = schema.getTypes();      if (schemas.size() == 2) {        if (schemas.get(0).getType().equals(Schema.Type.NULL)) {          return schemas.get(1);        } else if (schemas.get(1).getType().equals(Schema.Type.NULL)) {          return schemas.get(0);        } else {          return schema;        }      } else {        return schema;      }    } else {      return schema;    }  }
private boolean isElementType(Type repeatedType, String parentName) {    return (        // can't be a synthetic layer because it would be invalid        repeatedType.isPrimitive() ||        repeatedType.asGroupType().getFieldCount() > 1 ||        repeatedType.asGroupType().getType(0).isRepetition(REPEATED) ||        // known patterns without the synthetic layer        repeatedType.getName().equals("array") ||        repeatedType.getName().equals(parentName + "_tuple") ||        // default assumption        assumeRepeatedIsListElement    );  }
public static JobContext newJobContext(Configuration conf, JobID jobId) {    try {      return (JobContext)          JOB_CONTEXT_CONSTRUCTOR.newInstance(conf, jobId);    } catch (InstantiationException e) {      throw new IllegalArgumentException("Can't instantiate JobContext", e);    } catch (IllegalAccessException e) {      throw new IllegalArgumentException("Can't instantiate JobContext", e);    } catch (InvocationTargetException e) {      throw new IllegalArgumentException("Can't instantiate JobContext", e);    }  }
public static TaskAttemptContext newTaskAttemptContext(      Configuration conf, TaskAttemptID taskAttemptId) {    try {      return (TaskAttemptContext)          TASK_CONTEXT_CONSTRUCTOR.newInstance(conf, taskAttemptId);    } catch (InstantiationException e) {      throw new IllegalArgumentException("Can't instantiate TaskAttemptContext", e);    } catch (IllegalAccessException e) {      throw new IllegalArgumentException("Can't instantiate TaskAttemptContext", e);    } catch (InvocationTargetException e) {      throw new IllegalArgumentException("Can't instantiate TaskAttemptContext", e);    }  }
public static Configuration getConfiguration(JobContext context) {    try {      return (Configuration) GET_CONFIGURATION_METHOD.invoke(context);    } catch (IllegalAccessException e) {      throw new IllegalArgumentException("Can't invoke method", e);    } catch (InvocationTargetException e) {      throw new IllegalArgumentException("Can't invoke method", e);    }  }
private static Object invoke(Method method, Object obj, Object... args) {    try {      return method.invoke(obj, args);    } catch (IllegalAccessException e) {      throw new IllegalArgumentException("Can't invoke method " + method.getName(), e);    } catch (InvocationTargetException e) {      throw new IllegalArgumentException("Can't invoke method " + method.getName(), e);    }  }
void membersDisplayString(StringBuilder sb, String indent) {    for (Type field : fields) {      field.writeToStringBuilder(sb, indent);      if (field.isPrimitive()) {        sb.append(";");      }      sb.append("\n");    }  }
@Override  public void writeToStringBuilder(StringBuilder sb, String indent) {    sb.append(indent)        .append(getRepetition().name().toLowerCase(Locale.ENGLISH))        .append(" group ")        .append(getName())        .append(getLogicalTypeAnnotation() == null ? "" : " (" + getLogicalTypeAnnotation().toString() +")")        .append(getId() == null ? "" : " = " + getId())        .append(" {\n");    membersDisplayString(sb, indent + "  ");    sb.append(indent)        .append("}");  }
List<Type> mergeFields(GroupType toMerge, boolean strict) {    List<Type> newFields = new ArrayList<Type>();    // merge existing fields    for (Type type : this.getFields()) {      Type merged;      if (toMerge.containsField(type.getName())) {        Type fieldToMerge = toMerge.getType(type.getName());        if (type.getLogicalTypeAnnotation() != null && !type.getLogicalTypeAnnotation().equals(fieldToMerge.getLogicalTypeAnnotation())) {          throw new IncompatibleSchemaModificationException("cannot merge logical type " + fieldToMerge.getLogicalTypeAnnotation() + " into " + type.getLogicalTypeAnnotation());        }        merged = type.union(fieldToMerge, strict);      } else {        merged = type;      }      newFields.add(merged);    }    // add new fields    for (Type type : toMerge.getFields()) {      if (!this.containsField(type.getName())) {        newFields.add(type);      }    }    return newFields;  }
public static void initCounterFromReporter(Reporter reporter, Configuration configuration) {    counterLoader = new MapRedCounterLoader(reporter, configuration);    loadCounters();  }
@Override  public synchronized int compress(byte[] buffer, int off, int len) throws IOException {    SnappyUtil.validateBuffer(buffer, off, len);    if (needsInput()) {      // No buffered output bytes and no input to consume, need more input      return 0;    }    if (!outputBuffer.hasRemaining()) {      // There is uncompressed input, compress it now      int maxOutputSize = Snappy.maxCompressedLength(inputBuffer.position());      if (maxOutputSize > outputBuffer.capacity()) {        ByteBuffer oldBuffer = outputBuffer;        outputBuffer = ByteBuffer.allocateDirect(maxOutputSize);        CleanUtil.clean(oldBuffer);      }      // Reset the previous outputBuffer      outputBuffer.clear();      inputBuffer.limit(inputBuffer.position());      inputBuffer.position(0);      int size = Snappy.compress(inputBuffer, outputBuffer);      outputBuffer.limit(size);      inputBuffer.limit(0);      inputBuffer.rewind();    }    // Return compressed output up to 'len'    int numBytes = Math.min(len, outputBuffer.remaining());    outputBuffer.get(buffer, off, numBytes);        bytesWritten += numBytes;    return numBytes;	      }
public static void closeAndSwallowIOExceptions(Closeable c) {    if (c == null) { return; }    try {      c.close();    } catch (IOException e) {      LOG.warn("Encountered exception closing closeable", e);    }  }
public static Filter getFilter(Configuration conf) {    return FilterCompat.get(getFilterPredicate(conf), getUnboundRecordFilterInstance(conf));  }
@Override  public RecordReader<Void, T> createRecordReader(      InputSplit inputSplit,      TaskAttemptContext taskAttemptContext) throws IOException, InterruptedException {    Configuration conf = ContextUtil.getConfiguration(taskAttemptContext);    ReadSupport<T> readSupport = getReadSupport(conf);    return new ParquetRecordReader<T>(readSupport, getFilter(conf));  }
@Override  public List<InputSplit> getSplits(JobContext jobContext) throws IOException {    Configuration configuration = ContextUtil.getConfiguration(jobContext);    List<InputSplit> splits = new ArrayList<InputSplit>();    if (isTaskSideMetaData(configuration)) {      // Although not required by the API, some clients may depend on always      // receiving ParquetInputSplit. Translation is required at some point.      for (InputSplit split : super.getSplits(jobContext)) {        Preconditions.checkArgument(split instanceof FileSplit,            "Cannot wrap non-FileSplit: " + split);        splits.add(ParquetInputSplit.from((FileSplit) split));      }      return splits;    } else {      splits.addAll(getSplits(configuration, getFooters(jobContext)));    }    return splits;  }
@Override  protected List<FileStatus> listStatus(JobContext jobContext) throws IOException {    return getAllFileRecursively(super.listStatus(jobContext),       ContextUtil.getConfiguration(jobContext));  }
public List<Footer> getFooters(Configuration configuration, Collection<FileStatus> statuses) throws IOException {    LOG.debug("reading {} files", statuses.size());    boolean taskSideMetaData = isTaskSideMetaData(configuration);    return ParquetFileReader.readAllFootersInParallelUsingSummaryFiles(configuration, statuses, taskSideMetaData);  }
static <T> List<ParquetInputSplit> generateSplits(          List<BlockMetaData> rowGroupBlocks,          BlockLocation[] hdfsBlocksArray,          FileStatus fileStatus,          String requestedSchema,          Map<String, String> readSupportMetadata, long minSplitSize, long maxSplitSize) throws IOException {    List<SplitInfo> splitRowGroups =        generateSplitInfo(rowGroupBlocks, hdfsBlocksArray, minSplitSize, maxSplitSize);    //generate splits from rowGroups of each split    List<ParquetInputSplit> resultSplits = new ArrayList<ParquetInputSplit>();    for (SplitInfo splitInfo : splitRowGroups) {      ParquetInputSplit split = splitInfo.getParquetInputSplit(fileStatus, requestedSchema, readSupportMetadata);      resultSplits.add(split);    }    return resultSplits;  }
public static <T extends Comparable<T>, C extends Column<T> & SupportsEqNotEq> Eq<T> eq(C column, T value) {    return new Eq<T>(column, value);  }
public static <T extends Comparable<T>, C extends Column<T> & SupportsEqNotEq> NotEq<T> notEq(C column, T value) {    return new NotEq<T>(column, value);  }
public static <T extends Comparable<T>, C extends Column<T> & SupportsLtGt> Lt<T> lt(C column, T value) {    return new Lt<T>(column, value);  }
public static <T extends Comparable<T>, C extends Column<T> & SupportsLtGt> LtEq<T> ltEq(C column, T value) {    return new LtEq<T>(column, value);  }
public static <T extends Comparable<T>, C extends Column<T> & SupportsLtGt> Gt<T> gt(C column, T value) {    return new Gt<T>(column, value);  }
public static <T extends Comparable<T>, C extends Column<T> & SupportsLtGt> GtEq<T> gtEq(C column, T value) {    return new GtEq<T>(column, value);  }
public static <T extends Comparable<T>, U extends UserDefinedPredicate<T>>    UserDefined<T, U> userDefined(Column<T> column, Class<U> clazz) {    return new UserDefinedByClass<T, U>(column, clazz);  }
public static <T extends Comparable<T>, U extends UserDefinedPredicate<T> & Serializable>    UserDefined<T, U> userDefined(Column<T> column, U udp) {    return new UserDefinedByInstance<T, U>(column, udp);  }
public void debug(Object m) {    if (m instanceof Throwable) {      logger.debug("", (Throwable) m);    } else {      logger.debug(String.valueOf(m));    }  }
public void debug(Object m, Throwable t) {    logger.debug(String.valueOf(m), t);  }
public void info(Object m) {    if (m instanceof Throwable) {      logger.info("", (Throwable) m);    } else {      logger.info(String.valueOf(m));    }  }
public void info(Object m, Throwable t) {    logger.info(String.valueOf(m), t);  }
public void warn(Object m) {    if (m instanceof Throwable) {      logger.warn("", (Throwable) m);    } else {      logger.warn(String.valueOf(m));    }  }
public void warn(Object m, Throwable t) {    logger.warn(String.valueOf(m), t);  }
public void error(Object m) {    if (m instanceof Throwable) {      logger.error("", (Throwable) m);    } else {      logger.error(String.valueOf(m));    }  }
public void error(Object m, Throwable t) {    logger.error(String.valueOf(m), t);  }
public static final UnboundRecordFilter or( final UnboundRecordFilter filter1, final UnboundRecordFilter filter2 ) {    Preconditions.checkNotNull( filter1, "filter1" );    Preconditions.checkNotNull( filter2, "filter2" );    return new UnboundRecordFilter() {      @Override      public RecordFilter bind(Iterable<ColumnReader> readers) {        return new OrRecordFilter( filter1.bind(readers), filter2.bind( readers) );      }    };  }
@Override  public void write(T record) {    recordConsumer.startMessage();    try {      messageWriter.writeTopLevelMessage(record);    } catch (RuntimeException e) {      Message m = (record instanceof Message.Builder) ? ((Message.Builder) record).build() : (Message) record;      LOG.error("Cannot write message " + e.getMessage() + " : " + m);      throw e;    }    recordConsumer.endMessage();  }
private void validatedMapping(Descriptor descriptor, GroupType parquetSchema) {    List<FieldDescriptor> allFields = descriptor.getFields();    for (FieldDescriptor fieldDescriptor: allFields) {      String fieldName = fieldDescriptor.getName();      int fieldIndex = fieldDescriptor.getIndex();      int parquetIndex = parquetSchema.getFieldIndex(fieldName);      if (fieldIndex != parquetIndex) {        String message = "FieldIndex mismatch name=" + fieldName + ": " + fieldIndex + " != " + parquetIndex;        throw new IncompatibleSchemaModificationException(message);      }    }  }
private String serializeDescriptor(Class<? extends Message> protoClass) {    Descriptor descriptor = Protobufs.getMessageDescriptor(protoClass);    DescriptorProtos.DescriptorProto asProto = descriptor.toProto();    return TextFormat.printToString(asProto);  }
public static CodecFactory createDirectCodecFactory(Configuration config, ByteBufferAllocator allocator, int pageSize) {    return new DirectCodecFactory(config, allocator, pageSize);  }
public static Schema filterSchema(Schema schema, String... fieldPaths) {    return filterSchema(schema, Lists.newArrayList(fieldPaths));  }
public List<TProtocol> amendMissingRequiredFields(StructType recordThriftType) throws TException {    Iterator<TProtocol> protocolIter = rootEvents.iterator();    checkStruct(protocolIter, recordThriftType);    return fixedEvents;  }
private void checkSet(Iterator<TProtocol> eventIter, ThriftField setFieldDefinition) throws TException {    TSet thriftSet = acceptProtocol(eventIter.next()).readSetBegin();    ThriftField elementFieldDefinition = ((ThriftType.SetType) setFieldDefinition.getType()).getValues();    int setSize = thriftSet.size;    for (int i = 0; i < setSize; i++) {      checkField(thriftSet.elemType, eventIter, elementFieldDefinition);    }    acceptProtocol(eventIter.next()).readSetEnd();  }
public static FileMetaData readFileMetaData(InputStream from, boolean skipRowGroups) throws IOException {    FileMetaData md = new FileMetaData();    if (skipRowGroups) {      readFileMetaData(from, new DefaultFileMetaDataConsumer(md), skipRowGroups);    } else {      read(from, md);    }    return md;  }
@Override  public void close() throws IOException {    try {      recordWriter.close(taskAttemptContext);    } catch (InterruptedException e) {      Thread.interrupted();      throw new IOException("The thread was interrupted", e);    }  }
public static void setSchema(Job job, MessageType schema) {    GroupWriteSupport.setSchema(schema, ContextUtil.getConfiguration(job));  }
private static void add(Class<?> c, PrimitiveTypeName p) {    Set<PrimitiveTypeName> descriptors = classToParquetType.get(c);    if (descriptors == null) {      descriptors = new HashSet<PrimitiveTypeName>();      classToParquetType.put(c, descriptors);    }    descriptors.add(p);    Set<Class<?>> classes = parquetTypeToClass.get(p);    if (classes == null) {      classes = new HashSet<Class<?>>();      parquetTypeToClass.put(p, classes);    }    classes.add(c);  }
public static <T extends Comparable<T>> void assertTypeValid(Column<T> foundColumn, PrimitiveTypeName primitiveType) {    Class<T> foundColumnType = foundColumn.getColumnType();    ColumnPath columnPath = foundColumn.getColumnPath();    Set<PrimitiveTypeName> validTypeDescriptors = classToParquetType.get(foundColumnType);    if (validTypeDescriptors == null) {      StringBuilder message = new StringBuilder();      message          .append("Column ")          .append(columnPath.toDotString())          .append(" was declared as type: ")          .append(foundColumnType.getName())          .append(" which is not supported in FilterPredicates.");      Set<Class<?>> supportedTypes = parquetTypeToClass.get(primitiveType);      if (supportedTypes != null) {        message          .append(" Supported types for this column are: ")          .append(supportedTypes);      } else {        message.append(" There are no supported types for columns of " + primitiveType);      }      throw new IllegalArgumentException(message.toString());    }    if (!validTypeDescriptors.contains(primitiveType)) {      StringBuilder message = new StringBuilder();      message          .append("FilterPredicate column: ")          .append(columnPath.toDotString())          .append("'s declared type (")          .append(foundColumnType.getName())          .append(") does not match the schema found in file metadata. Column ")          .append(columnPath.toDotString())          .append(" is of type: ")          .append(primitiveType)          .append("\nValid types for this column are: ")          .append(parquetTypeToClass.get(primitiveType));      throw new IllegalArgumentException(message.toString());    }  }
public static String join(Iterable<String> s, String on) {    return join(s.iterator(), on);  }
public static String join(Iterator<String> iter, String on) {    StringBuilder sb = new StringBuilder();    while (iter.hasNext()) {      sb.append(iter.next());      if (iter.hasNext()) {        sb.append(on);      }    }    return sb.toString();  }
public static String join(String[] s, String on) {    return join(Arrays.asList(s), on);  }
public static List<WildcardPath> expandGlobToWildCardPaths(String globPattern, char delim) {    List<WildcardPath> ret = new ArrayList<WildcardPath>();    for (String expandedGlob : Strings.expandGlob(globPattern)) {      ret.add(new WildcardPath(globPattern, expandedGlob, delim));    }    return ret;  }
public static int checkedCast(long value) {    int valueI = (int) value;    if (valueI != value) {      throw new IllegalArgumentException(String.format("Overflow casting %d to an int", value));    }    return valueI;  }
@SuppressWarnings("rawtypes")  Class<? extends HiveBinding> create(ClassLoader classLoader) {    // HiveVersionInfo was added in 0.11, if the class does    // not exist then return the hive binding for 0.10    Class hiveVersionInfo;    try {      hiveVersionInfo = Class.forName(HIVE_VERSION_CLASS_NAME, true, classLoader);    } catch (ClassNotFoundException e) {      LOG.debug("Class " + HIVE_VERSION_CLASS_NAME + ", not found, returning {}",          Hive010Binding.class.getSimpleName());      return Hive010Binding.class;    }    return createInternal(hiveVersionInfo);  }
@SuppressWarnings({"unchecked", "rawtypes"})  Class<? extends HiveBinding> createInternal(Class hiveVersionInfo) {    String hiveVersion;    try {      Method getVersionMethod = hiveVersionInfo.          getMethod(HIVE_VERSION_METHOD_NAME, (Class[])null);      String rawVersion = (String)getVersionMethod.invoke(null, (Object[])null);      LOG.debug("Raw Version from {} is '{}'", hiveVersionInfo.getSimpleName(), rawVersion);      hiveVersion = trimVersion(rawVersion);    } catch (Exception e) {      throw new UnexpectedHiveVersionProviderError("Unexpected error whilst " +          "determining Hive version", e);    }    if(hiveVersion.equalsIgnoreCase(HIVE_VERSION_UNKNOWN)) {      LOG.debug("Unknown hive version, attempting to guess");      return createBindingForUnknownVersion();    }    if(hiveVersion.startsWith(HIVE_VERSION_010)) {      LOG.debug("Hive version {}, returning {}", hiveVersion, Hive010Binding.class.getSimpleName());      return Hive010Binding.class;    } else if(hiveVersion.startsWith(HIVE_VERSION_011)) {      LOG.debug("Hive version " + hiveVersion + ", returning " +          Hive010Binding.class.getSimpleName() + " as it's expected the 0.10 " +          "binding will work with 0.11");      return Hive010Binding.class;    } else if(hiveVersion.startsWith(HIVE_VERSION_013)) {      throw new HiveBindingInstantiationError("Hive 0.13 contains native Parquet support " +           "and the parquet-hive jars from the parquet project should not be included " +          "in Hive's classpath.");    }    LOG.debug("Hive version {}, returning {}", hiveVersion,        Hive012Binding.class.getSimpleName());    // as of 11/26/2013 it looks like the 0.12 binding will work for 0.13    return Hive012Binding.class;  }
public static void writeMetaDataFile(Configuration configuration, Path outputPath) {    JobSummaryLevel level = ParquetOutputFormat.getJobSummaryLevel(configuration);    if (level == JobSummaryLevel.NONE) {      return;    }    try {      final FileSystem fileSystem = outputPath.getFileSystem(configuration);      FileStatus outputStatus = fileSystem.getFileStatus(outputPath);      List<Footer> footers;      switch (level) {        case ALL:          footers = ParquetFileReader.readAllFootersInParallel(configuration, outputStatus, false); // don't skip row groups          break;        case COMMON_ONLY:          footers = ParquetFileReader.readAllFootersInParallel(configuration, outputStatus, true); // skip row groups          break;        default:          throw new IllegalArgumentException("Unrecognized job summary level: " + level);      }      // If there are no footers, _metadata file cannot be written since there is no way to determine schema!      // Onus of writing any summary files lies with the caller in this case.      if (footers.isEmpty()) {        return;      }      try {        ParquetFileWriter.writeMetadataFile(configuration, outputPath, footers, level);      } catch (Exception e) {        LOG.warn("could not write summary file(s) for " + outputPath, e);        final Path metadataPath = new Path(outputPath, ParquetFileWriter.PARQUET_METADATA_FILE);        try {          if (fileSystem.exists(metadataPath)) {            fileSystem.delete(metadataPath, true);          }        } catch (Exception e2) {          LOG.warn("could not delete metadata file" + outputPath, e2);        }        try {          final Path commonMetadataPath = new Path(outputPath, ParquetFileWriter.PARQUET_COMMON_METADATA_FILE);          if (fileSystem.exists(commonMetadataPath)) {            fileSystem.delete(commonMetadataPath, true);          }        } catch (Exception e2) {          LOG.warn("could not delete metadata file" + outputPath, e2);        }      }    } catch (Exception e) {      LOG.warn("could not write summary file for " + outputPath, e);    }  }
@Deprecated  public void unpack8Values(final byte[] input, final int inPos, final int[] output, final int outPos) {    unpack8Values(ByteBuffer.wrap(input), inPos, output, outPos);  }
@Deprecated  public void unpack32Values(byte[] input, int inPos, int[] output, int outPos) {    unpack32Values(ByteBuffer.wrap(input), inPos, output, outPos);  }
public SchemaMapping fromArrow(Schema arrowSchema) {    List<Field> fields = arrowSchema.getFields();    List<TypeMapping> parquetFields = fromArrow(fields);    MessageType parquetType = addToBuilder(parquetFields, Types.buildMessage()).named("root");    return new SchemaMapping(arrowSchema, parquetType, parquetFields);  }
public SchemaMapping fromParquet(MessageType parquetSchema) {    List<Type> fields = parquetSchema.getFields();    List<TypeMapping> mappings = fromParquet(fields);    List<Field> arrowFields = fields(mappings);    return new SchemaMapping(new Schema(arrowFields), parquetSchema, mappings);  }
public SchemaMapping map(Schema arrowSchema, MessageType parquetSchema) {    List<TypeMapping> children = map(arrowSchema.getFields(), parquetSchema.getFields());    return new SchemaMapping(arrowSchema, parquetSchema, children);  }
List<SchemaElement> toParquetSchema(MessageType schema) {    List<SchemaElement> result = new ArrayList<SchemaElement>();    addToList(result, schema);    return result;  }
Set<org.apache.parquet.column.Encoding> fromFormatEncodings(List<Encoding> encodings) {    Set<org.apache.parquet.column.Encoding> converted = new HashSet<org.apache.parquet.column.Encoding>();    for (Encoding encoding : encodings) {      converted.add(getEncoding(encoding));    }    // make converted unmodifiable, drop reference to modifiable copy    converted = Collections.unmodifiableSet(converted);    // atomically update the cache    Set<org.apache.parquet.column.Encoding> cached = cachedEncodingSets.putIfAbsent(converted, converted);    if (cached == null) {      // cached == null signifies that converted was *not* in the cache previously      // so we can return converted instead of throwing it away, it has now      // been cached      cached = converted;    }    return cached;  }
static org.apache.parquet.column.statistics.Statistics fromParquetStatisticsInternal      (String createdBy, Statistics formatStats, PrimitiveType type, SortOrder typeSortOrder) {    // create stats object based on the column type    org.apache.parquet.column.statistics.Statistics.Builder statsBuilder =        org.apache.parquet.column.statistics.Statistics.getBuilderForReading(type);    if (formatStats != null) {      // Use the new V2 min-max statistics over the former one if it is filled      if (formatStats.isSetMin_value() && formatStats.isSetMax_value()) {        byte[] min = formatStats.min_value.array();        byte[] max = formatStats.max_value.array();        if (isMinMaxStatsSupported(type) || Arrays.equals(min, max)) {          statsBuilder.withMin(min);          statsBuilder.withMax(max);        }      } else {        boolean isSet = formatStats.isSetMax() && formatStats.isSetMin();        boolean maxEqualsMin = isSet ? Arrays.equals(formatStats.getMin(), formatStats.getMax()) : false;        boolean sortOrdersMatch = SortOrder.SIGNED == typeSortOrder;        // NOTE: See docs in CorruptStatistics for explanation of why this check is needed        // The sort order is checked to avoid returning min/max stats that are not        // valid with the type's sort order. In previous releases, all stats were        // aggregated using a signed byte-wise ordering, which isn't valid for all the        // types (e.g. strings, decimals etc.).        if (!CorruptStatistics.shouldIgnoreStatistics(createdBy, type.getPrimitiveTypeName()) &&            (sortOrdersMatch || maxEqualsMin)) {          if (isSet) {            statsBuilder.withMin(formatStats.min.array());            statsBuilder.withMax(formatStats.max.array());          }        }      }      if (formatStats.isSetNull_count()) {        statsBuilder.withNumNulls(formatStats.null_count);      }    }    return statsBuilder.build();  }
private boolean overrideSortOrderToSigned(PrimitiveType type) {    // even if the override is set, only return stats for string-ish types    // a null type annotation is considered string-ish because some writers    // failed to use the UTF8 annotation.    LogicalTypeAnnotation annotation = type.getLogicalTypeAnnotation();    return useSignedStringMinMax &&        PrimitiveTypeName.BINARY == type.getPrimitiveTypeName() &&        (annotation == null || STRING_TYPES.contains(annotation.getClass()));  }
Type getType(PrimitiveTypeName type) {    switch (type) {      case INT64:        return Type.INT64;      case INT32:        return Type.INT32;      case BOOLEAN:        return Type.BOOLEAN;      case BINARY:        return Type.BYTE_ARRAY;      case FLOAT:        return Type.FLOAT;      case DOUBLE:        return Type.DOUBLE;      case INT96:        return Type.INT96;      case FIXED_LEN_BYTE_ARRAY:        return Type.FIXED_LEN_BYTE_ARRAY;      default:        throw new RuntimeException("Unknown primitive type " + type);    }  }
LogicalTypeAnnotation getLogicalTypeAnnotation(ConvertedType type, SchemaElement schemaElement) {    switch (type) {      case UTF8:        return LogicalTypeAnnotation.stringType();      case MAP:        return LogicalTypeAnnotation.mapType();      case MAP_KEY_VALUE:        return LogicalTypeAnnotation.MapKeyValueTypeAnnotation.getInstance();      case LIST:        return LogicalTypeAnnotation.listType();      case ENUM:        return LogicalTypeAnnotation.enumType();      case DECIMAL:        int scale = (schemaElement == null ? 0 : schemaElement.scale);        int precision = (schemaElement == null ? 0 : schemaElement.precision);        return LogicalTypeAnnotation.decimalType(scale, precision);      case DATE:        return LogicalTypeAnnotation.dateType();      case TIME_MILLIS:        return LogicalTypeAnnotation.timeType(true, LogicalTypeAnnotation.TimeUnit.MILLIS);      case TIME_MICROS:        return LogicalTypeAnnotation.timeType(true, LogicalTypeAnnotation.TimeUnit.MICROS);      case TIMESTAMP_MILLIS:        return LogicalTypeAnnotation.timestampType(true, LogicalTypeAnnotation.TimeUnit.MILLIS);      case TIMESTAMP_MICROS:        return LogicalTypeAnnotation.timestampType(true, LogicalTypeAnnotation.TimeUnit.MICROS);      case INTERVAL:        return LogicalTypeAnnotation.IntervalLogicalTypeAnnotation.getInstance();      case INT_8:        return LogicalTypeAnnotation.intType(8, true);      case INT_16:        return LogicalTypeAnnotation.intType(16, true);      case INT_32:        return LogicalTypeAnnotation.intType(32, true);      case INT_64:        return LogicalTypeAnnotation.intType(64, true);      case UINT_8:        return LogicalTypeAnnotation.intType(8, false);      case UINT_16:        return LogicalTypeAnnotation.intType(16, false);      case UINT_32:        return LogicalTypeAnnotation.intType(32, false);      case UINT_64:        return LogicalTypeAnnotation.intType(64, false);      case JSON:        return LogicalTypeAnnotation.jsonType();      case BSON:        return LogicalTypeAnnotation.bsonType();      default:        throw new RuntimeException("Can't convert converted type to logical type, unknown converted type " + type);    }  }
static FileMetaData filterFileMetaDataByMidpoint(FileMetaData metaData, RangeMetadataFilter filter) {    List<RowGroup> rowGroups = metaData.getRow_groups();    List<RowGroup> newRowGroups = new ArrayList<RowGroup>();    for (RowGroup rowGroup : rowGroups) {      long totalSize = 0;      long startIndex = getOffset(rowGroup.getColumns().get(0));      for (ColumnChunk col : rowGroup.getColumns()) {        totalSize += col.getMeta_data().getTotal_compressed_size();      }      long midPoint = startIndex + totalSize / 2;      if (filter.contains(midPoint)) {        newRowGroups.add(rowGroup);      }    }    metaData.setRow_groups(newRowGroups);    return metaData;  }
static FileMetaData filterFileMetaDataByStart(FileMetaData metaData, OffsetMetadataFilter filter) {    List<RowGroup> rowGroups = metaData.getRow_groups();    List<RowGroup> newRowGroups = new ArrayList<RowGroup>();    for (RowGroup rowGroup : rowGroups) {      long startIndex = getOffset(rowGroup.getColumns().get(0));      if (filter.contains(startIndex)) {        newRowGroups.add(rowGroup);      }    }    metaData.setRow_groups(newRowGroups);    return metaData;  }
static long getOffset(ColumnChunk columnChunk) {    ColumnMetaData md = columnChunk.getMeta_data();    long offset = md.getData_page_offset();    if (md.isSetDictionary_page_offset() && offset > md.getDictionary_page_offset()) {      offset = md.getDictionary_page_offset();    }    return offset;  }
MessageType fromParquetSchema(List<SchemaElement> schema, List<ColumnOrder> columnOrders) {    Iterator<SchemaElement> iterator = schema.iterator();    SchemaElement root = iterator.next();    Types.MessageTypeBuilder builder = Types.buildMessage();    if (root.isSetField_id()) {      builder.id(root.field_id);    }    buildChildren(builder, iterator, root.getNum_children(), columnOrders, 0);    return builder.named(root.name);  }
@Deprecated  public void writeDataPageV2Header(      int uncompressedSize, int compressedSize,      int valueCount, int nullCount, int rowCount,      org.apache.parquet.column.statistics.Statistics statistics,      org.apache.parquet.column.Encoding dataEncoding,      int rlByteLength, int dlByteLength,      OutputStream to) throws IOException {    writePageHeader(        newDataPageV2Header(            uncompressedSize, compressedSize,            valueCount, nullCount, rowCount,            dataEncoding,            rlByteLength, dlByteLength), to);  }
public final void writeLong(long v) throws IOException {    writeBuffer[7] = (byte)(v >>> 56);    writeBuffer[6] = (byte)(v >>> 48);    writeBuffer[5] = (byte)(v >>> 40);    writeBuffer[4] = (byte)(v >>> 32);    writeBuffer[3] = (byte)(v >>> 24);    writeBuffer[2] = (byte)(v >>> 16);    writeBuffer[1] = (byte)(v >>>  8);    writeBuffer[0] = (byte)(v >>>  0);    out.write(writeBuffer, 0, 8);  }
private void skipToMatch() {    while (recordsRead < recordCount && !recordFilter.isMatch()) {      State currentState = getState(0);      do {        ColumnReader columnReader = currentState.column;        // currentLevel = depth + 1 at this point        // set the current value        if (columnReader.getCurrentDefinitionLevel() >= currentState.maxDefinitionLevel) {          columnReader.skip();        }        columnReader.consume();        // Based on repetition level work out next state to go to        int nextR = currentState.maxRepetitionLevel == 0 ? 0 : columnReader.getCurrentRepetitionLevel();        currentState = currentState.getNextState(nextR);      } while (currentState != null);      ++ recordsRead;    }  }
public static void writeObjectToConfAsBase64(String key, Object obj, Configuration conf) throws IOException {    try(ByteArrayOutputStream baos = new ByteArrayOutputStream()) {      try(GZIPOutputStream gos = new GZIPOutputStream(baos);            ObjectOutputStream oos = new ObjectOutputStream(gos)) {        oos.writeObject(obj);      }      conf.set(key, new String(Base64.encodeBase64(baos.toByteArray()), StandardCharsets.UTF_8));    }  }
@SuppressWarnings("unchecked")  public static <T> T readObjectFromConfAsBase64(String key, Configuration conf) throws IOException {    String b64 = conf.get(key);    if (b64 == null) {      return null;    }    byte[] bytes = Base64.decodeBase64(b64.getBytes(StandardCharsets.UTF_8));    try (ByteArrayInputStream bais = new ByteArrayInputStream(bytes);           GZIPInputStream gis = new GZIPInputStream(bais);           ObjectInputStream ois  = new ObjectInputStream(gis)) {      return (T) ois.readObject();    } catch (ClassNotFoundException e) {      throw new IOException("Could not read object from config with key " + key, e);    } catch (ClassCastException e) {      throw new IOException("Couldn't cast object read from config with key " + key, e);    }  }
public void add(int compressedPageSize, long rowCount) {    add(previousOffset + previousPageSize, compressedPageSize, previousRowIndex + previousRowCount);    previousRowCount = rowCount;  }
public void add(long offset, int compressedPageSize, long firstRowIndex) {    previousOffset = offset;    offsets.add(offset);    previousPageSize = compressedPageSize;    compressedPageSizes.add(compressedPageSize);    previousRowIndex = firstRowIndex;    firstRowIndexes.add(firstRowIndex);  }
public OffsetIndex build(long firstPageOffset) {    if (compressedPageSizes.isEmpty()) {      return null;    }    long[] offsets = this.offsets.toLongArray();    if (firstPageOffset != 0) {      for (int i = 0, n = offsets.length; i < n; ++i) {        offsets[i] += firstPageOffset;      }    }    OffsetIndexImpl offsetIndex = new OffsetIndexImpl();    offsetIndex.offsets = offsets;    offsetIndex.compressedPageSizes = compressedPageSizes.toIntArray();    offsetIndex.firstRowIndexes = firstRowIndexes.toLongArray();    return offsetIndex;  }
public V remove(final K key) {    V oldValue = cacheMap.remove(key);    if (oldValue != null) {      LOG.debug("Removed cache entry for '{}'", key);    }    return oldValue;  }
public void put(final K key, final V newValue) {    if (newValue == null || !newValue.isCurrent(key)) {      if (LOG.isWarnEnabled()) {        LOG.warn("Ignoring new cache entry for '{}' because it is {}", key,                (newValue == null ? "null" : "not current"));      }      return;    }    V oldValue = cacheMap.get(key);    if (oldValue != null && oldValue.isNewerThan(newValue)) {      if (LOG.isWarnEnabled()) {        LOG.warn("Ignoring new cache entry for '{}' because "                + "existing cache entry is newer", key);      }      return;    }    // no existing value or new value is newer than old value    oldValue = cacheMap.put(key, newValue);    if (LOG.isDebugEnabled()) {      if (oldValue == null) {        LOG.debug("Added new cache entry for '{}'", key);      } else {        LOG.debug("Overwrote existing cache entry for '{}'", key);      }    }  }
public V getCurrentValue(final K key) {    V value = cacheMap.get(key);    LOG.debug("Value for '{}' {} in cache", key, (value == null ? "not " : ""));    if (value != null && !value.isCurrent(key)) {      // value is not current; remove it and return null      remove(key);      return null;    }    return value;  }
private void writeValue(Type type, Schema avroSchema, Object value) {    Schema nonNullAvroSchema = AvroSchemaConverter.getNonNull(avroSchema);    LogicalType logicalType = nonNullAvroSchema.getLogicalType();    if (logicalType != null) {      Conversion<?> conversion = model.getConversionByClass(          value.getClass(), logicalType);      writeValueWithoutConversion(type, nonNullAvroSchema,          convert(nonNullAvroSchema, logicalType, conversion, value));    } else {      writeValueWithoutConversion(type, nonNullAvroSchema, value);    }  }
@SuppressWarnings("unchecked")  private void writeValueWithoutConversion(Type type, Schema avroSchema, Object value) {    switch (avroSchema.getType()) {      case BOOLEAN:        recordConsumer.addBoolean((Boolean) value);        break;      case INT:        if (value instanceof Character) {          recordConsumer.addInteger((Character) value);        } else {          recordConsumer.addInteger(((Number) value).intValue());        }        break;      case LONG:        recordConsumer.addLong(((Number) value).longValue());        break;      case FLOAT:        recordConsumer.addFloat(((Number) value).floatValue());        break;      case DOUBLE:        recordConsumer.addDouble(((Number) value).doubleValue());        break;      case FIXED:        recordConsumer.addBinary(Binary.fromReusedByteArray(((GenericFixed) value).bytes()));        break;      case BYTES:        if (value instanceof byte[]) {          recordConsumer.addBinary(Binary.fromReusedByteArray((byte[]) value));        } else {          recordConsumer.addBinary(Binary.fromReusedByteBuffer((ByteBuffer) value));        }        break;      case STRING:        recordConsumer.addBinary(fromAvroString(value));        break;      case RECORD:        writeRecord(type.asGroupType(), avroSchema, value);        break;      case ENUM:        recordConsumer.addBinary(Binary.fromString(value.toString()));        break;      case ARRAY:        listWriter.writeList(type.asGroupType(), avroSchema, value);        break;      case MAP:        writeMap(type.asGroupType(), avroSchema, (Map<CharSequence, ?>) value);        break;      case UNION:        writeUnion(type.asGroupType(), avroSchema, value);        break;    }
public void set(String glob) {    StringBuilder regex = new StringBuilder();    int setOpen = 0;    int curlyOpen = 0;    int len = glob.length();    hasWildcard = false;    for (int i = 0; i < len; i++) {      char c = glob.charAt(i);      switch (c) {        case BACKSLASH:          if (++i >= len) {            error("Missing escaped character", glob, i);          }          regex.append(c).append(glob.charAt(i));          continue;        case '.':        case '$':        case '(':        case ')':        case '|':        case '+':          // escape regex special chars that are not glob special chars          regex.append(BACKSLASH);          break;        case '*':          if (i + 1 < len && glob.charAt(i + 1) == '*') {            regex.append('.');            i++;            break;          }          regex.append("[^" + PATH_SEPARATOR + "]");          hasWildcard = true;          break;        case '?':          regex.append('.');          hasWildcard = true;          continue;        case '{': // start of a group          regex.append("(?:"); // non-capturing          curlyOpen++;          hasWildcard = true;          continue;        case ',':          regex.append(curlyOpen > 0 ? '|' : c);          continue;        case '}':          if (curlyOpen > 0) {            // end of a group            curlyOpen--;            regex.append(")");            continue;          }          break;        case '[':          if (setOpen > 0) {            error("Unclosed character class", glob, i);          }          setOpen++;          hasWildcard = true;          break;        case '^': // ^ inside [...] can be unescaped          if (setOpen == 0) {            regex.append(BACKSLASH);          }          break;        case '!': // [! needs to be translated to [^          regex.append(setOpen > 0 && '[' == glob.charAt(i - 1) ? '^' : '!');          continue;        case ']':          // Many set errors like [][] could not be easily detected here,          // as []], []-] and [-] are all valid POSIX glob and java regex.          // We'll just let the regex compiler do the real work.          setOpen = 0;          break;        default:      }      regex.append(c);    }    if (setOpen > 0) {      error("Unclosed character class", glob, len);    }    if (curlyOpen > 0) {      error("Unclosed group", glob, len);    }    compiled = Pattern.compile(regex.toString());  }
public void output(String content, Logger console, String filename)      throws IOException {    if (filename == null || "-".equals(filename)) {      console.info(content);    } else {      FSDataOutputStream outgoing = create(filename);      try {        outgoing.write(content.getBytes(StandardCharsets.UTF_8));      } finally {        outgoing.close();      }    }  }
public Path qualifiedPath(String filename) throws IOException {    Path cwd = defaultFS().makeQualified(new Path("."));    return new Path(filename).makeQualified(defaultFS().getUri(), cwd);  }
public URI qualifiedURI(String filename) throws IOException {    URI fileURI = URI.create(filename);    if (RESOURCE_URI_SCHEME.equals(fileURI.getScheme())) {      return fileURI;    } else {      return qualifiedPath(filename).toUri();    }  }
public InputStream open(String filename) throws IOException {    if (STDIN_AS_SOURCE.equals(filename)) {      return System.in;    }    URI uri = qualifiedURI(filename);    if (RESOURCE_URI_SCHEME.equals(uri.getScheme())) {      return Resources.getResource(uri.getRawSchemeSpecificPart()).openStream();    } else {      Path filePath = new Path(uri);      // even though it was qualified using the default FS, it may not be in it      FileSystem fs = filePath.getFileSystem(getConf());      return fs.open(filePath);    }  }
protected static ClassLoader loaderFor(List<String> jars, List<String> paths)      throws MalformedURLException {    return AccessController.doPrivileged(new GetClassLoader(urls(jars, paths)));  }
protected static ClassLoader loaderForJars(List<String> jars)      throws MalformedURLException {    return AccessController.doPrivileged(new GetClassLoader(urls(jars, null)));  }
protected static ClassLoader loaderForPaths(List<String> paths)      throws MalformedURLException {    return AccessController.doPrivileged(new GetClassLoader(urls(null, paths)));  }
@Override  public void writeInteger(int v) {    try {      bitPackingWriter.write(v);    } catch (IOException e) {      throw new ParquetEncodingException(e);    }  }
@Override  public BytesInput getBytes() {    try {      this.bitPackingWriter.finish();      return BytesInput.from(out);    } catch (IOException e) {      throw new ParquetEncodingException(e);    }  }
public static final UnboundRecordFilter column(final String columnPath,                                                 final ColumnPredicates.Predicate predicate) {    checkNotNull(columnPath, "columnPath");    checkNotNull(predicate,  "predicate");    return new UnboundRecordFilter() {      final String[] filterPath = columnPath.split("\\.");      @Override      public RecordFilter bind(Iterable<ColumnReader> readers) {        for (ColumnReader reader : readers) {          if ( Arrays.equals( reader.getDescriptor().getPath(), filterPath)) {            return new ColumnRecordFilter(reader, predicate);          }        }        throw new IllegalArgumentException( "Column " + columnPath + " does not exist.");      }    };  }
static OffsetIndex filterOffsetIndex(OffsetIndex offsetIndex, RowRanges rowRanges, long totalRowCount) {    IntList indexMap = new IntArrayList();    for (int i = 0, n = offsetIndex.getPageCount(); i < n; ++i) {      long from = offsetIndex.getFirstRowIndex(i);      if (rowRanges.isOverlapping(from, offsetIndex.getLastRowIndex(i, totalRowCount))) {        indexMap.add(i);      }    }    return new FilteredOffsetIndex(offsetIndex, indexMap.toIntArray());  }
public MessageType convert(StructType struct) {    MessageType messageType = ThriftSchemaConvertVisitor.convert(struct, fieldProjectionFilter, true);    fieldProjectionFilter.assertNoUnmatchedPatterns();    return messageType;  }
public static MessageType convertWithoutProjection(StructType struct) {    return ThriftSchemaConvertVisitor.convert(struct, FieldProjectionFilter.ALL_COLUMNS, false);  }
static boolean isListElementType(Type repeatedType,                                   ThriftField thriftElement) {    if (repeatedType.isPrimitive() ||        (repeatedType.asGroupType().getFieldCount() != 1) ||        (repeatedType.asGroupType().getType(0).isRepetition(REPEATED))) {      // The repeated type must be the element type because it is an invalid      // synthetic wrapper. Must be a group with one optional or required field      return true;    } else if (thriftElement != null && thriftElement.getType() instanceof StructType) {      Set<String> fieldNames = new HashSet<String>();      for (ThriftField field : ((StructType) thriftElement.getType()).getChildren()) {        fieldNames.add(field.getName());      }      // If the repeated type is a subset of the structure of the ThriftField,      // then it must be the element type.      return fieldNames.contains(repeatedType.asGroupType().getFieldName(0));    }    return false;  }
private static GroupType listWrapper(Repetition repetition, String alias, LogicalTypeAnnotation logicalTypeAnnotation, Type nested) {    if (!nested.isRepetition(Repetition.REPEATED)) {      throw new IllegalArgumentException("Nested type should be repeated: " + nested);    }    return new GroupType(repetition, alias, logicalTypeAnnotation, nested);  }
public static GroupType listOfElements(Repetition listRepetition, String name, Type elementType) {    Preconditions.checkArgument(elementType.getName().equals(ELEMENT_NAME),        "List element type must be named 'element'");    return listWrapper(        listRepetition,        name,        LogicalTypeAnnotation.listType(),        new GroupType(Repetition.REPEATED, "list", elementType)    );  }
@Override  public void checkSchema(ResourceSchema s) throws IOException {    getProperties().setProperty(SCHEMA, s.toString());  }
@Override  public OutputFormat<Void, Tuple> getOutputFormat() throws IOException {    Schema pigSchema = getSchema();    return new ParquetOutputFormat<Tuple>(new TupleWriteSupport(pigSchema));  }
@Override  public void putNext(Tuple tuple) throws IOException {    try {      this.recordWriter.write(null, tuple);    } catch (InterruptedException e) {      Thread.interrupted();      throw new ParquetEncodingException("Interrupted while writing", e);    }  }
@Deprecated  public Map<String, String> getMergedKeyValueMetaData() {    if (mergedKeyValueMetadata == null) {      Map<String, String> mergedKeyValues = new HashMap<String, String>();      for (Entry<String, Set<String>> entry : keyValueMetadata.entrySet()) {        if (entry.getValue().size() > 1) {          throw new RuntimeException("could not merge metadata: key " + entry.getKey() + " has conflicting values: " + entry.getValue());        }        mergedKeyValues.put(entry.getKey(), entry.getValue().iterator().next());      }      mergedKeyValueMetadata = mergedKeyValues;    }    return mergedKeyValueMetadata;  }
protected ParquetInputSplit getSplit(      final InputSplit oldSplit,      final JobConf conf      ) throws IOException {    if (oldSplit instanceof FileSplit) {      FileSplit fileSplit = (FileSplit) oldSplit;      final long splitStart = fileSplit.getStart();      final long splitLength = fileSplit.getLength();      final Path finalPath = fileSplit.getPath();      final JobConf cloneJob = hiveBinding.pushProjectionsAndFilters(conf, finalPath.getParent());      final ParquetMetadata parquetMetadata = ParquetFileReader.readFooter(cloneJob, finalPath, SKIP_ROW_GROUPS);      final FileMetaData fileMetaData = parquetMetadata.getFileMetaData();      final ReadContext readContext =          new DataWritableReadSupport()            .init(cloneJob, fileMetaData.getKeyValueMetaData(), fileMetaData.getSchema());      schemaSize = MessageTypeParser.parseMessageType(            readContext.getReadSupportMetadata().get(DataWritableReadSupport.HIVE_SCHEMA_KEY)          ).getFieldCount();       return new ParquetInputSplit(                finalPath,                splitStart,                splitStart + splitLength,                splitLength,                fileSplit.getLocations(),                null);    } else {      throw new IllegalArgumentException("Unknown split type: " + oldSplit);    }  }
@Override  public RecordWriter<Void, T> getRecordWriter(TaskAttemptContext taskAttemptContext)      throws IOException, InterruptedException {    final Configuration conf = getConfiguration(taskAttemptContext);    CompressionCodecName codec = getCodec(taskAttemptContext);    String extension = codec.getExtension() + ".parquet";    Path file = getDefaultWorkFile(taskAttemptContext, extension);    return getRecordWriter(conf, file, codec);  }
public final int skipBytes(int n) throws IOException {    int total = 0;    int cur = 0;    while ((total<n) && ((cur = (int) in.skip(n-total)) > 0)) {      total += cur;    }    return total;  }
public final int readUnsignedShort() throws IOException {    int ch2 = in.read();    int ch1 = in.read();    if ((ch1 | ch2) < 0)      throw new EOFException();    return (ch1 << 8) + (ch2 << 0);  }
public final long readLong() throws IOException {    // TODO: see perf question above in readInt    readFully(readBuffer, 0, 8);    return (((long)readBuffer[7] << 56) +        ((long)(readBuffer[6] & 255) << 48) +        ((long)(readBuffer[5] & 255) << 40) +        ((long)(readBuffer[4] & 255) << 32) +        ((long)(readBuffer[3] & 255) << 24) +        ((readBuffer[2] & 255) << 16) +        ((readBuffer[1] & 255) <<  8) +        ((readBuffer[0] & 255) <<  0));  }
static ParquetInputSplit from(FileSplit split) throws IOException {    return new ParquetInputSplit(split.getPath(),        split.getStart(), split.getStart() + split.getLength(),        split.getLength(), split.getLocations(), null);  }
static ParquetInputSplit from(org.apache.hadoop.mapred.FileSplit split) throws IOException {    return new ParquetInputSplit(split.getPath(),        split.getStart(), split.getStart() + split.getLength(),        split.getLength(), split.getLocations(), null);  }
@Override  public void readFields(DataInput hin) throws IOException {    byte[] bytes = readArray(hin);    DataInputStream in = new DataInputStream(new GZIPInputStream(new ByteArrayInputStream(bytes)));    super.readFields(in);    this.end = in.readLong();    if (in.readBoolean()) {      this.rowGroupOffsets = new long[in.readInt()];      for (int i = 0; i < rowGroupOffsets.length; i++) {        rowGroupOffsets[i] = in.readLong();      }    }    in.close();  }
@Override  public void write(DataOutput hout) throws IOException {    ByteArrayOutputStream baos = new ByteArrayOutputStream();    DataOutputStream out = new DataOutputStream(new GZIPOutputStream(baos));    super.write(out);    out.writeLong(end);    out.writeBoolean(rowGroupOffsets != null);    if (rowGroupOffsets != null) {      out.writeInt(rowGroupOffsets.length);      for (long o : rowGroupOffsets) {        out.writeLong(o);      }    }    out.close();    writeArray(hout, baos.toByteArray());  }
public static PrimitiveBuilder<PrimitiveType> required(PrimitiveTypeName type) {    return new PrimitiveBuilder<PrimitiveType>(PrimitiveType.class, type)        .repetition(Type.Repetition.REQUIRED);  }
public static PrimitiveBuilder<PrimitiveType> optional(PrimitiveTypeName type) {    return new PrimitiveBuilder<PrimitiveType>(PrimitiveType.class, type)        .repetition(Type.Repetition.OPTIONAL);  }
public static PrimitiveBuilder<PrimitiveType> repeated(PrimitiveTypeName type) {    return new PrimitiveBuilder<PrimitiveType>(PrimitiveType.class, type)        .repetition(Type.Repetition.REPEATED);  }
public static GroupBuilder<GroupType> requiredGroup() {    return new GroupBuilder<GroupType>(GroupType.class)        .repetition(Type.Repetition.REQUIRED);  }
public static GroupBuilder<GroupType> optionalGroup() {    return new GroupBuilder<GroupType>(GroupType.class)        .repetition(Type.Repetition.OPTIONAL);  }
public static GroupBuilder<GroupType> repeatedGroup() {    return new GroupBuilder<GroupType>(GroupType.class)        .repetition(Type.Repetition.REPEATED);  }
public IntIterator iterator() {    if (currentSlab == null) {      allocateSlab();    }    int[][] itSlabs = slabs.toArray(new int[slabs.size() + 1][]);    itSlabs[slabs.size()] = currentSlab;    return new IntIterator(itSlabs, size());  }
public static boolean shouldIgnoreStatistics(String createdBy, PrimitiveTypeName columnType) {    if (columnType != PrimitiveTypeName.BINARY && columnType != PrimitiveTypeName.FIXED_LEN_BYTE_ARRAY) {      // the bug only applies to binary columns      return false;    }    if (Strings.isNullOrEmpty(createdBy)) {      // created_by is not populated, which could have been caused by      // parquet-mr during the same time as PARQUET-251, see PARQUET-297      warnOnce("Ignoring statistics because created_by is null or empty! See PARQUET-251 and PARQUET-297");      return true;    }    try {      ParsedVersion version = VersionParser.parse(createdBy);      if (!"parquet-mr".equals(version.application)) {        // assume other applications don't have this bug        return false;      }      if (Strings.isNullOrEmpty(version.version)) {        warnOnce("Ignoring statistics because created_by did not contain a semver (see PARQUET-251): " + createdBy);        return true;      }      SemanticVersion semver = SemanticVersion.parse(version.version);      if (semver.compareTo(PARQUET_251_FIXED_VERSION) < 0 &&          !(semver.compareTo(CDH_5_PARQUET_251_FIXED_START) >= 0 &&              semver.compareTo(CDH_5_PARQUET_251_FIXED_END) < 0)) {        warnOnce("Ignoring statistics because this file was created prior to "            + PARQUET_251_FIXED_VERSION            + ", see PARQUET-251");        return true;      }      // this file was created after the fix      return false;    } catch (RuntimeException e) {      // couldn't parse the created_by field, log what went wrong, don't trust the stats,      // but don't make this fatal.      warnParseErrorOnce(createdBy, e);      return true;    } catch (SemanticVersionParseException e) {      // couldn't parse the created_by field, log what went wrong, don't trust the stats,      // but don't make this fatal.      warnParseErrorOnce(createdBy, e);      return true;    } catch (VersionParseException e) {      // couldn't parse the created_by field, log what went wrong, don't trust the stats,      // but don't make this fatal.      warnParseErrorOnce(createdBy, e);      return true;    }  }
private RecordConsumer validator(RecordConsumer recordConsumer, boolean validating, MessageType schema) {    return validating ? new ValidatingRecordConsumer(recordConsumer, schema) : recordConsumer;  }
private static Map<String, Class<?>> getFieldsByName(Class<?> recordClass,                                                       boolean excludeJava) {    Map<String, Class<?>> fields = new LinkedHashMap<String, Class<?>>();    if (recordClass != null) {      Class<?> current = recordClass;      do {        if (excludeJava && current.getPackage() != null            && current.getPackage().getName().startsWith("java.")) {          break; // skip java built-in classes        }        for (Field field : current.getDeclaredFields()) {          if (field.isAnnotationPresent(AvroIgnore.class) ||              isTransientOrStatic(field)) {            continue;          }          AvroName altName = field.getAnnotation(AvroName.class);          Class<?> existing = fields.put(              altName != null ? altName.value() : field.getName(),              field.getType());          if (existing != null) {            throw new AvroTypeException(                current + " contains two fields named: " + field.getName());          }        }        current = current.getSuperclass();      } while (current != null);    }    return fields;  }
static boolean isElementType(Type repeatedType, Schema elementSchema) {    if (repeatedType.isPrimitive() ||        repeatedType.asGroupType().getFieldCount() > 1 ||        repeatedType.asGroupType().getType(0).isRepetition(REPEATED)) {      // The repeated type must be the element type because it is an invalid      // synthetic wrapper. Must be a group with one optional or required field      return true;    } else if (elementSchema != null &&        elementSchema.getType() == Schema.Type.RECORD) {      Schema schemaFromRepeated = CONVERTER.convert(repeatedType.asGroupType());      if (checkReaderWriterCompatibility(elementSchema, schemaFromRepeated)          .getType() == COMPATIBLE) {        return true;      }    }    return false;  }
@Override  public void writeMessageBegin(TMessage message) throws TException {    LOG.debug("writeMessageBegin({})", message);    currentProtocol.writeMessageBegin(message);  }
@Override  public void writeStructBegin(TStruct struct) throws TException {    if (LOG.isDebugEnabled()) LOG.debug("writeStructBegin("+toString(struct)+")");    currentProtocol.writeStructBegin(struct);  }
@Override  public void writeFieldBegin(TField field) throws TException {    LOG.debug("writeFieldBegin({})", field);    currentProtocol.writeFieldBegin(field);  }
@Override  public void writeMapBegin(TMap map) throws TException {    if (LOG.isDebugEnabled()) LOG.debug("writeMapBegin("+toString(map)+")");    currentProtocol.writeMapBegin(map);  }
@Override  public void writeListBegin(TList list) throws TException {    if (LOG.isDebugEnabled()) LOG.debug("writeListBegin("+toString(list)+")");    currentProtocol.writeListBegin(list);  }
@Override  public void writeSetBegin(TSet set) throws TException {    LOG.debug("writeSetBegin({})", set);    currentProtocol.writeSetBegin(set);  }
@Override  public void writeBool(boolean b) throws TException {    LOG.debug("writeBool({})", b);    currentProtocol.writeBool(b);  }
@Override  public void writeByte(byte b) throws TException {    LOG.debug("writeByte({})", b);    currentProtocol.writeByte(b);  }
@Override  public void writeI16(short i16) throws TException {    LOG.debug("writeI16({})", i16);    currentProtocol.writeI16(i16);  }
@Override  public void writeI32(int i32) throws TException {    LOG.debug("writeI32({})", i32);    currentProtocol.writeI32(i32);  }
@Override  public void writeI64(long i64) throws TException {    LOG.debug("writeI64({})", i64);    currentProtocol.writeI64(i64);  }
@Override  public void writeDouble(double dub) throws TException {    LOG.debug("writeDouble({})", dub);    currentProtocol.writeDouble(dub);  }
@Override  public void writeString(String str) throws TException {    LOG.debug("writeString({})", str);    currentProtocol.writeString(str);  }
@Override  public void writeBinary(ByteBuffer buf) throws TException {    LOG.debug("writeBinary({})", buf);    currentProtocol.writeBinary(buf);  }
private MessageType resolveSchemaAccess(MessageType requestedSchema, MessageType fileSchema,          Configuration configuration) {    if(configuration.getBoolean(PARQUET_COLUMN_INDEX_ACCESS, false)) {      final List<String> listColumns = getColumns(configuration.get(IOConstants.COLUMNS));      List<Type> requestedTypes = new ArrayList<Type>();      for(Type t : requestedSchema.getFields()) {        int index = listColumns.indexOf(t.getName());        requestedTypes.add(fileSchema.getType(index));      }      requestedSchema = new MessageType(requestedSchema.getName(), requestedTypes);    }    return requestedSchema;  }
@Override    public void startField(String field, int index) {      logOpen(field);      delegate.startField(field, index);    }
@Override    public void addBinary(Binary value) {      if (LOG.isDebugEnabled()) log(Arrays.toString(value.getBytesUnsafe()));      delegate.addBinary(value);    }
@Override    public void endField(String field, int index) {      logClose(field);      delegate.endField(field, index);    }
private List<Path> getInputFiles(List<String> input) throws IOException {    List<Path> inputFiles = null;    if (input.size() == 1) {      Path p = new Path(input.get(0));      FileSystem fs = p.getFileSystem(conf);      FileStatus status = fs.getFileStatus(p);      if (status.isDir()) {        inputFiles = getInputFilesFromDirectory(status);      }    } else {      inputFiles = parseInputFiles(input);    }    checkParquetFiles(inputFiles);    return inputFiles;  }
private void checkParquetFiles(List<Path> inputFiles) throws IOException {    if (inputFiles == null || inputFiles.size() <= 1) {      throw new IllegalArgumentException("Not enough files to merge");    }    for (Path inputFile: inputFiles) {      FileSystem fs = inputFile.getFileSystem(conf);      FileStatus status = fs.getFileStatus(inputFile);      if (status.isDir()) {        throw new IllegalArgumentException("Illegal parquet file: " + inputFile.toUri());      }    }  }
private List<Path> getInputFilesFromDirectory(FileStatus partitionDir) throws IOException {    FileSystem fs = partitionDir.getPath().getFileSystem(conf);    FileStatus[] inputFiles = fs.listStatus(partitionDir.getPath(), HiddenFileFilter.INSTANCE);    List<Path> input = new ArrayList<Path>();    for (FileStatus f: inputFiles) {      input.add(f.getPath());    }    return input;  }
@Override  public void initFromPage(int valueCount, ByteBufferInputStream stream) throws IOException {    int effectiveBitLength = valueCount * bitsPerValue;    int length = BytesUtils.paddedByteCountFromBits(effectiveBitLength);    LOG.debug("reading {} bytes for {} values of size {} bits.", length, valueCount, bitsPerValue);    this.in = stream.sliceStream(length);    this.bitPackingReader = createBitPackingReader(bitsPerValue, this.in, valueCount);    updateNextOffset(length);  }
public static final UnboundRecordFilter page( final long startPos, final long pageSize ) {    return new UnboundRecordFilter() {      @Override      public RecordFilter bind(Iterable<ColumnReader> readers) {        return new PagedRecordFilter( startPos, pageSize );      }    };  }
static void readFully(InputStream f, byte[] bytes, int start, int len) throws IOException {    int offset = start;    int remaining = len;    while (remaining > 0) {      int bytesRead = f.read(bytes, offset, remaining);      if (bytesRead < 0) {        throw new EOFException(            "Reached the end of stream with " + remaining + " bytes left to read");      }      remaining -= bytesRead;      offset += bytesRead;    }  }
static int readHeapBuffer(InputStream f, ByteBuffer buf) throws IOException {    int bytesRead = f.read(buf.array(), buf.arrayOffset() + buf.position(), buf.remaining());    if (bytesRead < 0) {      // if this resulted in EOF, don't update position      return bytesRead;    } else {      buf.position(buf.position() + bytesRead);      return bytesRead;    }  }
static void readFullyHeapBuffer(InputStream f, ByteBuffer buf) throws IOException {    readFully(f, buf.array(), buf.arrayOffset() + buf.position(), buf.remaining());    buf.position(buf.limit());  }
static int readDirectBuffer(InputStream f, ByteBuffer buf, byte[] temp) throws IOException {    // copy all the bytes that return immediately, stopping at the first    // read that doesn't return a full buffer.    int nextReadLength = Math.min(buf.remaining(), temp.length);    int totalBytesRead = 0;    int bytesRead;    while ((bytesRead = f.read(temp, 0, nextReadLength)) == temp.length) {      buf.put(temp);      totalBytesRead += bytesRead;      nextReadLength = Math.min(buf.remaining(), temp.length);    }    if (bytesRead < 0) {      // return -1 if nothing was read      return totalBytesRead == 0 ? -1 : totalBytesRead;    } else {      // copy the last partial buffer      buf.put(temp, 0, bytesRead);      totalBytesRead += bytesRead;      return totalBytesRead;    }  }
static void readFullyDirectBuffer(InputStream f, ByteBuffer buf, byte[] temp) throws IOException {    int nextReadLength = Math.min(buf.remaining(), temp.length);    int bytesRead = 0;    while (nextReadLength > 0 && (bytesRead = f.read(temp, 0, nextReadLength)) >= 0) {      buf.put(temp, 0, bytesRead);      nextReadLength = Math.min(buf.remaining(), temp.length);    }    if (bytesRead < 0 && buf.remaining() > 0) {      throw new EOFException(          "Reached the end of stream with " + buf.remaining() + " bytes left to read");    }  }
public static <T extends TBase<T,? extends TFieldIdEnum>> ListConsumer listOf(Class<T> c, final Consumer<List<T>> consumer) {    class ListConsumer implements Consumer<T> {      List<T> list;      @Override      public void consume(T t) {        list.add(t);      }    }    final ListConsumer co = new ListConsumer();    return new DelegatingListElementsConsumer(struct(c, co)) {      @Override      public void consumeList(TProtocol protocol,          EventBasedThriftReader reader, TList tList) throws TException {        co.list = new ArrayList<T>();        super.consumeList(protocol, reader, tList);        consumer.consume(co.list);      }    };  }
private void init(final JobConf job) {    final String plan = HiveConf.getVar(job, HiveConf.ConfVars.PLAN);    if (mrwork == null && plan != null && plan.length() > 0) {      mrwork = Utilities.getMapRedWork(job);      pathToPartitionInfo.clear();      for (final Map.Entry<String, PartitionDesc> entry : mrwork.getPathToPartitionInfo().entrySet()) {        pathToPartitionInfo.put(new Path(entry.getKey()).toUri().getPath().toString(), entry.getValue());      }    }  }
@Override  public JobConf pushProjectionsAndFilters(JobConf jobConf, Path path)      throws IOException {    init(jobConf);    final JobConf cloneJobConf = new JobConf(jobConf);    final PartitionDesc part = pathToPartitionInfo.get(path.toString());    if ((part != null) && (part.getTableDesc() != null)) {      Utilities.copyTableJobPropertiesToConf(part.getTableDesc(), cloneJobConf);    }    pushProjectionsAndFilters(cloneJobConf, path.toString(), path.toUri().toString());    return cloneJobConf;  }
private <T> GroupBuilder<T> convertFields(GroupBuilder<T> groupBuilder, List<FieldDescriptor> fieldDescriptors) {    for (FieldDescriptor fieldDescriptor : fieldDescriptors) {      groupBuilder =          addField(fieldDescriptor, groupBuilder)          .id(fieldDescriptor.getNumber())          .named(fieldDescriptor.getName());    }    return groupBuilder;  }
public MessageType filter(MessageType schemaToFilter, Schema requestedPigSchema) {    return filter(schemaToFilter, requestedPigSchema, null);  }
public MessageType filter(MessageType schemaToFilter, Schema requestedPigSchema, RequiredFieldList requiredFieldList) {    try {      if (LOG.isDebugEnabled()) LOG.debug("filtering schema:\n" + schemaToFilter + "\nwith requested pig schema:\n " + requestedPigSchema);      List<Type> result = columnAccess.filterTupleSchema(schemaToFilter, requestedPigSchema, requiredFieldList);      if (LOG.isDebugEnabled()) LOG.debug("schema:\n" + schemaToFilter + "\nfiltered to:\n" + result);      return new MessageType(schemaToFilter.getName(), result);    } catch (RuntimeException e) {      throw new RuntimeException("can't filter " + schemaToFilter + " with " + requestedPigSchema, e);    }  }
private static Schema schema(Schema.Type type, boolean makeNullable) {    Schema schema = Schema.create(type == null ? Schema.Type.STRING : type);    if (makeNullable || type == null) {      schema = Schema.createUnion(Lists.newArrayList(          Schema.create(Schema.Type.NULL), schema));    }    return schema;  }
@Deprecated  public static void setRecordConverterClass(JobConf conf,      Class<?> klass) {    setRecordConverterClass((Configuration) conf, klass);  }
public static void setRecordConverterClass(Configuration conf,                                             Class<?> klass) {    conf.set(RECORD_CONVERTER_CLASS_KEY, klass.getName());  }
private static TupleSummaryData merge(Tuple t) throws IOException {    TupleSummaryData summaryData = new TupleSummaryData();    DataBag bag = (DataBag) t.get(0);    for (Tuple tuple : bag) {      summaryData.merge(getData(tuple));    }    return summaryData;  }
private static TupleSummaryData sumUp(Schema schema, Tuple t) throws ExecException {    TupleSummaryData summaryData = new TupleSummaryData();    DataBag bag = (DataBag) t.get(0);    for (Tuple tuple : bag) {      summaryData.addTuple(schema, tuple);    }    return summaryData;  }
@Override  public void initialize(InputSplit inputSplit, TaskAttemptContext context)      throws IOException, InterruptedException {    if (ContextUtil.hasCounterMethod(context)) {      BenchmarkCounter.initCounterFromContext(context);    } else {      LOG.error(          String.format("Can not initialize counter because the class '%s' does not have a '.getCounterMethod'",               context.getClass().getCanonicalName()));    }    initializeInternalReader(toParquetSplit(inputSplit), ContextUtil.getConfiguration(context));  }
@Benchmark  public void write1MRowsDefaultBlockAndPageSizeSNAPPY()          throws IOException  {    dataGenerator.generateData(file_1M_SNAPPY,                               configuration,                               PARQUET_2_0,                               BLOCK_SIZE_DEFAULT,                               PAGE_SIZE_DEFAULT,                               FIXED_LEN_BYTEARRAY_SIZE,                               SNAPPY,                               ONE_MILLION);  }
public void readStruct(FieldConsumer c) throws TException {    protocol.readStructBegin();    readStructContent(c);    protocol.readStructEnd();  }
public void readStructContent(FieldConsumer c) throws TException {    TField field;    while (true) {      field = protocol.readFieldBegin();      if (field.type == TType.STOP) {        break;      }      c.consumeField(protocol, this, field.id, field.type);    }  }
public void readSetContent(SetConsumer eventConsumer, TSet tSet)      throws TException {    for (int i = 0; i < tSet.size; i++) {      eventConsumer.consumeElement(protocol, this, tSet.elemType);    }  }
public void readMapContent(MapConsumer eventConsumer, TMap tMap)      throws TException {    for (int i = 0; i < tMap.size; i++) {      eventConsumer.consumeEntry(protocol, this, tMap.keyType, tMap.valueType);    }  }
public void readMapEntry(byte keyType, TypedConsumer keyConsumer, byte valueType, TypedConsumer valueConsumer)      throws TException {    keyConsumer.read(protocol, this, keyType);    valueConsumer.read(protocol, this, valueType);  }
public void readListContent(ListConsumer eventConsumer, TList tList)      throws TException {    for (int i = 0; i < tList.size; i++) {      eventConsumer.consumeElement(protocol, this, tList.elemType);    }  }
public void writeInt(int value) throws IOException {    input[inputSize] = value;    ++ inputSize;    if (inputSize == VALUES_WRITTEN_AT_A_TIME) {      pack();      if (packedPosition == slabSize) {        slabs.add(BytesInput.from(packed));        totalFullSlabSize += slabSize;        if (slabSize < bitWidth * MAX_SLAB_SIZE_MULT) {          slabSize *= 2;        }        initPackedSlab();      }    }  }
public static int readIntLittleEndian(ByteBuffer in, int offset) throws IOException {    int ch4 = in.get(offset) & 0xff;    int ch3 = in.get(offset + 1) & 0xff;    int ch2 = in.get(offset + 2) & 0xff;    int ch1 = in.get(offset + 3) & 0xff;    return ((ch1 << 24) + (ch2 << 16) + (ch3 << 8) + (ch4 << 0));  }
public static void writeIntLittleEndianPaddedOnBitWidth(OutputStream out, int v, int bitWidth)      throws IOException {    int bytesWidth = paddedByteCountFromBits(bitWidth);    switch (bytesWidth) {      case 0:        break;      case 1:        writeIntLittleEndianOnOneByte(out, v);        break;      case 2:        writeIntLittleEndianOnTwoBytes(out, v);        break;      case 3:        writeIntLittleEndianOnThreeBytes(out, v);        break;      case 4:        writeIntLittleEndian(out, v);        break;      default:        throw new IOException(          String.format("Encountered value (%d) that requires more than 4 bytes", v));    }  }
public static int readZigZagVarInt(InputStream in) throws IOException {    int raw = readUnsignedVarInt(in);    int temp = (((raw << 31) >> 31) ^ raw) >> 1;    return temp ^ (raw & (1 << 31));  }
public static long readZigZagVarLong(InputStream in) throws IOException {    long raw = readUnsignedVarLong(in);    long temp = (((raw << 63) >> 63) ^ raw) >> 1;    return temp ^ (raw & (1L << 63));  }
@Override  public synchronized int decompress(byte[] buffer, int off, int len) throws IOException {    SnappyUtil.validateBuffer(buffer, off, len);	if (inputBuffer.position() == 0 && !outputBuffer.hasRemaining()) {      return 0;    }        if (!outputBuffer.hasRemaining()) {      inputBuffer.rewind();      Preconditions.checkArgument(inputBuffer.position() == 0, "Invalid position of 0.");      Preconditions.checkArgument(outputBuffer.position() == 0, "Invalid position of 0.");      // There is compressed input, decompress it now.      int decompressedSize = Snappy.uncompressedLength(inputBuffer);      if (decompressedSize > outputBuffer.capacity()) {        ByteBuffer oldBuffer = outputBuffer;        outputBuffer = ByteBuffer.allocateDirect(decompressedSize);        CleanUtil.clean(oldBuffer);      }      // Reset the previous outputBuffer (i.e. set position to 0)      outputBuffer.clear();      int size = Snappy.uncompress(inputBuffer, outputBuffer);      outputBuffer.limit(size);      // We've decompressed the entire input, reset the input now      inputBuffer.clear();      inputBuffer.limit(0);      finished = true;    }    // Return compressed output up to 'len'    int numBytes = Math.min(len, outputBuffer.remaining());    outputBuffer.get(buffer, off, numBytes);    return numBytes;	      }
@Override  public synchronized void setInput(byte[] buffer, int off, int len) {    SnappyUtil.validateBuffer(buffer, off, len);    if (inputBuffer.capacity() - inputBuffer.position() < len) {      ByteBuffer newBuffer = ByteBuffer.allocateDirect(inputBuffer.position() + len);      inputBuffer.rewind();      newBuffer.put(inputBuffer);      ByteBuffer oldBuffer = inputBuffer;      inputBuffer = newBuffer;      CleanUtil.clean(oldBuffer);    } else {      inputBuffer.limit(inputBuffer.position() + len);    }    inputBuffer.put(buffer, off, len);  }
public static void setSchema(Job job, Schema schema) {    AvroWriteSupport.setSchema(ContextUtil.getConfiguration(job), schema);  }
@Override  public List<String> getColumns(final String columns) {    final List<String> result = (List<String>) StringUtils.getStringCollection(columns);    result.removeAll(virtualColumns);    return result;  }
public static SeekableInputStream wrap(FSDataInputStream stream) {    Preconditions.checkNotNull(stream, "Cannot wrap a null input stream");    if (byteBufferReadableClass != null && h2SeekableConstructor != null &&        byteBufferReadableClass.isInstance(stream.getWrappedStream())) {      try {        return h2SeekableConstructor.newInstance(stream);      } catch (InstantiationException e) {        LOG.warn("Could not instantiate H2SeekableInputStream, falling back to byte array reads", e);        return new H1SeekableInputStream(stream);      } catch (IllegalAccessException e) {        LOG.warn("Could not instantiate H2SeekableInputStream, falling back to byte array reads", e);        return new H1SeekableInputStream(stream);      } catch (InvocationTargetException e) {        throw new ParquetDecodingException(            "Could not instantiate H2SeekableInputStream", e.getTargetException());      }    } else {      return new H1SeekableInputStream(stream);    }  }
private <T> String convertToRawListString(Collection<T> collection) {    return "[ " + collection.stream().map(x -> '"'+x.toString()+'"').collect(Collectors.joining(", ")) + " ]";  }
@Override  public void createTopicIfNotExists(String topic, Map<String, Object> kafkaClientConfigs, String metadataBrokerList)      throws StageException {    // check stream path and topic    if (topic.startsWith("/") && topic.contains(":")) {      String[] path = topic.split(":");      if (path.length != 2) {        // Stream topic has invalid format. Record will be sent to error        throw new StageException(MapRStreamsErrors.MAPRSTREAMS_21, topic);      }      String streamPath = path[0];      if (!streamCache.contains(streamPath)) {        // This pipeline sees this stream path for the 1st time        Configuration conf = new Configuration();        kafkaClientConfigs.forEach((k, v) -> {          conf.set(k, v.toString());        });        Admin streamAdmin = null;        try {          streamAdmin = Streams.newAdmin(conf);          // Check if the stream path exists already          streamAdmin.countTopics(streamPath);          streamCache.add(streamPath);        } catch (TableNotFoundException e) {          LOG.debug("Stream not found. Creating a new stream: " + streamPath);          try {            streamAdmin.createStream(streamPath, Streams.newStreamDescriptor());            streamCache.add(streamPath);          } catch (IOException ioex) {            throw new StageException(MapRStreamsErrors.MAPRSTREAMS_22, streamPath, e.getMessage(), e);          }        } catch (IOException | IllegalArgumentException e) {          throw new StageException(MapRStreamsErrors.MAPRSTREAMS_23, e.getMessage(), e);        } finally {          if (streamAdmin != null) {            streamAdmin.close();          }        }      }    }    // Stream topic can be created through KafkaProducer if Stream Path exists already    KafkaProducer<String, String> kafkaProducer = createProducerTopicMetadataClient(kafkaClientConfigs);    kafkaProducer.partitionsFor(topic);  }
public static StringRedactor createFromJsonFile(String fileName)          throws IOException {    StringRedactor sr = new StringRedactor();    if (fileName == null) {      sr.policy = RedactionPolicy.emptyRedactionPolicy();      return sr;    }    File file = new File(fileName);    // An empty file is explicitly allowed as "no rules"    if (file.exists() && file.length() == 0) {      sr.policy = RedactionPolicy.emptyRedactionPolicy();      return sr;    }    ObjectMapper mapper = new ObjectMapper();    RedactionPolicy policy = mapper.readValue(file, RedactionPolicy.class);    policy.postProcess();    sr.policy = policy;    return sr;  }
public static StringRedactor createFromJsonString(String json)          throws IOException {    StringRedactor sr = new StringRedactor();    if ((json == null) || json.isEmpty()) {      sr.policy = RedactionPolicy.emptyRedactionPolicy();      return sr;    }    ObjectMapper mapper = new ObjectMapper();    RedactionPolicy policy = mapper.readValue(json, RedactionPolicy.class);    policy.postProcess();    sr.policy = policy;    return sr;  }
public PipelineBean create(      boolean forExecution,      StageLibraryTask library,      PipelineConfiguration pipelineConf,      InterceptorCreatorContextBuilder interceptorContextBuilder,      List<Issue> errors,      Map<String, Object> runtimeParameters  ) {    int priorErrors = errors.size();    PipelineConfigBean pipelineConfigBean = create(pipelineConf, errors, runtimeParameters);    StageBean errorStageBean = null;    StageBean statsStageBean = null;    StageBean origin = null;    PipelineStageBeans stages = null;    PipelineStageBeans startEventBeans = null;    PipelineStageBeans stopEventBeans = null;    if (pipelineConfigBean != null && pipelineConfigBean.constants != null) {      Map<String, Object> resolvedConstants = pipelineConfigBean.constants;      if(interceptorContextBuilder != null) {        interceptorContextBuilder          .withExecutionMode(pipelineConfigBean.executionMode)          .withDeliveryGuarantee(pipelineConfigBean.deliveryGuarantee)        ;      }      // Instantiate usual stages      if(!pipelineConf.getStages().isEmpty()) {        origin = createStageBean(            forExecution,            library,            pipelineConf.getStages().get(0),            true,            false,            false,            resolvedConstants,            interceptorContextBuilder,            errors        );        stages = createPipelineStageBeans(            forExecution,            library,            pipelineConf.getStages().subList(1, pipelineConf.getStages().size()),            interceptorContextBuilder,            resolvedConstants,            errors        );      }      // It is not mandatory to have a stats aggregating target configured      StageConfiguration statsStageConf = pipelineConf.getStatsAggregatorStage();      if (statsStageConf != null) {        statsStageBean = createStageBean(            forExecution,            library,            statsStageConf,            true,            false,            false,            resolvedConstants,            interceptorContextBuilder,            errors        );      }      // Error stage is mandatory      StageConfiguration errorStageConf = pipelineConf.getErrorStage();      if (errorStageConf != null) {        errorStageBean = createStageBean(            forExecution,            library,            errorStageConf,            true,            true,            false,            resolvedConstants,            interceptorContextBuilder,            errors        );      } else if (!(pipelineConfigBean.executionMode.equals(ExecutionMode.BATCH) ||          pipelineConfigBean.executionMode.equals(ExecutionMode.STREAMING))) {        errors.add(IssueCreator.getPipeline().create(            PipelineGroups.BAD_RECORDS.name(),            "badRecordsHandling",            CreationError.CREATION_009        ));      }      // Pipeline Lifecycle event handlers      StageBean startBean = null;      if(CollectionUtils.isNotEmpty(pipelineConf.getStartEventStages())) {         startBean = createStageBean(            forExecution,            library,            pipelineConf.getStartEventStages().get(0),            true,            false,            true,            resolvedConstants,            interceptorContextBuilder,            errors        );      }      startEventBeans = new PipelineStageBeans(startBean == null ? Collections.emptyList() : ImmutableList.of(startBean));      StageBean stopBean = null;      if(CollectionUtils.isNotEmpty(pipelineConf.getStopEventStages())) {         stopBean = createStageBean(            forExecution,            library,            pipelineConf.getStopEventStages().get(0),            true,            false,            true,            resolvedConstants,            interceptorContextBuilder,            errors        );      }      stopEventBeans = new PipelineStageBeans(stopBean == null ? Collections.emptyList() : ImmutableList.of(stopBean));      // Validate Webhook Configs      if (pipelineConfigBean.webhookConfigs != null && !pipelineConfigBean.webhookConfigs.isEmpty()) {        int index = 0;        for (PipelineWebhookConfig webhookConfig: pipelineConfigBean.webhookConfigs) {          if (StringUtils.isEmpty(webhookConfig.webhookUrl)) {            Issue issue = IssueCreator.getPipeline().create(                PipelineGroups.NOTIFICATIONS.name(),                "webhookUrl",                CreationError.CREATION_080            );            issue.setAdditionalInfo("index", index);            errors.add(issue);            break;          }          index++;        }      }    }    // Something went wrong    if(errors.size() != priorErrors) {      return  null;    }    return new PipelineBean(        pipelineConfigBean,        origin,        stages,        errorStageBean,        statsStageBean,        startEventBeans,        stopEventBeans    );  }
public PipelineStageBeans duplicatePipelineStageBeans(    StageLibraryTask stageLib,    PipelineStageBeans pipelineStageBeans,    InterceptorCreatorContextBuilder interceptorCreatorContextBuilder,    Map<String, Object> constants,    List<Issue> errors  ) {    List<StageBean> stageBeans = new ArrayList<>(pipelineStageBeans.size());    for(StageBean original: pipelineStageBeans.getStages()) {      // Create StageDefinition map for this stage      Map<Class, ServiceDefinition> services = original.getServices().stream()        .collect(Collectors.toMap(c -> c.getDefinition().getProvides(), ServiceBean::getDefinition));      StageBean stageBean = createStage(          stageLib,          original.getDefinition(),          ClassLoaderReleaser.NOOP_RELEASER,          original.getConfiguration(),          services::get,          interceptorCreatorContextBuilder,          constants,          errors      );      if (stageBean != null) {        stageBeans.add(stageBean);      }    }    return new PipelineStageBeans(stageBeans);  }
public StageBean createStageBean(      boolean forExecution,      StageLibraryTask library,      StageConfiguration stageConf,      boolean validateAnnotations,      boolean errorStage,      boolean pipelineLifecycleStage,      Map<String, Object> constants,      InterceptorCreatorContextBuilder interceptorContextBuilder,      List<Issue> errors  ) {    IssueCreator issueCreator = IssueCreator.getStage(stageConf.getInstanceName());    StageBean bean = null;    StageDefinition stageDef = library.getStage(stageConf.getLibrary(), stageConf.getStageName(),                                                forExecution);    if (stageDef != null) {      // Pipeline lifecycle events validation must match, whether it's also marked as error stage does not matter      if(validateAnnotations) {        if (pipelineLifecycleStage) {          if (!stageDef.isPipelineLifecycleStage()) {            errors.add(issueCreator.create(              CreationError.CREATION_018,              stageDef.getLibraryLabel(),              stageDef.getLabel(),              stageConf.getStageVersion())            );          }          // For non pipeline lifecycle stages, the error stage annotation must match        } else if (stageDef.isErrorStage() != errorStage) {          if (stageDef.isErrorStage()) {            errors.add(issueCreator.create(CreationError.CREATION_007, stageDef.getLibraryLabel(), stageDef.getLabel(),              stageConf.getStageVersion()));          } else {            errors.add(issueCreator.create(CreationError.CREATION_008, stageDef.getLibraryLabel(), stageDef.getLabel(),              stageConf.getStageVersion()));          }        }      }      bean = createStage(        library,        stageDef,        library,        stageConf,        serviceClass -> library.getServiceDefinition(serviceClass, true),        interceptorContextBuilder,        constants,        errors      );    } else {      errors.add(issueCreator.create(CreationError.CREATION_006, stageConf.getLibrary(), stageConf.getStageName(),                                     stageConf.getStageVersion()));    }    return bean;  }
public List<InterceptorBean> createInterceptors(    StageLibraryTask stageLib,    StageConfiguration stageConfiguration,    StageDefinition stageDefinition,    InterceptorCreatorContextBuilder contextBuilder,    InterceptorCreator.InterceptorType interceptorType,    List<Issue> issues  ) {    List<InterceptorBean> beans = new ArrayList<>();    if(contextBuilder == null) {      return beans;    }    for(InterceptorDefinition definition : stageLib.getInterceptorDefinitions()) {      InterceptorBean bean = createInterceptor(stageLib, definition, stageConfiguration, stageDefinition, contextBuilder, interceptorType, issues);      if (bean != null) {        beans.add(bean);      }    }    return beans;  }
public InterceptorBean createInterceptor(    StageLibraryTask stageLib,    InterceptorDefinition definition,    StageConfiguration stageConfiguration,    StageDefinition stageDefinition,    InterceptorCreatorContextBuilder contextBuilder,    InterceptorCreator.InterceptorType interceptorType,    List<Issue> issues  ) {    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();    InterceptorCreator.Context context = contextBuilder.buildFor(      definition.getLibraryDefinition().getName(),      definition.getKlass().getName(),      stageConfiguration,      stageDefinition,      interceptorType    );    try {      Thread.currentThread().setContextClassLoader(definition.getStageClassLoader());      InterceptorCreator creator = definition.getDefaultCreator().newInstance();      Interceptor interceptor = creator.create(context);      if(interceptor == null) {        return null;      }      return new InterceptorBean(        definition,        interceptor,        stageLib      );    } catch (IllegalAccessException|InstantiationException e) {      LOG.debug("Can't instantiate interceptor: {}", e.toString(), e);      IssueCreator issueCreator = IssueCreator.getStage(stageDefinition.getName());      issues.add(issueCreator.create(        CreationError.CREATION_000, "interceptor", definition.getKlass().getName(), e.toString()      ));    } finally {      Thread.currentThread().setContextClassLoader(classLoader);    }    return null;  }
public static Schema parseSchema(String schema) {    Schema.Parser parser = new Schema.Parser();    parser.setValidate(true);    // We sadly can't use this method directly because it was added after 1.7.3 and we have to stay    // compatible with 1.7.3 as this version ships with mapr (and thus we end up using it). This code is    // however compiled against 1.7.7 and hence we don't have to do reflection here.    try {      parser.setValidateDefaults(true);    } catch (NoSuchMethodError e) {      LOG.debug("Running old Avro version that doesn't have 'setValidateDefaults' method", e);    }    return parser.parse(schema);  }
public static long daysToMillis(int days) {    long millisUtc = (long)days * MILLIS_PER_DAY;    long tmp = millisUtc - (long)(localTimeZone.getOffset(millisUtc));    return millisUtc - (long)(localTimeZone.getOffset(tmp));  }
private static int millisToDays(long millisLocal) {    // We assume millisLocal is midnight of some date. What we are basically trying to do    // here is go from local-midnight to UTC-midnight (or whatever time that happens to be).    long millisUtc = millisLocal + localTimeZone.getOffset(millisLocal);    int days;    if (millisUtc >= 0L) {      days = (int) (millisUtc / MILLIS_PER_DAY);    } else {      days = (int) ((millisUtc - 86399999 /*(MILLIS_PER_DAY - 1)*/) / MILLIS_PER_DAY);    }    return days;  }
public static String getAvroSchemaFromHeader(Record record, String headerName) throws DataGeneratorException {    String jsonSchema = record.getHeader().getAttribute(headerName);    if(jsonSchema == null || jsonSchema.isEmpty()) {      throw new DataGeneratorException(Errors.AVRO_GENERATOR_03, record.getHeader().getSourceId());    }    return jsonSchema;  }
public static BigDecimal bigDecimalFromBytes(byte[] decimalBytes, int scale) {    final BigInteger bigInt = new BigInteger(decimalBytes);    return new BigDecimal(bigInt, scale);  }
private void upgradeV1ToV2(List<Config> configs, Context context) {    List<Config> dataFormatConfigs = configs.stream()      .filter(c -> c.getName().startsWith("dataFormat"))      .collect(Collectors.toList());    // Remove those configs    configs.removeAll(dataFormatConfigs);    // Provide proper prefix    dataFormatConfigs = dataFormatConfigs.stream()      .map(c -> new Config(c.getName().replace("dataFormatConfig.", "dataGeneratorFormatConfig."), c.getValue()))      .collect(Collectors.toList());    // And finally register new service    context.registerService(DataFormatGeneratorService.class, dataFormatConfigs);  }
public long getLength() throws IOException {    long length = -1;    if (generator != null) {      length = textOutputStream.getByteCount();    } else if (seqWriter != null) {      length = seqWriter.getLength();    }    return length;  }
private void copyBlobstore(List<String> blobStoreResources, File rootDataDir, File pipelineDir) throws IOException {    if (blobStoreResources == null) {      return;    }    File blobstoreDir = new File(runtimeInfo.getDataDir(), BLOBSTORE_BASE_DIR);    File stagingBlobstoreDir = new File(rootDataDir, BLOBSTORE_BASE_DIR);    if (!stagingBlobstoreDir.exists()) {      if (!stagingBlobstoreDir.mkdirs()) {        throw new RuntimeException("Failed to create blobstore directory: " + pipelineDir.getPath());      }    }    for (String blobstoreFile: blobStoreResources) {      File srcFile = new File(blobstoreDir, blobstoreFile);      if (srcFile.exists()){        final File dstFile = new File(stagingBlobstoreDir, srcFile.getName());        if (srcFile.canRead()) { // ignore files which cannot be read          try (InputStream in = new FileInputStream((srcFile))) {            try (OutputStream out = new FileOutputStream((dstFile))) {              IOUtils.copy(in, out);            }          }        }      }    }  }
public void reset(){    columns.clear();    this.columnsExpected = null;    columnNames = null;    table = null;    schema = null;    insideStatement = false;  }
public boolean reportHealth(String threadName, int scheduledDelay, long timestamp) {    ThreadHealthReport threadHealthReport = new ThreadHealthReport(threadName, scheduledDelay, timestamp);    if(threadToGaugeMap.containsKey(threadName)) {      threadToGaugeMap.get(threadName).setThreadHealthReport(threadHealthReport);      return true;    }    return false;  }
public boolean register(String threadName) {    if(threadToGaugeMap.containsKey(threadName)) {      return false;    }    ThreadHealthReportGauge threadHealthReportGauge = new ThreadHealthReportGauge();    MetricsConfigurator.createGauge(metrics, getHealthGaugeName(threadName), threadHealthReportGauge, name, rev);    threadToGaugeMap.put(threadName, threadHealthReportGauge);    return true;  }
public static void storeControlHubConfigs(      RuntimeInfo runtimeInfo,      Map<String, String> newConfigs  ) throws IOException {    File configFile = new File(runtimeInfo.getDataDir(), SCH_CONF_OVERRIDE);    Properties properties = new Properties();    // Load existing properties from disk if they exists    if(configFile.exists()) {      try (FileReader reader = new FileReader(configFile)) {        properties.load(reader);      }    }    // Propagate updated configuration    for(Map.Entry<String, String> entry : newConfigs.entrySet()) {      if(entry.getValue() == null) {        properties.remove(entry.getKey());      } else {        properties.setProperty(entry.getKey(), entry.getValue());      }    }    // Store the new updated configuration back to disk    try(FileWriter writer = new FileWriter(configFile)) {      properties.store(writer, null);    }  }
@Override  public UserInfo getUserInfo(String username) throws Exception  {    LdapEntry entry = getEntryWithCredential(username);    if (entry == null)    {      return null;    }    String pwdCredential = getUserCredential(entry);    pwdCredential = convertCredentialLdapToJetty(pwdCredential);    Credential credential = Credential.getCredential(pwdCredential);    List<String> roles = getUserRoles(username, entry.getDn());    return new UserInfo(username, credential, roles);  }
private LdapEntry getEntryWithCredential(String username) throws LdapException  {    if (StringUtils.isBlank(_userObjectClass)|| StringUtils.isBlank(_userIdAttribute)        || StringUtils.isBlank(_userBaseDn) || StringUtils.isBlank(_userPasswordAttribute)){      LOG.error("Failed to get user because at least one of the following is null : " +          "[_userObjectClass, _userIdAttribute, _userBaseDn, _userPasswordAttribute ]");      return null;    }    // Create the format of &(objectClass=_userObjectClass)(_userIdAttribute={user}))    String userFilter = buildFilter(_userFilter, _userObjectClass, _userIdAttribute);    if (userFilter.contains("{user}")){      userFilter = userFilter.replace("{user}", username);    }    LOG.debug("Searching user using the filter {} on user baseDn {}", userFilter, _userBaseDn);    // Get the group names from each group, which is obtained from roleNameAttribute attribute.    SearchRequest request = new SearchRequest(_userBaseDn, userFilter, _userPasswordAttribute);    request.setSearchScope(SearchScope.SUBTREE);    request.setSizeLimit(1);    try {      SearchOperation search = new SearchOperation(conn);      org.ldaptive.SearchResult result = search.execute(request).getResult();      LdapEntry entry = result.getEntry();      LOG.info("Found user?: {}", entry != null);      return entry;    } catch (LdapException ex) {      LOG.error("{}", ex.toString(), ex);      return null;    }  }
private List<String> getUserRoles(String username, String userDn)  {    List<String> roleList = new ArrayList<>();    if (StringUtils.isBlank(_roleBaseDn)|| StringUtils.isBlank(_roleObjectClass)        || StringUtils.isBlank(_roleNameAttribute) || StringUtils.isBlank(_roleMemberAttribute)){      LOG.debug("Failed to get roles because at least one of the following is null : " +          "[_roleBaseDn, _roleObjectClass, _roleNameAttribute, _roleMemberAttribute ]");      return roleList;    }    String roleFilter = buildFilter(_roleFilter, _roleObjectClass, _roleMemberAttribute);    if (_roleFilter.contains(DN)) {      userDn = userDn.replace("\\", "\\\\\\");      roleFilter = roleFilter.replace(DN, userDn);    } else if (_roleFilter.contains(USER)){      roleFilter = roleFilter.replace(USER, username);    } else {      LOG.error("roleFilter contains invalid filter {}. Check the roleFilter option");      return roleList;    }    LOG.debug("Searching roles using the filter {} on role baseDn {}", roleFilter, _roleBaseDn);    // Get the group names from each group, which is obtained from roleNameAttribute attribute.    SearchRequest request = new SearchRequest(_roleBaseDn, roleFilter, _roleNameAttribute);    request.setSearchScope(SearchScope.SUBTREE);    try {      SearchOperation search = new SearchOperation(conn);      org.ldaptive.SearchResult result = search.execute(request).getResult();      Collection<LdapEntry> entries = result.getEntries();      LOG.info("Found roles?: {}", !(entries == null || entries.isEmpty()));      if (entries != null) {        for (LdapEntry entry : entries) {          roleList.add(entry.getAttribute().getStringValue());        }      }    } catch (LdapException ex) {      LOG.error(ex.getMessage(), ex);    }    LOG.info("Found roles: {}", roleList);    return roleList;  }
@VisibleForTesting  static String buildFilter(String attrFilter, String objClass, String attrName){    // check if the filter has surrounding "()"    if(!attrFilter.startsWith("(")){      attrFilter = "(" + attrFilter;    }    if (!attrFilter.endsWith(")")) {      attrFilter = attrFilter + ")";    }    return String.format(filterFormat, objClass, String.format(attrFilter, attrName));  }
@Override  public boolean login() throws LoginException  {    try    {      if (getCallbackHandler() == null)      {        throw new LoginException("No callback handler");      }      if (conn == null){        return false;      }      Callback[] callbacks = configureCallbacks();      getCallbackHandler().handle(callbacks);      String webUserName = ((NameCallback) callbacks[0]).getName();      Object webCredential = ((ObjectCallback) callbacks[1]).getObject();      if (webUserName == null || webCredential == null)      {        setAuthenticated(false);        return isAuthenticated();      }      // Please see the following stackoverflow article      // http://security.stackexchange.com/questions/6713/ldap-security-problems      // Some LDAP implementation "MAY" accept empty password as a sign of anonymous connection and thus      // return "true" for the authentication request.      if((webCredential instanceof String) && ((String)webCredential).isEmpty()) {        LOG.info("Ignoring login request for user {} as the password is empty.", webUserName);        setAuthenticated(false);        return isAuthenticated();      }      if (_forceBindingLogin)      {        return bindingLogin(webUserName, webCredential);      }      // This sets read and the credential      UserInfo userInfo = getUserInfo(webUserName);      if (userInfo == null)      {        setAuthenticated(false);        return false;      }      JAASUserInfo jaasUserInfo = new JAASUserInfo(userInfo);      jaasUserInfo.fetchRoles();      setCurrentUser(jaasUserInfo);      if (webCredential instanceof String)      {        return credentialLogin(Credential.getCredential((String) webCredential));      }      return credentialLogin(webCredential);    }    catch (UnsupportedCallbackException e)    {      throw new LoginException("Error obtaining callback information.");    }    catch (IOException e)    {      LOG.error("IO Error performing login", e);    }    catch (Exception e)    {      LOG.error("IO Error performing login", e);    }    return false;  }
protected boolean credentialLogin(Object webCredential) throws LoginException  {    boolean credResult = getCurrentUser().checkCredential(webCredential);    setAuthenticated(credResult);    if (!credResult){      LOG.warn("Authentication failed - Possibly the user password is wrong");    }    return isAuthenticated();  }
public boolean bindingLogin(String username, Object password) throws Exception {    if (StringUtils.isBlank(_userObjectClass)|| StringUtils.isBlank(_userIdAttribute)        || StringUtils.isBlank(_userBaseDn)){      LOG.error("Failed to get user because at least one of the following is null : " +          "[_userObjectClass, _userIdAttribute, _userBaseDn ]");      return false;    }    LdapEntry userEntry = authenticate(username, password);    if (userEntry == null) {      return false;    }    // If authenticated by LDAP server, the returned LdapEntry contains full DN of the user    String userDn = userEntry.getDn();    if(userDn == null){      // This shouldn't happen if LDAP server is configured properly.      LOG.error("userDn is found null for the user {}", username);      return false;    }    List<String> roles = getUserRoles(username, userDn);    //Authentication already succeeded. We won't store user password so passing empty credential    UserInfo userInfo = new UserInfo(username, Credential.getCredential(""), roles);    JAASUserInfo jaasUserInfo = new JAASUserInfo(userInfo);    jaasUserInfo.fetchRoles();    setCurrentUser(jaasUserInfo);    setAuthenticated(true);    return true;  }
private LdapEntry authenticate(String username,Object password)  {    try {      SearchDnResolver dnResolver = new SearchDnResolver(new DefaultConnectionFactory(connConfig));      dnResolver.setBaseDn(_userBaseDn);      dnResolver.setSubtreeSearch(true);      String userFilter = buildFilter(_userFilter, _userObjectClass, _userIdAttribute);      LOG.debug("Searching a user with filter {} where user is {}", userFilter, username);      dnResolver.setUserFilter(userFilter);      // Set Authenticator with username and password. It will return the user if username/password matches.      BindAuthenticationHandler authHandler = new BindAuthenticationHandler(new DefaultConnectionFactory(connConfig));      Authenticator auth = new Authenticator(dnResolver, authHandler);      AuthenticationRequest authRequest = new AuthenticationRequest();      authRequest.setUser(username);      if (password instanceof char[]) {        authRequest.setCredential(new org.ldaptive.Credential(new String((char[]) password)));      } else if (password instanceof String){        authRequest.setCredential(new org.ldaptive.Credential((String)password));      } else {        LOG.error("Unexpected type for password '{}'", (password != null) ? password.getClass() : "NULL");        return null;      }      String[] userRoleAttribute = ReturnAttributes.ALL.value();      authRequest.setReturnAttributes(userRoleAttribute);      LOG.debug("Retrieved authenticator from factory: {}", auth);      LOG.debug("Retrieved authentication request from factory: {}", authRequest);      AuthenticationResponse response = auth.authenticate(authRequest);      LOG.info("Found user?: {}", response.getResult());      if (response.getResult()) {        LdapEntry entry = response.getLdapEntry();        return entry;      } else {        // User not found. Most likely username/password didn't match. Log the reason.        LOG.error("Result code: {} - {}", response.getResultCode(), response.getMessage());      }    }
public static int moveAllTo(List<Config> configs, String... names) {    Map<String, String> nameMap = new HashMap<>();    if (names.length % 2 == 1) {      throw new IllegalArgumentException("names was of uneven length");    }    for (int i=0; i<names.length; ) {      nameMap.put(names[i], names[i+1]);      i+=2;    }    return moveAllTo(configs, nameMap);  }
public static int moveAllTo(List<Config> configs, Map<String, String> oldToNewNames) {    List<Config> configsToAdd = new ArrayList<>();    List<Config> configsToRemove = new ArrayList<>();    int numMoved = 0;    for (Config config : configs) {      final String oldName = config.getName();      if (oldToNewNames.containsKey(oldName)) {        configsToRemove.add(config);        final Object value = config.getValue();        final String newName = oldToNewNames.get(oldName);        configsToAdd.add(new Config(newName, value));        LOG.info(String.format(            "Moving config value %s from old name %s to new name %s",            value,            oldName,            newName        ));        numMoved++;      }    }    configs.removeAll(configsToRemove);    configs.addAll(configsToAdd);    return numMoved;  }
public static Config getAndRemoveConfigWithName(List<Config> configs, String name) {    final Config config = getConfigWithName(configs, name);    if (config != null) {      configs.remove(config);    }    return config;  }
private synchronized void reLogin() throws LoginException {        if (!isKrbTicket) {            return;        }        if (login == null) {            throw new LoginException("Login must be done first");        }        if (!hasSufficientTimeElapsed()) {            return;        }        log.info("Initiating logout for {}", principal);        synchronized (Login.class) {            // register most recent relogin attempt            lastLogin = currentElapsedTime();            //clear up the kerberos state. But the tokens are not cleared! As per            //the Java kerberos login module code, only the kerberos credentials            //are cleared            login.logout();            //login and also update the subject field of this instance to            //have the new credentials (pass it to the LoginContext constructor)            login = new LoginContext(loginContextName, subject);            log.info("Initiating re-login for {}", principal);            login.login();        }    }
public PipelineConfiguration upgradeIfNecessary(      StageLibraryTask library,      PipelineConfiguration pipelineConf,      List<Issue> issues  ) {    Preconditions.checkArgument(issues.isEmpty(), "Given list of issues must be empty.");    boolean upgrade;    // Firstly upgrading schema if needed, then data    upgrade = needsSchemaUpgrade(pipelineConf, issues);    if(upgrade && issues.isEmpty()) {      pipelineConf = upgradeSchema(library, pipelineConf, issues);    }    // Something went wrong with the schema upgrade    if(!issues.isEmpty()) {      return null;    }    // Upgrading data if needed    upgrade = needsUpgrade(library, pipelineConf, issues);    if (upgrade && issues.isEmpty()) {      //we try to upgrade only if we have all defs for the pipelineConf      pipelineConf = upgrade(library, pipelineConf, issues);    }    return (issues.isEmpty()) ? pipelineConf : null;  }
public StageConfiguration upgradeIfNecessary(StageLibraryTask libraryTask, StageConfiguration stageConf, List<Issue> issues) {    Preconditions.checkArgument(issues.isEmpty(), "Given list of issues must be empty.");    boolean upgrade = needsUpgrade(libraryTask, stageConf, issues);    if(upgrade) {      stageConf = upgradeIfNeeded(libraryTask, stageConf, issues);    }    return issues.isEmpty() ? stageConf : null;  }
static StageConfiguration upgradeIfNeeded(StageLibraryTask library, StageConfiguration conf, List<Issue> issues) {    return upgradeIfNeeded(        library,        library.getStage(conf.getLibrary(), conf.getStageName(), false),        conf,        issues    );  }
static StageConfiguration upgradeIfNeeded(StageLibraryTask library, StageDefinition def, StageConfiguration conf, List<Issue> issues) {    IssueCreator issueCreator = IssueCreator.getStage(conf.getInstanceName());    int fromVersion = conf.getStageVersion();    int toVersion = def.getVersion();    try {      // Firstly upgrade stage itself (register any new services)      upgradeStageIfNeeded(def, conf, issueCreator, issues);      // And then upgrade all it's services      conf.getServices().forEach(serviceConf -> upgradeServicesIfNeeded(          library,          conf,          serviceConf,          issueCreator.forService(serviceConf.getService().getName()),          issues      ));    } catch (Exception ex) {      LOG.error("Unknown exception during upgrade: " + ex, ex);      issues.add(issueCreator.create(          ContainerError.CONTAINER_0900,          fromVersion,          toVersion,          ex.toString()      ));    }    return conf;  }
private static ServiceConfiguration upgradeServicesIfNeeded(      StageLibraryTask library,      StageConfiguration stageConf,      ServiceConfiguration conf,      IssueCreator issueCreator,      List<Issue> issues  ) {    ServiceDefinition def = library.getServiceDefinition(conf.getService(), false);    if (def == null) {      issues.add(issueCreator.create(ContainerError.CONTAINER_0903, conf.getService().getName()));    }    int fromVersion = conf.getServiceVersion();    int toVersion = def.getVersion();    // In case we don't need an upgrade    if(!needsUpgrade(toVersion, fromVersion, issueCreator, issues)) {      return conf;    }    ClassLoader cl = Thread.currentThread().getContextClassLoader();    try {      LOG.warn("Upgrading service instance from version '{}' to version '{}'", conf.getServiceVersion(), def.getVersion());      UpgradeContext upgradeContext = new UpgradeContext(          "",          def.getName(),          stageConf.getInstanceName(),          fromVersion,          toVersion      );      List<Config> configs = def.getUpgrader().upgrade(conf.getConfiguration(), upgradeContext);      if(!upgradeContext.registeredServices.isEmpty()) {        throw new StageException(ContainerError.CONTAINER_0904);      }      conf.setServiceVersion(toVersion);      conf.setConfig(configs);    } catch (StageException ex) {      issues.add(issueCreator.create(ex.getErrorCode(), ex.getParams()));    } finally {      Thread.currentThread().setContextClassLoader(cl);    }    return conf;  }
static private void upgradeStageIfNeeded(      StageDefinition def,      StageConfiguration conf,      IssueCreator issueCreator,      List<Issue> issues  ) {    int fromVersion = conf.getStageVersion();    int toVersion = def.getVersion();    // In case we don't need an upgrade    if(!needsUpgrade(toVersion, fromVersion, IssueCreator.getStage(conf.getInstanceName()), issues)) {      return;    }    ClassLoader cl = Thread.currentThread().getContextClassLoader();    try {      Thread.currentThread().setContextClassLoader(def.getStageClassLoader());      LOG.warn("Upgrading stage instance '{}' from version '{}' to version '{}'", conf.getInstanceName(), fromVersion, toVersion);      UpgradeContext upgradeContext = new UpgradeContext(          def.getLibrary(),          def.getName(),          conf.getInstanceName(),          fromVersion,          toVersion      );      List<Config> configs = def.getUpgrader().upgrade(conf.getConfiguration(), upgradeContext);      conf.setStageVersion(def.getVersion());      conf.setConfig(configs);      // Propagate newly registered services to the StageConfiguration      if(!upgradeContext.registeredServices.isEmpty()) {        List<ServiceConfiguration> services = new ArrayList<>();        services.addAll(conf.getServices());        // Version -1 is special to note that this version has been created by stage and not by the service itself        upgradeContext.registeredServices            .forEach((s, c) -> services.add(new ServiceConfiguration(s, -1, c)));        conf.setServices(services);      }    } catch (StageException ex) {      issues.add(issueCreator.create(ex.getErrorCode(), ex.getParams()));    } finally {      Thread.currentThread().setContextClassLoader(cl);    }  }
@Override  public void setOffsets(Map<String, String> offsets) throws IOException {    Utils.checkNotNull(offsets, "offsets");    LOG.trace("setOffsets()");    // We look for created directory paths here    findCreatedDirectories();    // we look for new files only here    findNewFileContexts();    // we purge file only here    purge();    super.setOffsets(offsets);    startNewLoop();  }
private List<String> getFieldsToNull(List<NullReplacerConditionalConfig> nullReplacerConditionalConfigs, Set<String> fieldsThatDoNotExist, Set<String> fieldPaths, Record record) throws OnRecordErrorException {    //Gather in this all fields to null    List<String> fieldsToNull = new ArrayList<>();    for (NullReplacerConditionalConfig nullReplacerConditionalConfig : nullReplacerConditionalConfigs) {      List<String> fieldNamesToNull = nullReplacerConditionalConfig.fieldsToNull;      //Gather fieldsPathsToNull for this nullReplacerConditionalConfig      List<String> fieldPathsToNull = new ArrayList<>();      //Gather existing paths for each nullReplacerConditionalConfig      //And if field does not exist gather them in fieldsThatDoNotExist      for (String fieldNameToNull : fieldNamesToNull) {        try {          final List<String> matchingPaths = FieldPathExpressionUtil.evaluateMatchingFieldPaths(              fieldNameToNull,              fieldPathEval,              fieldPathVars,              record,              fieldPaths          );          if (matchingPaths.isEmpty()) {            // FieldPathExpressionUtil.evaluateMatchingFieldPaths does NOT return the supplied param in its result            // regardless, like FieldRegexUtil#getMatchingFieldPaths did, so we add manually here            fieldsThatDoNotExist.add(fieldNameToNull);          } else {            for (String matchingField : matchingPaths) {              if (record.has(matchingField)) {                fieldPathsToNull.add(matchingField);              } else {                fieldsThatDoNotExist.add(matchingField);              }            }          }        } catch (ELEvalException e) {          LOG.error("Error evaluating condition: " + nullReplacerConditionalConfig.condition, e);          throw new OnRecordErrorException(record, Errors.VALUE_REPLACER_07, fieldNameToNull, e.toString(), e);        }      }      //Now evaluate the condition in nullReplacerConditionalConfig      //If it empty or condition evaluates to true, add all the gathered fields in fieldsPathsToNull      // for this nullReplacerConditionalConfig to fieldsToNull      try {        boolean evaluatedCondition = true;        //If it is empty we assume it is true.        if (!StringUtils.isEmpty(nullReplacerConditionalConfig.condition)) {          evaluatedCondition = nullConditionELEval.eval(nullConditionELVars, nullReplacerConditionalConfig.condition, Boolean.class);        }        if (evaluatedCondition) {          fieldsToNull.addAll(fieldPathsToNull);        }      } catch (ELEvalException e) {        LOG.error("Error evaluating condition: " + nullReplacerConditionalConfig.condition, e);        throw new OnRecordErrorException(record, Errors.VALUE_REPLACER_06, nullReplacerConditionalConfig.condition, e.toString());      }    }    return fieldsToNull;  }
private static boolean isSystemClass(String name, List<String> packageList) {    boolean result = false;    if (packageList != null) {      String canonicalName = ClassLoaderUtil.canonicalizeClassOrResource(name);      for (String c : packageList) {        boolean shouldInclude = true;        if (c.startsWith("-")) {          c = c.substring(1);          shouldInclude = false;        }        if (canonicalName.startsWith(c)) {          if ( c.endsWith(".")                                   // package            || canonicalName.length() == c.length()              // class            ||    canonicalName.length() > c.length()            // nested            && canonicalName.charAt(c.length()) == '$' ) {            if (shouldInclude) {              result = true;            } else {              return false;            }          }        }      }    }    return result;  }
CheckpointPath getCheckPointPath(String topic, String consumerGroup) {    return new CheckpointPath.Builder(CHECKPOINT_BASE_DIR)        .sdcId(Utils.getPropertyNotNull(properties, SDC_ID))        .topic(topic)        .consumerGroup(consumerGroup)        .pipelineName(Utils.getPropertyNotNull(properties, ClusterModeConstants.CLUSTER_PIPELINE_NAME))        .build();  }
@Override public boolean add(E e) {    checkNotNull(e);  // check before removing    if (maxSize == 0) {      return true;    }    if (size() == maxSize) {      delegate.remove();    }    delegate.add(e);    return true;  }
public E addAndGetEvicted(E e) {    checkNotNull(e);  // check before removing    if (maxSize == 0) {      return null;    }    E evicted = null;    if (size() == maxSize) {      evicted = delegate.remove();    }    delegate.add(e);    return evicted;  }
private Optional<Value> valueOrDefault(Key key, Optional<Value> value) {    // If value is present simply return it    if(value.isPresent()) {      return value;    }    if(!cacheMissingValues) {      delegate.invalidate(key);    }    return defaultValue;  }
private List<StageOutput> addReportedErrorsIfNeeded(List<StageOutput> snapshotsOfAllStagesOutput) {    synchronized (this.reportedErrors) {      if(reportedErrors.isEmpty()) {        return snapshotsOfAllStagesOutput;      }      try {        return snapshotsOfAllStagesOutput.stream()          .map(so -> new StageOutput(            so.getInstanceName(),            so.getOutput(),            so.getErrorRecords(),            reportedErrors.get(so.getInstanceName()),            so.getEventRecords()          ))          .collect(Collectors.toList());      } finally {        reportedErrors.clear();      }    }  }
public static Descriptors.Descriptor getDescriptor(      ProtoConfigurableEntity.Context context,      String protoDescriptorFile,      String messageType,      Map<String, Set<Descriptors.FieldDescriptor>> messageTypeToExtensionMap,      Map<String, Object> defaultValueMap  ) throws StageException {    File descriptorFileHandle = new File(context.getResourcesDirectory(), protoDescriptorFile);    try(      FileInputStream fin = new FileInputStream(descriptorFileHandle);      ) {      DescriptorProtos.FileDescriptorSet set = DescriptorProtos.FileDescriptorSet.parseFrom(fin);      // Iterate over all the file descriptor set computed above and cache dependencies and all encountered      // file descriptors      // this map holds all the dependencies that a given file descriptor has.      // This cached map will be looked up while building FileDescriptor instances      Map<String, Set<Descriptors.FileDescriptor>> fileDescriptorDependentsMap = new HashMap<>();      // All encountered FileDescriptor instances cached based on their name.      Map<String, Descriptors.FileDescriptor> fileDescriptorMap = new HashMap<>();      ProtobufTypeUtil.getAllFileDescriptors(set, fileDescriptorDependentsMap, fileDescriptorMap);      // Get the descriptor for the expected message type      Descriptors.Descriptor descriptor = ProtobufTypeUtil.getDescriptor(set, fileDescriptorMap, protoDescriptorFile, messageType);      // Compute and cache all extensions defined for each message type      ProtobufTypeUtil.populateDefaultsAndExtensions(fileDescriptorMap, messageTypeToExtensionMap, defaultValueMap);      return descriptor;    } catch (FileNotFoundException e) {      throw new StageException(Errors.PROTOBUF_06, descriptorFileHandle.getAbsolutePath(), e);    } catch (IOException e) {      throw new StageException(Errors.PROTOBUF_08, e.toString(), e);    }  }
public static void getAllFileDescriptors(      DescriptorProtos.FileDescriptorSet set,      Map<String, Set<Descriptors.FileDescriptor>> dependenciesMap,      Map<String, Descriptors.FileDescriptor> fileDescriptorMap  ) throws StageException {    List<DescriptorProtos.FileDescriptorProto> fileList = set.getFileList();    try {      for (DescriptorProtos.FileDescriptorProto fdp : fileList) {        if (!fileDescriptorMap.containsKey(fdp.getName())) {          Set<Descriptors.FileDescriptor> dependencies = dependenciesMap.get(fdp.getName());          if (dependencies == null) {            dependencies = new LinkedHashSet<>();            dependenciesMap.put(fdp.getName(), dependencies);            dependencies.addAll(getDependencies(dependenciesMap, fileDescriptorMap, fdp, set));          }          Descriptors.FileDescriptor fileDescriptor = Descriptors.FileDescriptor.buildFrom(              fdp,              dependencies.toArray(new Descriptors.FileDescriptor[dependencies.size()])          );          fileDescriptorMap.put(fdp.getName(), fileDescriptor);        }      }    } catch (Descriptors.DescriptorValidationException e) {      throw new StageException(Errors.PROTOBUF_07, e.getDescription(), e);    }  }
public static void populateDefaultsAndExtensions(      Map<String, Descriptors.FileDescriptor> fileDescriptorMap,      Map<String, Set<Descriptors.FieldDescriptor>> typeToExtensionMap,      Map<String, Object> defaultValueMap  ) {    for (Descriptors.FileDescriptor f : fileDescriptorMap.values()) {      // go over every file descriptor and look for extensions and default values of those extensions      for (Descriptors.FieldDescriptor fieldDescriptor : f.getExtensions()) {        String containingType = fieldDescriptor.getContainingType().getFullName();        Set<Descriptors.FieldDescriptor> fieldDescriptors = typeToExtensionMap.get(containingType);        if (fieldDescriptors == null) {          fieldDescriptors = new LinkedHashSet<>();          typeToExtensionMap.put(containingType, fieldDescriptors);        }        fieldDescriptors.add(fieldDescriptor);        if (fieldDescriptor.hasDefaultValue()) {          defaultValueMap.put(containingType + "." + fieldDescriptor.getName(), fieldDescriptor.getDefaultValue());        }      }      // go over messages within file descriptor and look for all fields and extensions and their defaults      for (Descriptors.Descriptor d : f.getMessageTypes()) {        addDefaultsAndExtensions(typeToExtensionMap, defaultValueMap, d);      }    }  }
public static Descriptors.Descriptor getDescriptor(      DescriptorProtos.FileDescriptorSet set,      Map<String, Descriptors.FileDescriptor> fileDescriptorMap,      String descriptorFile,      String qualifiedMessageType  ) throws StageException {    // find the FileDescriptorProto which contains the message type    // IF cannot find, then bail out    String packageName = null;    String messageType = qualifiedMessageType;    int lastIndex = qualifiedMessageType.lastIndexOf('.');    if (lastIndex != -1) {      packageName = qualifiedMessageType.substring(0, lastIndex);      messageType = qualifiedMessageType.substring(lastIndex + 1);    }    DescriptorProtos.FileDescriptorProto file = getFileDescProtoForMsgType(packageName, messageType, set);    if (file == null) {      // could not find the message type from all the proto files contained in the descriptor file      throw new StageException(Errors.PROTOBUF_00, qualifiedMessageType, descriptorFile);    }    // finally get the FileDescriptor for the message type    Descriptors.FileDescriptor fileDescriptor = fileDescriptorMap.get(file.getName());    // create builder using the FileDescriptor    // this can only find the top level message types    return fileDescriptor.findMessageTypeByName(messageType);  }
public static Field protobufToSdcField(      Record record,      String fieldPath,      Descriptors.Descriptor descriptor,      Map<String, Set<Descriptors.FieldDescriptor>> messageTypeToExtensionMap,      Object message  ) throws DataParserException {    LinkedHashMap<String, Field> sdcRecordMapFieldValue = new LinkedHashMap<>();    // get all the expected fields from the proto file    Map<String, Descriptors.FieldDescriptor> protobufFields = new LinkedHashMap<>();    for (Descriptors.FieldDescriptor fieldDescriptor : descriptor.getFields()) {      protobufFields.put(fieldDescriptor.getName(), fieldDescriptor);    }    // get all fields in the read message    Map<Descriptors.FieldDescriptor, Object> values = ((DynamicMessage) message).getAllFields();    // for every field present in the proto definition create an sdc field.    for (Descriptors.FieldDescriptor fieldDescriptor : protobufFields.values()) {      Object value = values.get(fieldDescriptor);      sdcRecordMapFieldValue.put(          fieldDescriptor.getName(),          createField(record, fieldPath, fieldDescriptor, messageTypeToExtensionMap, value)      );    }    // handle applicable extensions for this message type    if (messageTypeToExtensionMap.containsKey(descriptor.getFullName())) {      for (Descriptors.FieldDescriptor fieldDescriptor : messageTypeToExtensionMap.get(descriptor.getFullName())) {        if (values.containsKey(fieldDescriptor)) {          Object value = values.get(fieldDescriptor);          sdcRecordMapFieldValue.put(              fieldDescriptor.getName(),              createField(record, fieldPath, fieldDescriptor, messageTypeToExtensionMap, value)          );        }      }    }    // handle unknown fields    // unknown fields can go into the record header    UnknownFieldSet unknownFields = ((DynamicMessage) message).getUnknownFields();    if (!unknownFields.asMap().isEmpty()) {      ByteArrayOutputStream bOut = new ByteArrayOutputStream();      try {        unknownFields.writeDelimitedTo(bOut);        bOut.flush();        bOut.close();      } catch (IOException e) {        throw new DataParserException(Errors.PROTOBUF_10, e.toString(), e);      }      String path = fieldPath.isEmpty() ? FORWARD_SLASH : fieldPath;      byte[] bytes = org.apache.commons.codec.binary.Base64.encodeBase64(bOut.toByteArray());      record.getHeader().setAttribute(PROTOBUF_UNKNOWN_FIELDS_PREFIX + path, new String(bytes, StandardCharsets.UTF_8));    }    return Field.createListMap(sdcRecordMapFieldValue);  }
@SuppressWarnings("unchecked")  private static Field createField(      Record record,      String fieldPath,      Descriptors.FieldDescriptor fieldDescriptor,      Map<String, Set<Descriptors.FieldDescriptor>> messageTypeToExtensionMap,      Object message  ) throws DataParserException {    Field newField;    if (message == null) {      // If the message does not contain required fields then builder.build() throws UninitializedMessageException      Object defaultValue = null;      Descriptors.FieldDescriptor.JavaType javaType = fieldDescriptor.getJavaType();      // get default values only for optional fields and non-message types      if (fieldDescriptor.isOptional() && fieldDescriptor.getJavaType() != Descriptors.FieldDescriptor.JavaType.MESSAGE) {        defaultValue = fieldDescriptor.getDefaultValue();        //Default value for byte string should be converted to byte array        if (javaType == Descriptors.FieldDescriptor.JavaType.BYTE_STRING            && defaultValue instanceof ByteString) {          defaultValue = ((ByteString)defaultValue).toByteArray();        }      }      newField = Field.create(getFieldType(javaType), defaultValue);    } else if (fieldDescriptor.isMapField()) {      // Map entry (protobuf 3 map)      Map<String, Field> sdcMapFieldValues = new HashMap<>();      Collection<DynamicMessage> mapEntries = (Collection<DynamicMessage>) message;      // MapEntry      for (DynamicMessage dynamicMessage : mapEntries) {        // MapEntry has 2 fields, key and value        Map<Descriptors.FieldDescriptor, Object> kv = dynamicMessage.getAllFields();        String key = null;        Object value = null;        Descriptors.FieldDescriptor valueDescriptor = null;        for (Map.Entry<Descriptors.FieldDescriptor, Object> entry : kv.entrySet()) {          switch (entry.getKey().getName()) {            case KEY:              key = entry.getValue().toString();              break;            case VALUE:              value = entry.getValue();              valueDescriptor = entry.getKey();              break;            default:              throw new DataParserException(Errors.PROTOBUF_09, entry.getKey().getName());          }        }        if (key != null && valueDescriptor != null) {          sdcMapFieldValues.put(              key, createSdcField(record, fieldPath, valueDescriptor, messageTypeToExtensionMap, value)          );        }      }      newField = Field.create(sdcMapFieldValues);    } else if (fieldDescriptor.isRepeated()) {      // List entry (repeated)      List<?> list = (List<?>) message;      List<Field> listField = new ArrayList<>();      for (int i = 0; i < list.size(); i++) {        if (fieldDescriptor.getJavaType() == Descriptors.FieldDescriptor.JavaType.MESSAGE) {          listField.add(              protobufToSdcField(                  record,                  fieldPath + "[" + i + "]",                  fieldDescriptor.getMessageType(),                  messageTypeToExtensionMap,                  list.get(i)              )          );        } else {          listField.add(              createSdcField(                  record,                  fieldPath + "[" + i + "]",                  fieldDescriptor,                  messageTypeToExtensionMap,                  list.get(i)              )          );        }      }      newField = Field.create(listField);    } else {      // normal entry      newField = createSdcField(record, fieldPath, fieldDescriptor, messageTypeToExtensionMap, message);    }    return newField;  }
public static DynamicMessage sdcFieldToProtobufMsg(      Record record,      Descriptors.Descriptor desc,      Map<String, Set<Descriptors.FieldDescriptor>> messageTypeToExtensionMap,      Map<String, Object> defaultValueMap  ) throws DataGeneratorException {    return sdcFieldToProtobufMsg(record, record.get(), "", desc, messageTypeToExtensionMap, defaultValueMap);  }
private static DynamicMessage sdcFieldToProtobufMsg(      Record record,      Field field,      String fieldPath,      Descriptors.Descriptor desc,      Map<String, Set<Descriptors.FieldDescriptor>> messageTypeToExtensionMap,      Map<String, Object> defaultValueMap  ) throws DataGeneratorException {    if (field == null) {      return null;    }    // compute all fields to look for including extensions    DynamicMessage.Builder builder = DynamicMessage.newBuilder(desc);    List<Descriptors.FieldDescriptor> fields = new ArrayList<>();    fields.addAll(desc.getFields());    if (messageTypeToExtensionMap.containsKey(desc.getFullName())) {      fields.addAll(messageTypeToExtensionMap.get(desc.getFullName()));    }    // root field is always a Map in a record representing protobuf data    Map<String, Field> valueAsMap = field.getValueAsMap();    for (Descriptors.FieldDescriptor f : fields) {      Field mapField = valueAsMap.get(f.getName());      // Repeated field      if (f.isMapField()) {        handleMapField(record, mapField, fieldPath, messageTypeToExtensionMap, defaultValueMap, f, builder);      } else if (f.isRepeated()) {        if (mapField != null) {          handleRepeatedField(              record,              mapField,              fieldPath,              messageTypeToExtensionMap,              defaultValueMap,              f,              builder          );        }      } else {        // non repeated field        handleNonRepeatedField(            record,            valueAsMap,            fieldPath,            messageTypeToExtensionMap,            defaultValueMap,            desc,            f,            builder        );      }    }    // if record has unknown fields for this field path, handle it    try {      handleUnknownFields(record, fieldPath, builder);    } catch (IOException e) {      throw new DataGeneratorException(Errors.PROTOBUF_05, e.toString(), e);    }    return builder.build();  }
public static void upgradeToJerseyConfigBean(List<Config> configs) {    List<Config> configsToAdd = new ArrayList<>();    List<Config> configsToRemove = new ArrayList<>();    List<String> movedConfigs = ImmutableList.of(        "conf.requestTimeoutMillis",        "conf.numThreads",        "conf.authType",        "conf.oauth",        "conf.basicAuth",        "conf.useProxy",        "conf.proxy",        "conf.sslConfig"    );    for (Config config : configs) {      if (hasPrefixIn(movedConfigs, config.getName())) {        configsToRemove.add(config);        configsToAdd.add(new Config(config.getName().replace("conf.", "conf.client."), config.getValue()));      }    }    configsToAdd.add(new Config("conf.client.transferEncoding", RequestEntityProcessing.CHUNKED));    configs.removeAll(configsToRemove);    configs.addAll(configsToAdd);  }
public static void checkConnection(AsyncKuduClient kuduClient,                                     Context context,                                     String KUDU_MASTER,                                     final List<Stage.ConfigIssue> issues  ){    try {      kuduClient.getTablesList().join();    } catch (Exception ex) {      issues.add(          context.createConfigIssue(              Groups.KUDU.name(),              KuduLookupConfig.CONF_PREFIX + KUDU_MASTER ,              Errors.KUDU_00,              ex.toString(),              ex          )      );    }  }
public static Field.Type convertFromKuduType(Type kuduType){    switch(kuduType) {      case BINARY: return Field.Type.BYTE_ARRAY;      case BOOL: return Field.Type.BOOLEAN;      case DOUBLE: return Field.Type.DOUBLE;      case FLOAT: return Field.Type.FLOAT;      case INT8: return Field.Type.BYTE;      case INT16: return Field.Type.SHORT;      case INT32: return Field.Type.INTEGER;      case INT64: return Field.Type.LONG;      case STRING: return  Field.Type.STRING;      case UNIXTIME_MICROS: return Field.Type.DATETIME;      default:        if ("DECIMAL".equals(kuduType.name())) {          return Field.Type.DECIMAL;        }        throw new UnsupportedOperationException("Unknown data type: " + kuduType.getName());    }  }
public static Field createField(RowResult result, String fieldName, Type type) throws StageException {    switch (type) {      case INT8:        return Field.create(Field.Type.BYTE, result.getByte(fieldName));      case INT16:        return Field.create(Field.Type.SHORT, result.getShort(fieldName));      case INT32:        return Field.create(Field.Type.INTEGER, result.getInt(fieldName));      case INT64:        return Field.create(Field.Type.LONG, result.getLong(fieldName));      case BINARY:        try {          return Field.create(Field.Type.BYTE_ARRAY, result.getBinary(fieldName));        } catch (IllegalArgumentException ex) {          throw new OnRecordErrorException(Errors.KUDU_35, fieldName);        }      case STRING:        return Field.create(Field.Type.STRING, result.getString(fieldName));      case BOOL:        return Field.create(Field.Type.BOOLEAN, result.getBoolean(fieldName));      case FLOAT:        return Field.create(Field.Type.FLOAT, result.getFloat(fieldName));      case DOUBLE:        return Field.create(Field.Type.DOUBLE, result.getDouble(fieldName));      case UNIXTIME_MICROS:        //UNIXTIME_MICROS is in microsecond        return Field.create(Field.Type.DATETIME, new Date(result.getLong(fieldName)/1000L));      default:        if ("DECIMAL".equals(type.name())) {          return Field.create(Field.Type.DECIMAL, result.getDecimal(fieldName));        }        throw new StageException(Errors.KUDU_10, fieldName, type.getName());    }  }
private List<Record> intercept(List<Record> records, List<? extends Interceptor> interceptors) throws StageException {    for(Interceptor interceptor : interceptors)  {      records = interceptor.intercept(records);    }    return records;  }
public String getText() {    if (line == null) {      line = new String(buffer, offsetInChunk, length, charset);    }    return line;  }
private boolean isConfigurationActive(ConfigDef configDef, Map<String, Object> configuration) {    String dependsOn = configDef.dependsOn();    if (!dependsOn.isEmpty()) {      Object dependsOnValue = configuration.get(dependsOn);      if (dependsOnValue != null) {        String valueStr = dependsOnValue.toString();        for (String trigger : configDef.triggeredByValue()) {          if (valueStr.equals(trigger)) {            return true;          }        }        return false;      }      return false;    }    return true;  }
public static void resolveStageAlias(    StageLibraryTask stageLibrary,    StageConfiguration stageConf  ) {    String aliasKey = Joiner.on(",").join(stageConf.getLibrary(), stageConf.getStageName());    String aliasValue = Strings.nullToEmpty(stageLibrary.getStageNameAliases().get(aliasKey));    if (LOG.isTraceEnabled()) {      for (String key : stageLibrary.getStageNameAliases().keySet()) {        LOG.trace("Stage Lib Alias: {} => {}", key, stageLibrary.getStageNameAliases().get(key));      }      LOG.trace("Looking for '{}' and found '{}'", aliasKey, aliasValue);    }    if (!aliasValue.isEmpty()) {      List<String> alias = Splitter.on(",").splitToList(aliasValue);      if (alias.size() == 2) {        LOG.debug("Converting '{}' to '{}'", aliasKey, aliasValue);        stageConf.setLibrary(alias.get(0));        stageConf.setStageName(alias.get(1));      } else {        LOG.error("Malformed stage alias: '{}'", aliasValue);      }    }  }
public static boolean resolveLibraryAliases(    StageLibraryTask stageLibrary,    List<StageConfiguration> stageConfigurations  ) {    for (StageConfiguration stageConf : stageConfigurations) {      String name = stageConf.getLibrary();      if (stageLibrary.getLibraryNameAliases().containsKey(name)) {        stageConf.setLibrary(stageLibrary.getLibraryNameAliases().get(name));      }      resolveStageAlias(stageLibrary, stageConf);    }    return true;  }
public static void addMissingConfigsToStage(    StageLibraryTask stageLibrary,    StageConfiguration stageConf  ) {    StageDefinition stageDef = stageLibrary.getStage(stageConf.getLibrary(), stageConf.getStageName(), false);    if (stageDef != null) {      for (ConfigDefinition configDef : stageDef.getConfigDefinitions()) {        String configName = configDef.getName();        Config config = stageConf.getConfig(configName);        if (config == null) {          Object defaultValue = configDef.getDefaultValue();          LOG.warn(              "Stage '{}' missing configuration '{}', adding with '{}' as default",              stageConf.getInstanceName(),              configName,              defaultValue          );          config = new Config(configName, defaultValue);          stageConf.addConfig(config);        }      }    }  }
public static boolean validateStageConfiguration(    StageLibraryTask stageLibrary,    boolean shouldBeSource,    StageConfiguration stageConf,    boolean notOnMainCanvas,    IssueCreator issueCreator,    boolean isPipelineFragment,    Map<String, Object> constants,    List<Issue> issues  ) {    boolean preview = true;    StageDefinition stageDef = stageLibrary.getStage(        stageConf.getLibrary(),        stageConf.getStageName(),        false    );    if (stageDef == null) {      // stage configuration refers to an undefined stage definition      issues.add(          issueCreator.create(              stageConf.getInstanceName(),              ValidationError.VALIDATION_0006,              stageConf.getLibrary(),              stageConf.getStageName(),              stageConf.getStageVersion()          )      );      preview = false;    } else {      if (shouldBeSource) {        if (stageDef.getType() != StageType.SOURCE && !isPipelineFragment) {          // first stage must be a Source          issues.add(issueCreator.create(stageConf.getInstanceName(), ValidationError.VALIDATION_0003));          preview = false;        }      } else {        if (!stageLibrary.isMultipleOriginSupported() && stageDef.getType() == StageType.SOURCE) {          // no stage other than first stage can be a Source          issues.add(issueCreator.create(stageConf.getInstanceName(), ValidationError.VALIDATION_0004));          preview = false;        }      }      if (!stageConf.isSystemGenerated() && !TextUtils.isValidName(stageConf.getInstanceName())) {        // stage instance name has an invalid name (it must match '[0-9A-Za-z_]+')        issues.add(            issueCreator.create(                stageConf.getInstanceName(),                ValidationError.VALIDATION_0016,                stageConf.getInstanceName(),                TextUtils.VALID_NAME            )        );        preview = false;      }      // Hidden stages can't appear on the main canvas      if(!notOnMainCanvas && !stageDef.getHideStage().isEmpty()) {        issues.add(issueCreator.create(stageConf.getInstanceName(), ValidationError.VALIDATION_0037));        preview = false;      }      for (String lane : stageConf.getInputLanes()) {        if (!TextUtils.isValidName(lane)) {          // stage instance input lane has an invalid name (it must match '[0-9A-Za-z_]+')          issues.add(              issueCreator.create(                  stageConf.getInstanceName(),                  ValidationError.VALIDATION_0017,                  lane,                  TextUtils.VALID_NAME              )          );          preview = false;        }      }      for (String lane : stageConf.getOutputLanes()) {        if (!TextUtils.isValidName(lane)) {          // stage instance output lane has an invalid name (it must match '[0-9A-Za-z_]+')          issues.add(              issueCreator.create(                  stageConf.getInstanceName(),                  ValidationError.VALIDATION_0018,                  lane,                  TextUtils.VALID_NAME              )          );          preview = false;        }      }      for (String lane : stageConf.getEventLanes()) {        if (!TextUtils.isValidName(lane)) {          // stage instance output lane has an invalid name (it must match '[0-9A-Za-z_]+')          issues.add(              issueCreator.create(                  stageConf.getInstanceName(),                  ValidationError.VALIDATION_0100,                  lane,                  TextUtils.VALID_NAME              )          );          preview = false;        }      }      // Special validation for stage exposed limit of input lanes      // -1: Means that framework is fully in control on how many input lanes should be present      //  0: Means that the stage supports unlimited number of input lanes      // >0: Means that stage needs exactly that amount of lanes which we will validate here      if(stageDef.getInputStreams() > 0) {        if(stageDef.getInputStreams() != stageConf.getInputLanes().size()) {           issues.add(              issueCreator.create(                  stageConf.getInstanceName(),                  ValidationError.VALIDATION_0094,                  stageDef.getInputStreams(),                  stageConf.getInputLanes().size()              )          );        }      }      // Validate proper input/output lane configuration      switch (stageDef.getType()) {        case SOURCE:          if (!stageConf.getInputLanes().isEmpty()) {            // source stage cannot have input lanes            issues.add(                issueCreator.create(                    stageConf.getInstanceName(),                    ValidationError.VALIDATION_0012,                    stageDef.getType(),                    stageConf.getInputLanes()                )            );            preview = false;          }          if (!notOnMainCanvas && !stageDef.isVariableOutputStreams()) {            // source stage must match the output stream defined in StageDef            if (stageDef.getOutputStreams() != stageConf.getOutputLanes().size()) {              issues.add(                  issueCreator.create(                      stageConf.getInstanceName(),                      ValidationError.VALIDATION_0015,                      stageDef.getOutputStreams(),                      stageConf.getOutputLanes().size()                  )              );            }          } else if (!notOnMainCanvas && stageConf.getOutputLanes().isEmpty()) {            // source stage must have at least one output lane            issues.add(issueCreator.create(stageConf.getInstanceName(), ValidationError.VALIDATION_0032));          }          break;        case PROCESSOR:          if (!notOnMainCanvas && stageConf.getInputLanes().isEmpty() && !isPipelineFragment) {            // processor stage must have at least one input lane            issues.add(                issueCreator.create(                    stageConf.getInstanceName(),                    ValidationError.VALIDATION_0014,                    "Processor"                )            );            preview = false;          }          if(!notOnMainCanvas) {            if (!stageDef.isVariableOutputStreams()) {              // processor stage must match the output stream defined in StageDef              if (stageDef.getOutputStreams() != stageConf.getOutputLanes().size()) {                issues.add(                  issueCreator.create(                    stageConf.getInstanceName(),                    ValidationError.VALIDATION_0015,                    stageDef.getOutputStreams(),                    stageConf.getOutputLanes().size()                  )                );              }            } else if (stageConf.getOutputLanes().isEmpty()) {              // processor stage must have at least one output lane              issues.add(issueCreator.create(stageConf.getInstanceName(), ValidationError.VALIDATION_0032));            }          }          break;        case EXECUTOR:        case TARGET:          // Normal target stage must have at least one input lane          if (!notOnMainCanvas && stageConf.getInputLanes().isEmpty() && !isPipelineFragment) {            issues.add(                issueCreator.create(                    stageConf.getInstanceName(),                    ValidationError.VALIDATION_0014,                    "Target"                )            );            preview = false;          }          // Error/Stats/Pipeline lifecycle must not have an input lane          if (notOnMainCanvas && !stageConf.getInputLanes().isEmpty()) {            issues.add(                issueCreator.create(                    stageConf.getInstanceName(),                    ValidationError.VALIDATION_0012,                    "Error/Stats/Lifecycle",                    stageConf.getInputLanes()                )            );            preview = false;          }          if (!stageConf.getOutputLanes().isEmpty()) {            // target stage cannot have output lanes            issues.add(                issueCreator.create(                    stageConf.getInstanceName(),                    ValidationError.VALIDATION_0013,                    stageDef.getType(),                    stageConf.getOutputLanes()                )            );            preview = false;          }          if (notOnMainCanvas && !stageConf.getEventLanes().isEmpty()) {            issues.add(                issueCreator.create(                    stageConf.getInstanceName(),                    ValidationError.VALIDATION_0036,                    stageDef.getType(),                    stageConf.getEventLanes()                )            );            preview = false;          }          break;        default:          throw new IllegalStateException("Unexpected stage type " + stageDef.getType());      }      // Validate proper event configuration      if(!notOnMainCanvas && stageConf.getEventLanes().size() > 1) {        issues.add(          issueCreator.create(            stageConf.getInstanceName(),            ValidationError.VALIDATION_0101          )        );        preview = false;      }      if(!notOnMainCanvas && !stageDef.isProducingEvents() && stageConf.getEventLanes().size() > 0) {        issues.add(          issueCreator.create(            stageConf.getInstanceName(),            ValidationError.VALIDATION_0102          )        );        preview = false;      }      // Validate stage owns configuration      preview &= validateComponentConfigs(        stageConf,        stageDef.getConfigDefinitions(),        stageDef.getConfigDefinitionsMap(),        stageDef.getHideConfigs(),        stageDef.hasPreconditions(),        constants,        issueCreator,        issues      );      // Validate service definitions      Set<String> expectedServices = stageDef.getServices().stream()        .map(service -> service.getService().getName())        .collect(Collectors.toSet());      Set<String> configuredServices = stageConf.getServices().stream()        .map(service -> service.getService().getName())        .collect(Collectors.toSet());      if(!expectedServices.equals(configuredServices)) {        issues.add(issueCreator.create(            stageConf.getInstanceName(),            ValidationError.VALIDATION_0200,            StringUtils.join(expectedServices, ","),            StringUtils.join(configuredServices, ",")        ));        preview = false;      } else {        // Validate all services        for (ServiceConfiguration serviceConf: stageConf.getServices()) {          ServiceDefinition serviceDef = stageLibrary.getServiceDefinition(serviceConf.getService(), false);          preview &= validateComponentConfigs(            serviceConf,            serviceDef.getConfigDefinitions(),            serviceDef.getConfigDefinitionsMap(),            Collections.emptySet(),            false,            constants,            issueCreator.forService(serviceConf.getService().getName()),            issues          );        }      }    }    return preview;  }
@Override  protected List<ConfigIssue> init() {    List<ConfigIssue> issues = super.init();    errorRecordHandler = new DefaultErrorRecordHandler(getContext()); // NOSONAR    double rateLimit = conf.rateLimit > 0 ? (1000.0 / conf.rateLimit) : Double.MAX_VALUE;    rateLimiter = RateLimiter.create(rateLimit);    httpClientCommon.init(issues, getContext());    conf.dataFormatConfig.init(        getContext(),        conf.dataFormat,        Groups.HTTP.name(),        HttpClientCommon.DATA_FORMAT_CONFIG_PREFIX,        issues    );    bodyVars = getContext().createELVars();    bodyEval = getContext().createELEval(REQUEST_BODY_CONFIG_NAME);    if (issues.isEmpty()) {      parserFactory = conf.dataFormatConfig.getParserFactory();    }    return issues;  }
@Override  public void process(Batch batch, SingleLaneBatchMaker batchMaker) throws StageException {    List<Future<Response>> responses = new ArrayList<>();    resolvedRecords.clear();    Iterator<Record> records = batch.getRecords();    while (records.hasNext()) {      Record record = records.next();      String resolvedUrl = httpClientCommon.getResolvedUrl(conf.resourceUrl, record);      WebTarget target = httpClientCommon.getClient().target(resolvedUrl);      LOG.debug("Resolved HTTP Client URL: '{}'",resolvedUrl);      // If the request (headers or body) contain a known sensitive EL and we're not using https then fail the request.      if (httpClientCommon.requestContainsSensitiveInfo(conf.headers, conf.requestBody) &&          !target.getUri().getScheme().toLowerCase().startsWith("https")) {        throw new StageException(Errors.HTTP_07);      }      // from HttpStreamConsumer      final MultivaluedMap<String, Object> resolvedHeaders = httpClientCommon.resolveHeaders(conf.headers, record);      String contentType = HttpStageUtil.getContentTypeWithDefault(resolvedHeaders, conf.defaultRequestContentType);      final AsyncInvoker asyncInvoker = target.request()          .property(OAuth1ClientSupport.OAUTH_PROPERTY_ACCESS_TOKEN, httpClientCommon.getAuthToken())          .headers(resolvedHeaders)          .async();      HttpMethod method = httpClientCommon.getHttpMethod(conf.httpMethod, conf.methodExpression, record);      rateLimiter.acquire();      if (conf.requestBody != null && !conf.requestBody.isEmpty() && method != HttpMethod.GET) {        RecordEL.setRecordInContext(bodyVars, record);        final String requestBody = bodyEval.eval(bodyVars, conf.requestBody, String.class);        resolvedRecords.put(record, new HeadersAndBody(resolvedHeaders, requestBody, contentType, method, target));        responses.add(asyncInvoker.method(method.getLabel(), Entity.entity(requestBody, contentType)));      } else {        resolvedRecords.put(record, new HeadersAndBody(resolvedHeaders, null, null, method, target));        responses.add(asyncInvoker.method(method.getLabel()));      }    }    records = batch.getRecords();    int recordNum = 0;    while (records.hasNext()) {      try {        Record record = processResponse(records.next(), responses.get(recordNum), conf.maxRequestCompletionSecs, false);        if (record != null) {          batchMaker.addRecord(record);        }      } catch (OnRecordErrorException e) {        errorRecordHandler.onError(e);      } finally {        ++recordNum;      }    }    if (!resolvedRecords.isEmpty()) {      reprocessIfRequired(batchMaker);    }  }
private Record processResponse(      Record record,      Future<Response> responseFuture,      long maxRequestCompletionSecs,      boolean failOn403  ) throws StageException {    Response response = null;    try {      response = responseFuture.get(maxRequestCompletionSecs, TimeUnit.SECONDS);      InputStream responseBody = null;      if (response.hasEntity()) {        responseBody = response.readEntity(InputStream.class);      }      int responseStatus = response.getStatus();      if (conf.client.useOAuth2 && response.getStatus() == 403 && !failOn403) {        HttpStageUtil.getNewOAuth2Token(conf.client.oauth2, httpClientCommon.getClient());        return null;      } else if (responseStatus < 200 || responseStatus >= 300) {        resolvedRecords.remove(record);        throw new OnRecordErrorException(            record,            Errors.HTTP_01,            response.getStatus(),            response.getStatusInfo().getReasonPhrase() + " " + responseBody        );      }      resolvedRecords.remove(record);      Record parsedResponse = parseResponse(responseBody);      if (parsedResponse != null) {        record.set(conf.outputField, parsedResponse.get());        addResponseHeaders(record, response);      } else if (responseBody == null && responseStatus != 204) {        throw new OnRecordErrorException(record, Errors.HTTP_34);      }      return record;    } catch (InterruptedException | ExecutionException e) {      LOG.error(Errors.HTTP_03.getMessage(), e.toString(), e);      throw new OnRecordErrorException(record, Errors.HTTP_03, e.toString());    } catch (TimeoutException e) {      LOG.error("HTTP request future timed out", e.toString(), e);      throw new OnRecordErrorException(record, Errors.HTTP_03, e.toString());    } finally {      if (response != null) {        response.close();      }    }  }
private Record parseResponse(InputStream response) throws StageException {    Record record = null;    if (conf.httpMethod == HttpMethod.HEAD) {      // Head will have no body so can't be parsed.   Return an empty record.      record = getContext().createRecord("");      record.set(Field.create(new HashMap()));    } else if (response != null) {      try (DataParser parser = parserFactory.getParser("", response, "0")) {        // A response may only contain a single record, so we only parse it once.        record = parser.parse();        if (conf.dataFormat == DataFormat.TEXT) {          // Output is placed in a field "/text" so we remove it here.          record.set(record.get("/text"));        }      } catch (IOException | DataParserException e) {        errorRecordHandler.onError(Errors.HTTP_00, e.toString(), e);      }    }    return record;  }
private void addResponseHeaders(Record record, Response response) throws StageException {    if (conf.headerOutputLocation == HeaderOutputLocation.NONE) {      return;    }    Record.Header header = record.getHeader();    if (conf.headerOutputLocation == HeaderOutputLocation.FIELD) {      writeResponseHeaderToField(record, response);    } else if (conf.headerOutputLocation == HeaderOutputLocation.HEADER) {      writeResponseHeaderToRecordHeader(response, header);    }  }
private void writeResponseHeaderToField(Record record, Response response) throws StageException {    if (record.has(conf.headerOutputField)) {      throw new StageException(Errors.HTTP_11, conf.headerOutputField);    }    Map<String, Field> headers = new HashMap<>(response.getStringHeaders().size());    for (Map.Entry<String, List<String>> entry : response.getStringHeaders().entrySet()) {      if (!entry.getValue().isEmpty()) {        String firstValue = entry.getValue().get(0);        headers.put(entry.getKey(), Field.create(firstValue));      }    }    record.set(conf.headerOutputField, Field.create(headers));  }
private void writeResponseHeaderToRecordHeader(Response response, Record.Header header) {    for (Map.Entry<String, List<String>> entry : response.getStringHeaders().entrySet()) {      if (!entry.getValue().isEmpty()) {        String firstValue = entry.getValue().get(0);        header.setAttribute(conf.headerAttributePrefix + entry.getKey(), firstValue);      }    }  }
synchronized private void saveMetadata() throws StageException {    // 0) Validate pre-conditions    if(Files.exists(newMetadataFile))  {      throw new StageException(BlobStoreError.BLOB_STORE_0010);    }    // 1) New content is written into a new temporary file.    try (      OutputStream os = Files.newOutputStream(newMetadataFile, StandardOpenOption.CREATE, StandardOpenOption.TRUNCATE_EXISTING)    ) {      jsonMapper.writeValue(os, metadata);    } catch (IOException e) {      throw new StageException(BlobStoreError.BLOB_STORE_0001, e.toString(), e);    }    // 2) Old metadata is dropped    try {      if(Files.exists(metadataFile)) {        Files.delete(metadataFile);      }    } catch (IOException e) {      throw new StageException(BlobStoreError.BLOB_STORE_0011, e.toString(), e);    }    // 3) Rename from new to old is done    try {      Files.move(newMetadataFile, metadataFile);    } catch (IOException e) {      throw new StageException(BlobStoreError.BLOB_STORE_0012, e.toString(), e);    }  }
@Override  protected List<ConfigIssue> init() {    List<ConfigIssue> issues = super.init();    errorRecordHandler = new DefaultErrorRecordHandler(getContext()); // NOSONAR    conf.basic.init(getContext(), Groups.HTTP.name(), BASIC_CONFIG_PREFIX, issues);    conf.dataFormatConfig.init(getContext(), conf.dataFormat, Groups.HTTP.name(), DATA_FORMAT_CONFIG_PREFIX, issues);    conf.init(getContext(), Groups.HTTP.name(), "conf.", issues);    if (conf.client.tlsConfig.isEnabled()) {      conf.client.tlsConfig.init(getContext(), Groups.TLS.name(), TLS_CONFIG_PREFIX, issues);    }    resourceVars = getContext().createELVars();    resourceEval = getContext().createELEval(RESOURCE_CONFIG_NAME);    bodyVars = getContext().createELVars();    bodyEval = getContext().createELEval(REQUEST_BODY_CONFIG_NAME);    Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone(ZoneId.of(conf.timeZoneID)));    TimeEL.setCalendarInContext(bodyVars, calendar);    headerVars = getContext().createELVars();    headerEval = getContext().createELEval(HEADER_CONFIG_NAME);    stopVars = getContext().createELVars();    stopEval = getContext().createELEval(STOP_CONFIG_NAME);    next = null;    haveMorePages = false;    if (conf.responseStatusActionConfigs != null) {      final String cfgName = "conf.responseStatusActionConfigs";      final EnumSet<ResponseAction> backoffRetries = EnumSet.of(          ResponseAction.RETRY_EXPONENTIAL_BACKOFF,          ResponseAction.RETRY_LINEAR_BACKOFF      );      for (HttpResponseActionConfigBean actionConfig : conf.responseStatusActionConfigs) {        final HttpResponseActionConfigBean prevAction = statusToActionConfigs.put(            actionConfig.getStatusCode(),            actionConfig        );        if (prevAction != null) {          issues.add(            getContext().createConfigIssue(                Groups.HTTP.name(),                cfgName,                Errors.HTTP_17,                actionConfig.getStatusCode()            )          );        }        if (backoffRetries.contains(actionConfig.getAction()) && actionConfig.getBackoffInterval() <= 0) {          issues.add(            getContext().createConfigIssue(                Groups.HTTP.name(),                cfgName,                Errors.HTTP_15            )          );        }        if (actionConfig.getStatusCode() >= 200 && actionConfig.getStatusCode() < 300) {          issues.add(            getContext().createConfigIssue(                Groups.HTTP.name(),                cfgName,                Errors.HTTP_16            )          );        }      }    }    this.timeoutActionConfig = conf.responseTimeoutActionConfig;    // Validation succeeded so configure the client.    if (issues.isEmpty()) {      try {        configureClient(issues);      } catch (StageException e) {        // should not happen on initial connect        ExceptionUtils.throwUndeclared(e);      }    }    return issues;  }
private void configureClient(List<ConfigIssue> issues) throws StageException {    clientCommon.init(issues, getContext());    if (issues.isEmpty()) {      client = clientCommon.getClient();      parserFactory = conf.dataFormatConfig.getParserFactory();    }  }
@Override  public String produce(String lastSourceOffset, int maxBatchSize, BatchMaker batchMaker) throws StageException {    long start = System.currentTimeMillis();    int chunksToFetch = Math.min(conf.basic.maxBatchSize, maxBatchSize);    Optional<String> newSourceOffset = Optional.empty();    recordCount = 0;    setPageOffset(lastSourceOffset);    setResolvedUrl(resolveInitialUrl(lastSourceOffset));    WebTarget target = client.target(getResolvedUrl());    // If the request (headers or body) contain a known sensitive EL and we're not using https then fail the request.    if (requestContainsSensitiveInfo() && !target.getUri().getScheme().toLowerCase().startsWith("https")) {      LOG.error(Errors.HTTP_07.getMessage());      throw new StageException(Errors.HTTP_07);    }    boolean uninterrupted = true;    while (!waitTimeExpired(start) && uninterrupted && (recordCount < chunksToFetch)) {      if (parser != null) {        // We already have an response that we haven't finished reading.        newSourceOffset = Optional.of(parseResponse(start, chunksToFetch, batchMaker));      } else if (shouldMakeRequest()) {        if (conf.pagination.mode != PaginationMode.NONE) {          target = client.target(resolveNextPageUrl(newSourceOffset.orElse(null)));          // Pause between paging requests so we don't get rate limited.          uninterrupted = ThreadUtil.sleep(conf.pagination.rateLimit);        }        makeRequest(target);        if (lastRequestTimedOut) {          String actionName = conf.responseTimeoutActionConfig.getAction().name();          LOG.warn(              "HTTPClient timed out after waiting {} ms for response from server;" +              " reconnecting client and proceeding as per configured {} action",              conf.client.readTimeoutMillis,              actionName          );          reconnectClient();          return nonTerminating(lastSourceOffset);        } else {          newSourceOffset = processResponse(start, chunksToFetch, batchMaker);        }      } else if (conf.httpMode == HttpClientMode.BATCH) {        // We are done.        return null;      } else {        // In polling mode, waiting for the next polling interval.        uninterrupted = ThreadUtil.sleep(SLEEP_TIME_WAITING_FOR_BATCH_SIZE_MS);      }    }    return newSourceOffset.orElse(lastSourceOffset);  }
@VisibleForTesting  String resolveNextPageUrl(String sourceOffset) throws ELEvalException {    String url;    if (LINK_PAGINATION.contains(conf.pagination.mode) && next != null) {      url = next.getUri().toString();      setResolvedUrl(url);    } else if (conf.pagination.mode == PaginationMode.BY_OFFSET || conf.pagination.mode == PaginationMode.BY_PAGE) {      if (sourceOffset != null) {        setPageOffset(sourceOffset);      }      url = resourceEval.eval(resourceVars, conf.resourceUrl, String.class);    } else {      url = getResolvedUrl();    }    return url;  }
private void setPageOffset(String sourceOffset) {    if (conf.pagination.mode == PaginationMode.NONE) {      return;    }    int startAt = conf.pagination.startAt;    if (StringUtils.isNotEmpty(sourceOffset)) {      startAt = HttpSourceOffset.fromString(sourceOffset).getStartAt();    }    resourceVars.addVariable(START_AT, startAt);    bodyVars.addVariable(START_AT, startAt);  }
private void makeRequest(WebTarget target) throws StageException {    hasher = HF.newHasher();    MultivaluedMap<String, Object> resolvedHeaders = resolveHeaders();    final Invocation.Builder invocationBuilder = target        .request()        .property(OAuth1ClientSupport.OAUTH_PROPERTY_ACCESS_TOKEN, authToken)        .headers(resolvedHeaders);    boolean keepRequesting = !getContext().isStopped();    boolean gotNewToken = false;    while (keepRequesting) {      long startTime = System.currentTimeMillis();      try {        if (conf.requestBody != null && !conf.requestBody.isEmpty() && conf.httpMethod != HttpMethod.GET) {          final String requestBody = bodyEval.eval(bodyVars, conf.requestBody, String.class);          final String contentType = HttpStageUtil.getContentTypeWithDefault(              resolvedHeaders, conf.defaultRequestContentType);          hasher.putString(requestBody, Charset.forName(conf.dataFormatConfig.charset));          setResponse(invocationBuilder.method(conf.httpMethod.getLabel(), Entity.entity(requestBody, contentType)));        } else {          setResponse(invocationBuilder.method(conf.httpMethod.getLabel()));        }        LOG.debug("Retrieved response in {} ms", System.currentTimeMillis() - startTime);        lastRequestTimedOut = false;        final int status = response.getStatus();        final boolean statusOk = status >= 200 && status < 300;        if (conf.client.useOAuth2 && status == 403) { // Token may have expired          if (gotNewToken) {            LOG.error(HTTP_21.getMessage());            throw new StageException(HTTP_21);          }          gotNewToken = HttpStageUtil.getNewOAuth2Token(conf.client.oauth2, client);        } else if (!statusOk && this.statusToActionConfigs.containsKey(status)) {          final HttpResponseActionConfigBean actionConf = this.statusToActionConfigs.get(status);          final boolean statusChanged = lastStatus != status || lastRequestTimedOut;          keepRequesting = applyResponseAction(              actionConf,              statusChanged,              input -> {                final StageException stageException = new StageException(                    Errors.HTTP_14,                    status,                    response.readEntity(String.class)                );                LOG.error(stageException.getMessage());                return stageException;              }          );        } else {          keepRequesting = false;          retryCount = 0;        }        lastStatus = status;      } catch (Exception e) {        LOG.debug("Request failed after {} ms", System.currentTimeMillis() - startTime);        final Throwable cause = e.getCause();        if (cause != null && (cause instanceof TimeoutException || cause instanceof SocketTimeoutException)) {          LOG.warn(              "{} attempting to read response in HttpClientSource: {}",              cause.getClass().getSimpleName(),              e.getMessage(),              e          );          // read timeout; consult configured action to decide on backoff and retry strategy          if (this.timeoutActionConfig != null) {            final HttpResponseActionConfigBean actionConf = this.timeoutActionConfig;            final boolean firstTimeout = !lastRequestTimedOut;            applyResponseAction(actionConf, firstTimeout, input -> {                  LOG.error(Errors.HTTP_18.getMessage());                  return new StageException(Errors.HTTP_18);                }            );          }          lastRequestTimedOut = true;          keepRequesting = false;        } else if (cause != null && cause instanceof InterruptedException) {          LOG.error(            String.format(                "InterruptedException attempting to make request in HttpClientSource; stopping: %s",                e.getMessage()            ),          e);          keepRequesting = false;        } else {          LOG.error(            String.format(                "ProcessingException attempting to make request in HttpClientSource: %s",                e.getMessage()            ),          e);          Throwable reportEx = cause != null ? cause : e;          final StageException stageException = new StageException(Errors.HTTP_32, reportEx.toString(), reportEx);          LOG.error(stageException.getMessage());          throw stageException;        }      }      keepRequesting &= !getContext().isStopped();    }    // Calculate request parameter hash    currentParameterHash = hasher.hash().toString();  }
private boolean shouldMakeRequest() {    final long now = System.currentTimeMillis();    boolean shouldMakeRequest = lastRequestCompletedTime == -1;    shouldMakeRequest |= lastRequestTimedOut;    shouldMakeRequest |= next != null;    shouldMakeRequest |= (haveMorePages && conf.pagination.mode != PaginationMode.LINK_HEADER);    shouldMakeRequest |= now > lastRequestCompletedTime + conf.pollingInterval &&        conf.httpMode == HttpClientMode.POLLING;    shouldMakeRequest |= now > lastRequestCompletedTime && conf.httpMode == HttpClientMode.STREAMING && conf.httpMethod != HttpMethod.HEAD;    return shouldMakeRequest;  }
@VisibleForTesting  String parseResponse(long start, int maxRecords, BatchMaker batchMaker) throws StageException {    HttpSourceOffset sourceOffset = new HttpSourceOffset(        getResolvedUrl(),        currentParameterHash,        System.currentTimeMillis(),        getCurrentPage()    );    InputStream in = null;    if (parser == null) {      // Only get a new parser if we are done with the old one.      in = getResponse().readEntity(InputStream.class);      try {        parser = parserFactory.getParser(sourceOffset.toString(), in, "0");      } catch (DataParserException e) {        if (e.getErrorCode() == JSON_PARSER_00) {          LOG.warn("No data returned in HTTP response body.", e);          return sourceOffset.toString();        }        LOG.warn("Error parsing response", e);        throw e;      }    }    Record record = null;    int subRecordCount = 0;    try {      do {        record = parser.parse();        if (record == null) {          break;        }        // LINK_FIELD pagination        if (conf.pagination.mode == PaginationMode.LINK_FIELD) {          // evaluate stopping condition          RecordEL.setRecordInContext(stopVars, record);          haveMorePages = !stopEval.eval(stopVars, conf.pagination.stopCondition, Boolean.class);          if (haveMorePages) {            next = Link.fromUri(record.get(conf.pagination.nextPageFieldPath).getValueAsString()).build();          } else {            next = null;          }        }        if (conf.pagination.mode != PaginationMode.NONE && record.has(conf.pagination.resultFieldPath)) {          subRecordCount = parsePaginatedResult(batchMaker, sourceOffset.toString(), record);          recordCount += subRecordCount;        } else {          addResponseHeaders(record.getHeader());          batchMaker.addRecord(record);          ++recordCount;        }      } while (recordCount < maxRecords && !waitTimeExpired(start));    } catch (IOException e) {      LOG.error(Errors.HTTP_00.getMessage(), e.toString(), e);      errorRecordHandler.onError(Errors.HTTP_00, e.toString(), e);    } finally {      try {        if (record == null) {          cleanupResponse(in);        }        if (subRecordCount != 0) {          incrementSourceOffset(sourceOffset, subRecordCount);        }      } catch(IOException e) {        LOG.warn(Errors.HTTP_28.getMessage(), e.toString(), e);        errorRecordHandler.onError(Errors.HTTP_28, e.toString(), e);      }    }    return sourceOffset.toString();  }
String parseHeadersOnly(BatchMaker batchMaker) throws StageException {    HttpSourceOffset sourceOffset = new HttpSourceOffset(            getResolvedUrl(),            currentParameterHash,            System.currentTimeMillis(),            getCurrentPage()    );    Record record = getContext().createRecord(sourceOffset + "::0");    addResponseHeaders(record.getHeader());    record.set(Field.create(new HashMap()));    batchMaker.addRecord(record);    recordCount++;    incrementSourceOffset(sourceOffset, 1);    lastRequestCompletedTime = System.currentTimeMillis();    return sourceOffset.toString();  }
private void incrementSourceOffset(HttpSourceOffset sourceOffset, int increment) {    if (conf.pagination.mode == PaginationMode.BY_PAGE) {      sourceOffset.incrementStartAt(1);    } else if (conf.pagination.mode == PaginationMode.BY_OFFSET) {      sourceOffset.incrementStartAt(increment);    }  }
private void cleanupResponse(InputStream in) throws IOException {    IOException ex = null;    LOG.debug("Cleanup after request processing complete.");    lastRequestCompletedTime = System.currentTimeMillis();    if (in != null) {      try {        in.close();      } catch(IOException e) {        LOG.warn("Error closing input stream", ex);        ex = e;      }    }    getResponse().close();    setResponse(null);    try {      parser.close();    } catch(IOException e) {      LOG.warn("Error closing parser", ex);      ex = e;    }    parser = null;    if(ex != null) {      throw ex;    }  }
@VisibleForTesting  int getCurrentPage() {    // Body params take precedence, but usually only one or the other should be used.    if (bodyVars.hasVariable(START_AT)) {      return (int) bodyVars.getVariable(START_AT);    } else if (resourceVars.hasVariable(START_AT)) {      return (int) resourceVars.getVariable(START_AT);    }    return 0;  }
private int parsePaginatedResult(BatchMaker batchMaker, String sourceOffset, Record record) throws      StageException {    int numSubRecords = 0;    if (!record.has(conf.pagination.resultFieldPath)) {      final StageException stageException = new StageException(Errors.HTTP_12, conf.pagination.resultFieldPath);      LOG.error(stageException.getMessage());      throw stageException;    }    Field resultField = record.get(conf.pagination.resultFieldPath);    if (resultField.getType() != Field.Type.LIST) {      final StageException stageException = new StageException(Errors.HTTP_08, resultField.getType());      LOG.error(stageException.getMessage());      throw stageException;    }    List<Field> results = resultField.getValueAsList();    int subRecordIdx = 0;    for (Field result : results) {      Record r = getContext().createRecord(sourceOffset + "::" + subRecordIdx++);      if (conf.pagination.keepAllFields) {        r.set(record.get().clone());        r.set(conf.pagination.resultFieldPath, result);      } else {        r.set(result);      }      addResponseHeaders(r.getHeader());      batchMaker.addRecord(r);      ++numSubRecords;    }    if (conf.pagination.mode != PaginationMode.LINK_FIELD) {      haveMorePages = numSubRecords > 0;    }    return numSubRecords;  }
private void addResponseHeaders(Record.Header header) {    final MultivaluedMap<String, String> headers = getResponse().getStringHeaders();    if (headers == null) {      return;    }    for (Map.Entry<String, List<String>> entry : headers.entrySet()) {      if (!entry.getValue().isEmpty()) {        String firstValue = entry.getValue().get(0);        header.setAttribute(entry.getKey(), firstValue);      }    }  }
private MultivaluedMap<String, Object> resolveHeaders() throws StageException {    MultivaluedMap<String, Object> requestHeaders = new MultivaluedHashMap<>();    for (Map.Entry<String, String> entry : conf.headers.entrySet()) {      List<Object> header = new ArrayList<>(1);      Object resolvedValue = headerEval.eval(headerVars, entry.getValue(), String.class);      header.add(resolvedValue);      requestHeaders.put(entry.getKey(), header);      hasher.putString(entry.getKey(), Charset.forName(conf.dataFormatConfig.charset));      hasher.putString(entry.getValue(), Charset.forName(conf.dataFormatConfig.charset));    }    return requestHeaders;  }
private Optional<String> processResponse(long start, int maxRecords, BatchMaker batchMaker) throws      StageException {    Optional<String> newSourceOffset = Optional.empty();    if (getResponse() == null) {      return newSourceOffset;    }    // Response was not in the OK range, so treat as an error    int status = getResponse().getStatus();    if (status < 200 || status >= 300) {      lastRequestCompletedTime = System.currentTimeMillis();      String reason = getResponse().getStatusInfo().getReasonPhrase();      String respString = getResponse().readEntity(String.class);      getResponse().close();      setResponse(null);      final String errorMsg = reason + " : " + respString;      LOG.warn(Errors.HTTP_01.getMessage(), status, errorMsg);      errorRecordHandler.onError(Errors.HTTP_01, status, errorMsg);      return newSourceOffset;    }    if (conf.pagination.mode == PaginationMode.LINK_HEADER) {      next = getResponse().getLink("next");      if (next == null) {        haveMorePages = false;      }    }    if (getResponse().hasEntity()) {      newSourceOffset = Optional.of(parseResponse(start, maxRecords, batchMaker));    } else if (conf.httpMethod.getLabel() == "HEAD") {      // Handle HEAD only requests, which have no body, by creating a blank record for output with headers.      newSourceOffset = Optional.of(parseHeadersOnly(batchMaker));    }    return newSourceOffset;  }
protected boolean propertyDefined(Configuration conf, String propertyName) {    String prop = conf.get(propertyName);    // String property will have default empty, integer -1, we'll skip both of them    return prop != null && !prop.isEmpty() && !prop.equals("-1");  }
public static DataParserException convert(      com.streamsets.pipeline.lib.parser.DataParserException original  ) {    if(original instanceof com.streamsets.pipeline.lib.parser.RecoverableDataParserException) {      return new RecoverableDataParserException(        ((com.streamsets.pipeline.lib.parser.RecoverableDataParserException) original).getUnparsedRecord(),        original.getErrorCode(),        original.getParams()      );    }    return new DataParserException(      original.getErrorCode(),      original.getParams()    );  }
public static DataGeneratorException convert(      com.streamsets.pipeline.lib.generator.DataGeneratorException original  ) {   return new DataGeneratorException(      original.getErrorCode(),      original.getParams()    );  }
public Optional<CredentialsProvider> getCredentialsProvider(Stage.Context context, List<Stage.ConfigIssue> issues) {    CredentialsProvider provider = null;    if (credentialsProvider.equals(CredentialsProviderType.DEFAULT_PROVIDER)) {      return Optional.of(SubscriptionAdminSettings.defaultCredentialsProviderBuilder().build());    } else if (credentialsProvider.equals(CredentialsProviderType.JSON_PROVIDER)) {      Credentials credentials = getCredentials(context, issues);      provider = new FixedCredentialsProvider() {        @Nullable        @Override        public Credentials getCredentials() {          return credentials;        }      };    }    return Optional.ofNullable(provider);  }
private Credentials getCredentials(Stage.Context context, List<Stage.ConfigIssue> issues) {    Credentials credentials = null;    File credentialsFile;    if (Paths.get(path).isAbsolute()) {      credentialsFile = new File(path);    } else {      credentialsFile = new File(context.getResourcesDirectory(), path);    }    if (!credentialsFile.exists() || !credentialsFile.isFile()) {      LOG.error(GOOGLE_01.getMessage(), credentialsFile.getPath());      issues.add(context.createConfigIssue(          Groups.CREDENTIALS.name(), CONF_CREDENTIALS_CREDENTIALS_PROVIDER,          GOOGLE_01,          credentialsFile.getPath()      ));      return null;    }    try (InputStream in = new FileInputStream(credentialsFile)) {      credentials = ServiceAccountCredentials.fromStream(in);    } catch (IOException | IllegalArgumentException e) {      LOG.error(GOOGLE_02.getMessage(), e);      issues.add(context.createConfigIssue(          Groups.CREDENTIALS.name(), CONF_CREDENTIALS_CREDENTIALS_PROVIDER,          GOOGLE_02      ));    }    return credentials;  }
public PreviewInfoJson previewWithOverride (String pipelineId, List<StageOutputJson> stageOutputsToOverrideJson,                                              String rev, Integer batchSize, Integer batches, Boolean skipTargets,                                              String endStage, Long timeout) throws ApiException {    Object postBody = stageOutputsToOverrideJson;    byte[] postBinaryBody = null;    // verify the required parameter 'pipelineId' is set    if (pipelineId == null) {      throw new ApiException(400, "Missing the required parameter 'pipelineId' when calling previewWithOverride");    }    // verify the required parameter 'stageOutputsToOverrideJson' is set    if (stageOutputsToOverrideJson == null) {      throw new ApiException(400,          "Missing the required parameter 'stageOutputsToOverrideJson' when calling previewWithOverride");    }    // create path and map variables    String path = "/v1/pipeline/{pipelineId}/preview".replaceAll("\\{format\\}","json")      .replaceAll("\\{" + "pipelineId" + "\\}", apiClient.escapeString(pipelineId.toString()));    // query params    List<Pair> queryParams = new ArrayList<Pair>();    Map<String, String> headerParams = new HashMap<String, String>();    Map<String, Object> formParams = new HashMap<String, Object>();    queryParams.addAll(apiClient.parameterToPairs("", "rev", rev));    queryParams.addAll(apiClient.parameterToPairs("", "batchSize", batchSize));    queryParams.addAll(apiClient.parameterToPairs("", "batches", batches));    queryParams.addAll(apiClient.parameterToPairs("", "skipTargets", skipTargets));    queryParams.addAll(apiClient.parameterToPairs("", "endStage", endStage));    queryParams.addAll(apiClient.parameterToPairs("", "timeout", timeout));    final String[] accepts = {      "application/json"    };    final String accept = apiClient.selectHeaderAccept(accepts);    final String[] contentTypes = {    };    final String contentType = apiClient.selectHeaderContentType(contentTypes);    String[] authNames = new String[] { "basic" };    TypeRef returnType = new TypeRef<PreviewInfoJson>() {};    return apiClient.invokeAPI(path, "POST", queryParams, postBody, postBinaryBody, headerParams, formParams, accept, contentType, authNames, returnType);  }
protected int copyToBuffer(StringBuilder s, int initialLen, int startChar, int currentChar) {    int overrun = 0;    int currentSize = s.length() - initialLen;    int readSize = currentChar - startChar;    if (maxLine > -1 && currentSize + readSize > maxLine) {      int adjustedReadSize = maxLine - currentSize;      if (adjustedReadSize > 0) {        s.append(cb, startChar, adjustedReadSize);        overrun = readSize - adjustedReadSize;      } else {        overrun = readSize;      }    } else {      s.append(cb, startChar, readSize);    }    return overrun;  }
private static SortedSet<String> findApplicationPackageNames(ClassLoader cl) {    SortedSet<String> packages = new TreeSet<>();    while (cl != null) {      if (cl instanceof URLClassLoader) {        for (URL url : ((URLClassLoader)cl).getURLs()) {          String path = url.getPath();          if (!path.startsWith(JAVA_HOME) && !path.startsWith(MACOS_JAVA_EXTENSIONS_DIR) &&            path.endsWith(JAR_FILE_SUFFIX)) {            try {              try (ZipInputStream zip = new ZipInputStream(url.openStream())) {                for (ZipEntry entry = zip.getNextEntry(); entry != null; entry = zip.getNextEntry()) {                  if (!entry.isDirectory() && entry.getName().endsWith(CLASS_FILE_SUFFIX)) {                    // This ZipEntry represents a class. Now, what class does it represent?                    String className = entry.getName().replace('/', '.'); // including ".class"                    className = className.substring(0, className.length() - CLASS_FILE_SUFFIX.length());                    if (className.contains(".") && !className.startsWith(STREAMSETS_PACKAGE)) {                      // must end with a . as we don't want o.a.h matching o.a.ha                      packages.add(className.substring(0, className.lastIndexOf('.')) + ".");                    }                  }                }              }            } catch (IOException unlikely) {              // since these are local URL we will likely only              // hit this if there is a corrupt jar in the classpath              // which we will ignore              if (SDCClassLoader.isDebug()) {                System.err.println("Error opening '" + url + "' : " + unlikely);                unlikely.printStackTrace();              }            }          }        }      }      cl = cl.getParent();    }    SystemPackage systemPackage = new SystemPackage(SDCClassLoader.SYSTEM_API_CHILDREN_CLASSES);    Iterator<String> iterator = packages.iterator();    while (iterator.hasNext()) {      String packageName = iterator.next();      if (systemPackage.isSystem(packageName)) {        iterator.remove();      }    }    removeLogicalDuplicates(packages);    return packages;  }
static void removeLogicalDuplicates(SortedSet<String> packages) {    Iterator<String> iterator = packages.iterator();    if (!iterator.hasNext()) {      return;    }    String last = iterator.next();    while (iterator.hasNext()) {      String current = iterator.next();      if (current.startsWith(last)) {        iterator.remove();      } else {        last = current;      }    }  }
protected void emptyBatch() throws StageException {    setBatchTime();    try {      hdfsTargetConfigBean.getUGI().doAs(new PrivilegedExceptionAction<Void>() {        @Override        public Void run() throws Exception {          hdfsTargetConfigBean.getCurrentWriters().purge();          if (hdfsTargetConfigBean.getLateWriters() != null) {            hdfsTargetConfigBean.getLateWriters().purge();          }          return null;        }      });    } catch (Exception ex) {      throw throwStageException(ex);    }  }
@Override  protected List<ConfigIssue> init() {    // Validate configuration values and open any required resources.    List<ConfigIssue> issues = super.init();    errorRecordHandler = new DefaultErrorRecordHandler(getContext());    elEvals.init(getContext());    Processor.Context context = getContext();    issues.addAll(hikariConfigBean.validateConfigs(context, issues));    if (issues.isEmpty() && null == dataSource) {      try {        dataSource = jdbcUtil.createDataSourceForWrite(hikariConfigBean, null, null,            false,            issues,            Collections.emptyList(),            getContext()        );      } catch (RuntimeException | SQLException | StageException e) {        LOG.debug("Could not connect to data source", e);        issues.add(getContext().createConfigIssue(Groups.JDBC.name(), CONNECTION_STRING, JdbcErrors.JDBC_00, e.toString()));      }    }    if (issues.isEmpty()) {      try {        schemaWriter = JdbcSchemaWriterFactory.create(hikariConfigBean.getConnectionString(), dataSource);      } catch (JdbcStageCheckedException e) {        issues.add(getContext().createConfigIssue(Groups.JDBC.name(), CONNECTION_STRING, e.getErrorCode(), e.getParams()));      }      schemaReader = new JdbcSchemaReader(dataSource, schemaWriter);      tableCache = CacheBuilder.newBuilder().maximumSize(50).build(new CacheLoader<Pair<String, String>, LinkedHashMap<String, JdbcTypeInfo>>() {        @Override        public LinkedHashMap<String, JdbcTypeInfo> load(Pair<String, String> pair) throws Exception {          return schemaReader.getTableSchema(pair.getLeft(), pair.getRight());        }      });    }    // If issues is not empty, the UI will inform the user of each configuration issue in the list.    return issues;  }
int findNextMainLine(LiveFileChunk chunk, int startIdx) {    List<FileLine> lines = chunk.getLines();    int found = -1;    for (int i = startIdx; found == -1 && i < lines.size(); i++) {      if (pattern.matcher(lines.get(i).getText().trim()).matches()) {        found = i;      }    }    return found;  }
LiveFileChunk resolveChunk(LiveFileChunk chunk) {    List<FileLine> completeLines = new ArrayList<>();    List<FileLine> chunkLines = chunk.getLines();    if (incompleteMultiLine.length() == 0) {      incompleteMultiLineOffset = chunk.getOffset();      incompleteMultiLineTruncated = chunk.isTruncated();    }    incompleteMultiLineTruncated |= chunk.isTruncated();    int pos = 0;    int idx = findNextMainLine(chunk, pos);    // while we have main lines we keep adding/compacting into the new chunk    while (idx > -1) {      //any multi lines up to the next main line belong to the previous main line      for (int i = pos; i < idx; i++) {        incompleteMultiLine.append(chunkLines.get(i).getText());      }      // if we have incomplete lines, at this point they are a complete multiline, compact and add to new chunk lines      if (incompleteMultiLine.length() != 0) {        completeLines.add(new FileLine(incompleteMultiLineOffset, incompleteMultiLine.toString()));        incompleteMultiLineOffset += incompleteMultiLine.length();        // clear the incomplete multi lines as we just used them to create a full line        incompleteMultiLine.setLength(0);        incompleteMultiLineTruncated = false;      }      // add the current main line as incomplete as we still don't if it is a complete line      incompleteMultiLine.append(chunkLines.get(idx).getText());      // find the next main line      pos = idx + 1;      idx = findNextMainLine(chunk, pos);    }    // lets process the left over multi lines in the chunk after the last main line.    // if any they will kept to completed with lines from the next chunk.    for (int i = pos; i < chunkLines.size(); i++) {      incompleteMultiLine.append(chunkLines.get(i).getText());    }    if (completeLines.isEmpty()) {      // didn't get a complete multi line yet, we keep storing lines but return a null chunk      chunk = null;    } else {      // create a new chunk with all complete multi lines      chunk = new LiveFileChunk(chunk.getTag(), chunk.getFile(), chunk.getCharset(), completeLines,                                incompleteMultiLineTruncated);    }    return chunk;  }
public Connection getConnection() throws SQLException {    if (threadLocalConnection.get() == null) {      threadLocalConnection.set(getNewConnection());    }    return threadLocalConnection.get();  }
public void closeConnection() {    LOGGER.debug("Closing connection");    Connection connectionToRemove = threadLocalConnection.get();    jdbcUtil.closeQuietly(connectionToRemove);    if (connectionToRemove != null) {      synchronized (this) {        connectionsToCloseDuringDestroy.remove(connectionToRemove);      }    }    threadLocalConnection.set(null);  }
@Override  public int read(byte[] b) throws IOException {    checkState(InputStream.class);    return ((InputStream)stream).read(b);  }
@Override  public int read(byte[] b, int offset, int len) throws IOException {    checkState(InputStream.class);    return  ((InputStream)stream).read(b, offset, len);  }
@Override  public long skip(long n) throws IOException {    checkState(InputStream.class);    return ((InputStream)stream).skip(n);  }
@Override  public int read(ByteBuffer dst) throws IOException {    checkState(ReadableByteChannel.class);    return  ((ReadableByteChannel)stream).read(dst);  }
private static String escapeQuotedSubstring(String input) {    String[] parts = input.split("'");    StringBuilder output = new StringBuilder(input.length() * 2);    for (int i = 0; i < parts.length; i++) {      if ((i % 2) == 1) {        output.append("'").append(parts[i].replace("|", "\\|")).append("'");      } else {        output.append(parts[i]);      }    }    return output.toString();  }
private FlowControlSettings getFlowControlSettings() {    return FlowControlSettings.newBuilder()        .setLimitExceededBehavior(FlowController.LimitExceededBehavior.Block)        .setMaxOutstandingElementCount((long) conf.basic.maxBatchSize * conf.maxThreads / conf.advanced.numSubscribers)        .build();  }
private InstantiatingGrpcChannelProvider getChannelProvider() {    return SubscriptionAdminSettings        .defaultGrpcTransportProviderBuilder()        .setMaxInboundMessageSize(MAX_INBOUND_MESSAGE_SIZE)        .setEndpoint(Strings.isNullOrEmpty(conf.advanced.customEndpoint) ? SubscriptionAdminSettings            .getDefaultEndpoint() : conf.advanced.customEndpoint)        .build();  }
public Field generateHiveTypeInfoFieldForMetadataRecord(HiveTypeInfo hiveTypeInfo) {    Map<String, Field> fields = new HashMap<>();    fields.put(HiveMetastoreUtil.TYPE, Field.create(hiveTypeInfo.getHiveType().name()));    fields.put(HiveMetastoreUtil.EXTRA_INFO, generateExtraInfoFieldForMetadataRecord(hiveTypeInfo));    fields.put(HiveMetastoreUtil.COMMENT, Field.create(Field.Type.STRING, hiveTypeInfo.getComment()));    return Field.create(fields);  }
@SuppressWarnings("unchecked")  public HiveTypeInfo generateHiveTypeInfoFromMetadataField(Field hiveTypeInfoField) throws StageException {    if (hiveTypeInfoField.getType() == Field.Type.MAP) {      Map<String, Field> fields = (Map<String, Field>) hiveTypeInfoField.getValue();      if (!fields.containsKey(HiveMetastoreUtil.TYPE)          || !fields.containsKey(HiveMetastoreUtil.EXTRA_INFO)) {        throw new StageException(Errors.HIVE_17, HiveMetastoreUtil.TYPE_INFO);      }      HiveType hiveType = HiveType.getHiveTypeFromString(fields.get(HiveMetastoreUtil.TYPE).getValueAsString());      String comment = "";      if(fields.containsKey(HiveMetastoreUtil.COMMENT)) {        comment = fields.get(HiveMetastoreUtil.COMMENT).getValueAsString();      }      return generateHiveTypeInfoFromMetadataField(hiveType, comment, fields.get(HiveMetastoreUtil.EXTRA_INFO));    } else {      throw new StageException(Errors.HIVE_17, HiveMetastoreUtil.TYPE_INFO);    }  }
public String generateColumnTypeDefinition(HiveTypeInfo hiveTypeInfo, String columnName) {    return String.format(      HiveMetastoreUtil.COLUMN_TYPE,      columnName,      hiveTypeInfo.toString(),      hiveTypeInfo.getComment()    );  }
public Object put(OffsetAndResult<Map.Entry> batch) {    if (consumerError != null) {      throw new RuntimeException(Utils.format("Consumer encountered error: {}", consumerError), consumerError);    }    if (producerError != null) {      throw new RuntimeException(Utils.format("Producer encountered error: {}", producerError), producerError);    }    try {      Object expectedOffset = "EMPTY_BATCH";      if (!batch.getResult().isEmpty()) {        expectedOffset = batch.getResult().get(batch.getResult().size() - 1).getKey(); // get the last one      }      while (!dataChannel.offer(batch, 10, TimeUnit.MILLISECONDS)) {        for (ControlChannel.Message controlMessage : controlChannel.getProducerMessages()) {          switch (controlMessage.getType()) {            case CONSUMER_ERROR:              Throwable throwable = (Throwable) controlMessage.getPayload();              consumerError = throwable;              throw new ConsumerRuntimeException(Utils.format("Consumer encountered error: {}", throwable), throwable);            default:              String msg = Utils.format("Illegal control message type: '{}'", controlMessage.getType());              throw new IllegalStateException(msg);          }        }      }      return expectedOffset;    } catch (Throwable throwable) {      controlChannel.producerComplete();      if (!(throwable instanceof ConsumerRuntimeException)) {        String msg = "Error caught in producer: " + throwable;        LOG.error(msg, throwable);        controlChannel.producerError(throwable);        if (producerError == null) {          producerError = throwable;        }      }      throw Throwables.propagate(throwable);    }  }
public Grok compileExpression(final String expression) {    throwErrorIfDictionaryIsNotReady();    final String digestedExpression = digestExpressionAux(expression);    logger.debug("Digested [" + expression + "] into [" + digestedExpression + "] before compilation");    return new Grok(Pattern.compile(digestedExpression));  }
private String digestExpressionAux(String originalExpression) {    final String PATTERN_START = "%{";    final String PATTERN_STOP = "}";    final char PATTERN_DELIMITER = ':';    while(true) {      int PATTERN_START_INDEX = originalExpression.indexOf(PATTERN_START);      int PATTERN_STOP_INDEX = originalExpression.indexOf(PATTERN_STOP, PATTERN_START_INDEX + PATTERN_START.length());      // End the loop is %{ or } is not in the current line      if (PATTERN_START_INDEX < 0 || PATTERN_STOP_INDEX < 0) {        break;      }      // Grab what's inside %{ }      String grokPattern = originalExpression.substring(PATTERN_START_INDEX + PATTERN_START.length(), PATTERN_STOP_INDEX);      // Where is the : character      int PATTERN_DELIMITER_INDEX = grokPattern.indexOf(PATTERN_DELIMITER);      String regexName = grokPattern;      String groupName = null;      if (PATTERN_DELIMITER_INDEX >= 0) {        regexName = grokPattern.substring(0, PATTERN_DELIMITER_INDEX);        groupName = grokPattern.substring(PATTERN_DELIMITER_INDEX + 1, grokPattern.length());      }      final String dictionaryValue = regexDictionary.get(regexName);      if (dictionaryValue == null) {        throw new GrokCompilationException("Missing value for regex name : " + regexName);      }      // Defer till next iteration      if (dictionaryValue.contains(PATTERN_START)) {        break;      }      String replacement = dictionaryValue;      // Named capture group      if (null != groupName) {        replacement = "(?<" + groupName + ">" + dictionaryValue + ")";      }      originalExpression = new StringBuilder(originalExpression).replace(PATTERN_START_INDEX, PATTERN_STOP_INDEX + PATTERN_STOP.length(), replacement).toString();    }    return originalExpression;  }
public void addDictionary(final InputStream inputStream) {    try {      addDictionaryAux(new InputStreamReader(inputStream, "UTF-8"));    } catch (IOException e) {      throw new GrokCompilationException(e);    }  }
public void addDictionary(Reader reader) {    try {      addDictionaryAux(reader);    } catch (IOException e) {      throw new GrokCompilationException(e);    } finally {      IOUtils.closeQuietly(reader);    }  }
public Map<Aggregator, AggregatorData> stop() {    Utils.checkState(started, "Not started");    Utils.checkState(!stopped, "Already stopped");    stopped = true;    long currentTimeMillis = System.currentTimeMillis();    for(Map.Entry<Aggregator, AggregatorData> e : data.entrySet()) {      e.getValue().setTime(currentTimeMillis);    }    Map<Aggregator, AggregatorData> result = data;    result = aggregateDataWindows(result);    return result;  }
public Map<Aggregator, AggregatorData> roll(long newDataWindowEndTimeMillis) {    Utils.checkState(started, "Not started");    Utils.checkState(!stopped, "Already stopped");    Map<Aggregator, AggregatorData> result = data;    Map<Aggregator, AggregatorData> newData = new ConcurrentHashMap<>();    for (Aggregator aggregator : aggregators) {      newData.put(aggregator, aggregator.createAggregatorData(newDataWindowEndTimeMillis));    }    data = newData;    Map<Aggregator, AggregatorData> oldData = result;    // In case of sliding window, aggregate the data windows to get the result    result = aggregateDataWindows(result);    if (currentDataWindow != null) {      currentDataWindow.setDataAndClose(oldData);    }    DataWindow newDataWindow = createDataWindow(newDataWindowEndTimeMillis);    synchronized (dataWindowQueue) {      dataWindowQueue.add(newDataWindow);      dataWindowList = new ArrayList<>(dataWindowQueue);    }    currentDataWindow = newDataWindow;    return result;  }
public AggregatorData getData(Aggregator aggregator) {    Utils.checkState(started, "Not started");    Utils.checkState(!stopped, "Already stopped");    Utils.checkNotNull(aggregator, "aggregator");    Utils.checkArgument(        aggregators.contains(aggregator),        Utils.formatL("Aggregator {} is not registered to provider", aggregator)    );    return data.get(aggregator);  }
public String serialize(Object obj) throws ApiException {    try {      if (obj != null)        return mapper.writeValueAsString(obj);      else        return null;    } catch (Exception e) {      throw new ApiException(400, e.getMessage());    }  }
public <T> T deserialize(String body, TypeRef returnType) throws ApiException {    JavaType javaType = mapper.constructType(returnType.getType());    try {      return mapper.readValue(body, javaType);    } catch (IOException e) {      if (returnType.getType().equals(String.class))        return (T) body;      else        throw new ApiException(500, e.getMessage(), null, body);    }  }
public <T> T deserialize(File file, TypeRef returnType) throws ApiException {    JavaType javaType = mapper.constructType(returnType.getType());    try {      return mapper.readValue(file, javaType);    } catch (IOException e) {      throw new ApiException(500, e.getMessage(), null, "File to read file");    }  }
@Override  protected List<ConfigIssue> init() {    // Validate configuration values and open any required resources.    List<ConfigIssue> issues = super.init();    if (getConfig().equals("invalidValue")) {      issues.add(          getContext().createConfigIssue(              Groups.SAMPLE.name(), "config", Errors.SAMPLE_00, "Here's what's wrong..."          )      );    }    // If issues is not empty, the UI will inform the user of each configuration issue in the list.    return issues;  }
@Override  public void write(Batch batch) throws StageException {    Iterator<Record> batchIterator = batch.getRecords();    while (batchIterator.hasNext()) {      Record record = batchIterator.next();      try {        write(record);      } catch (Exception e) {        switch (getContext().getOnErrorRecord()) {          case DISCARD:            break;          case TO_ERROR:            getContext().toError(record, Errors.SAMPLE_01, e.toString());            break;          case STOP_PIPELINE:            throw new StageException(Errors.SAMPLE_01, e.toString());          default:            throw new IllegalStateException(                Utils.format("Unknown OnError value '{}'", getContext().getOnErrorRecord(), e)            );        }      }    }  }
private void write(Record record) throws OnRecordErrorException {    // This is a contrived example, normally you may be performing an operation that could throw    // an exception or produce an error condition. In that case you can throw an OnRecordErrorException    // to send this record to the error pipeline with some details.    if (!record.has("/someField")) {      throw new OnRecordErrorException(Errors.SAMPLE_01, record, "exception detail message.");    }    // TODO: write the records to your final destination  }
public static String resolveEL(ELEval elEval, ELVars variables, String val) throws ELEvalException {    return elEval.eval(variables, val, String.class);  }
@SuppressWarnings("unchecked")  private static <T> void extractInnerMapFromTheList(      Record metadataRecord,      String listFieldName,      String innerPairFirstFieldName,      String innerPairSecondFieldName,      boolean isSecondFieldHiveType,      LinkedHashMap<String, T> returnValMap,      HiveStageCheckedException exception  ) throws HiveStageCheckedException{    boolean throwException = false;    try {      if (metadataRecord.has(SEP + listFieldName)) {        Field columnField = metadataRecord.get(SEP + listFieldName);        List<Field> columnList = columnField.getValueAsList();        if (columnList != null) {          for (Field listElementField : columnList) {            if (listElementField.getType() != Field.Type.MAP && listElementField.getType() != Field.Type.LIST_MAP) {              throwException = true;              break;            }            LinkedHashMap<String, Field> innerPair = listElementField.getValueAsListMap();            String innerPairFirstField = innerPair.get(innerPairFirstFieldName).getValueAsString();            T retVal;            if (isSecondFieldHiveType) {              Field hiveTypeInfoField = innerPair.get(innerPairSecondFieldName);              HiveType hiveType = HiveType.getHiveTypeFromString(                  hiveTypeInfoField.getValueAsMap().get(HiveMetastoreUtil.TYPE).getValueAsString()              );              retVal = (T) (hiveType.getSupport().generateHiveTypeInfoFromMetadataField(hiveTypeInfoField));            } else {              retVal = (T) innerPair.get(innerPairSecondFieldName).getValueAsString();            }            returnValMap.put(innerPairFirstField, retVal);          }        }      } else {        // we allow partition to be empty for non-partitioned table        if (!listFieldName.equals(PARTITION_FIELD))          throwException = true;      }    } catch(Exception e) {      LOG.error("Can't parse metadata record", e);      throwException = true;      exception.initCause(e);    }    if (throwException) {      throw exception;    }  }
private static <T> Field generateInnerFieldFromTheList(      LinkedHashMap<String, T> original,      String innerPairFirstFieldName,      String innerPairSecondFieldName,      boolean isSecondFieldHiveType  ) throws HiveStageCheckedException {    List<Field> columnList = new LinkedList<>();    for(Map.Entry<String,T> pair:  original.entrySet()) {      LinkedHashMap<String, Field> entry = new LinkedHashMap<>();      entry.put(innerPairFirstFieldName, Field.create(pair.getKey()));      if (isSecondFieldHiveType){        HiveTypeInfo hiveTypeInfo = (HiveTypeInfo) pair.getValue();        entry.put(            innerPairSecondFieldName,            hiveTypeInfo.getHiveType().getSupport().generateHiveTypeInfoFieldForMetadataRecord(hiveTypeInfo)        );      } else {        entry.put(innerPairSecondFieldName, Field.create(pair.getValue().toString())); //stored value is "INT". need to fix this      }      columnList.add(Field.createListMap(entry));    }    return !columnList.isEmpty() ? Field.create(columnList) : null;  }
public static String getQualifiedTableName(String dbName, String tableName) {    return (dbName == null || dbName.isEmpty())?        escapeHiveObjectName(tableName) :        JOINER.join(escapeHiveObjectName(dbName), escapeHiveObjectName(tableName))        ;  }
public static LinkedHashMap<String, HiveTypeInfo> getColumnNameType(Record metadataRecord) throws HiveStageCheckedException {    LinkedHashMap<String, HiveTypeInfo> columnNameType = new LinkedHashMap<>();    extractInnerMapFromTheList(        metadataRecord,        COLUMNS_FIELD,        COLUMN_NAME,        TYPE_INFO,        true,        columnNameType,        new HiveStageCheckedException(Errors.HIVE_17, COLUMNS_FIELD, metadataRecord)    );    return columnNameType;  }
public static LinkedHashMap<String, HiveTypeInfo> getPartitionNameType(Record metadataRecord)      throws HiveStageCheckedException{    LinkedHashMap<String, HiveTypeInfo> partitionNameType = new LinkedHashMap<>();    extractInnerMapFromTheList(        metadataRecord,        PARTITION_FIELD,        PARTITION_NAME,        TYPE_INFO,        true,        partitionNameType,        new HiveStageCheckedException(Errors.HIVE_17, PARTITION_FIELD, metadataRecord)    );    return partitionNameType;  }
public static LinkedHashMap<String, String> getPartitionNameValue(Record metadataRecord) throws HiveStageCheckedException{    LinkedHashMap<String, String> partitionNameValue = new LinkedHashMap<>();    extractInnerMapFromTheList(        metadataRecord,        PARTITION_FIELD,        PARTITION_NAME,        PARTITION_VALUE,        false,        partitionNameValue,        new HiveStageCheckedException(Errors.HIVE_17, PARTITION_FIELD, metadataRecord)    );    return partitionNameValue;  }
public static boolean isSchemaChangeRecord(Record metadataRecord) {    return MetadataRecordType.TABLE.name().equals(metadataRecord.get(SEP + METADATA_RECORD_TYPE).getValueAsString());  }
public static void validateTblPropertiesInfo(      HMPDataFormat hmpDataFormat,      TBLPropertiesInfoCacheSupport.TBLPropertiesInfo tblPropertiesInfo,      String qualifiedTableName  ) throws HiveStageCheckedException {    if (hmpDataFormat == HMPDataFormat.AVRO && !tblPropertiesInfo.getSerdeLibrary().equals(HiveMetastoreUtil.AVRO_SERDE)) {      throw new HiveStageCheckedException(          Errors.HIVE_32,          qualifiedTableName,          tblPropertiesInfo.getSerdeLibrary(),          hmpDataFormat.getLabel()      );    } else if (hmpDataFormat == HMPDataFormat.PARQUET && !tblPropertiesInfo.getSerdeLibrary().equals(HiveMetastoreUtil.PARQUET_SERDE)) {      throw new HiveStageCheckedException(          Errors.HIVE_32,          qualifiedTableName,          tblPropertiesInfo.getSerdeLibrary(),          hmpDataFormat.getLabel()      );    }  }
public static String getTableName(Record metadataRecord) throws HiveStageCheckedException {    if (metadataRecord.has(SEP + TABLE_FIELD)) {      return metadataRecord.get(SEP + TABLE_FIELD).getValueAsString();    }    throw new HiveStageCheckedException(Errors.HIVE_17, TABLE_FIELD, metadataRecord);  }
public static String getDatabaseName(Record metadataRecord) throws HiveStageCheckedException {    if (metadataRecord.has(SEP + DATABASE_FIELD)) {      String dbName = metadataRecord.get(SEP + DATABASE_FIELD).getValueAsString();      return dbName.isEmpty()? DEFAULT_DBNAME : dbName;    }    throw new HiveStageCheckedException(Errors.HIVE_17, DATABASE_FIELD, metadataRecord);  }
public static boolean getInternalField(Record metadataRecord) throws HiveStageCheckedException{    if (metadataRecord.has(SEP + INTERNAL_FIELD)) {      return metadataRecord.get(SEP + INTERNAL_FIELD).getValueAsBoolean();    }    throw new HiveStageCheckedException(Errors.HIVE_17, INTERNAL_FIELD, metadataRecord);  }
public static String getLocation(Record metadataRecord) throws HiveStageCheckedException{    if (metadataRecord.has(SEP + LOCATION_FIELD)) {      return metadataRecord.get(SEP + LOCATION_FIELD).getValueAsString();    }    throw new HiveStageCheckedException(Errors.HIVE_17, LOCATION_FIELD, metadataRecord);  }
public static boolean getCustomLocation(Record metadataRecord) throws HiveStageCheckedException{    if (metadataRecord.get(SEP + VERSION).getValueAsInteger() < 3) {      return DEFAULT_CUSTOM_LOCATION;    }    if (metadataRecord.has(SEP + CUSTOM_LOCATION)) {      return metadataRecord.get(SEP + CUSTOM_LOCATION).getValueAsBoolean();    }    throw new HiveStageCheckedException(Errors.HIVE_17, CUSTOM_LOCATION, metadataRecord);  }
public static String getAvroSchema(Record metadataRecord) throws HiveStageCheckedException{    if (metadataRecord.has(SEP + AVRO_SCHEMA)) {      return metadataRecord.get(SEP + AVRO_SCHEMA).getValueAsString();    }    throw new HiveStageCheckedException(Errors.HIVE_17, AVRO_SCHEMA, metadataRecord);  }
public static String getDataFormat(Record metadataRecord) throws HiveStageCheckedException {    if (metadataRecord.get(SEP + VERSION).getValueAsInteger() == 1) {      return DEFAULT_DATA_FORMAT;    }    if (metadataRecord.has(SEP + DATA_FORMAT)) {      return metadataRecord.get(SEP + DATA_FORMAT).getValueAsString();    }    throw new HiveStageCheckedException(Errors.HIVE_17, DATA_FORMAT, metadataRecord);  }
public static Field newPartitionMetadataFieldBuilder(      String database,      String tableName,      LinkedHashMap<String, String> partitionList,      String location,      boolean customLocation,      HMPDataFormat dataFormat) throws HiveStageCheckedException {    LinkedHashMap<String, Field> metadata = new LinkedHashMap<>();    metadata.put(VERSION, Field.create(PARTITION_ADDITION_METADATA_RECORD_VERSION));    metadata.put(METADATA_RECORD_TYPE, Field.create(MetadataRecordType.PARTITION.name()));    metadata.put(DATABASE_FIELD, Field.create(database));    metadata.put(TABLE_FIELD, Field.create(tableName));    metadata.put(LOCATION_FIELD, Field.create(location));    metadata.put(CUSTOM_LOCATION, Field.create(customLocation));    metadata.put(DATA_FORMAT, Field.create(dataFormat.name()));    //fill in the partition list here    metadata.put(        PARTITION_FIELD,        generateInnerFieldFromTheList(            partitionList,            PARTITION_NAME,            PARTITION_VALUE,            false        )    );    return Field.createListMap(metadata);  }
public static Field newSchemaMetadataFieldBuilder  (      String database,      String tableName,      LinkedHashMap<String, HiveTypeInfo> columnList,      LinkedHashMap<String, HiveTypeInfo> partitionTypeList,      boolean internal,      String location,      String avroSchema,      HMPDataFormat dataFormat  ) throws HiveStageCheckedException  {    LinkedHashMap<String, Field> metadata = new LinkedHashMap<>();    metadata.put(VERSION, Field.create(SCHEMA_CHANGE_METADATA_RECORD_VERSION));    metadata.put(METADATA_RECORD_TYPE, Field.create(MetadataRecordType.TABLE.name()));    metadata.put(DATABASE_FIELD, Field.create(database));    metadata.put(TABLE_FIELD, Field.create(tableName));    metadata.put(LOCATION_FIELD, Field.create(location));    metadata.put(DATA_FORMAT, Field.create(dataFormat.name()));    //fill in column type list here    metadata.put(        COLUMNS_FIELD,        generateInnerFieldFromTheList(            columnList,            COLUMN_NAME,            TYPE_INFO,            true        )    );    //fill in partition type list here    if (partitionTypeList != null && !partitionTypeList.isEmpty()) {      metadata.put(          PARTITION_FIELD,          generateInnerFieldFromTheList(              partitionTypeList,              PARTITION_NAME,              TYPE_INFO,              true          )      );    }    metadata.put(INTERNAL_FIELD, Field.create(internal));    metadata.put(AVRO_SCHEMA, Field.create(avroSchema));    return Field.createListMap(metadata);  }
private static int resolveScaleOrPrecisionExpression(      String type,      ELEval elEval,      ELVars variables,      String defaultScaleEL,      String fieldPath  ) throws ELEvalException, HiveStageCheckedException {    // By default we take the constant given to this method    String value = defaultScaleEL;    // And if so evaluate it    if (elEval != null) {      value = elEval.eval(          variables,          defaultScaleEL,          String.class      );    }    // Finally try to parse output as an integer. Failure means that we are unable to calculate proper scale/precision.    try {      return Integer.parseInt(value);    } catch(NumberFormatException e) {      throw new HiveStageCheckedException(Errors.HIVE_29, type, fieldPath, defaultScaleEL, value, e);    }  }
public static LinkedHashMap<String, HiveTypeInfo> convertRecordToHMSType(      Record record,      ELEval scaleEL,      ELEval precisionEL,      ELEval commentEL,      String scaleExpression,      String precisionExpression,      String commentExpression,      ELVars variables  ) throws HiveStageCheckedException, ELEvalException {    if(!record.get().getType().isOneOf(Field.Type.MAP, Field.Type.LIST_MAP)) {      throw new HiveStageCheckedException(Errors.HIVE_33, record.getHeader().getSourceId(), record.get().getType().toString());    }    LinkedHashMap<String, HiveTypeInfo> columns = new LinkedHashMap<>();    Map<String, Field> list = record.get().getValueAsMap();    for(Map.Entry<String,Field> pair:  list.entrySet()) {      if (StringUtils.isEmpty(pair.getKey())) {        throw new HiveStageCheckedException(Errors.HIVE_01, "Field name is empty");      }      Field currField = pair.getValue();      switch(currField.getType()) {        case SHORT:          currField = Field.create(Field.Type.INTEGER, currField.getValue());          break;        case CHAR:          currField = Field.create(currField.getValueAsString());          break;        case DATETIME:          currField = Field.create(Field.Type.STRING, currField.getValue() == null ? null : datetimeFormat.get().format(currField.getValueAsDate()));          break;        case TIME:          currField = Field.create(Field.Type.STRING, currField.getValue() == null ? null : timeFormat.get().format(currField.getValueAsTime()));          break;        default:          break;      }      // Set current field in the context - used by subsequent ELs (decimal resolution, comments, ...)      FieldPathEL.setFieldInContext(variables, pair.getKey());      String comment = commentEL.eval(variables, commentExpression, String.class);      if(!COMMENT_PATTERN.matcher(comment).matches()) {        throw new HiveStageCheckedException(com.streamsets.pipeline.stage.processor.hive.Errors.HIVE_METADATA_11, pair.getKey(), comment);      }      // Update the Field type and value in Record      pair.setValue(currField);      HiveType hiveType = HiveType.getHiveTypeforFieldType(currField.getType());      HiveTypeInfo hiveTypeInfo;      // Some types requires special checks or alterations      if (hiveType == HiveType.DECIMAL) {        int precision = resolveScaleOrPrecisionExpression("precision", precisionEL, variables, precisionExpression, pair.getKey());        int scale = resolveScaleOrPrecisionExpression("scale", scaleEL, variables, scaleExpression, pair.getKey());        validateScaleAndPrecision(pair.getKey(), currField, precision, scale);        hiveTypeInfo = hiveType.getSupport().generateHiveTypeInfoFromRecordField(currField, comment, precision, scale);        // We need to make sure that all java objects have the same scale        if(currField.getValue() != null) {          pair.setValue(Field.create(currField.getValueAsDecimal().setScale(scale)));        }      } else {        hiveTypeInfo = hiveType.getSupport().generateHiveTypeInfoFromRecordField(currField, comment);      }      columns.put(pair.getKey().toLowerCase(), hiveTypeInfo);    }    return columns;  }
public static String generateAvroSchema(Map<String, HiveTypeInfo> typeInfo, String qualifiedName)      throws HiveStageCheckedException {    Utils.checkNotNull(typeInfo, "Error TypeInfo cannot be null");    // Avro doesn't allow "`" in names, so we're dropping those from qualified name    AvroHiveSchemaGenerator gen = new AvroHiveSchemaGenerator(qualifiedName.replace("`", ""));    try {      return gen.inferSchema(typeInfo);    } catch (StageException e) {      //So that any error to generate avro schema will result in onRecordErrorException and routed to error lane.      throw new HiveStageCheckedException(e.getErrorCode(), e.getParams());    }  }
public static void validatePartitionInformation(      TypeInfoCacheSupport.TypeInfo typeInfo,      LinkedHashMap<String, String> partitionValMap,      String qualifiedTableName  ) throws HiveStageCheckedException {    Set<String> partitionNamesInHive = typeInfo.getPartitionTypeInfo().keySet();    Set<String> partitionNames = partitionValMap.keySet();    if (!(partitionNamesInHive.size() == partitionNames.size()        && partitionNamesInHive.containsAll(partitionNames))) {      LOG.error(Utils.format(          "Partition mismatch. In Hive: {}, In Record : {}",          partitionNamesInHive.size(),          partitionNames.size())      );      throw new HiveStageCheckedException(Errors.HIVE_27, qualifiedTableName);    }  }
public static String generatePartitionPath(LinkedHashMap<String, String> partitions) {    StringBuilder builder = new StringBuilder();    for(Map.Entry<String, String> pair:  partitions.entrySet()) {      builder.append(String.format(PARTITION_PATH, pair.getKey(), pair.getValue()));    }    return builder.toString();  }
public static String serializeSchemaToHDFS(      UserGroupInformation loginUGI,      final FileSystem fs,      final String location,      final String schemaFolder,      final String databaseName,      final String tableName,      final String schemaJson  ) throws StageException {    String folderLocation;    if (schemaFolder.startsWith(SEP)) {      folderLocation = schemaFolder;    } else {      folderLocation = location + SEP + schemaFolder;    }    final Path schemasFolderPath = new Path(folderLocation);    final String path =  folderLocation + SEP + String.format(        AVRO_SCHEMA_FILE_FORMAT,        databaseName,        tableName,        UUID.randomUUID().toString()    );    try {      loginUGI.doAs(new PrivilegedExceptionAction<Void>() {        @Override        public Void run() throws Exception{          if (!fs.exists(schemasFolderPath)) {            fs.mkdirs(schemasFolderPath);          }          Path schemaFilePath = new Path(path);          //This will never happen unless two HMS targets are writing, we will error out for this          //and let user handle this via error record handling.          if (!fs.exists(schemaFilePath)) {            try (FSDataOutputStream os = fs.create(schemaFilePath)) {              byte []schemaBytes = schemaJson.getBytes("UTF-8");              os.write(schemaBytes, 0, schemaBytes.length);            }          } else {            LOG.error(Utils.format("Already schema file {} exists in HDFS", path));            throw new IOException("Already schema file exists");          }          return null;        }      });    } catch (Exception e) {      LOG.error("Error in Writing Schema to HDFS: " + e.toString(), e);      throw new StageException(Errors.HIVE_18, path, e.getMessage());    }    return path;  }
@SuppressWarnings("unchecked")  public static <T extends HMSCacheSupport.HMSCacheInfo> T getCacheInfo(      HMSCache hmsCache,      HMSCacheType cacheType,      String qualifiedName,      HiveQueryExecutor queryExecutor  ) throws StageException {    HMSCacheSupport.HMSCacheInfo cacheInfo = hmsCache.getIfPresent(cacheType, qualifiedName);    if (cacheType != HMSCacheType.AVRO_SCHEMA_INFO && cacheInfo == null) {      // Try loading by executing HMS query      cacheInfo = hmsCache.getOrLoad(cacheType, qualifiedName, queryExecutor);    }    return (T)cacheInfo;  }
@VisibleForTesting  @SuppressWarnings("unchecked")  int setParameters(      int opCode,      SortedMap<String, String> columnsToParameters,      final Record record,      final Connection connection,      PreparedStatement statement  ) throws OnRecordErrorException {    int paramIdx = 1;    // Set columns and their value in query. No need to perform this for delete operation.    if(opCode != OperationType.DELETE_CODE) {      paramIdx = setParamsToStatement(paramIdx, statement, columnsToParameters, record, connection, opCode);    }    // Set primary keys in WHERE clause for update and delete operations    if(opCode != OperationType.INSERT_CODE){      paramIdx = setPrimaryKeys(paramIdx, record, statement, opCode);    }    return paramIdx;  }
private void handleBatchUpdateException(      Collection<Record> failedRecords, SQLException e, List<OnRecordErrorException> errorRecords  ) throws StageException {    if (jdbcUtil.isDataError(getCustomDataSqlStateCodes(), getConnectionString(), e)) {      String formattedError = JdbcErrors.JDBC_79.getMessage();      LOG.error(formattedError);      LOG.debug(formattedError, e);      if (!getRollbackOnError() && e instanceof BatchUpdateException &&          ((BatchUpdateException) e).getUpdateCounts().length > 0) {        BatchUpdateException bue = (BatchUpdateException) e;        int i = 0;        for (Record record : failedRecords) {          if (i >= bue.getUpdateCounts().length || bue.getUpdateCounts()[i] == PreparedStatement.EXECUTE_FAILED) {            errorRecords.add(new OnRecordErrorException(                record,                JDBC_14,                e.getSQLState(),                e.getErrorCode(),                e.getMessage(),                jdbcUtil.formatSqlException(e),                e            ));          }          i++;        }      } else {        for (Record record : failedRecords) {          errorRecords.add(new OnRecordErrorException(              record,              JDBC_14,              e.getSQLState(),              e.getErrorCode(),              e.getMessage(),              jdbcUtil.formatSqlException(e),              e          ));        }      }    } else {      handleSqlException(e);    }  }
public Map<String, Object> getConfiguration () throws ApiException {    Object postBody = null;    byte[] postBinaryBody = null;    // create path and map variables    String path = "/v1/system/configuration".replaceAll("\\{format\\}","json");    // query params    List<Pair> queryParams = new ArrayList<Pair>();    Map<String, String> headerParams = new HashMap<String, String>();    Map<String, Object> formParams = new HashMap<String, Object>();    final String[] accepts = {      "application/json"    };    final String accept = apiClient.selectHeaderAccept(accepts);    final String[] contentTypes = {    };    final String contentType = apiClient.selectHeaderContentType(contentTypes);    String[] authNames = new String[] { "basic" };    TypeRef returnType = new TypeRef<Map<String, Object>>() {};    return apiClient.invokeAPI(path, "GET", queryParams, postBody, postBinaryBody, headerParams, formParams, accept,        contentType, authNames, returnType);  }
@SuppressWarnings("unchecked")  private LoadingCache<TableRuntimeContext, TableReadContext> buildReadContextCache(CacheLoader<TableRuntimeContext, TableReadContext> tableCacheLoader) {    CacheBuilder resultSetCacheBuilder = CacheBuilder.newBuilder()        .removalListener(new JdbcTableReadContextInvalidationListener());    if (tableJdbcConfigBean.batchTableStrategy == BatchTableStrategy.SWITCH_TABLES) {      if (tableJdbcConfigBean.resultCacheSize > 0) {        resultSetCacheBuilder = resultSetCacheBuilder.maximumSize(tableJdbcConfigBean.resultCacheSize);      }    } else {      resultSetCacheBuilder = resultSetCacheBuilder.maximumSize(1);    }    if (tableCacheLoader != null) {      return resultSetCacheBuilder.build(tableCacheLoader);    } else {      return resultSetCacheBuilder.build(new JdbcTableReadContextLoader(          connectionManager,          offsets,          tableJdbcConfigBean.fetchSize,          tableJdbcConfigBean.quoteChar.getQuoteCharacter(),          tableJdbcELEvalContext,          isReconnect      ));    }  }
private void initGaugeIfNeeded() {    gaugeMap.put(THREAD_NAME, Thread.currentThread().getName());    gaugeMap.put(STATUS, "");    gaugeMap.put(TABLES_OWNED_COUNT, tableReadContextCache.size());    gaugeMap.put(CURRENT_TABLE, "");  }
private void generateBatchAndCommitOffset(BatchContext batchContext) {    int recordCount = 0;    int eventCount = 0;    try {        while (tableRuntimeContext == null) {          tableRuntimeContext = tableProvider.nextTable(threadNumber);          if (tableRuntimeContext == null) {            // small sleep before trying to acquire a table again, to potentially allow a new partition to be            // returned to shared queue or created            final boolean uninterrupted = ThreadUtil.sleep(ACQUIRE_TABLE_SLEEP_INTERVAL);            if (!uninterrupted) {              LOG.trace("Interrupted which trying to acquire table");            }            if (!uninterrupted || tableRuntimeContext == null) {              return;            }          }        }        updateGauge(JdbcBaseRunnable.Status.QUERYING_TABLE);        tableReadContext = getOrLoadTableReadContext();        ResultSet rs = tableReadContext.getResultSet();        boolean resultSetEndReached = false;        try {          updateGauge(JdbcBaseRunnable.Status.GENERATING_BATCH);          while (recordCount < batchSize) {            if (rs.isClosed() || !rs.next()) {              if (rs.isClosed()) {                LOG.trace("ResultSet is closed");              }              resultSetEndReached = true;              break;            }            createAndAddRecord(rs, tableRuntimeContext, batchContext);            recordCount++;          }          LOG.trace("{} records generated", recordCount);          if (commonSourceConfigBean.enableSchemaChanges) {            generateSchemaChanges(batchContext);          }          tableRuntimeContext.setResultSetProduced(true);          //Reset numSqlErrors if we are able to read result set and add records to the batch context.          numSQLErrors = 0;          firstSqlException = null;          //If exception happened we do not report anything about no more data event          //We report noMoreData if either evictTableReadContext is true (result set no more rows) / record count is 0.          final AtomicBoolean tableFinished = new AtomicBoolean(false);          final AtomicBoolean schemaFinished = new AtomicBoolean(false);          final List<String> schemaFinishedTables = new LinkedList<>();          tableProvider.reportDataOrNoMoreData(              tableRuntimeContext,              recordCount,              batchSize,              resultSetEndReached,              tableFinished,              schemaFinished,              schemaFinishedTables          );          if (tableFinished.get()) {            TableJdbcEvents.createTableFinishedEvent(context, batchContext, tableRuntimeContext);            eventCount++;          }          if (schemaFinished.get()) {            TableJdbcEvents.createSchemaFinishedEvent(context, batchContext, tableRuntimeContext, schemaFinishedTables);            eventCount++;          }        } finally {          if (resultSetEndReached) {            tableReadContext.closeResultSet();          }          handlePostBatchAsNeeded(resultSetEndReached, recordCount, eventCount, batchContext);        }      } catch (SQLException | ExecutionException | StageException | InterruptedException e) {        LOG.error("Error happened", e);        //invalidate if the connection is closed        tableReadContextCache.invalidateAll();        connectionManager.closeConnection();        //If we have executed post batch that had errored out        if (tableRuntimeContext != null) {          final TableContext table = tableRuntimeContext.getSourceTableContext();          //if the currently acquired tableContext is no longer a valid candidate, try re-fetch the table from table provider          if (commonSourceConfigBean.allowLateTable && !tableProvider.getActiveRuntimeContexts().containsKey(table)) {            tableRuntimeContext = null;          }        }        Throwable th = (e instanceof ExecutionException)? e.getCause() : e;        if (th instanceof SQLException) {          handleSqlException((SQLException)th);        } else if (e instanceof InterruptedException) {          LOG.error("Thread {} interrupted", gaugeMap.get(THREAD_NAME));        } else {          handleStageError(JdbcErrors.JDBC_67, e);        }      }    }
protected void handlePostBatchAsNeeded(      boolean resultSetEndReached,      int recordCount,      int eventCount,      BatchContext batchContext  ) {    AtomicBoolean shouldEvict = new AtomicBoolean(resultSetEndReached);    // If we read at least one record, it's safe to drop the starting offsets, otherwise they have to re-used    if(recordCount > 0) {      tableRuntimeContext.getSourceTableContext().clearStartOffset();    }    //Only process batch if there are records or events    if (recordCount > 0 || eventCount > 0) {      TableReadContext tableReadContext = tableReadContextCache.getIfPresent(tableRuntimeContext);      Optional.ofNullable(tableReadContext)          .ifPresent(readContext -> {            readContext.addProcessingMetrics(1, recordCount);            LOG.debug(                "Table {} read batches={} and records={}",                tableRuntimeContext.getQualifiedName(),                readContext.getNumberOfBatches(),                readContext.getNumberOfRecords()            );            calculateEvictTableFlag(shouldEvict, tableReadContext);          });      updateGauge(JdbcBaseRunnable.Status.BATCH_GENERATED);      //Process And Commit offsets      if (tableRuntimeContext.isUsingNonIncrementalLoad()) {        // process the batch now, will handle the offset commit outside this block        context.processBatch(batchContext);      } else {        // for incremental (normal) mode, the offset was already stored in this map        // by the specific subclass's createAndAddRecord method        final String offsetValue = offsets.get(tableRuntimeContext.getOffsetKey());        context.processBatch(batchContext, tableRuntimeContext.getOffsetKey(), offsetValue);      }    }    if (tableRuntimeContext.isUsingNonIncrementalLoad()) {      // for non-incremental mode, the offset is simply a singleton map indicating whether it's finished      final String offsetValue = createNonIncrementalLoadOffsetValue(resultSetEndReached);      context.commitOffset(tableRuntimeContext.getOffsetKey(), offsetValue);    }    //Make sure we close the result set only when there are no more rows in the result set    if (shouldEvict.get()) {      //Invalidate so as to fetch a new result set      //We close the result set/statement in Removal Listener      tableReadContextCache.invalidate(tableRuntimeContext);      tableProvider.releaseOwnedTable(tableRuntimeContext, threadNumber);      tableRuntimeContext = null;    } else if (        tableJdbcConfigBean.batchTableStrategy == BatchTableStrategy.SWITCH_TABLES            && !tableRuntimeContext.isUsingNonIncrementalLoad()) {      tableRuntimeContext = null;    }    final List<TableRuntimeContext> removedPartitions = tableProvider.getAndClearRemovedPartitions();    if (removedPartitions != null && removedPartitions.size() > 0) {      for (TableRuntimeContext partition : removedPartitions) {        LOG.debug(            "Removing offset entry for partition {} since it has been removed from the table provider",            partition.getDescription()        );        context.commitOffset(partition.getOffsetKey(), null);      }    }  }
private static void initTableEvalContextForProduce(      TableJdbcELEvalContext tableJdbcELEvalContext,      TableRuntimeContext tableContext,      Calendar calendar  ) {    tableJdbcELEvalContext.setCalendar(calendar);    tableJdbcELEvalContext.setTime(calendar.getTime());    tableJdbcELEvalContext.setTableContext(tableContext);  }
private void waitIfNeeded() throws InterruptedException {    if (queryRateLimiter != null) {      updateGauge(Status.WAITING_FOR_RATE_LIMIT_PERMIT);      double waitTime = queryRateLimiter.acquire();      updateGauge(Status.ACQUIRED_RATE_LIMIT_PERMIT);      gaugeMap.put(LAST_RATE_LIMIT_WAIT_TIME, waitTime);    } else {      LOG.debug("No query rate limiter in effect; not waiting");    }  }
private TableReadContext getOrLoadTableReadContext() throws ExecutionException, InterruptedException {    initTableEvalContextForProduce(        tableJdbcELEvalContext, tableRuntimeContext,        Calendar.getInstance(TimeZone.getTimeZone(ZoneId.of(tableJdbcConfigBean.timeZoneID)))    );    //Check and then if we want to wait for query being issued do that    TableReadContext tableReadContext = tableReadContextCache.getIfPresent(tableRuntimeContext);    LOG.trace("Selected table : '{}' for generating records", tableRuntimeContext.getDescription());    if (tableReadContext == null) {      //Wait before issuing query (Optimization instead of waiting during each batch)      waitIfNeeded();      //Set time before query      initTableEvalContextForProduce(          tableJdbcELEvalContext, tableRuntimeContext,          Calendar.getInstance(TimeZone.getTimeZone(ZoneId.of(tableJdbcConfigBean.timeZoneID)))      );      tableReadContext = tableReadContextCache.get(tableRuntimeContext);      //Record query time      lastQueryIntervalTime = System.currentTimeMillis();    }    return tableReadContext;  }
@Override  public void setOffsets(Map<String, String> offsets) throws IOException{    Utils.checkNotNull(offsets, "offsets");    // retrieve file:offset for each directory    for (FileContext fileContext : fileContexts) {      String offset = offsets.get(fileContext.getMultiFileInfo().getFileKey());      LiveFile file = null;      long fileOffset = 0;      if (offset != null && !offset.isEmpty()) {        file = FileContextProviderUtil.getRefreshedLiveFileFromFileOffset(offset);        fileOffset = FileContextProviderUtil.getLongOffsetFromFileOffset(offset);      }      fileContext.setStartingCurrentFileName(file);      fileContext.setStartingOffset(fileOffset);      if (LOG.isTraceEnabled()) {        LOG.trace("Setting offset: directory '{}', file '{}', offset '{}'",            fileContext.getMultiFileInfo().getFileFullPath(), file, fileOffset);      }    }    currentIdx = startingIdx;  }
public static long parseRfc5424Date(LoadingCache<String, Long> cache, String tsStr) throws OnRecordErrorException {    boolean includesTimezone = true;    long ts;    int curPos = 0;    int msgLen = tsStr.length();    if (msgLen <= RFC5424_PREFIX_LEN) {      throw new OnRecordErrorException(Errors.SYSLOG_09, tsStr);    }    String timestampPrefix = tsStr.substring(curPos, RFC5424_PREFIX_LEN);    try {      ts = cache.get(timestampPrefix);    } catch (ExecutionException ex) {      Throwable cause = Throwables.getRootCause(ex);      if (cause instanceof IllegalArgumentException) {        throw new OnRecordErrorException(Errors.SYSLOG_05, cause, timestampPrefix, cause);      } else {        // I don't believe this will ever occur        throw new IllegalStateException(            Utils.format(Errors.SYSLOG_05.getMessage(), cause, timestampPrefix),            cause);      }    }    curPos += RFC5424_PREFIX_LEN;    // look for the optional fractional seconds    if (tsStr.charAt(curPos) == '.') {      // figure out how many numeric digits      boolean foundEnd = false;      int endMillisPos = curPos + 1;      if (msgLen <= endMillisPos) {        throw new OnRecordErrorException(Errors.SYSLOG_06, tsStr);      }      // FIXME: TODO: ensure we handle all bad formatting cases      while (!foundEnd && endMillisPos < msgLen) {        char curDigit = tsStr.charAt(endMillisPos);        if (curDigit >= '0' && curDigit <= '9') {          endMillisPos++;        } else {          foundEnd = true;        }      }      includesTimezone = foundEnd;      if (!includesTimezone) {        endMillisPos--;      }      // if they had a valid fractional second, append it rounded to millis      final int fractionalPositions = endMillisPos - (curPos + 1);      if (fractionalPositions > 0) {        long milliseconds = Long.parseLong(tsStr.substring(curPos + 1, endMillisPos));        if (fractionalPositions > 3) {          milliseconds /= Math.pow(10, (fractionalPositions - 3));        } else if (fractionalPositions < 3) {          milliseconds *= Math.pow(10, (3 - fractionalPositions));        }        ts += milliseconds;      } else {        throw new OnRecordErrorException(Errors.SYSLOG_07, tsStr);      }      curPos = endMillisPos;    }    // look for timezone    if (includesTimezone) {      char tzFirst = tsStr.charAt(curPos);      // UTC      if (tzFirst == 'Z') {        // no-op      } else if (tzFirst == '+' || tzFirst == '-') {        if (msgLen <= curPos + 5) {          throw new OnRecordErrorException(Errors.SYSLOG_08, tsStr);        }        int polarity;        if (tzFirst == '+') {          polarity = +1;        } else {          polarity = -1;        }        char[] h = new char[5];        for (int i = 0; i < 5; i++) {          h[i] = tsStr.charAt(curPos + 1 + i);        }        if (h[0] >= '0' && h[0] <= '9'            && h[1] >= '0' && h[1] <= '9'            && h[2] == ':'            && h[3] >= '0' && h[3] <= '9'            && h[4] >= '0' && h[4] <= '9') {          try {            int hourOffset = Integer.parseInt(tsStr.substring(curPos + 1, curPos + 3));            int minOffset = Integer.parseInt(tsStr.substring(curPos + 4, curPos + 6));            ts -= polarity * ((hourOffset * 60L) + minOffset) * 60000L;          } catch (NumberFormatException nfe) {            throw new OnRecordErrorException(Errors.SYSLOG_08, tsStr, nfe);          }        } else {          throw new OnRecordErrorException(Errors.SYSLOG_08, tsStr);        }      }    }    return ts;  }
public static long parseRfc3164Time(String ts) throws OnRecordErrorException {    LocalDateTime now = LocalDateTime.now();    int year = now.getYear();    ts = TWO_SPACES.matcher(ts).replaceFirst(" ");    LocalDateTime date;    try {      MonthDay monthDay = MonthDay.parse(ts, rfc3164Format);      LocalTime time = LocalTime.parse(ts, rfc3164Format);      // this is overly complicated because of the way Java 8 Time API works, as compared to Joda      // essentially, we just want to pull year out of "now" and set all other fields based on      // what was parsed      date = now;      // zero out millis since we aren't actually parsing those      date = date.with(ChronoField.MILLI_OF_SECOND, 0);      // set month and day of month from parsed      date = date.withMonth(monthDay.getMonthValue()).withDayOfMonth(monthDay.getDayOfMonth());      // set time fields from parsed      date = date.withHour(time.getHour()).withMinute(time.getMinute()).withSecond(time.getSecond());    } catch (DateTimeParseException e) {      throw new OnRecordErrorException(Errors.SYSLOG_10, ts, e);    }    // The RFC3164 is a bit weird date format - it contains day and month, but no year. So we have to somehow guess    // the year. The current logic is to provide a sliding window - going 11 months to the past and 1 month to the    // future. If the message is outside of this window, it will have incorrectly guessed year. We go 11 months to the    // past as we're expecting that more messages will be from the past (syslog usually contains historical data).    LocalDateTime fixed = date;    if (fixed.isAfter(now) && fixed.minusMonths(1).isAfter(now)) {      fixed = date.withYear(year - 1);    } else if (fixed.isBefore(now) && fixed.plusMonths(11).isBefore(now)) {      fixed = date.withYear(year + 1);    }    date = fixed;    return date.toInstant(ZoneOffset.UTC).toEpochMilli();  }
public static boolean sleep(long milliseconds) {    //checking if we got pre-interrupted.    boolean interrupted = Thread.interrupted();    if (!interrupted) {      try {        Thread.sleep(milliseconds);      } catch (InterruptedException ex) {        interrupted = true;        // clearing the interrupt flag        Thread.interrupted();      }    }    return !interrupted;  }
public static String format(String template, Object... args) {    String[] templateArr = TEMPLATES.get(template);    if (templateArr == null) {      // we may have a race condition here but the end result is idempotent      templateArr = prepareTemplate(template);      TEMPLATES.put(template, templateArr);    }    StringBuilder sb = new StringBuilder(template.length() * 2);    for (int i = 0; i < templateArr.length; i++) {      sb.append(templateArr[i]);      if (args != null && (i < templateArr.length - 1)) {        sb.append((i < args.length) ? args[i] : TOKEN);      }    }    return sb.toString();  }
@SuppressWarnings("unchecked")  public String serialize() {    Map map = new LinkedHashMap();    map.put("path", path.toString());    map.put("headHash", headHash);    map.put("headLen", headLen);    map.put("inode", iNode);    try {      JsonMapper objectMapper = DataCollectorServices.instance().get(JsonMapper.SERVICE_KEY);      return objectMapper.writeValueAsString(map);    } catch (Exception ex) {      throw new RuntimeException(Utils.format("Unexpected exception: {}", ex.toString()), ex);    }  }
public static LiveFile deserialize(String str) throws IOException {    Utils.checkNotNull(str, "str");    try {      JsonMapper objectMapper = DataCollectorServices.instance().get(JsonMapper.SERVICE_KEY);      Map map = objectMapper.readValue(str, Map.class);      Path path = Paths.get((String) map.get("path"));      String headHash = (map.containsKey("headHash")) ? (String) map.get("headHash") : "";      int headLen = (map.containsKey("headLen")) ? (int) map.get("headLen") : 0;      String inode = (String) map.get("inode");      return new LiveFile(path, inode, headHash, headLen);    } catch (RuntimeException|IOException ex) {      throw new IllegalArgumentException(Utils.format("Invalid LiveFile serialized string '{}': {}", str,                                                      ex.toString()), ex);    }  }
public LiveFile refresh() throws IOException {    LiveFile refresh = this;    boolean changed;    try {      BasicFileAttributes attrs = Files.readAttributes(path, BasicFileAttributes.class);      String iNodeCurrent = attrs.fileKey().toString();      int headLenCurrent = (int) Math.min(headLen, attrs.size());      String headHashCurrent = computeHash(path, headLenCurrent);      changed = !this.iNode.equals(iNodeCurrent) || !this.headHash.equals(headHashCurrent);    } catch (NoSuchFileException ex) {      changed = true;    }    if (changed) {      try (DirectoryStream<Path> directoryStream = Files.newDirectoryStream(path.getParent())) {        for (Path path : directoryStream) {          BasicFileAttributes attrs = Files.readAttributes(path, BasicFileAttributes.class);          String iNode = attrs.fileKey().toString();          int headLen = (int) Math.min(this.headLen, attrs.size());          String headHash = computeHash(path, headLen);          if (iNode.equals(this.iNode) && headHash.equals(this.headHash)) {            if (headLen == 0) {              headLen = (int) Math.min(HEAD_LEN, attrs.size());              headHash = computeHash(path, headLen);            }            refresh = new LiveFile(path, iNode, headHash, headLen);            break;          }        }      }    }    return refresh;  }
@Override  protected List<ConfigIssue> init() {    // Validate configuration values and open any required resources.    List<ConfigIssue> issues = super.init();    errorRecordHandler = new DefaultErrorRecordHandler(getContext());    Processor.Context context = getContext();    issues = hikariConfigBean.validateConfigs(context, issues);    if (hikariConfigBean.getConnectionString().toLowerCase().startsWith("jdbc:sqlserver") && useMultiRowOp) {      issues.add(getContext().createConfigIssue(Groups.JDBC.name(), MULTI_ROW_OP, JdbcErrors.JDBC_57));    }    if (dynamicTableName) {      tableNameVars = getContext().createELVars();      tableNameEval = context.createELEval(JdbcUtil.TABLE_NAME);      ELUtils.validateExpression(          tableNameTemplate,          getContext(),          Groups.JDBC.getLabel(),          JdbcUtil.TABLE_NAME,          JdbcErrors.JDBC_26,          issues      );    }    if (issues.isEmpty() && null == dataSource) {      try {        dataSource = jdbcUtil.createDataSourceForWrite(            hikariConfigBean, schema,            tableNameTemplate,            caseSensitive,            issues,            customMappings,            getContext()        );      } catch (RuntimeException | SQLException | StageException e) {        LOG.debug("Could not connect to data source", e);        issues.add(getContext().createConfigIssue(Groups.JDBC.name(), CONNECTION_STRING, JdbcErrors.JDBC_00, e.toString()));      }    }    // If issues is not empty, the UI will inform the user of each configuration issue in the list.    return issues;  }
@Override  public void process(Batch batch, SingleLaneBatchMaker batchMaker) throws StageException {    if (!batch.getRecords().hasNext()) {      // No records - take the opportunity to clean up the cache so that we don't hold on to memory indefinitely      cacheCleaner.periodicCleanUp();    }    boolean perRecord = false;    // MS SQL Server does not support returning generateKey after executeBatch    // Instead of executeBatch, do executeUpdate per record    if (hikariConfigBean.getConnectionString().toLowerCase().startsWith("jdbc:sqlserver")) {      perRecord = true;    }    if (dynamicTableName) {      jdbcUtil.write(          batch,          tableNameEval,          tableNameVars,          tableNameTemplate,          recordWriters,          errorRecordHandler,          perRecord      );    } else {      jdbcUtil.write(batch.getRecords(), tableNameTemplate, recordWriters, errorRecordHandler, perRecord);    }    Iterator<Record> it = batch.getRecords();    while (it.hasNext()) {      batchMaker.addRecord(it.next());    }  }
@Override  public String getFieldPath(String fieldPath, int operation) {    if (operation == OperationType.UPDATE_CODE) {    if (fieldPath.contains(ID_FIELD)){      // _id is stored in "/o2/column_name for update records. Need to change the fieldpath"      return fieldPath.replace(OP_FIELD, OP2_FIELD);    } else {      // column and values are stored in "/o/$set/column_name". Need to change the fieldpath      return fieldPath.replaceFirst(OP_FIELD, String.format("%s/%s", OP_FIELD, SET_FIELD));    }  }    return fieldPath;  }
@Override  public final BatchContext startBatch() {    return (BatchContext) AccessController.doPrivileged(new PrivilegedAction() {      public Object run() {        try {          Thread.currentThread().setContextClassLoader(mainClassLoader);          return pushSourceContextDelegate.startBatch();        } finally {          Thread.currentThread().setContextClassLoader(getDefinition().getStageClassLoader());        }      }    });  }
static HttpSourceOffset fromString(String s) {    LOG.debug("Parsing HttpSourceOffset from '{}'", s);    String[] parts = s.split("::");    if (parts.length < 8) {      throw new IllegalArgumentException("Offset must have at least 8 parts");    }    return new HttpSourceOffset(parts[1], parts[3], Long.parseLong(parts[5]), Integer.parseInt(parts[7]));  }
public void init(Stage.Context context, String prefix, List<Stage.ConfigIssue> issues) {    underlyingConfig = new TlsConfigBean();    underlyingConfig.tlsEnabled = true;    if (useMutualAuth) {      underlyingConfig.keyStorePassword = keyStorePassword;      underlyingConfig.keyStoreFilePath = keyStoreFilePath;      underlyingConfig.keyStoreAlgorithm = keyStoreAlgorithm;      underlyingConfig.keyStoreType = keyStoreType;      underlyingConfig.init(context, "TLS", prefix, issues);      LOG.debug("Initialized Mutual Authentication config with {} keystore file {}",          underlyingConfig.keyStoreType,          underlyingConfig.keyStoreFilePath      );    }  }
private boolean checkRecordContainsSolrFields(      Map<String, Field> recordFieldMap,      Record record,      List<String> solrFieldsMap,      Errors errorToThrow  ) throws StageException {    // for (Map.Entry<String, Field> recordFieldMapEntry : recordFieldMap.entrySet())    List<String> fieldsFound = new ArrayList<>();    recordFieldMap.keySet().forEach(recordFieldKey -> {      if (solrFieldsMap.contains(recordFieldKey)) {        fieldsFound.add(recordFieldKey);      }    });    // if record does not contain solr fields then process error accordingly    if (solrFieldsMap.size() != fieldsFound.size()) {      Set<String> missingFields = new HashSet<>();      solrFieldsMap.forEach(requiredField -> {        if (!fieldsFound.contains(requiredField)) {          missingFields.add(requiredField);        }      });      handleError(record, errorToThrow, Joiner.on(",").join(missingFields));      return false;    }    return true;  }
private List<String> filterAutogeneratedFieldNames(List<String> fieldNames) {    List<String> result = new ArrayList<>();    fieldNames.forEach(name -> {      if (!autogeneratedFieldNamesMap.contains(name)) {        result.add(name);      }    });    return result;  }
private List<String> checkMissingFields(List<SolrFieldMappingConfig> mappings, List<String> solrFields) {    List<String> missingFields = new ArrayList<>(solrFields);    for (SolrFieldMappingConfig map : mappings) {      missingFields.remove(map.solrFieldName);    }    return missingFields;  }
private void handleError(Record record, Errors errorTemplate, String errorMessage) throws StageException {    handleError(record, errorTemplate, new String[] {errorMessage});  }
private void handleError(Record record, Errors errorTemplate, String ... errorArguments) throws StageException {    switch (missingFieldAction) {      case DISCARD:        LOG.debug(errorTemplate.getMessage(), errorArguments);        break;      case STOP_PIPELINE:        throw new StageException(errorTemplate, errorArguments);      case TO_ERROR:        throw new OnRecordErrorException(record, errorTemplate, errorArguments);      default: //unknown operation        LOG.debug("Sending record to error due to unknown operation {}", missingFieldAction);        throw new OnRecordErrorException(record, errorTemplate, errorArguments);    }  }
private void sendOnRecordErrorExceptionToHandler(Record record, Errors error, StageException ex)      throws StageException {    errorRecordHandler.onError(new OnRecordErrorException(        record,        error,        record.getHeader().getSourceId(),        ex.toString(),        ex    ));  }
public static Optional<Dependency> parseJarName(String sourceName, String jarName) {    if(SPECIAL_CASES.containsKey(jarName)) {      Dependency specialCase = SPECIAL_CASES.get(jarName);      return Optional.of(new Dependency(sourceName, specialCase.getName(), specialCase.getVersion()));    }    // Go over all known patterns    for(Pattern p : PATTERNS) {      Matcher m = p.matcher(jarName);      if (m.matches()) {        LOG.trace("Applied pattern '{}' to {}", p.pattern(), jarName);        return Optional.of(new Dependency(sourceName, m.group(1), m.group(2)));      }    }    // Otherwise this jar name is unknown to us    return Optional.empty();  }
public static Optional<Dependency> parseURL(URL url) {    return parseJarName(url.toString(), Paths.get(url.getPath()).getFileName().toString());  }
public static synchronized CouchbaseConnector getInstance(BaseCouchbaseConfig config, List<Stage.ConfigIssue> issues, Stage.Context context) {    Map<String, Object> runnerSharedMap = context.getStageRunnerSharedMap();    if(runnerSharedMap.containsKey(INSTANCE)) {      LOG.debug("Using existing instance of CouchbaseConnector");    } else {      LOG.debug("CouchbaseConnector not yet instantiated. Creating new instance");      validateConfig(config, issues, context);      if(issues.isEmpty()) {        runnerSharedMap.put(INSTANCE, new CouchbaseConnector(config, issues, context));      }    }    return (CouchbaseConnector) runnerSharedMap.get(INSTANCE);  }
public synchronized void close() {    if(!isClosed) {      if(bucket != null) {        LOG.debug("Closing Couchbase bucket");        bucket.close();      }      if(cluster != null) {        LOG.debug("Disconnecting Couchbase cluster");        cluster.disconnect();      }      if(env != null) {        LOG.debug("Shutting down Couchbase environment");        env.shutdown();      }      // Explicitly shutdown the RxJava scheduler threads. Not doing so will leak threads when a pipeline stops.      // Note: this disallows restarting scheduler threads without also explicitly calling Schedulers.start()      // LOG.debug("Stopping RxJava schedulers");      // Schedulers.shutdown();      isClosed = true;    }  }
private static void validateConfig(BaseCouchbaseConfig config, List<Stage.ConfigIssue> issues, Stage.Context context){    if(config.couchbase.nodes == null) {      issues.add(context.createConfigIssue(Groups.COUCHBASE.name(), "config.couchbase.nodes", Errors.COUCHBASE_29));    }    if(config.couchbase.kvTimeout < 0) {      issues.add(context.createConfigIssue(Groups.COUCHBASE.name(), "config.couchbase.kvTimeout", Errors.COUCHBASE_30));    }    if(config.couchbase.connectTimeout < 0) {      issues.add(context.createConfigIssue(Groups.COUCHBASE.name(), "config.couchbase.connectTimeout", Errors.COUCHBASE_31));    }    if(config.couchbase.disconnectTimeout < 0) {      issues.add(context.createConfigIssue(Groups.COUCHBASE.name(), "config.couchbase.disconnectTimeout", Errors.COUCHBASE_32));    }    if(config.couchbase.tls.tlsEnabled) {      config.couchbase.tls.init(context, Groups.COUCHBASE.name(), "config.couchbase.tls.", issues);    }    if(config.credentials.version == null) {      issues.add(context.createConfigIssue(Groups.CREDENTIALS.name(), "config.credentials.version", Errors.COUCHBASE_33));    }    if(config.credentials.version == AuthenticationType.USER) {      if(config.credentials.userName == null) {        issues.add(context.createConfigIssue(Groups.CREDENTIALS.name(), "config.credentials.userName", Errors.COUCHBASE_34));      }      if(config.credentials.userPassword == null) {        issues.add(context.createConfigIssue(Groups.CREDENTIALS.name(), "config.credentials.userPassword", Errors.COUCHBASE_35));      }    }  }
@Override  public String produce(String lastSourceOffset, int maxBatchSize, BatchMaker batchMaker) throws StageException {    // Offsets can vary depending on the data source. Here we use an integer as an example only.    long nextSourceOffset = 0;    lastSourceOffset = lastSourceOffset == null ? "" : lastSourceOffset;    if (!lastSourceOffset.equals("")) {      nextSourceOffset = Long.parseLong(lastSourceOffset);    }    int recordCounter = 0;    long startTime = System.currentTimeMillis();    int maxRecords = Math.min(maxBatchSize, conf.maxBatchSize);    while (recordCounter < maxRecords && (startTime + conf.maxWaitTime) > System.currentTimeMillis()) {      String message = buffer.poll();      if (null == message) {        try {          Thread.sleep(100);        } catch (Exception e) {          LOG.debug(e.getMessage(), e);          break;        }      } else {        List<Record> records = processRedisMessage("id::" + nextSourceOffset, message);        for (Record record : records) {          batchMaker.addRecord(record);        }        recordCounter += records.size();        ++nextSourceOffset;      }    }    return lastSourceOffset;  }
public static String getLabelFromStringCode(String code) throws NumberFormatException {    try {      int intCode = Integer.parseInt(code);      return getLabelFromIntCode(intCode);    } catch (NumberFormatException ex) {      throw new NumberFormatException(          String.format("%s but received '%s'","operation code must be numeric", code)      );    }  }
private void verifyDependencyExists(      Map<String, ConfigDefinition> definitionsMap,      ConfigDefinition def,      String dependsOnKey,      Object contextMsg  ) {    Preconditions.checkState(definitionsMap.containsKey(dependsOnKey),        Utils.format("Error while processing {} ConfigDef='{}'. Dependency='{}' does not exist.",            contextMsg, def.getName(), dependsOnKey));  }
private boolean detectCycle(LinkedHashSet<String> dependencyAncestors, Set<String> cycles, final String child) {    if (dependencyAncestors.contains(child)) {      // Find index of the child in the ancestors list      int index = -1;      for (String s : dependencyAncestors) {        index++;        if (s.equals(child)) {          break;        }      }      // The cycle starts from the first time the child is seen in the ancestors list      // and continues till the end of the list, followed by the child again.      cycles.add(Joiner.on(" -> ").join(Iterables.skip(dependencyAncestors, index)) + " -> " + child);      return true;    }    return false;  }
AWSCredentialsProvider createCredentialsProvider() throws StageException {    String accessKey = credentialConfigs.getAccessKey().get();    String secretKey = credentialConfigs.getSecretKey().get();    if (accessKey != null && !accessKey.isEmpty() && secretKey != null && !secretKey.isEmpty()) {      return new AWSStaticCredentialsProvider(new BasicAWSCredentials(credentialConfigs.getAccessKey().get(),          credentialConfigs.getSecretKey().get()      ));    }    return null;  }
ClientConfiguration createClientConfiguration() throws StageException {    ClientConfiguration clientConfig = new ClientConfiguration();    clientConfig.setConnectionTimeout(connectionConfigs.getConnectionTimeoutMillis());    clientConfig.setSocketTimeout(connectionConfigs.getSocketTimeoutMillis());    clientConfig.withMaxErrorRetry(connectionConfigs.getMaxErrorRetry());    if (connectionConfigs.isProxyEnabled()) {      clientConfig.setProxyHost(connectionConfigs.getProxyHost());      clientConfig.setProxyPort(connectionConfigs.getProxyPort());      if (connectionConfigs.isProxyAuthenticationEnabled()) {        clientConfig.setProxyUsername(connectionConfigs.getProxyUser().get());        clientConfig.setProxyPassword(connectionConfigs.getProxyPassword().get());      }    }    return clientConfig;  }
AmazonS3Client createS3Client() throws StageException {    AmazonS3ClientBuilder builder = createAmazonS3ClientBuilder().withClientConfiguration(createClientConfiguration())                                                                 .withChunkedEncodingDisabled(connectionConfigs                                                                     .isChunkedEncodingEnabled())                                                                 .withPathStyleAccessEnabled(true);    AWSCredentialsProvider awsCredentialsProvider = getCredentialsProvider();    // If we don't call build.withCredentials(...) then we will not overwrite the default credentials provider    // already set in the builder when doing AmazonS3ClientBuilder.standard() so only calling build.withCredentials(...)    // if our own provider exists    if (awsCredentialsProvider != null) {      builder.withCredentials(awsCredentialsProvider);    }    String region = (connectionConfigs.getRegion() == null || connectionConfigs.getRegion().isEmpty())                    ? null                    : connectionConfigs.getRegion();    if (connectionConfigs.isUseEndpoint()) {      builder.withEndpointConfiguration(new AwsClientBuilder.EndpointConfiguration(connectionConfigs.getEndpoint(),          region      ));    } else if (region != null) {      builder.withRegion(connectionConfigs.getRegion());    } else {      builder.withRegion(AwsRegion.US_WEST_1.getId());      builder.withForceGlobalBucketAccessEnabled(true);    }    return (AmazonS3Client) builder.build();  }
TransferManager createTransferManager(AmazonS3 s3Client) throws StageException {    return createTransferManagerBuilder().withS3Client(s3Client)                                         .withExecutorFactory(                                             createExecutorFactory(transferManagerConfigs.getThreads())                                         )                                         .withShutDownThreadPools(true)                                         .withMinimumUploadPartSize(transferManagerConfigs.getMinimumUploadPartSize())                                         .withMultipartUploadThreshold(transferManagerConfigs                                             .getMultipartUploadThreshold())                                         .build();  }
static String calculateUserId(String csId) {    try {      // Try to hash based on default interface      InetAddress ip = InetAddress.getLocalHost();      NetworkInterface netIf = NetworkInterface.getByInetAddress(ip);      byte[] mac = netIf.getHardwareAddress();      if (mac == null) {        // In some cases the default interface may be a tap/tun device which has no MAC        // instead pick the first available interface.        Enumeration<NetworkInterface> netIfs = NetworkInterface.getNetworkInterfaces();        while (netIfs.hasMoreElements() && mac == null) {          netIf = netIfs.nextElement();          mac = netIf.getHardwareAddress();        }      }      if (mac == null) {        throw new IllegalStateException("Could not find network interface with MAC address.");      }      Hasher hasher = HASH_FUNCTION.newHasher(6); // MAC is 6 bytes.      return hasher.putBytes(mac).hash().toString();    } catch (IOException e) {      LOG.error("CredentialStore '{}' Vault, could not compute Vault user-id: '{}'", csId, e);      throw new VaultRuntimeException("Could not compute Vault user-id: " + e.toString());    }  }
public String read(String path, String key, long delay) {    if (!secrets.containsKey(path)) {      VaultClient vault = new VaultClient(getConfig());      Secret secret;      try {        secret = vault.logical().read(path);      } catch (VaultException e) {        LOG.error(e.toString(), e);        throw new VaultRuntimeException(e.toString());      }      // Record the expiration date of this lease      String leaseId;      if (secret.isRenewable()) {        // Only renewable secrets seem to have a leaseId        leaseId = secret.getLeaseId();      } else {        // So for non-renewable secrets we'll store the path with an extra / so that we can purge them correctly.        leaseId = path + "/";      }      leases.put(leaseId, System.currentTimeMillis() + (secret.getLeaseDuration() * 1000));      secrets.put(path, secret);      try {        Thread.sleep(delay);      } catch (InterruptedException e) {        Thread.currentThread().interrupt();      }    }    Map<String, Object> data = secrets.get(path).getData();    String value = getSecretValue(data, key).orElseThrow(() -> new VaultRuntimeException("Value not found for key"));    LOG.trace("CredentialStore '{}' Vault, retrieved value for key '{}'", csId, key);    return value;  }
private WriteOperationType getOperationFromHeader(Record record, String key) {    String op = record.getHeader().getAttribute(OperationType.SDC_OPERATION_TYPE);    if (op == null || op.isEmpty()) {      return config.defaultWriteOperation;    }    int opCode;    try {      opCode = Integer.parseInt(op);    } catch(NumberFormatException e) {        LOG.debug("Unparsable CDC operation. Sending record to error.");        handleError(record, Errors.COUCHBASE_08, e);        return null;      }    switch (opCode) {      case OperationType.INSERT_CODE:        return WriteOperationType.INSERT;      case OperationType.UPDATE_CODE:        return WriteOperationType.REPLACE;      case OperationType.UPSERT_CODE:        return WriteOperationType.UPSERT;      case OperationType.DELETE_CODE:        return WriteOperationType.DELETE;      default:        switch (config.unsupportedOperation) {          case DISCARD:            LOG.debug("Unsupported CDC operation for key: {}. Discarding record per configuration.", key);            return null;          case TOERROR:            LOG.debug("Unsupported CDC operation for key: {}. Sending record to error configuration.", key);            handleError(record, Errors.COUCHBASE_09, new RuntimeException());            return null;          default:            LOG.debug("Unsupported CDC operation for key: {}. Using default write operation per configuration.", key);            return config.defaultWriteOperation;        }    }  }
private Observable<AbstractDocument> writeDoc(String key, int ttl, long cas, ByteArrayOutputStream baos, Record record) {    WriteOperationType opType = getOperationFromHeader(record, key);    if(opType == null) {      return Observable.empty();    }    AbstractDocument doc;    if(config.dataFormat == DataFormat.JSON) {      try {         doc = JsonDocument.create(key, ttl, JsonObject.fromJson(baos.toString(config.dataFormatConfig.charset)), cas);      } catch(Exception e) {        return handleError(record, Errors.COUCHBASE_10, e);      }    } else {       doc = ByteArrayDocument.create(key, ttl, baos.toByteArray(), cas);    }    switch (opType) {      case DELETE: {          LOG.debug("DELETE key: {}, TTL: {}, CAS: {}", key, ttl, cas);          return connector.bucket().remove(doc, config.persistTo, config.replicateTo)              .timeout(config.couchbase.kvTimeout, TimeUnit.MILLISECONDS);      }      case INSERT: {          LOG.debug("INSERT key: {}, TTL: {}, CAS: {}", key, ttl, cas);          return connector.bucket().insert(doc, config.persistTo, config.replicateTo)              .timeout(config.couchbase.kvTimeout, TimeUnit.MILLISECONDS);      }      case REPLACE: {          LOG.debug("REPLACE key: {}, TTL: {}, CAS: {}", key, ttl, cas);          return connector.bucket().replace(doc, config.persistTo, config.replicateTo)              .timeout(config.couchbase.kvTimeout, TimeUnit.MILLISECONDS);      }      case UPSERT: {          LOG.debug("UPSERT key: {}, TTL: {}, CAS: {}", key, ttl, cas);          return connector.bucket().upsert(doc, config.persistTo, config.replicateTo)              .timeout(config.couchbase.kvTimeout, TimeUnit.MILLISECONDS);      }      default:        return Observable.empty();    }  }
private Observable<DocumentFragment<Mutation>> writeSubdoc(String key, int ttl, long cas, ByteArrayOutputStream baos,      String subdocPath, Record record) {    JsonObject frag;    try {      frag = JsonObject.fromJson(baos.toString(config.dataFormatConfig.charset));    }    catch (IOException e) {      return handleError(record, Errors.COUCHBASE_12, e);    }    AsyncMutateInBuilder mutation = connector.bucket().mutateIn(key);    SubdocOptionsBuilder options = new SubdocOptionsBuilder().createPath(true);    String subdocOpType;    try {      subdocOpType = subdocOperationELEval.eval(elVars, config.subdocOperationEL, String.class);    } catch (ELEvalException e) {      return handleError(record, Errors.COUCHBASE_13, e);    }    if(config.allowSubdoc && !subdocOpType.isEmpty()) {      switch (subdocOpType.toUpperCase()) {        case "DELETE":          LOG.debug("Sub-document DELETE key: {}, sub-document path: {}, TTL: {}, CAS: {}", key, subdocPath, ttl, cas);          return buildSubdocMutation(mutation.remove(subdocPath, options), ttl, cas, false);        case "INSERT":          LOG.debug("Sub-document INSERT key: {}, sub-document path: {}, TTL: {}, CAS: {}", key, subdocPath, ttl, cas);          return buildSubdocMutation(mutation.insert(subdocPath, frag, options), ttl, cas, true);        case "REPLACE":          LOG.debug("Sub-document REPLACE key: {}, sub-document path: {}, TTL: {}, CAS: {}", key, subdocPath, ttl, cas);          return buildSubdocMutation(mutation.replace(subdocPath, frag), ttl, cas,false);        case "UPSERT":          LOG.debug("Sub-document UPSERT key: {}, sub-document path: {}, TTL: {}, CAS: {}", key, subdocPath, ttl, cas);          return buildSubdocMutation(mutation.upsert(subdocPath, frag, options), ttl, cas,true);        case "ARRAY_PREPEND":          LOG.debug("Sub-document ARRAY_PREPEND key: {}, sub-document path: {}, TTL: {}, CAS: {}", key, subdocPath, ttl, cas);          return buildSubdocMutation(mutation.arrayPrepend(subdocPath, frag, options), ttl, cas,true);        case "ARRAY_APPEND":          LOG.debug("Sub-document ARRAY_APPEND key: {}, sub-document path: {}, TTL: {}, CAS: {}", key, subdocPath, ttl, cas);          return buildSubdocMutation(mutation.arrayAppend(subdocPath, frag, options), ttl, cas, true);        case "ARRAY_ADD_UNIQUE":          LOG.debug("Sub-document ARRAY_ADD_UNIQUE key: {}, sub-document path: {}, TTL: {}, CAS: {}", key, subdocPath, ttl, cas);          return buildSubdocMutation(mutation.arrayAddUnique(subdocPath, frag, options), ttl, cas, true);        default:          switch (config.unsupportedOperation) {            case DISCARD:              LOG.debug("Unsupported sub-document operation: {} for key: {}. Discarding record per configuration.", subdocOpType, key);              return Observable.empty();            case TOERROR:              LOG.debug("Unsupported sub-document operation: {} for key: {}. Sending record to error per configuration.", subdocOpType, key);              return handleError(record, Errors.COUCHBASE_14, new RuntimeException());            default:              LOG.debug("Unsupported sub-document operation: {} for key: {}. Using default write operation per configuration.", subdocOpType, key);              // Fall through              // Inherit the CDC or default operation          }      }    }    WriteOperationType opType = getOperationFromHeader(record, key);    if(opType == null) {      return Observable.empty();    }    switch (opType) {      case DELETE:        LOG.debug("Sub-document DELETE key: {}, sub-document path: {}, TTL: {}, CAS: {}", key, subdocPath, ttl, cas);        return buildSubdocMutation(mutation.remove(subdocPath, options), ttl, cas,false);      case INSERT:        LOG.debug("Sub-document INSERT key: {}, sub-document path: {}, TTL: {}, CAS: {}", key, subdocPath, ttl, cas);        return buildSubdocMutation(mutation.insert(subdocPath, frag, options), ttl, cas, true);      case REPLACE:        LOG.debug("Sub-document REPLACE key: {}, sub-document path: {}, TTL: {}, CAS: {}", key, subdocPath, ttl, cas);        return buildSubdocMutation(mutation.replace(subdocPath, frag), ttl, cas, false);      case UPSERT:        LOG.debug("Sub-document UPSERT key: {}, sub-document path: {}, TTL: {}, CAS: {}", key, subdocPath, ttl, cas);        return buildSubdocMutation(mutation.upsert(subdocPath, frag, options), ttl, cas, true);      default:        return Observable.empty();    }  }
private Observable<DocumentFragment<Mutation>> buildSubdocMutation(AsyncMutateInBuilder mutation, int ttl, long cas,      boolean upsertDoc) {    return mutation        .upsertDocument(upsertDoc)        .withExpiry(ttl)        .withCas(cas)        .withDurability(config.persistTo, config.replicateTo)        .execute()        .timeout(config.couchbase.kvTimeout, TimeUnit.MILLISECONDS);  }
public static <T> T doAs(      Subject subject,      PrivilegedExceptionAction<T> privilegedExceptionAction  ) throws PrivilegedActionException {    checkDoAsPermission();    if (privilegedExceptionAction == null) {      throw new RuntimeException("No privileged exception action provided");    }    return AccessController.doPrivileged(privilegedExceptionAction,        createContext(subject, AccessController.getContext())    );  }
public static <T> T doAs(      final Subject subject, final PrivilegedAction<T> privilegedAction  ) {    checkDoAsPermission();    if (privilegedAction == null) {      throw new RuntimeException("No privileged action provided");    }    return AccessController.doPrivileged(privilegedAction, createContext(subject, AccessController.getContext()));  }
@Override  public Path getPath(FileSystem fs, Date recordDate, Record record) throws StageException, IOException {    //Check whether the real file already exists    Path path = new Path(mgr.getDirPath(recordDate, record), getTempFile(recordDate, record));    //this will check the file exists.    Path renamableFinalPath = getRenamablePath(fs, path);    updateFsPermissionsIfNeeded(record);    wholeFileEventRecord = createWholeFileEventRecord(record, renamableFinalPath);    return path;  }
@Override  protected String makeAlterTableSqlString(      String schema, String tableName, LinkedHashMap<String, JdbcTypeInfo> columnDiff  ) {    String tableSchema = (schema == null) ? getDefaultSchema() : schema;    StringBuilder sqlString = new StringBuilder();    boolean first = true;    for (Map.Entry<String, JdbcTypeInfo> entry : columnDiff.entrySet()) {      if (first) {        first = false;      } else {        sqlString.append("\n");      }      sqlString          .append(ALTER_TABLE)          .append(" ");      if (tableSchema != null) {        sqlString.append(tableSchema);        sqlString.append(".");      }      sqlString.append(tableName)          .append(" ")          .append("ADD COLUMN")          .append(" ")          .append(entry.getKey())          .append(" ")          .append(entry.getValue().toString())          .append(";");    }    return sqlString.toString();  }
protected Object decode(ChannelHandlerContext ctx, ByteBuf in) throws Exception {    if (discardingTooLongFrame) {      long bytesToDiscard = this.bytesToDiscard;      int localBytesToDiscard = (int) Math.min(bytesToDiscard, in.readableBytes());      in.skipBytes(localBytesToDiscard);      bytesToDiscard -= localBytesToDiscard;      this.bytesToDiscard = bytesToDiscard;      failIfNecessary(false);      return null;    }    if (consumingLength) {      int delimIndex = indexOf(in, delimiter);      if (delimIndex < 0) {        return null;      }      final String lengthStr = in.toString(in.readerIndex(), delimIndex, lengthFieldCharset);      try {        frameLength = Long.parseLong(trimLengthString ? lengthStr.trim() : lengthStr);      } catch (NumberFormatException e) {        throw new CorruptedFrameException(            String.format(                "Invalid length field decoded (in %s charset): %s",                lengthFieldCharset.name(),                lengthStr            ),            e        );      }      if (frameLength < 0) {        throw new CorruptedFrameException("negative pre-adjustment length field: " + frameLength);      }      frameLength += lengthAdjustment;      //consume length field and delimiter bytes      in.skipBytes(delimIndex + delimiter.capacity());      //consume delimiter bytes      consumingLength = false;    }    if (frameLength > maxFrameLength) {      long discard = frameLength - in.readableBytes();      tooLongFrameLength = frameLength;      if (discard < 0) {        // buffer contains more bytes then the frameLength so we can discard all now        in.skipBytes((int) frameLength);      } else {        // Enter the discard mode and discard everything received so far.        discardingTooLongFrame = true;        consumingLength = true;        bytesToDiscard = discard;        in.skipBytes(in.readableBytes());      }      failIfNecessary(true);      return null;    }    // never overflows because it's less than maxFrameLength    int frameLengthInt = (int) frameLength;    if (in.readableBytes() < frameLengthInt) {      // need more bytes available to read actual frame      return null;    }    // the frame is now entirely present, reset state vars    consumingLength = true;    frameLength = 0;    // extract frame    int readerIndex = in.readerIndex();    int actualFrameLength = frameLengthInt;// - initialBytesToStrip;    ByteBuf frame = extractFrame(ctx, in, readerIndex, actualFrameLength);    in.readerIndex(readerIndex + actualFrameLength);    return frame;  }
protected ByteBuf extractFrame(ChannelHandlerContext ctx, ByteBuf buffer, int index, int length) {    return buffer.slice(index, length).retain();  }
public void configure(Map<String, ?> configs, final String loginContextName) {    super.configure(configs, loginContextName);    this.loginContextName = loginContextName;    this.ticketRenewWindowFactor = (Double) configs.get(SaslConfigs.SASL_KERBEROS_TICKET_RENEW_WINDOW_FACTOR);    this.ticketRenewJitter = (Double) configs.get(SaslConfigs.SASL_KERBEROS_TICKET_RENEW_JITTER);    this.minTimeBeforeRelogin = (Long) configs.get(SaslConfigs.SASL_KERBEROS_MIN_TIME_BEFORE_RELOGIN);    this.kinitCmd = (String) configs.get(SaslConfigs.SASL_KERBEROS_KINIT_CMD);    this.serviceName = getServiceName(configs, loginContextName);  }
private synchronized void reLogin() throws LoginException {    if (!isKrbTicket) {      return;    }    if (loginContext == null) {      throw new LoginException("Login must be done first");    }    if (!hasSufficientTimeElapsed()) {      return;    }    log.info("Initiating logout for {}", principal);    synchronized (KerberosLogin.class) {      // register most recent relogin attempt      lastLogin = currentElapsedTime();      //clear up the kerberos state. But the tokens are not cleared! As per      //the Java kerberos login module code, only the kerberos credentials      //are cleared      loginContext.logout();      //login and also update the subject field of this instance to      //have the new credentials (pass it to the LoginContext constructor)      loginContext = new LoginContext(loginContextName, subject);      log.info("Initiating re-login for {}", principal);      loginContext.login();    }  }
private void checkWorkerStatus(ExecutorCompletionService<Future> completionService) throws StageException {    Future future = completionService.poll();    if (future != null) {      try {        future.get();      } catch (InterruptedException e) {        LOG.error("Thread interrupted", e);      } catch (ExecutionException e) {        Throwable cause = Throwables.getRootCause(e);        if (cause != null && cause instanceof StageException) {          throw (StageException) cause;        } else {          LOG.error("Internal Error", e);          throw new StageException(JdbcErrors.JDBC_75, e.toString(), e);        }      }    }  }
public OffsetAndResult<Map.Entry> take() {    if (producerError != null) {      throw new RuntimeException(Utils.format("Producer encountered error: {}", producerError), producerError);    }    if (consumerError != null) {      throw new RuntimeException(Utils.format("Consumer encountered error: {}", consumerError), consumerError);    }    try {      Utils.checkState(batchCommitted, "Cannot take messages when last batch is uncommitted");      while (running) {        for (ControlChannel.Message controlMessage : controlChannel.getConsumerMessages()) {          switch (controlMessage.getType()) {            case PRODUCER_COMPLETE:              // producer is complete, empty channel and afterwards return null              running = false;              break;            case PRODUCER_ERROR:              running = false;              Throwable throwable = (Throwable) controlMessage.getPayload();              producerError = throwable;              throw new ProducerRuntimeException(Utils.format("Producer encountered error: {}", throwable), throwable);            default:              String msg = Utils.format("Illegal control message type: '{}'", controlMessage.getType());              throw new IllegalStateException(msg);          }        }        OffsetAndResult<Map.Entry> batch = dataChannel.take(10, TimeUnit.MILLISECONDS);        LOG.trace("Received batch: {}", batch);        if (batch != null) {          batchCommitted = false; // got a new batch          return batch;        }      }      LOG.trace("Returning null");      return null;    } catch (Throwable throwable) {      if (!(throwable instanceof ProducerRuntimeException)) {        String msg = "Error caught in consumer: " + throwable;        LOG.error(msg, throwable);        error(throwable);      }      throw Throwables.propagate(throwable);    }  }
public void commit(String offset) {    batchCommitted = true;    LOG.trace("Last committed offset '{}', attempting to commit '{}'", lastCommittedOffset, offset);    Utils.checkState(null != lastCommittedOffset, "Last committed offset cannot be null");    controlChannel.consumerCommit(offset);    lastCommittedOffset = offset;  }
public void error(Throwable throwable) {    if (consumerError == null) {      consumerError = throwable;      controlChannel.consumerError(throwable);    }  }
public static int getRatio(String s1, String s2) {    if (s1.length() >= s2.length()) {      // We need to swap s1 and s2      String temp = s2;      s2 = s1;      s1 = temp;    }    // Get alpha numeric characters    Set<String> set1 = tokenizeString(escapeString(s1));    Set<String> set2 = tokenizeString(escapeString(s2));    SetView<String> intersection = Sets.intersection(set1, set2);    TreeSet<String> sortedIntersection = Sets.newTreeSet(intersection);    if (LOG.isTraceEnabled()) {      StringBuilder sortedSb = new StringBuilder();      for (String s : sortedIntersection) {        sortedSb.append(s).append(" ");      }      LOG.trace("Sorted intersection --> {}", sortedSb.toString());    }    // Find out difference of sets set1 and intersection of set1,set2    SetView<String> restOfSet1 = Sets.symmetricDifference(set1, intersection);    // Sort it    TreeSet<String> sortedRestOfSet1 = Sets.newTreeSet(restOfSet1);    SetView<String> restOfSet2 = Sets.symmetricDifference(set2, intersection);    TreeSet<String> sortedRestOfSet2 = Sets.newTreeSet(restOfSet2);    if (LOG.isTraceEnabled()) {      StringBuilder sb1 = new StringBuilder();      for (String s : sortedRestOfSet1) {        sb1.append(s).append(" ");      }      LOG.trace("Sorted rest of 1 --> {}", sb1.toString());      StringBuilder sb2 = new StringBuilder();      for (String s : sortedRestOfSet1) {        sb2.append(s).append(" ");      }      LOG.trace("Sorted rest of 2 --> {}", sb2.toString());    }    StringBuilder t0Builder = new StringBuilder("");    StringBuilder t1Builder = new StringBuilder("");    StringBuilder t2Builder = new StringBuilder("");    for (String s : sortedIntersection) {      t0Builder.append(" ").append(s);    }    String t0 = t0Builder.toString().trim();    Set<String> setT1 = Sets.union(sortedIntersection, sortedRestOfSet1);    for (String s : setT1) {      t1Builder.append(" ").append(s);    }    String t1 = t1Builder.toString().trim();    Set<String> setT2 = Sets.union(intersection, sortedRestOfSet2);    for (String s : setT2) {      t2Builder.append(" ").append(s);    }    String t2 = t2Builder.toString().trim();    int amt1 = calculateLevenshteinDistance(t0, t1);    int amt2 = calculateLevenshteinDistance(t0, t2);    int amt3 = calculateLevenshteinDistance(t1, t2);    LOG.trace("t0 = {} --> {}", t0, amt1);    LOG.trace("t1 = {} --> {}", t1, amt2);    LOG.trace("t2 = {} --> {}", t2, amt3);    return Math.max(Math.max(amt1, amt2), amt3);  }
private void close(boolean idleClosed) throws IOException, StageException {    closeLock.writeLock().lock();    LOG.debug("Path[{}] - Closing", filePath);    try {      throwIfIdleClosed();      // If this was closed previously, just return      if (isClosed()) {        return;      }      if (generator != null) {        generator.close();      }      this.idleClosed = idleClosed;      // writers can never be null, except in tests      if (idleClosed && outputStreamHelper != null) {        //writers.release(this, false);        outputStreamHelper.commitFile(filePath);      }    } finally {      closeLock.writeLock().unlock();      //Gracefully Shutdown the thread, so rename goes through without glitch.      if (!idleClosed) {        idleCloseExecutor.shutdown();      }    }  }
public<S> DetachedStageRuntime<? extends S> createDetachedStage(    String jsonDefinition,    StageLibraryTask stageLibrary,    String pipelineId,    String pipelineTitle,    String rev,    Stage.UserContext userContext,    MetricRegistry metrics,    ExecutionMode executionMode,    DeliveryGuarantee deliveryGuarantee,    RuntimeInfo runtimeInfo,    EmailSender emailSender,    Configuration configuration,    long startTime,    LineagePublisherDelegator lineagePublisherDelegator,    Class<S> klass,    List<Issue> errors  ) {    DetachedStageConfiguration stageConf;    try {      ObjectMapper objectMapper = ObjectMapperFactory.get();      DetachedStageConfigurationJson stageConfJson = objectMapper.readValue(jsonDefinition, DetachedStageConfigurationJson.class);      stageConf = stageConfJson.getDetachedStageConfiguration();    } catch (IOException e) {      LOG.error(CreationError.CREATION_0900.getMessage(), e.toString(), e);      errors.add(IssueCreator.getPipeline().create(        CreationError.CREATION_0900,        e.toString()      ));      return null;    }    return createDetachedStage(      stageConf,      stageLibrary,      pipelineId,      pipelineTitle,      rev,      userContext,      metrics,      executionMode,      deliveryGuarantee,      runtimeInfo,      emailSender,      configuration,      startTime,      lineagePublisherDelegator,      klass,      errors    );  }
public<S> DetachedStageRuntime<? extends S> createDetachedStage(    DetachedStageConfiguration stageConf,    StageLibraryTask stageLibrary,    String pipelineId,    String pipelineTitle,    String rev,    Stage.UserContext userContext,    MetricRegistry metrics,    ExecutionMode executionMode,    DeliveryGuarantee deliveryGuarantee,    RuntimeInfo runtimeInfo,    EmailSender emailSender,    Configuration configuration,    long startTime,    LineagePublisherDelegator lineagePublisherDelegator,    Class<S> klass,    List<Issue> errors  ) {    // Firstly validate that the configuration is correct and up to date    DetachedStageValidator validator = new DetachedStageValidator(stageLibrary, stageConf);    DetachedStageConfiguration detachedStageConfiguration =  validator.validate();    // If the stage is not valid, we can't create instance of it    if(detachedStageConfiguration.getIssues().hasIssues()) {      errors.addAll(detachedStageConfiguration.getIssues().getIssues());      return null;    }    // Then stageBean that will create new instance and properly propagate all the    StageBean stageBean = PipelineBeanCreator.get().createStageBean(      true,      stageLibrary,      stageConf.getStageConfiguration(),      false,      false,      false,      Collections.emptyMap(),      null,      errors    );    if(!errors.isEmpty()) {      return null;    }    // Stage.Info and Stage.Context    Stage.Info stageInfo = new Stage.Info() {      @Override      public String getName() {        return stageBean.getDefinition().getName();      }      @Override      public int getVersion() {        return stageBean.getDefinition().getVersion();      }      @Override      public String getInstanceName() {        return stageBean.getConfiguration().getInstanceName();      }      @Override      public String getLabel() {        return stageBean.getConfiguration().getInstanceName();      }    };    StageContext context = new StageContext(      pipelineId,      pipelineTitle,      null, //TODO. Will need to set here if this stage needs to publish lineage events      rev,      null, //TODO. Will need to set here if this stage needs to publish lineage events      Collections.emptyList(),      userContext,      stageBean.getDefinition().getType(),      0,      false,      metrics,      stageBean.getDefinition().getConfigDefinitions(),      stageBean.getSystemConfigs().stageOnRecordError,      Collections.emptyList(),      Collections.emptyMap(),      stageInfo,      executionMode,      deliveryGuarantee,      runtimeInfo,      emailSender,      configuration,      Collections.emptyMap(),      startTime,      lineagePublisherDelegator,      Collections.emptyMap(),      false    );    return DetachedStageRuntime.create(stageBean, stageInfo, context, klass);  }
private void registerFunction(ElFunctionDefinition function) {    String namespace;    String functionName;    if (function.getName().contains(":")) {      String[] tokens = function.getName().split(":");      namespace = tokens[0];      functionName = tokens[1];    } else {      namespace = "";      functionName = function.getName();    }    Map<String, Method> namespaceFunctions = functionsByNamespace.get(namespace);    if (namespaceFunctions == null) {      namespaceFunctions = new HashMap<>();      functionsByNamespace.put(namespace, namespaceFunctions);    }    namespaceFunctions.put(functionName, function.getMethod());  }
public void injectStage(Object stage, StageDefinition stageDef, StageConfiguration stageConf, Map<String, Object> constants, List<Issue> issues) {    injectConfigsToObject(stage, new StageInjectorContext(stageDef, stageConf, constants, issues));  }
@Override  public Record createRecord(Record originatorRecord) {    Preconditions.checkNotNull(originatorRecord, "originatorRecord cannot be null");    RecordImpl record = new RecordImpl(stageInfo.getInstanceName(), originatorRecord, null, null);    HeaderImpl header = record.getHeader();    header.setStagesPath("");    return record;  }
@Override  public Record createRecord(Record originatorRecord, String sourceIdPostfix) {    Preconditions.checkNotNull(originatorRecord, "originatorRecord cannot be null");    RecordImpl record = new RecordImpl(stageInfo.getInstanceName(), originatorRecord, null, null);    HeaderImpl header = record.getHeader();    header.setSourceId(header.getSourceId() + "_" + sourceIdPostfix);    header.setStagesPath("");    return record;  }
@Override  public Record createRecord(Record originatorRecord, byte[] raw, String rawMime) {    return new RecordImpl(stageInfo.getInstanceName(), originatorRecord, raw, rawMime);  }
@Override  public Record cloneRecord(Record record) {    RecordImpl clonedRecord = ((RecordImpl) record).clone();    HeaderImpl header = clonedRecord.getHeader();    header.setStagesPath("");    return clonedRecord;  }
@Override  public Record cloneRecord(Record record, String sourceIdPostfix) {    RecordImpl clonedRecord = ((RecordImpl) record).clone();    HeaderImpl header = clonedRecord.getHeader();    header.setSourceId(header.getSourceId() + "_" + sourceIdPostfix);    header.setStagesPath("");    return clonedRecord;  }
@SuppressWarnings("unchecked")  public <T extends HMSCacheSupport.HMSCacheInfo> T getIfPresent(      HMSCacheType hmsCacheType,      String qualifiedTableName  ) throws StageException {    if (!cacheMap.containsKey(hmsCacheType)) {      throw new StageException(Errors.HIVE_16, hmsCacheType);    }    Optional<HMSCacheSupport.HMSCacheInfo> ret = cacheMap.get(hmsCacheType).getIfPresent(qualifiedTableName);    return ret == null ? null : (T)ret.orNull();  }
@SuppressWarnings("unchecked")  public <T extends HMSCacheSupport.HMSCacheInfo> T getOrLoad(      HMSCacheType hmsCacheType,      String qualifiedTableName,      HiveQueryExecutor queryExecutor  ) throws StageException {    if (!cacheMap.containsKey(hmsCacheType)) {      throw new StageException(Errors.HIVE_16, hmsCacheType);    }    // Firstly validate if the data already exists to avoid locking    T cacheValue = getIfPresent(hmsCacheType, qualifiedTableName);    if(cacheValue != null) {      return cacheValue;    }    // For altering operation, get exclusive lock    Lock lock = null;    try {      lock = tableLocks.get(keyForLockMap(hmsCacheType, qualifiedTableName));      lock.lock();      // Check the presence again as another thread could load the value before we got the lock      cacheValue = getIfPresent(hmsCacheType, qualifiedTableName);      if(cacheValue != null) {        return cacheValue;      }      // Load the value from Hive      return (T)(cacheMap.get(hmsCacheType).get(        qualifiedTableName,        () -> hmsCacheType.getSupport().newHMSCacheLoader(queryExecutor).load(qualifiedTableName)      )).orNull();    } catch(ExecutionException e) {      throw new StageException(Errors.HIVE_01, e);    } finally {      if(lock != null) {        lock.unlock();      }    }  }
public <T extends HMSCacheSupport.HMSCacheInfo> void put(      HMSCacheType cacheType,      String qualifiedTableName,      T hmsCacheInfo  ) throws StageException {    if (!cacheMap.containsKey(cacheType)) {      throw new StageException(Errors.HIVE_16, cacheType);    }    cacheMap.get(cacheType).put(qualifiedTableName, Optional.of(hmsCacheInfo));  }
public DefinitionsJson getDefinitions (HideStage.Type hideStage) throws ApiException {    Object postBody = null;    byte[] postBinaryBody = null;    // create path and map variables    String path = "/v1/definitions".replaceAll("\\{format\\}","json");    // query params    List<Pair> queryParams = new ArrayList<Pair>();    if (hideStage != null) {      queryParams.add(new Pair("hideStage", hideStage.name()));    }    Map<String, String> headerParams = new HashMap<String, String>();    Map<String, Object> formParams = new HashMap<String, Object>();    final String[] accepts = {      "application/json"    };    final String accept = apiClient.selectHeaderAccept(accepts);    final String[] contentTypes = {    };    final String contentType = apiClient.selectHeaderContentType(contentTypes);    String[] authNames = new String[] { "basic" };    TypeRef returnType = new TypeRef<DefinitionsJson>() {};    return apiClient.invokeAPI(path, "GET", queryParams, postBody, postBinaryBody, headerParams,        formParams, accept, contentType, authNames, returnType);  }
private LineagePublisherDefinition getDefinition(String name) {    String defConfig = LineagePublisherConstants.configDef(name);    String publisherDefinition = configuration.get(defConfig, null);    if(StringUtils.isEmpty(publisherDefinition)) {      throw new IllegalArgumentException(Utils.format("Missing definition '{}'", defConfig));    }    String []lineagePluginDefs = publisherDefinition.split("::");    if(lineagePluginDefs.length != 2) {      throw new IllegalStateException(Utils.format(        "Invalid definition '{}', expected $libraryName::$publisherName",        publisherDefinition      ));    }    LineagePublisherDefinition def = stageLibraryTask.getLineagePublisherDefinition(      lineagePluginDefs[0], // Library      lineagePluginDefs[1]  // Plugin name    );    if(def == null) {      throw new IllegalStateException(Utils.format("Can't find publisher '{}'", publisherDefinition));    }    return def;  }
private static String formatName(String columnName, boolean caseSensitive) {    String returnValue = format(columnName);    if (caseSensitive) {      return returnValue;    }    return returnValue.toUpperCase();  }
private static String formatValue(String value) {    // The value can either be null (if the IS keyword is present before it or just a NULL string with no quotes)    if (value == null || NULL_STRING.equalsIgnoreCase(value)) {      return null;    }    String returnValue = format(value);    return returnValue.replaceAll("''", "'");  }
public PipelineConfigurationJson getPipelineInfo (String pipelineId, String rev, String get, Boolean attachment)      throws ApiException {    Object postBody = null;    byte[] postBinaryBody = null;    // verify the required parameter 'pipelineId' is set    if (pipelineId == null) {      throw new ApiException(400, "Missing the required parameter 'pipelineId' when calling getPipelineInfo");    }    // create path and map variables    String path = "/v1/pipeline/{pipelineId}".replaceAll("\\{format\\}","json")        .replaceAll("\\{" + "pipelineId" + "\\}", apiClient.escapeString(pipelineId.toString()));    // query params    List<Pair> queryParams = new ArrayList<Pair>();    Map<String, String> headerParams = new HashMap<String, String>();    Map<String, Object> formParams = new HashMap<String, Object>();    queryParams.addAll(apiClient.parameterToPairs("", "rev", rev));    queryParams.addAll(apiClient.parameterToPairs("", "get", get));    queryParams.addAll(apiClient.parameterToPairs("", "attachment", attachment));    final String[] accepts = {        "application/json"    };    final String accept = apiClient.selectHeaderAccept(accepts);    final String[] contentTypes = {    };    final String contentType = apiClient.selectHeaderContentType(contentTypes);    String[] authNames = new String[] { "basic" };    TypeRef returnType = new TypeRef<PipelineConfigurationJson>() {};    return apiClient.invokeAPI(path, "GET", queryParams, postBody, postBinaryBody, headerParams, formParams, accept,        contentType, authNames, returnType);  }
public PipelineFragmentEnvelopeJson createDraftPipelineFragment (      String fragmentId,      String description,      List<StageConfigurationJson> stageInstances  ) throws ApiException {    Object postBody = stageInstances;    byte[] postBinaryBody = null;    // verify the required parameter 'pipelineId' is set    if (fragmentId == null) {      throw new ApiException(400, "Missing the required parameter 'fragmentId' when calling createPipelineFragment");    }    // create path and map variables    String path = "/v1/fragment/{fragmentId}".replaceAll("\\{format\\}","json")        .replaceAll("\\{" + "fragmentId" + "\\}", apiClient.escapeString(fragmentId.toString()));    // query params    List<Pair> queryParams = new ArrayList<Pair>();    Map<String, String> headerParams = new HashMap<String, String>();    Map<String, Object> formParams = new HashMap<String, Object>();    queryParams.addAll(apiClient.parameterToPairs("", "description", description));    queryParams.addAll(apiClient.parameterToPairs("", "draft", true));    final String[] accepts = {        "application/json"    };    final String accept = apiClient.selectHeaderAccept(accepts);    final String[] contentTypes = {    };    final String contentType = apiClient.selectHeaderContentType(contentTypes);    String[] authNames = new String[] { "basic" };    TypeRef returnType = new TypeRef<PipelineFragmentEnvelopeJson>() {};    return apiClient.invokeAPI(path, "PUT", queryParams, postBody, postBinaryBody, headerParams, formParams,        accept, contentType, authNames, returnType);  }
public List<PipelineInfoJson> getPipelines (      String filterText,      String label,      int offset,      int len,      PipelineOrderByFields orderBy,      Order order,      boolean includeStatus  ) throws ApiException {    Object postBody = null;    byte[] postBinaryBody = null;    // create path and map variables    String path = "/v1/pipelines".replaceAll("\\{format\\}","json");    // query params    List<Pair> queryParams = new ArrayList<Pair>();    Map<String, String> headerParams = new HashMap<String, String>();    Map<String, Object> formParams = new HashMap<String, Object>();    queryParams.addAll(apiClient.parameterToPairs("", "filterText", filterText));    queryParams.addAll(apiClient.parameterToPairs("", "label", label));    queryParams.addAll(apiClient.parameterToPairs("", "offset", offset));    queryParams.addAll(apiClient.parameterToPairs("", "len", len));    queryParams.addAll(apiClient.parameterToPairs("", "orderBy", orderBy));    queryParams.addAll(apiClient.parameterToPairs("", "order", order));    final String[] accepts = {        "application/json"    };    final String accept = apiClient.selectHeaderAccept(accepts);    final String[] contentTypes = {    };    final String contentType = apiClient.selectHeaderContentType(contentTypes);    String[] authNames = new String[] { "basic" };    TypeRef returnType = new TypeRef<List<PipelineInfoJson>>() {};    return apiClient.invokeAPI(path, "GET", queryParams, postBody, postBinaryBody, headerParams, formParams, accept,        contentType, authNames, returnType);  }
public PipelineFragmentEnvelopeJson importPipelineFragment (      String fragmentId,      boolean draft,      boolean includeLibraryDefinitions,      PipelineFragmentEnvelopeJson fragmentEnvelope  ) throws ApiException {    Object postBody = fragmentEnvelope;    byte[] postBinaryBody = null;    // verify the required parameter 'fragmentId' is set    if (fragmentId == null) {      throw new ApiException(400, "Missing the required parameter 'fragmentId' when calling importPipelineFragment");    }    // verify the required parameter 'fragmentEnvelope' is set    if (fragmentEnvelope == null) {      throw new ApiException(          400,          "Missing the required parameter 'pipelineEnvelope' when calling importPipelineFragment"      );    }    // create path and map variables    String path = "/v1/fragment/{fragmentId}/import".replaceAll("\\{format\\}","json")        .replaceAll("\\{" + "fragmentId" + "\\}", apiClient.escapeString(fragmentId.toString()));    // query params    List<Pair> queryParams = new ArrayList<Pair>();    Map<String, String> headerParams = new HashMap<String, String>();    Map<String, Object> formParams = new HashMap<String, Object>();    queryParams.addAll(apiClient.parameterToPairs("", "draft", draft));    queryParams.addAll(apiClient.parameterToPairs("", "includeLibraryDefinitions", includeLibraryDefinitions));    final String[] accepts = {        "application/json"    };    final String accept = apiClient.selectHeaderAccept(accepts);    final String[] contentTypes = {        "application/json"    };    final String contentType = apiClient.selectHeaderContentType(contentTypes);    String[] authNames = new String[] { "basic" };    TypeRef returnType = new TypeRef<PipelineFragmentEnvelopeJson>() {};    return apiClient.invokeAPI(path, "POST", queryParams, postBody, postBinaryBody, headerParams, formParams,        accept, contentType, authNames, returnType);  }
public synchronized void release(RecordWriter writer, boolean roll) throws StageException, IOException {    writer.closeLock();    try {      if (roll || writer.isIdleClosed() || manager.isOverThresholds(writer)) {        if (IS_TRACE_ENABLED) {          LOG.trace("Release '{}'", writer.getPath());        }        writers.remove(writer.getPath().toString());        manager.commitWriter(writer);      }    } finally {      writer.closeUnlock();    }    purge();  }
public String getFilePath(      String dirPathTemplate,      Record record,      Date recordTime  ) throws StageException {    String dirPath;    // get directory path    if (dirPathTemplateInHeader) {      dirPath = record.getHeader().getAttribute(DataLakeTarget.TARGET_DIRECTORY_HEADER);      Utils.checkArgument(!(dirPath == null || dirPath.isEmpty()), "Directory Path cannot be null");    } else {      dirPath = resolvePath(dirPathTemplateEval, dirPathTemplateVars, dirPathTemplate, recordTime, record);    }    // SDC-5492: replace "//" to "/" in file path    dirPath = dirPath.replaceAll("/+","/");    if (dirPath.endsWith("/")) {      dirPath = dirPath.substring(0, dirPath.length()-1);    }    return outputStreamHelper.getTempFilePath(dirPath, record, recordTime);  }
public void closeAll() throws IOException, StageException {    Set<String> filePathsToClose = ImmutableSet.copyOf(tmpFilePathToGenerators.keySet());    for (String filePath : filePathsToClose) {      close(filePath);    }  }
public void issueCachedEvents() throws IOException {    String closedPath;    while((closedPath = closedPaths.poll()) != null) {      produceCloseFileEvent(closedPath);    }  }
@VisibleForTesting  final int getOperationFromRecord(      Record record,      JDBCOperationType defaultOp,      UnsupportedOperationAction unsupportedAction,      List<OnRecordErrorException> errorRecords  ) {    return getOperationFromRecord(record, defaultOp.getCode(), unsupportedAction, errorRecords);  }
int getOperationFromRecord(      Record record,      int defaultOpCode,      UnsupportedOperationAction unsupportedAction,      List<OnRecordErrorException> errorRecords  ) {    String op = record.getHeader().getAttribute(OperationType.SDC_OPERATION_TYPE);    int opCode = -1; // unsupported    if (Strings.isNullOrEmpty(op)) {      return defaultOpCode;    }    // Check if the operation code from header attribute is valid    try {      opCode = JDBCOperationType.convertToIntCode(op);    } catch (NumberFormatException | UnsupportedOperationException ex) {      LOG.debug(          "Operation obtained from record is not supported. Handle by UnsupportedOperationAction {}. {}",          unsupportedAction.getLabel(),          ex      );      switch (unsupportedAction) {        case SEND_TO_ERROR:          LOG.debug("Sending record to error due to unsupported operation {}", op);          errorRecords.add(new OnRecordErrorException(record, JdbcErrors.JDBC_70, op));          break;        case USE_DEFAULT:          opCode = defaultOpCode;          break;        case DISCARD:        default: // unknown action          LOG.debug("Discarding record with unsupported operation {}", op);      }    }    return opCode;  }
@VisibleForTesting  SortedMap<String, String> getColumnsToParameters(      final Record record,      int op,      Map<String, String> parameters,      Map<String, String> columnsToFields  ) {    SortedMap<String, String> filtered = new TreeMap<>();    for (Map.Entry<String, String> entry : columnsToFields.entrySet()) {      String columnName = entry.getKey();      String fieldPath = entry.getValue();      if (record.has(fieldPath)) {        filtered.put(columnName, parameters.get(columnName));      } else {        LOG.trace("Record is missing a field for column {} for the operation code {}", columnName, op);      }    }    return filtered;  }
String getFieldPath(String columnName, Map<String, String> columnsToField, int op){    return columnsToField.get(columnName);  }
public SortedSet<V> sort() {    Utils.checkState(!new CycleDetector<>(directedGraph).isGraphCyclic(), "Cycles found in the graph");    final Map<V, Integer> vertexToSortedNumber = new HashMap<>();    Map<V, Integer> inEdgesCount = new TreeMap<>();    SortedSet<V> sortedSet = new TreeSet<>((o1, o2) -> {      Integer sortedNumber1 = vertexToSortedNumber.get(o1);      Integer sortedNumber2 = vertexToSortedNumber.get(o2);      if (sortedNumber1.intValue() == sortedNumber2.intValue()) {        //If there is no tie comparator and there is a tie, arrange o1 before o2.        return (tieComparator != null)? tieComparator.compare(o1, o2) : -1;      }      return sortedNumber1.compareTo(sortedNumber2);    });    final AtomicInteger startNumber = new AtomicInteger(1);    directedGraph.vertices().forEach(vertex -> {      Collection<V> inwardVertices = directedGraph.getInwardEdgeVertices(vertex);      inEdgesCount.put(vertex, inwardVertices.size());    });    while (!inEdgesCount.isEmpty()) {      Set<V> nextVertices = nextVerticesForProcessing(inEdgesCount);      nextVertices.forEach(vertexForProcessing -> {        inEdgesCount.remove(vertexForProcessing);        updateCounts(vertexForProcessing, inEdgesCount);        vertexToSortedNumber.put(vertexForProcessing, startNumber.getAndIncrement());      });    }    sortedSet.addAll(vertexToSortedNumber.keySet());    return sortedSet;  }
public EnrichedEvent poll(long timeout, TimeUnit unit) throws StageException {    try {      return queue.poll(timeout, unit);    } catch (InterruptedException e) {      LOG.error(Errors.MYSQL_001.getMessage(), e.toString(), e);      Thread.currentThread().interrupt();      throw new StageException(Errors.MYSQL_001, e.toString(), e);    }  }
public static Integer getMapMemoryMb(String javaOpts, Configuration conf) {    String[] javaOptsArray = javaOpts.split(" ");    Integer upperLimitMemory = null;    for (String opts : javaOptsArray) {      if (opts.contains("-Xmx")) {        Integer memoryMb = Integer.valueOf(opts.substring(4, opts.length() - 1));        switch (opts.charAt(opts.length() - 1)) {          case 'm':          case 'M':            break;          case 'k':          case 'K':            memoryMb = memoryMb / (1024);            break;          case 'g':          case 'G':            memoryMb = memoryMb * 1024;            break;          default:            memoryMb = Integer.valueOf(opts.substring(4, opts.length())) / (1024 * 1024);            break;        }        // Add 25% to Java heap as MAP_MEMORY_MB is the total physical memory for the map task        upperLimitMemory = ((int) (memoryMb * 0.25)) + memoryMb;        // dont break as there could be multiple -Xmx, we need to honor the last      }    }    if (upperLimitMemory != null) {      String defaultMapMemoryString = conf.get(MAPREDUCE_MAP_MEMORY_MB);      if (defaultMapMemoryString != null) {        Integer defaultMapMemory = Integer.valueOf(defaultMapMemoryString);        upperLimitMemory = (upperLimitMemory > defaultMapMemory ? upperLimitMemory : defaultMapMemory);      }    }    return upperLimitMemory;  }
private static void tarFolder(String parent, String path, TarOutputStream out) throws IOException {    BufferedInputStream src = null;    File f = new File(path);    String files[] = f.list();    // is file    if (files == null) {      files = new String[1];      files[0] = f.getName();    }    parent = ((parent == null) ? (f.isFile()) ? "" : f.getName() + "/" : parent + f.getName() + "/");    for (int i = 0; i < files.length; i++) {      File fe = f;      if (f.isDirectory()) {        fe = new File(f, files[i]);      }      if (fe.isDirectory()) {        String[] fl = fe.list();        if (fl != null && fl.length != 0) {          tarFolder(parent, fe.getPath(), out);        } else {          TarEntry entry = new TarEntry(fe, parent + files[i] + "/");          out.putNextEntry(entry);        }        continue;      }      FileInputStream fi = new FileInputStream(fe);      src = new BufferedInputStream(fi);      TarEntry entry = new TarEntry(fe, parent + files[i]);      out.putNextEntry(entry);      IOUtils.copy(src, out);      src.close();      out.flush();    }  }
public T getRunner() throws PipelineRuntimeException {    validateNotDestroyed();    try {      return queue.take().runner;    } catch (InterruptedException e) {      throw new PipelineRuntimeException(ContainerError.CONTAINER_0801, e);    } finally {      runtimeStats.setAvailableRunners(queue.size());      histogram.update(queue.size());    }  }
public T getIdleRunner(long idleTime) {    // Take the first runner    QueueItem<T> item = queue.poll();    // All runners might be currently in use, which is fine in this case.    if(item == null) {      return null;    }    // If the runner wasn't idle for the expected time, we need to put it back to the queue (it will be added to the    // begging again).    if((System.currentTimeMillis() - item.timestamp) < idleTime) {      queue.add(item);      return null;    }    // Otherwise we do have runner that hasn't been used for at least idleTime, so we can return it now    return item.runner;  }
public void returnRunner(T runner) throws PipelineRuntimeException {    validateNotDestroyed();    queue.add(new QueueItem<>(runner));    runtimeStats.setAvailableRunners(queue.size());    histogram.update(queue.size());  }
public void destroy() throws PipelineRuntimeException {    // Firstly set this runner as destroyed    destroyed.set(true);    // Validate that this thread pool have all runners back, otherwise we're missing something and that is sign of    // a trouble.    if(queue.size() < runtimeStats.getTotalRunners()) {      throw new PipelineRuntimeException(ContainerError.CONTAINER_0802, queue.size(), runtimeStats.getTotalRunners());    }  }
private void validateNotDestroyed() throws PipelineRuntimeException {    if(destroyed.get()) {      throw new PipelineRuntimeException(ContainerError.CONTAINER_0803, queue.size(), runtimeStats.getTotalRunners());    }  }
public static long checkStreamExists(      ClientConfiguration awsClientConfig,      KinesisConfigBean conf,      String streamName,      List<Stage.ConfigIssue> issues,      Stage.Context context  ) {    long numShards = 0;    try {      numShards = getShardCount(awsClientConfig, conf, streamName);    } catch (AmazonClientException|StageException e) {      LOG.error(Errors.KINESIS_01.getMessage(), e.toString(), e);      issues.add(context.createConfigIssue(          Groups.KINESIS.name(),          KINESIS_CONFIG_BEAN + ".streamName", Errors.KINESIS_01, e.toString()      ));    }    return numShards;  }
public static String getLastShardId(      ClientConfiguration awsClientConfig,      KinesisConfigBean conf,      String streamName  ) throws StageException {    AmazonKinesis kinesisClient = getKinesisClient(awsClientConfig, conf);    String lastShardId = null;    try {      StreamDescription description;      do {        if (lastShardId == null) {          description = kinesisClient.describeStream(streamName).getStreamDescription();        } else {          description = kinesisClient.describeStream(streamName, lastShardId).getStreamDescription();        }        int pageSize = description.getShards().size();        lastShardId = description.getShards().get(pageSize - 1).getShardId();      } while (description.getHasMoreShards());      return lastShardId;    } finally {      kinesisClient.shutdown();    }  }
private void processQueue(      LinkedList<Record> queue,      List<OnRecordErrorException> errorRecords,      Connection connection,      int maxRowsPerBatch,      int opCode  ) throws StageException {    if (queue.isEmpty()) {      return;    }    int rowCount = 0;    // Assume that columns are all same for the same operation to the same table    // If some columns are missing in record, the record goes to error.    final Record first = queue.getFirst();    SortedMap<String, String> columnsToParameters = recordReader.getColumnsToParameters(        first,        opCode,        getColumnsToParameters(),        opCode == OperationType.UPDATE_CODE ? getColumnsToFieldNoPK() : getColumnsToFields()    );    if (columnsToParameters.isEmpty()) {      // no parameters found for configured columns      if (LOG.isWarnEnabled()) {        LOG.warn("No parameters found for record with ID {}; skipping", first.getHeader().getSourceId());      }      return;    }    String query = generateQueryForMultiRow(        opCode,        columnsToParameters,        getPrimaryKeyColumns(),        // the next batch will have either the max number of records, or however many are left.        Math.min(maxRowsPerBatch, queue.size())    );    // Need to store removed records from queue, because we might need to add newly generated columns    // to records for Jdbc Tee Processor.    LinkedList<Record> removed = new LinkedList<>();    try (PreparedStatement statement = jdbcUtil.getPreparedStatement(getGeneratedColumnMappings(), query, connection)) {      int paramIdx = 1;      // Start processing records in queue. All records have the same operation to the same table.      while (!queue.isEmpty()) {        Record r = queue.removeFirst();        if (opCode != DELETE_CODE) {          paramIdx = setParamsToStatement(paramIdx, statement, columnsToParameters, r, connection, opCode);        }        if (opCode != OperationType.INSERT_CODE) {          paramIdx = setPrimaryKeys(paramIdx, r, statement, opCode);        }        removed.add(r);        ++rowCount;        if (rowCount == maxRowsPerBatch) {          // time to execute the current batch          processBatch(removed, errorRecords, statement, connection);          // reset our counters          rowCount = 0;          paramIdx = 1;          removed.clear();        }      }    } catch (SQLException e) {      handleSqlException(e, removed, errorRecords);    }    // Process the rest of the records that are removed from queue but haven't processed yet    // this happens when rowCount is still less than maxRowsPerBatch.    // This is a bit of an ugly fix as its not very DRY but sufficient until there's a larger    // refactoring of this code.    if (!removed.isEmpty()) {      query = generateQueryForMultiRow(          opCode,          columnsToParameters,          getPrimaryKeyColumns(),          removed.size() // always the remainder      );      try (PreparedStatement statement = jdbcUtil.getPreparedStatement(          getGeneratedColumnMappings(),          query,          connection      )) {        int paramIdx = 1;        for (Record r : removed) {          if (opCode != DELETE_CODE) {            paramIdx = setParamsToStatement(paramIdx, statement, columnsToParameters, r, connection, opCode);          }          if (opCode != OperationType.INSERT_CODE) {            paramIdx = setPrimaryKeys(paramIdx, r, statement, opCode);          }        }        processBatch(removed, errorRecords, statement, connection);      } catch (SQLException e) {        handleSqlException(e, removed, errorRecords);      }    }  }
private void handleSqlException(    SQLException exception,    List<Record> inputRecords,    List<OnRecordErrorException> errors  ) throws StageException {    if(jdbcUtil.isDataError(getCustomDataSqlStateCodes(), getConnectionString(), exception)) {      String formattedError = jdbcUtil.formatSqlException(exception);      LOG.error(JdbcErrors.JDBC_89.getMessage(), formattedError);      for(Record inputRecord : inputRecords) {        errors.add(new OnRecordErrorException(inputRecord, JdbcErrors.JDBC_89, formattedError));      }      return;    }    super.handleSqlException(exception);  }
private HashCode getColumnHash(Record record, int op) throws OnRecordErrorException {    Map<String, String> parameters = getColumnsToParameters();    SortedMap<String, String> columnsToParameters        = recordReader.getColumnsToParameters(record, op, parameters, getColumnsToFields());    return columnHashFunction.newHasher().putObject(columnsToParameters, stringMapFunnel).hash();  }
String getLoginUrl(HttpServletRequest request, boolean repeatedRedirect) {    String requestUrl = getRequestUrl(request, TOKEN_PARAM_SET).toString();    return getSsoService().createRedirectToLoginUrl(requestUrl, repeatedRedirect);  }
Authentication redirectToSelf(HttpServletRequest httpReq, HttpServletResponse httpRes) throws ServerAuthException {    String authToken = httpReq.getParameter(SSOConstants.USER_AUTH_TOKEN_PARAM);    String urlWithoutToken = getRequestUrlWithoutToken(httpReq);    httpRes.setHeader(SSOConstants.X_USER_AUTH_TOKEN, authToken);    try {      LOG.debug("Redirecting to self without token '{}'", urlWithoutToken);      httpRes.sendRedirect(urlWithoutToken);      return Authentication.SEND_CONTINUE;    } catch (IOException ex) {      throw new ServerAuthException(Utils.format("Could not redirect to '{}': {}", urlWithoutToken, ex.toString(), ex));    }  }
@Override  protected Authentication returnUnauthorized(      HttpServletRequest httpReq, HttpServletResponse httpRes, String principalId, String logMessageTemplate  ) throws ServerAuthException {    Authentication ret;    httpRes.addCookie(createAuthCookie(httpReq, "", 0));    if (httpReq.getHeader(SSOConstants.X_REST_CALL) != null) {      ret = super.returnUnauthorized(httpReq, httpRes, null, logMessageTemplate);    } else {      redirectToLogin(httpReq, httpRes);      ret = Authentication.SEND_FAILURE;    }    return ret;  }
public Optional<List<ConfigIssue>> validateSchemaAndTables(List<SchemaTableConfigBean>      schemaTableConfigs) {    List<ConfigIssue> issues = new ArrayList<>();    for (SchemaTableConfigBean tables : configBean.baseConfigBean.schemaTableConfigs) {      validateSchemaAndTable(tables).ifPresent(issues::add);    }    return Optional.ofNullable(issues);  }
public static boolean compareFiles(WrappedFileSystem fs, WrappedFile f1, WrappedFile f2) {    if (!fs.exists(f2)) {      return true;    }    try {      long mtime1 = fs.getLastModifiedTime(f1);      long mtime2 = fs.getLastModifiedTime(f2);      long ctime1 = fs.getChangedTime(f1);      long ctime2 = fs.getChangedTime(f2);      long time1 = Math.max(mtime1, ctime1);      long time2 = Math.max(mtime2, ctime2);      int compares = Long.compare(time1, time2);      if (compares != 0) {        return compares > 0;      }    } catch (IOException ex) {      LOG.error("Failed to get ctime: '{}'", f1.getFileName(), ex);      return false;    }    return f1.getAbsolutePath().compareTo(f2.getAbsolutePath()) > 0;  }
public static DataParser getParser(      WrappedFileSystem fs,      WrappedFile file,      DataFormat dataFormat,      DataParserFactory parserFactory,      String offset,      int wholeFileMaxObjectLen,      ELEval rateLimitElEval,      ELVars rateLimitElVars,      String rateLimit  ) throws DataParserException, ELEvalException, IOException {    DataParser parser;    switch (dataFormat) {      case WHOLE_FILE:        FileRef fileRef = fs.getFileRefBuilder()            .filePath(file.getAbsolutePath())            .bufferSize(wholeFileMaxObjectLen)            .rateLimit(FileRefUtil.evaluateAndGetRateLimit(rateLimitElEval, rateLimitElVars, rateLimit))            .createMetrics(true)            .totalSizeInBytes(file.getSize())            .build();        parser = parserFactory.getParser(file.getFileName(), file.getFileMetadata(), fileRef);        break;      default:        parser = parserFactory.getParser(file.getFileName(), file.getInputStream(), offset);    }    return parser;  }
public static String truncateGlobPatternDirectory(String directory) {    String[] absolutePath = directory.split(ESCAPED_ASTERISK);    String truncatedString = absolutePath[0];    if (lastCharacterIsAsterisk(truncatedString) != SLASH.toCharArray()[0]) {      List<String> subDirectories = Arrays.asList(truncatedString.split(SLASH));      StringBuffer stringBuffer = new StringBuffer();      stringBuffer.append(String.join(SLASH, subDirectories.subList(0, subDirectories.size() - 1))).append(SLASH);      truncatedString = stringBuffer.toString();    }    LOG.debug(String.format("Checking existence of path: %s", truncatedString));    return truncatedString;  }
private static int retrievePidIfFeasible(Process process) {    if(unixProcessClass == null) {      return UNDETERMINED_PID;    }    if(!unixProcessClass.isInstance(process)) {      LOG.debug("Do not support retrieving PID from {}", process.getClass().getName());      return UNDETERMINED_PID;    }    try {      return (int)pidField.get(process);    } catch (IllegalAccessException e) {      LOG.debug("Can't retrieve PID value from the field", e);      return UNDETERMINED_PID;    }  }
private Set<String> validateAndExtractFieldsToHash(      Record record,      Set<String> fieldsDontExist,      Set<String> fieldsWithListOrMapType,      Set<String> fieldsWithNull,      Collection<String> matchingFieldsPath  ) {    Set<String> validFieldsToHashForThisConfig = new HashSet<String>();    for (String matchingFieldPath : matchingFieldsPath) {      if (record.has(matchingFieldPath)) {        Field field = record.get(matchingFieldPath);        if (UNSUPPORTED_FIELD_TYPES.contains(field.getType())) {          fieldsWithListOrMapType.add(matchingFieldPath);        } else if (field.getValue() == null) {          fieldsWithNull.add(matchingFieldPath);        } else {          validFieldsToHashForThisConfig.add(matchingFieldPath);        }      } else {        fieldsDontExist.add(matchingFieldPath);      }    }    return validFieldsToHashForThisConfig;  }
public static UserGroupInformation getProxyUser(    String user,                    // Hadoop user (HDFS User, HBase user, generally the to-be-impersonated user in component's configuration)    Stage.Context context,          // Stage context object    UserGroupInformation loginUser, // Login UGI (sdc user)    List<Stage.ConfigIssue> issues, // Reports errors    String configGroup,             // Group where "HDFS User" is present    String configName               // Config name of "HDFS User"  ) {    // Should we always impersonate current user?    boolean alwaysImpersonate = context.getConfiguration().get(      HadoopConfigConstants.IMPERSONATION_ALWAYS_CURRENT_USER,      false    );    // If so, propagate current user to "user" (the one to be impersonated)    if(alwaysImpersonate) {      if(!StringUtils.isEmpty(user)) {        issues.add(context.createConfigIssue(configGroup, configName, Errors.HADOOP_00001));      }      user = context.getUserContext().getAliasName();    }    // If impersonated user is empty, simply return login UGI (no impersonation performed)    if(StringUtils.isEmpty(user)) {      return loginUser;    }    // Optionally lower case the user name    boolean lowerCase = context.getConfiguration().get(      HadoopConfigConstants.LOWERCASE_USER,      false    );    if(lowerCase) {      user = user.toLowerCase();    }    return UserGroupInformation.createProxyUser(user, loginUser);  }
public ActiveStats roll() {    long now = System.currentTimeMillis();    setEndTime(now);    ActiveStats statsBean = new ActiveStats().setStartTime(now)                                             .setDataCollectorVersion(getDataCollectorVersion())                                             .setDpmEnabled(isDpmEnabled())                                             .setUpTime(getUpTime().roll());    statsBean.setPipelines(getPipelines().stream().map(UsageTimer::roll).collect(Collectors.toList()));    statsBean.setStages(getStages().stream()                                   .filter(timer -> timer.getMultiplier() > 0)                                   .map(UsageTimer::roll)                                   .collect(Collectors.toList()));    return statsBean;  }
public ActiveStats snapshot() {    ActiveStats snapshot = new ActiveStats().setStartTime(getStartTime())                                            .setDataCollectorVersion(getDataCollectorVersion())                                            .setDpmEnabled(isDpmEnabled())                                            .setUpTime(getUpTime().snapshot())                                            .setRecordCount(getRecordCount());    snapshot.setPipelines(getPipelines().stream().map(UsageTimer::snapshot).collect(Collectors.toList()));    snapshot.setStages(getStages().stream().map(UsageTimer::snapshot).collect(Collectors.toList()));    return snapshot;  }
private void ensureDirectoryExists(FileSystem fs, Path path) throws IOException {    if(!fs.exists(path)) {      LOG.debug("Creating directory: {}", path);      if(!fs.mkdirs(path)) {        throw new IOException("Can't create directory: " + path);      }    }  }
@Override  public CredentialValue get(String group, String name, String credentialStoreOptions) throws StageException {    Utils.checkNotNull(group, "group cannot be NULL");    Utils.checkNotNull(name, "name cannot be NULL");    try {      Map<String, String> optionsMap =          Splitter.on(",").omitEmptyStrings().trimResults().withKeyValueSeparator("=").split(credentialStoreOptions);      String separator = optionsMap.get(SEPARATOR_OPTION);      if (separator == null) {        separator = pathKeySeparator;      }      String[] splits = name.split(separator, 2);      if (splits.length != 2) {        throw new IllegalArgumentException(Utils.format("Vault CredentialStore name '{}' should be <path>{}<key>",            name, separator        ));      }      String delayStr = optionsMap.get(DELAY_OPTION);      long delay = (delayStr == null) ? 0 : Long.parseLong(delayStr);      CredentialValue credential = new VaultCredentialValue(splits[0], splits[1], delay);      credential.get();      return credential;    } catch (Exception ex) {      throw new StageException(Errors.VAULT_001, name, ex);    }  }
public String formatSqlException(SQLException ex) {    StringBuilder sb = new StringBuilder();    Set<String> messages = new HashSet<>();    for (Throwable e : ex) {      if (e instanceof SQLException) {        String message = e.getMessage();        if (!messages.add(message)) {          continue;        }        sb.append("SQLState: " + ((SQLException) e).getSQLState() + "\n")            .append("Error Code: " + ((SQLException) e).getErrorCode() + "\n")            .append("Message: " + message + "\n");        Throwable t = ex.getCause();        while (t != null) {          if (messages.add(t.getMessage())) {            sb.append("Cause: " + t + "\n");          }          t = t.getCause();        }      }    }    return sb.toString();  }
private String getCatalog(Connection connection, String schema) throws SQLException {    if (Strings.isNullOrEmpty(schema)) {      return connection.getCatalog();    }    String name = connection.getMetaData().getDatabaseProductName().toLowerCase();    for (String d : RDBMS_WITHOUT_SCHEMAS) {      if (name.contains(d)) {        return schema;      }    }    return connection.getCatalog();  }
public ResultSet getColumnMetadata(Connection connection, String schema, String tableName) throws SQLException {    DatabaseMetaData metadata = connection.getMetaData();    // Get all columns for this table    return metadata.getColumns(getCatalog(connection, schema), schema, tableName, null);  }
public ResultSet getTableAndViewMetadata(      Connection connection,      String schema,      String tableName  ) throws SQLException {    return connection.getMetaData().getTables(        getCatalog(connection, schema),        schema,        tableName,        METADATA_TABLE_VIEW_TYPE    );  }
public ResultSet getTableMetadata(Connection connection, String schema, String tableName) throws SQLException {    DatabaseMetaData metadata = connection.getMetaData();    return metadata.getTables(getCatalog(connection, schema), schema, tableName, METADATA_TABLE_TYPE);  }
public List<String> getPrimaryKeys(Connection connection, String schema, String tableName) throws SQLException {    String table = tableName;    DatabaseMetaData metadata = connection.getMetaData();    List<String> keys = new ArrayList<>();    try (ResultSet result = metadata.getPrimaryKeys(getCatalog(connection, schema), schema, table)) {      while (result.next()) {        keys.add(result.getString(COLUMN_NAME));      }    }    return keys;  }
public Set<String> getReferredTables(Connection connection, String schema, String tableName) throws SQLException {    DatabaseMetaData metadata = connection.getMetaData();    ResultSet result = metadata.getImportedKeys(getCatalog(connection, schema), schema, tableName);    Set<String> referredTables = new HashSet<>();    while (result.next()) {      referredTables.add(result.getString(PK_TABLE_NAME));    }    return referredTables;  }
public void write(      Batch batch,      SchemaTableClassifier schemaTableClassifier,      LoadingCache<SchemaAndTable, JdbcRecordWriter> recordWriters,      ErrorRecordHandler errorRecordHandler,      boolean perRecord  ) throws StageException {    Multimap<SchemaAndTable, Record> partitions = schemaTableClassifier.classify(batch);    for (SchemaAndTable key : partitions.keySet()) {      Iterator<Record> recordIterator = partitions.get(key).iterator();      write(recordIterator, key, recordWriters, errorRecordHandler, perRecord);    }  }
public void write(      Batch batch,      ELEval tableNameEval,      ELVars tableNameVars,      String tableNameTemplate,      LoadingCache<String, JdbcRecordWriter> recordWriters,      ErrorRecordHandler errorRecordHandler,      boolean perRecord  ) throws StageException {    Multimap<String, Record> partitions = ELUtils.partitionBatchByExpression(        tableNameEval,        tableNameVars,        tableNameTemplate,        batch    );    for (String tableName : partitions.keySet()) {      Iterator<Record> recordIterator = partitions.get(tableName).iterator();      write(recordIterator, tableName, recordWriters, errorRecordHandler, perRecord);    }  }
public <T> void write(      Iterator<Record> recordIterator,      T key,      LoadingCache<T, JdbcRecordWriter> recordWriters,      ErrorRecordHandler errorRecordHandler,      boolean perRecord  ) throws StageException {    final JdbcRecordWriter jdbcRecordWriter;    try {      jdbcRecordWriter = recordWriters.getUnchecked(key);    } catch (UncheckedExecutionException ex) {      final Throwable throwable = ex.getCause();      final ErrorCode errorCode;      final Object[] messageParams;      if (throwable instanceof StageException) {        StageException stageEx = (StageException) ex.getCause();        errorCode = stageEx.getErrorCode();        messageParams = stageEx.getParams();      } else {        errorCode = JdbcErrors.JDBC_301;        messageParams = new Object[] {ex.getMessage(), ex.getCause()};      }      // Failed to create RecordWriter, report all as error records.      while (recordIterator.hasNext()) {        Record record = recordIterator.next();        errorRecordHandler.onError(new OnRecordErrorException(record, errorCode, messageParams));      }      return;    }    List<OnRecordErrorException> errors = perRecord        ? jdbcRecordWriter.writePerRecord(recordIterator)        : jdbcRecordWriter.writeBatch(recordIterator);    for (OnRecordErrorException error : errors) {      errorRecordHandler.onError(error);    }  }
public void generateNoMoreDataEvent(PushSource.Context context) {    LOG.info("No More data to process, Triggered No More Data Event");    BatchContext batchContext = context.startBatch();    CommonEvents.NO_MORE_DATA.create(context, batchContext).createAndSend();    context.processBatch(batchContext);  }
private Map<PartitionInfoCacheSupport.PartitionValues, String> detectNewPartition(      PartitionInfoCacheSupport.PartitionValues partitionValues,      PartitionInfoCacheSupport.PartitionInfo pCache,      String location  ) throws StageException{    Map<PartitionInfoCacheSupport.PartitionValues, String> partitionInfoDiff = new HashMap<>();    partitionInfoDiff.put(partitionValues, location);    partitionInfoDiff        = (pCache != null)? pCache.getDiff(partitionInfoDiff) : partitionInfoDiff;    if (pCache == null || !partitionInfoDiff.isEmpty()){      return partitionInfoDiff;    }    return null;  }
@VisibleForTesting  LinkedHashMap<String, String> getPartitionValuesFromRecord(ELVars variables) throws StageException {    LinkedHashMap<String, String> values = new LinkedHashMap<>();    for (PartitionConfig pName: partitionConfigList) {      String ret = HiveMetastoreUtil.resolveEL(elEvals.partitionValueELEval, variables, pName.valueEL);      if (ret == null || ret.isEmpty()) {        // If no partition value is found in record, this record goes to Error Record        throw new HiveStageCheckedException(Errors.HIVE_METADATA_02, pName.valueEL);      } else if (HiveMetastoreUtil.hasUnsupportedChar(ret)){        throw new HiveStageCheckedException(Errors.HIVE_METADATA_10, pName.valueEL, ret);      }      values.put(pName.name.toLowerCase(), ret);    }    return values;  }
@VisibleForTesting  Record generateNewPartitionRecord(      String database,      String tableName,      LinkedHashMap<String, String> partitionList,      String location,      boolean customLocation,      Map<String, String> metadataHeaderAttributes) throws StageException {    //creating a record with uuid as postfix so multiple SDCs won't generate the record with same id.    Record metadataRecord = getContext().createRecord("Partition Metadata Record" + UUID.randomUUID().toString());    Field metadataField = HiveMetastoreUtil.newPartitionMetadataFieldBuilder(        database,        tableName,        partitionList,        location,        customLocation,        dataFormat    );    metadataRecord.set(metadataField);    for (Map.Entry<String, String> entry : metadataHeaderAttributes.entrySet()){      metadataRecord.getHeader().setAttribute(entry.getKey(), entry.getValue());    }    return metadataRecord;  }
@VisibleForTesting  static void updateRecordForHDFS(      Record record,      boolean roll,      String avroSchema,      String location  ){    if(roll){      record.getHeader().setAttribute(HDFS_HEADER_ROLL, "true");    }    record.getHeader().setAttribute(HDFS_HEADER_AVROSCHEMA, avroSchema);    record.getHeader().setAttribute(HDFS_HEADER_TARGET_DIRECTORY, location);    LOG.trace("Record {} will be stored in {} path: roll({}), avro schema: {}", record.getHeader().getSourceId(), location, roll, avroSchema);  }
public void process(String group, T value) {    getData().process(ImmutableMap.of(group, value));  }
public static boolean isSameVersion(Class<? extends Stage> a, Class<? extends Stage> b) {    StageDef aDef = a.getAnnotation(StageDef.class);    StageDef bDef = b.getAnnotation(StageDef.class);    return aDef.version() == bDef.version();  }
public static void main(String[] args) throws Exception {    BootstrapCluster.printSystemPropsEnvVariables();    String mesosDir = System.getenv("MESOS_DIRECTORY");    if (mesosDir == null) {      throw new IllegalStateException("Expected the env. variable MESOS_DIRECTORY to be defined");    }    File mesosHomeDir = new File(mesosDir);    String sparkDir = System.getenv("SPARK_HOME");    if (sparkDir == null) {      throw new IllegalStateException("Expected the env. variable SPARK_HOME to be defined");    }    File sparkHomeDir = new File(sparkDir);    int processExitValue = BootstrapCluster.findAndExtractJar(mesosHomeDir, sparkHomeDir);    if (processExitValue != 0) {      throw new IllegalStateException(        "Process extracting archives from uber jar exited abnormally; check Mesos driver stdout file");    }    System.setProperty("SDC_MESOS_BASE_DIR",      new File(mesosHomeDir, BootstrapCluster.SDC_MESOS_BASE_DIR).getAbsolutePath());    final Class<?> clazz = Class.forName("com.streamsets.pipeline.BootstrapClusterStreaming");    final Method method = clazz.getMethod("main", String[].class);    method.invoke(null, new Object[] { args });  }
public void forceQuit() {    synchronized (relatedTasks){      if (runningThread != null) {        runningThread.interrupt();        runningThread = null;        cancelTask();        postStop();      }    }    countDownLatch.countDown();  }
private void configureAuthAndBuildClient(      ClientBuilder clientBuilder,      List<Stage.ConfigIssue> issues  ) {    if (jerseyClientConfig.authType == AuthenticationType.OAUTH) {      String consumerKey = jerseyClientConfig.oauth.resolveConsumerKey(context,"CREDENTIALS", "conf.oauth.", issues);      String consumerSecret = jerseyClientConfig.oauth.resolveConsumerSecret(context, "CREDENTIALS", "conf.oauth.", issues);      String token = jerseyClientConfig.oauth.resolveToken(context, "CREDENTIALS", "conf.oauth.", issues);      String tokenSecret = jerseyClientConfig.oauth.resolveTokenSecret(context, "CREDENTIALS", "conf.oauth.", issues);      if(issues.isEmpty()) {        authToken = JerseyClientUtil.configureOAuth1(          consumerKey,          consumerSecret,          token,          tokenSecret,          clientBuilder        );      }    } else if (jerseyClientConfig.authType.isOneOf(AuthenticationType.DIGEST, AuthenticationType.BASIC, AuthenticationType.UNIVERSAL)) {      String username = jerseyClientConfig.basicAuth.resolveUsername(context,"CREDENTIALS", "conf.basicAuth.", issues);      String password = jerseyClientConfig.basicAuth.resolvePassword(context,"CREDENTIALS", "conf.basicAuth.", issues);      if(issues.isEmpty()) {        JerseyClientUtil.configurePasswordAuth(          jerseyClientConfig.authType,          username,          password,          clientBuilder        );      }    }    try {      buildNewAuthenticatedClient(issues, false);      clientInitialized = true;    } catch (StageException e) {      // should not happen, since we passed throwExceptions as false above      ExceptionUtils.throwUndeclared(e);    }  }
public boolean requestContainsSensitiveInfo(Map<String, String> headers, String requestBody) {    boolean sensitive = false;    for (Map.Entry<String, String> header : headers.entrySet()) {      if (header.getKey().contains(VAULT_EL_PREFIX) || header.getValue().contains(VAULT_EL_PREFIX)) {        sensitive = true;        break;      }    }    if (requestBody != null && requestBody.contains(VAULT_EL_PREFIX)) {      sensitive = true;    }    return sensitive;  }
public MultivaluedMap<String, Object> resolveHeaders(      Map<String, String> headers,      Record record  ) throws StageException {    RecordEL.setRecordInContext(headerVars, record);    MultivaluedMap<String, Object> requestHeaders = new MultivaluedHashMap<>();    for (Map.Entry<String, String> entry : headers.entrySet()) {      List<Object> header = new ArrayList<>(1);      Object resolvedValue = headerEval.eval(headerVars, entry.getValue(), String.class);      header.add(resolvedValue);      requestHeaders.put(entry.getKey(), header);    }    return requestHeaders;  }
public HttpMethod getHttpMethod(      HttpMethod httpMethod,      String methodExpression,      Record record  ) throws ELEvalException {    if (httpMethod != HttpMethod.EXPRESSION) {      return httpMethod;    }    RecordEL.setRecordInContext(methodVars, record);    return HttpMethod.valueOf(methodEval.eval(methodVars, methodExpression, String.class));  }
public static void fillNullTypes(SimpleBindings bindings) {    bindings.put("NULL_BOOLEAN", NULL_BOOLEAN);    bindings.put("NULL_CHAR", NULL_CHAR);    bindings.put("NULL_BYTE", NULL_BYTE);    bindings.put("NULL_SHORT", NULL_SHORT);    bindings.put("NULL_INTEGER", NULL_INTEGER);    bindings.put("NULL_LONG", NULL_LONG);    bindings.put("NULL_FLOAT", NULL_FLOAT);    bindings.put("NULL_DOUBLE", NULL_DOUBLE);    bindings.put("NULL_DATE", NULL_DATE);    bindings.put("NULL_DATETIME", NULL_DATETIME);    bindings.put("NULL_TIME", NULL_TIME);    bindings.put("NULL_DECIMAL", NULL_DECIMAL);    bindings.put("NULL_BYTE_ARRAY", NULL_BYTE_ARRAY);    bindings.put("NULL_STRING", NULL_STRING);    bindings.put("NULL_LIST", NULL_LIST);    bindings.put("NULL_MAP", NULL_MAP);  }
public static Object getFieldNull(Record record, String fieldPath) {    Field f = record.get(fieldPath);    if (f != null ) {      return f.getValue() == null? getTypedNullFromField(f) : f.getValue();    }    return null;  }
public static Field getTypedNullFieldFromScript(Object scriptObject) {    Field field;    if(scriptObject == NULL_BOOLEAN)      field = Field.create(Field.Type.BOOLEAN, null);    else if(scriptObject == NULL_CHAR)      field = Field.create(Field.Type.CHAR, null);    else if(scriptObject == NULL_BYTE)      field = Field.create(Field.Type.BYTE, null);    else if(scriptObject == NULL_SHORT)      field = Field.create(Field.Type.SHORT, null);    else if (scriptObject == NULL_INTEGER)      field = Field.create(Field.Type.INTEGER, null);    else if(scriptObject == NULL_LONG)      field = Field.create(Field.Type.LONG, null);    else if (scriptObject == NULL_FLOAT)      field = Field.create(Field.Type.FLOAT, null);    else if(scriptObject == NULL_DOUBLE)      field = Field.create(Field.Type.DOUBLE, null);    else if(scriptObject == NULL_DATE)      field = Field.createDate(null);    else if(scriptObject == NULL_DATETIME)      field = Field.createDatetime(null);    else if(scriptObject == NULL_TIME)      field = Field.createTime(null);    else if(scriptObject == NULL_DECIMAL)      field = Field.create(Field.Type.DECIMAL, null);    else if(scriptObject == NULL_BYTE_ARRAY)      field = Field.create(Field.Type.BYTE_ARRAY, null);    else if(scriptObject == NULL_STRING)      field = Field.create(Field.Type.STRING, null);    else if(scriptObject == NULL_LIST)      field = Field.create(Field.Type.LIST, null);    else if(scriptObject == NULL_MAP)      field = Field.create(Field.Type.MAP, null);    else  //this scriptObject is not Null typed field. Return null.      field = null;    return field;  }
public Field getDateTimeStampField(      String column,      String columnValue,      int columnType,      String actualType  ) throws StageException {    Field.Type type;    if (DATE.equalsIgnoreCase(actualType)) {      type = Field.Type.DATE;    } else if (TIME.equalsIgnoreCase(actualType)) {      type = Field.Type.TIME;    } else if (TIMESTAMP.equalsIgnoreCase(actualType)) {      type = Field.Type.DATETIME;    } else {      throw new StageException(JDBC_37, columnType, column);    }    if (columnValue == null) {      return Field.create(type, null);    } else {      Optional<String> ts = matchDateTimeString(toTimestampPattern.matcher(columnValue));      if (ts.isPresent()) {        if (timestampAsString) {          return Field.create(Field.Type.STRING, ts.get());        }        Timestamp timestamp = Timestamp.valueOf(ts.get());        Field field = Field.create(type, timestamp);        JdbcUtil.setNanosecondsinAttribute(timestamp.getNanos(), field);        return field;      }      // We did not find TO_TIMESTAMP, so try TO_DATE      Optional<String> dt = matchDateTimeString(toDatePattern.matcher(columnValue));      return Field.create(Field.Type.DATE,          dt.map(s -> Date.from(getDate(s).atZone(zoneId).toInstant())).orElse(null));    }  }
public Schema loadFromRegistry(String subject, int schemaId) throws SchemaRegistryException {    try {      if (isEmpty(subject)) {        return loadFromRegistry(schemaId);      } else {        return loadFromRegistry(subject);      }    } catch (SchemaRegistryException e) {      throw new SchemaRegistryException(e);    }  }
public int registerSchema(Schema schema, String subject) throws SchemaRegistryException {    try {      return schemaIdCache.get(subject + schema.hashCode(), () -> registryClient.register(subject, schema));    } catch (ExecutionException  e) {      throw new SchemaRegistryException(e);    }  }
public Schema loadFromRegistry(String subject) throws SchemaRegistryException {    try {      SchemaMetadata metadata = registryClient.getLatestSchemaMetadata(subject);      return registryClient.getByID(metadata.getId());    } catch (IOException | RestClientException e) {      throw new SchemaRegistryException(e);    }  }
public int getSchemaIdFromSubject(String subject) throws SchemaRegistryException {    try {      SchemaMetadata metadata = registryClient.getLatestSchemaMetadata(subject);      return metadata.getId();    } catch (IOException | RestClientException e) {      throw new SchemaRegistryException(e);    }  }
public Schema loadFromRegistry(int id) throws SchemaRegistryException {    try {      return registryClient.getByID(id);    } catch (IOException | RestClientException e) {      throw new SchemaRegistryException(e);    }  }
public int writeSchemaId(OutputStream os, int schemaId) throws IOException {    if (schemaId > 0) {      os.write(MAGIC_BYTE);      os.write(ByteBuffer.allocate(ID_SIZE).putInt(schemaId).array());    }    return schemaId;  }
public Optional<Integer> detectSchemaId(byte[] data) {    if (data.length < 5) {      return Optional.empty();    }    ByteBuffer wrapped = ByteBuffer.wrap(data);    // 5 == MAGIC_BYTE + ID_SIZE    if (wrapped.get() != MAGIC_BYTE) {      return Optional.empty();    }    return Optional.of(wrapped.getInt());  }
public static Map<String, Object> getDefaultValues(Schema schema) throws SchemaRegistryException {    Map<String, Object> defaultValues = new HashMap<>();    try {      defaultValues.putAll(AvroTypeUtil.getDefaultValuesFromSchema(schema, new HashSet<String>()));    } catch (IOException e) {      throw new SchemaRegistryException(e);    }    return defaultValues;  }
public static List<Record> parseAll(    Stage.Context stageContext,    ToErrorContext toErrorContext,    boolean produceSingleRecordPerMessage,    String messageId,    byte[] payload  ) throws StageException {    List<Record> records = new ArrayList<>();    try (DataParser parser = stageContext.getService(DataFormatParserService.class).getParser(messageId, payload)) {      Record record = null;      do {        try {          record = parser.parse();        } catch (RecoverableDataParserException e) {          handleException(stageContext, toErrorContext, messageId, e, e.getUnparsedRecord());          //Go to next record          continue;        }        if (record != null) {          records.add(record);        }      } while (record != null);    } catch (IOException |DataParserException ex) {      Record record = stageContext.createRecord(messageId);      record.set(Field.create(payload));      handleException(stageContext, toErrorContext, messageId, ex, record);      return records;    }    if (produceSingleRecordPerMessage) {      List<Field> list = new ArrayList<>();      for (Record record : records) {        list.add(record.get());      }      Record record = records.get(0);      record.set(Field.create(list));      records.clear();      records.add(record);    }    return records;  }
public void logDetails() {    if(isValid()) {      return;    }    LOG.warn("Validation results for {}", name);    if(!unparseablePaths.isEmpty()) {      LOG.warn("Can't parse the following artifacts:");      for(String path : unparseablePaths) {        LOG.warn("  {}", path);      }    }    if(!versionCollisions.isEmpty()) {      LOG.warn("Detected colliding dependency versions:");      for(Map.Entry<String, Map<String, List<Dependency>>> entry : versionCollisions.entrySet()) {        LOG.warn("  Dependency {} have versions: {}", entry.getKey(), StringUtils.join(entry.getValue().keySet(), ", "));        for(Map.Entry<String, List<Dependency>> versionEntry : entry.getValue().entrySet()) {          LOG.warn("    Version: {}", versionEntry.getKey());          for(Dependency dependency: versionEntry.getValue()) {            LOG.warn("      {}", dependency.getSourceName());          }        }      }    }  }
private String toFieldName(String fieldPath) {    String path = fieldPath.substring(1).replaceAll("/", ".");    path = "/" + path;    return EscapeUtil.getLastFieldNameFromPath(path);  }
public void init(Source.Context context, String groupName, String prefix, List<Stage.ConfigIssue> issues) {    // Validate the ELs for string configs    List<String> elConfigs = ImmutableList.of("resourceUrl", "requestBody");    for (String configName : elConfigs) {      ELVars vars = context.createELVars();      vars.addVariable(START_AT, 0);      ELEval eval = context.createELEval(configName);      try {        eval.eval(vars, (String)getClass().getField(configName).get(this), String.class);      } catch (ELEvalException | NoSuchFieldException | IllegalAccessException e) {        LOG.error(Errors.HTTP_06.getMessage(), e.toString(), e);        issues.add(context.createConfigIssue(groupName, prefix + configName, Errors.HTTP_06, e.toString()));      }    }    client.init(context, Groups.PROXY.name(), prefix + "client.", issues);    // Validate the EL for each header entry    ELVars headerVars = context.createELVars();    ELEval headerEval = context.createELEval("headers");    for (String headerValue : headers.values()) {      try {        headerEval.eval(headerVars, headerValue, String.class);      } catch (ELEvalException e) {        LOG.error(Errors.HTTP_06.getMessage(), e.toString(), e);        issues.add(context.createConfigIssue(groupName, prefix + "headers", Errors.HTTP_06, e.toString()));      }    }  }
private void processResponse(      Record record,      Future<Response> responseFuture,      long maxRequestCompletionSecs,      boolean failOn403  ) throws StageException {    Response response;    try {      response = responseFuture.get(maxRequestCompletionSecs, TimeUnit.SECONDS);      String responseBody = "";      if (response.hasEntity()) {        responseBody = response.readEntity(String.class);      }      response.close();      if (conf.client.useOAuth2 && response.getStatus() == 403 && !failOn403) {        HttpStageUtil.getNewOAuth2Token(conf.client.oauth2, httpClientCommon.getClient());      } else if (response.getStatus() < 200 || response.getStatus() >= 300) {        throw new OnRecordErrorException(            record,            Errors.HTTP_40,            response.getStatus(),            response.getStatusInfo().getReasonPhrase() + " " + responseBody        );      } else {        if (conf.responseConf.sendResponseToOrigin) {          if (ResponseType.SUCCESS_RECORDS.equals(conf.responseConf.responseType)) {            getContext().toSourceResponse(record);          } else {            getContext().toSourceResponse(createResponseRecord(responseBody));          }        }      }    } catch (InterruptedException | ExecutionException e) {      LOG.error(Errors.HTTP_41.getMessage(), e.toString(), e);      throw new OnRecordErrorException(record, Errors.HTTP_41, e.toString());    } catch (TimeoutException e) {      LOG.error("HTTP request future timed out", e.toString(), e);      throw new OnRecordErrorException(record, Errors.HTTP_41, e.toString());    }  }
private String binLogRecordFieldtoSdc(String fieldPath, int operation) {    if (operation == KuduOperationType.DELETE.code) {      return "/OldData" + fieldPath;    }    return fieldPath;  }
private List<Record> getBadRecords(ErrorSink errorSink) {    List<Record> badRecords = new ArrayList<>();    for (Map.Entry<String, List<Record>> entry : errorSink.getErrorRecords().entrySet()) {      for (Record record : entry.getValue()) {        RecordImpl errorRecord;        switch (errorRecordPolicy) {          case ORIGINAL_RECORD:            errorRecord = (RecordImpl) ((RecordImpl)record).getHeader().getSourceRecord();            errorRecord.getHeader().copyErrorFrom(record);            break;          case STAGE_RECORD:            errorRecord = (RecordImpl) record;            break;          default:           throw new IllegalArgumentException("Uknown error record policy: " + errorRecordPolicy);        }        errorRecord.getHeader().setErrorContext(runtimeInfo.getId(), pipelineName);        badRecords.add(errorRecord);      }    }    return badRecords;  }
public int compare(Version other) {    int maxParts = Math.max(this.versions.length, other.versions.length);    for(int i = 0; i < maxParts; i++) {      int eq = this.getVersionPosition(i) - other.getVersionPosition(i);      if(eq != 0) {        if(eq > 0) {          return 1;        } else {          return -1;        }      }    }    return 0;  }
public List<Stage.ConfigIssue> init(SchemaGeneratorConfig config, Stage.Context context) {    this.config = config;    return Collections.emptyList();  }
public Collection<V> getOutwardEdgeVertices(V vertex) {    Collection<V> outwardEdgeVerticesForVertex =  outwardEdgeVertices.get(vertex);    return outwardEdgeVerticesForVertex != null ? outwardEdgeVerticesForVertex : Collections.<V>emptySet();  }
public Collection<V> getInwardEdgeVertices(V vertex) {    Collection<V> inwardEdgeVerticesForVertex =  inwardEdgesVertices.get(vertex);    return inwardEdgeVerticesForVertex != null ? inwardEdgeVerticesForVertex : Collections.<V>emptySet();  }
public void addDirectedEdge(V vertex1, V vertex2) {    addVertex(vertex1);    addVertex(vertex2);    outwardEdgeVertices.put(vertex1, vertex2);    inwardEdgesVertices.put(vertex2, vertex1);  }
public static String serializeOffsetMap(Map<String, String> offsetMap) throws IOException {    return JSON_MAPPER.writeValueAsString(offsetMap);  }
@SuppressWarnings("unchecked")  public static Map<String, String> deserializeOffsetMap(String lastSourceOffset) throws IOException {    Map<String, String> offsetMap;    if (lastSourceOffset == null || lastSourceOffset.isEmpty()) {      offsetMap = new HashMap<>();    } else {      offsetMap = JSON_MAPPER.readValue(lastSourceOffset, Map.class);    }    return offsetMap;  }
public int queueReport() throws IOException, InterruptedException, ExecutionException, TimeoutException, StageException {    final AsyncInvoker asyncInvoker = queueResource.request()        .header(WSSE_HEADER, OmnitureAuthUtil.getHeader(username.get(), sharedSecret.get()))        .async();    LOG.debug("Queueing report using URL {} with description {}",        queueResource.getUri().toURL().toString(), reportDescription);    final Future<Response> responseFuture = asyncInvoker.post(Entity.json(reportDescription));    Response response = responseFuture.get(responseTimeoutMillis, TimeUnit.MILLISECONDS);    if (response == null) {      LOG.error("Failed to get response using URL {}", queueResource.getUri().toURL().toString());      throw new StageException(Errors.OMNITURE_01, "HTTP response was null");    }    LOG.debug("Received response: status {}", response.getStatus());    ObjectMapper mapper = new ObjectMapper();    String json = response.readEntity(String.class);    LOG.trace("Response JSON: {}", json);    JsonNode root = mapper.readTree(json);    if (root == null) {      LOG.error("Invalid JSON in response: {}", json);      throw new StageException(Errors.OMNITURE_01, json);    }    if (root.has("error")) {      throw new StageException(Errors.OMNITURE_01, root.get("error_description").asText());    }    LOG.info("Omniture report queued");    return root.get("reportID").asInt();  }
public void getReport(int reportId)      throws InterruptedException, ExecutionException, TimeoutException, IOException, StageException {    int waitTime = 1000;    Response response = null;    while (!stop) {      final AsyncInvoker asyncInvoker = getResource.request()          .header(WSSE_HEADER, OmnitureAuthUtil.getHeader(username.get(), sharedSecret.get()))          .async();      LOG.debug("Getting report using URL {} with report ID {}", getResource.getUri().toURL().toString(), reportId);      final Future<Response> responseFuture = asyncInvoker.post(Entity.json("{ \"reportID\": " + reportId + " }"));      response = responseFuture.get(responseTimeoutMillis, TimeUnit.MILLISECONDS);      String input = response.readEntity(String.class);      ObjectMapper mapper = new ObjectMapper();      JsonNode root = mapper.readTree(input);      // If the report has an error field, it means the report has not finished generating      if (!root.has("error")) {        boolean accepted = entityQueue.offer(input, responseTimeoutMillis, TimeUnit.MILLISECONDS);        if (!accepted) {          LOG.warn("Response buffer full, dropped record.");        }        break;      } else {        // Exponential backoff while making subsequent Report.Get requests        if (root.get("error").textValue().equals("report_not_ready")) {          waitTime *= 2;          LOG.info("Report not available. Sleeping for {} seconds", waitTime / 1000);          Thread.sleep(waitTime);        } else {          throw new StageException(Errors.OMNITURE_02,              root.get("error").get("error_description").asText());        }      }    }    response.close();  }
public boolean isSDCCheckPointing()  {    try {      return fs.exists(checkPointFilePath) || fs.exists(backupCheckPointFilePath);    } catch (IOException ex) {      LOG.error("Error doing isSDCCheckPointing", ex);      throw new RuntimeException(Utils.format("Error checking exists on hdfs path: {}. Reason: {}", checkPointFilePath.toString(), ex.toString()), ex);    }  }
private void writeOffsetsToMainOffsetFile(Map<Integer, Long> partitionToOffsetMap) throws IOException {    LOG.info("Saving the following offset {} to {}", partitionToOffsetMap, checkPointFilePath);    //Creating a marker file (overwriting if it already exists) to mark that we are going to write offsets out the offsets to the main offset file.    try(OutputStream os = fs.create(checkPointMarkerFilePath, true)) {      //NOOP    }    //If the both above passes and writing fails or leaves corrupted file we will have the back file    try (OutputStream os = fs.create(checkPointFilePath, true)) {      OBJECT_MAPPER.writeValue(os, new ClusterSourceOffsetJson(serializeKafkaPartitionOffset(partitionToOffsetMap), SDC_STREAMING_OFFSET_VERSION));    }    //If this fails we are still good, as we will start from the backup offset file. (Not optimal, but deterministic)    boolean deleted = fs.delete(checkPointMarkerFilePath, false);    LOG.warn("Status {} for Deleting Marker File {}", deleted, checkPointMarkerFilePath);    //If the write fails we don't want to touch the timestamp and will error out so not doing this in finally    lastOffsetStoredTime = System.currentTimeMillis();  }
private Map<Integer, Long> readClusterOffsetFile(Path checkPointFilePath, int numberOfPartitions) throws IOException{    if (!fs.exists(checkPointFilePath)) {      throw new IOException(Utils.format("Checkpoint file path {} does not exist", checkPointFilePath));    }    ClusterSourceOffsetJson clusterSourceOffsetJson = OBJECT_MAPPER.readValue(        (InputStream) fs.open(checkPointFilePath),        ClusterSourceOffsetJson.class    );    String lastSourceOffset = clusterSourceOffsetJson.getOffset();    if (!StringUtils.isEmpty(lastSourceOffset)) {      return deserializeKafkaPartitionOffset(lastSourceOffset, numberOfPartitions);    } else {      throw new IOException("Partition Offset Cannot be empty");    }  }
public TableOrderProvider create() {    switch (tableOrderStrategy) {      case NONE:        //Don't do any ordering, just add tables as per the incoming order.        return new DefaultTableOrderProvider(new LinkedHashSet<>());      case ALPHABETICAL:        //Alphabetical sorting based on table qualified names.        return new DefaultTableOrderProvider(new TreeSet<>());      case REFERENTIAL_CONSTRAINTS:        return new ReferentialTblOrderProvider(connection);      default:        throw new IllegalArgumentException(Utils.format("Unknown table order strategy: {}", tableOrderStrategy));    }  }
private void delete(BlobId blobId) {    LOG.debug("Deleting object '{}'", String.format(BLOB_PATH_TEMPLATE, blobId.getBucket(), blobId.getName()));    boolean deleted = storage.delete(blobId);    if (!deleted) {      LOG.error("Cannot delete object '{}'", String.format(BLOB_PATH_TEMPLATE, blobId.getBucket(), blobId.getName()));    }  }
private void copy(BlobId sourceBlobId, String destinationBucket, String destinationPath, boolean deleteSource) {    LOG.debug(        "Copying object '{}' to Object '{}'",        String.format(BLOB_PATH_TEMPLATE, sourceBlobId.getBucket(), sourceBlobId.getName()),        String.format(BLOB_PATH_TEMPLATE, destinationBucket, destinationPath)    );    Storage.CopyRequest copyRequest = new Storage.CopyRequest.Builder()        .setSource(sourceBlobId)        .setTarget(BlobId.of(destinationBucket, destinationPath))        .build();    Blob destinationBlob = storage.copy(copyRequest).getResult();    LOG.debug(        "Copied object '{}' to Object '{}'",        String.format(BLOB_PATH_TEMPLATE, sourceBlobId.getBucket(), sourceBlobId.getName()),        String.format(BLOB_PATH_TEMPLATE, destinationBlob.getBlobId().getBucket(), destinationBlob.getBlobId().getName())    );    if (deleteSource) {      delete(sourceBlobId);    }  }
void handleError(BlobId blobId) {    switch (gcsOriginErrorConfig.errorHandlingOption) {      case NONE:        break;      case ARCHIVE:        handleArchive(blobId);        break;      case DELETE:        delete(blobId);        break;    }  }
private void handleArchive(BlobId blobId) {    String destinationPath = getDestinationPath(blobId, gcsOriginErrorConfig.errorPrefix);    switch (gcsOriginErrorConfig.archivingOption) {      case COPY_TO_BUCKET:        copy(blobId, gcsOriginErrorConfig.errorBucket, destinationPath, false);        break;      case MOVE_TO_BUCKET:        copy(blobId, gcsOriginErrorConfig.errorBucket, destinationPath, true);        break;      case COPY_TO_PREFIX:        copy(blobId, blobId.getBucket(), destinationPath, false);        break;      case MOVE_TO_PREFIX:        copy(blobId, blobId.getBucket(), destinationPath, true);        break;    }  }
public LiveFileReader getReader() throws IOException {    Utils.checkState(open, "FileContext is closed");    if (reader == null) {      currentFile = getStartingCurrentFileName();      long fileOffset = getStartingOffset();      boolean needsToScan = currentFile == null || fileOffset == Long.MAX_VALUE;      if (needsToScan) {        if (currentFile != null) {          // we need to refresh the file in case the name changed before scanning as the scanner does not refresh          currentFile = currentFile.refresh();        }        currentFile = scanner.scan(currentFile);        fileOffset = 0;      }      if (currentFile != null) {        reader = new SingleLineLiveFileReader(getRollMode(), getMultiFileInfo().getTag(), currentFile, charset,                                              fileOffset, maxLineLength);        if (!multiFileInfo.getMultiLineMainLinePatter().isEmpty()) {          reader = new MultiLineLiveFileReader(getMultiFileInfo().getTag(), reader,                                               Pattern.compile(multiFileInfo.getMultiLineMainLinePatter()));        }        if (fileOffset == 0) {          // file start event          eventPublisher.publish(new FileEvent(currentFile, FileEvent.Action.START));        }      }    }    return reader;  }
public void releaseReader(boolean inErrorDiscardReader) throws IOException {    Utils.checkState(open, "FileContext is closed");    // update starting offsets for next invocation either cold (no reader) or hot (reader)    boolean hasNext;    try {      hasNext = reader != null && reader.hasNext();    } catch (IOException ex) {      IOUtils.closeQuietly(reader);      reader = null;      hasNext = false;    }    boolean doneWithFile = !hasNext || inErrorDiscardReader;    if (doneWithFile) {      IOUtils.closeQuietly(reader);      reader = null;      // Using Long.MAX_VALUE to signal we reach the end of the file and next iteration should get the next file.      setStartingCurrentFileName(currentFile);      setStartingOffset(Long.MAX_VALUE);      // If we failed to open the file in first place, it will be null and hence we won't do anything with it.      if(currentFile == null) {        return;      }      // File end event      LiveFile file = currentFile.refresh();      if (inErrorDiscardReader) {        LOG.warn("Processing file '{}' produced an error, skipping '{}' post processing on that file",                 file, postProcessing);        eventPublisher.publish(new FileEvent(file, FileEvent.Action.ERROR));      } else {        eventPublisher.publish(new FileEvent(file, FileEvent.Action.END));        switch (postProcessing) {          case NONE:            LOG.debug("File '{}' processing completed, post processing action 'NONE'", file);            break;          case DELETE:            if(!inPreviewMode) {              try {                Files.delete(file.getPath());                LOG.debug("File '{}' processing completed, post processing action 'DELETED'", file);              } catch (IOException ex) {                throw new IOException(Utils.format("Could not delete '{}': {}", file, ex.toString()), ex);              }            }            break;          case ARCHIVE:            if(!inPreviewMode) {              Path fileArchive = Paths.get(archiveDir, file.getPath().toString());              if (fileArchive == null) {                throw new IOException("Could not find archive file");              }              try {                Files.createDirectories(fileArchive.getParent());                Files.move(file.getPath(), fileArchive);                LOG.debug("File '{}' processing completed, post processing action 'ARCHIVED' as", file);              } catch (IOException ex) {                throw new IOException(Utils.format("Could not archive '{}': {}", file, ex.toString()), ex);              }            }            break;        }      }    } else {      setStartingCurrentFileName(currentFile);      setStartingOffset(getReader().getOffset());    }  }
public ApiClient setDPMBaseURL(String dpmBaseURL) {    if(dpmBaseURL != null && authentication != null) {      authentication.setDPMBaseURL(dpmBaseURL);    }    return this;  }
public ApiClient addDefaultHeader(String key, String value) {    defaultHeaderMap.put(key, value);    return this;  }
public Date parseDate(String str) {    try {      return dateFormat.parse(str);    } catch (java.text.ParseException e) {      throw new RuntimeException(e);    }  }
public String selectHeaderAccept(String[] accepts) {    if (accepts.length == 0) return null;    if (StringUtil.containsIgnoreCase(accepts, "application/json")) return "application/json";    return StringUtil.join(accepts, ",");  }
public String selectHeaderContentType(String[] contentTypes) {    if (contentTypes.length == 0) return "application/json";    if (StringUtil.containsIgnoreCase(contentTypes, "application/json")) return "application/json";    return contentTypes[0];  }
public String escapeString(String str) {    try {      return URLEncoder.encode(str, "utf8").replaceAll("\\+", "%20");    } catch (UnsupportedEncodingException e) {      return str;    }  }
public String serialize(Object obj, String contentType) throws ApiException {    if (contentType.startsWith("application/json")) {      return json.serialize(obj);    } else {      throw new ApiException(400, "can not serialize object into Content-Type: " + contentType);    }  }
private <T> T deserialize(Response response, TypeRef returnType) throws ApiException {    String contentType = null;    List<Object> contentTypes = response.getHeaders().get("Content-Type");    if (contentTypes != null && !contentTypes.isEmpty()) {      contentType = (String)contentTypes.get(0);    }    if (contentType == null) {      throw new ApiException(500, "missing Content-Type in response");    }    if (contentType.startsWith("application/json")) {      String body;      if (response.hasEntity()) {        body = response.readEntity(String.class);      } else {        body = "";      }      if (body.length() > 0) {        return json.deserialize(body, returnType);      }      return null;    } if (contentType.startsWith("image")) {      return (T) response.readEntity(InputStream.class);    } else {      throw new ApiException(500, "can not deserialize Content-Type: " + contentType);    }  }
private Client getClient() {    if(!hostMap.containsKey(basePath)) {      ClientConfig config = new ClientConfig();      config.property(ClientProperties.SUPPRESS_HTTP_COMPLIANCE_VALIDATION, true);      Client client = ClientBuilder.newClient(config);      client.register(new CsrfProtectionFilter("CSRF"));      hostMap.put(basePath, client);    }    return hostMap.get(basePath);  }
private GPUdb initConnection(KineticaConfigBean conf) throws GPUdbException, StageException {    KineticaConnectionUtils kineticaConnectionUtils = new KineticaConnectionUtils();    return kineticaConnectionUtils.getGPUdb(conf);  }
private void getTableMetadata(GPUdb gpudb, String tableName) throws GPUdbException {    KineticaTableUtils kineticaTableUtils = new KineticaTableUtils(gpudb, tableName);    type = kineticaTableUtils.getType();  }
private BulkInserter<IndexedRecord> createBulkInserter(GPUdb gpudb, Type type, KineticaConfigBean conf)      throws GPUdbException {    KineticaBulkInserterUtils kineticaBulkInserterUtils = new KineticaBulkInserterUtils(gpudb, type, conf);    return kineticaBulkInserterUtils.createBulkInserter();  }
public EventBuilder create(Stage.Context context, ToEventContext toEvent) {    return new EventBuilder(context, toEvent);  }
public static Schema buildSchema(Map<String, Schema> fields, Object... levels) {    List<Schema.Field> recordFields = new ArrayList<>(fields.size());    for (Map.Entry<String, Schema> entry : fields.entrySet()) {      recordFields.add(new Schema.Field(          entry.getKey(), entry.getValue(),          null,   // Avro's Schema.Field constructor requires doc.          entry.getValue().getJsonProp("default"))      );    }    Schema recordSchema;    if (levels.length == 0) {      recordSchema = Schema.createRecord(schemaName, null, null, false);    } else {      LinkedList<String> lvl = (LinkedList<String>)levels[0];      recordSchema = Schema.createRecord(joiner.join(lvl), null, null, false);    }    recordSchema.setFields(recordFields);    return recordSchema;  }
public static int convertFromOracleToSDCCode(String code){    try {      int intCode = Integer.parseInt(code);      switch (intCode) {        case INSERT_CODE:          return OperationType.INSERT_CODE;        case DELETE_CODE:          return OperationType.DELETE_CODE;        case UPDATE_CODE:        case SELECT_FOR_UPDATE_CODE:          return OperationType.UPDATE_CODE;        default:  //DDL_CODE          throw new UnsupportedOperationException(Utils.format("Operation code {} is not supported", code));      }    } catch (NumberFormatException ex) {      throw new NumberFormatException("Operation code must be a numeric value. " + ex.getMessage());    }  }
public static void addJarsToJob(Configuration conf, Class ...klasses) {    // Build set of jars that needs to be added, order doesn't matter for us and we will remove duplicates    Set<String> additinonalJars = new HashSet<>();    for(Class klass : klasses) {      final String jar = jarForClass(klass);      LOG.info("Adding jar {} for class {}", jar, klass.getCanonicalName());      additinonalJars.add(jar);    }    appendJars(conf, additinonalJars);  }
public static void addJarsToJob(Configuration conf, boolean allowMultiple, String... jarPatterns) {    final ClassLoader loader = MapreduceUtils.class.getClassLoader();    if (!(loader instanceof URLClassLoader)) {      throw new IllegalStateException(String.format(          "ClassLoader for %s is not an instance of URLClassLoader (it is %s), and thus this method cannot be used",          MapreduceUtils.class.getCanonicalName(),          loader.getClass().getCanonicalName()      ));    }    final URLClassLoader urlClassLoader = (URLClassLoader) loader;    addJarsToJob(conf, allowMultiple, urlClassLoader.getURLs(), jarPatterns);  }
@Override  public void initialize(InitializationInput initializationInput) {    shardId = initializationInput.getShardId();    if (LOG.isDebugEnabled()) {      LOG.debug("Initializing record processor at: {}", initializationInput.getExtendedSequenceNumber().toString());      LOG.debug("Initializing record processor for shard: {}", shardId);    }  }
@Override  public void processRecords(ProcessRecordsInput processRecordsInput) {    LOG.debug("RecordProcessor processRecords called");    try {      IRecordProcessorCheckpointer checkpointer = processRecordsInput.getCheckpointer();      startBatch();      Optional<Record> lastProcessedRecord = Optional.empty();      int recordCount = 0;      for (Record kRecord : processRecordsInput.getRecords()) {        try {          KinesisUtil.processKinesisRecord(shardId, kRecord, parserFactory).forEach(batchMaker::addRecord);          lastProcessedRecord = Optional.of(kRecord);          if (++recordCount == maxBatchSize) {            recordCount = 0;            finishBatch(checkpointer, kRecord);            startBatch();          }        } catch (DataParserException | IOException e) {          com.streamsets.pipeline.api.Record record = context.createRecord(kRecord.getSequenceNumber());          record.set(Field.create(kRecord.getData().array()));          try {            errorRecordHandler.onError(new OnRecordErrorException(                record,                Errors.KINESIS_03,                kRecord.getSequenceNumber(),                e.toString(),                e            ));            // move the lastProcessedRecord forward if not set to stop pipeline            lastProcessedRecord = Optional.of(kRecord);          } catch (StageException ex) {            // KCL skips over the data records that were passed prior to the exception            // that is, these records are not re-sent to this record processor            // or to any other record processor in the consumer.            lastProcessedRecord.ifPresent(r -> finishBatch(checkpointer, r));            try {              error.put(ex);            } catch (InterruptedException ie) {              Thread.currentThread().interrupt();            }            return;          }        }      }      lastProcessedRecord.ifPresent(r -> finishBatch(checkpointer, r));    } catch (Exception e) {      LOG.error("Unknown error while processing records: {}", e.toString(), e);      context.reportError(Errors.KINESIS_17, e.toString());    }  }
@Override  public void shutdown(ShutdownInput shutdownInput) {    LOG.info("Shutting down record processor for shard: {}", shardId);    if (ShutdownReason.TERMINATE.equals(shutdownInput.getShutdownReason())) {      // Shard is closed / finished processing. Checkpoint all processing up to here.      try {        shutdownInput.getCheckpointer().checkpoint();        LOG.debug("Checkpointed due to record processor shutdown request.");      } catch (InvalidStateException | ShutdownException e) {        LOG.error("Error checkpointing batch: {}", e.toString(), e);      }    }  }
@Override  public void process(final HttpRequest request, final HttpContext context)      throws HttpException, IOException {    URIBuilder uriBuilder;    try {      uriBuilder = new URIBuilder(request.getRequestLine().getUri());    } catch (URISyntaxException e) {      throw new IOException("Invalid URI" , e);    }    // Copy Apache HttpRequest to AWS DefaultRequest    DefaultRequest<?> signableRequest = new DefaultRequest<>(service);    HttpHost host = (HttpHost) context.getAttribute(HttpCoreContext.HTTP_TARGET_HOST);    if (host != null) {      signableRequest.setEndpoint(URI.create(host.toURI()));    }    final HttpMethodName httpMethod =        HttpMethodName.fromValue(request.getRequestLine().getMethod());    signableRequest.setHttpMethod(httpMethod);    try {      signableRequest.setResourcePath(uriBuilder.build().getRawPath());    } catch (URISyntaxException e) {      throw new IOException("Invalid URI" , e);    }    if (request instanceof HttpEntityEnclosingRequest) {      HttpEntityEnclosingRequest httpEntityEnclosingRequest =          (HttpEntityEnclosingRequest) request;      if (httpEntityEnclosingRequest.getEntity() != null) {        signableRequest.setContent(httpEntityEnclosingRequest.getEntity().getContent());      }    }    signableRequest.setParameters(nvpToMapParams(uriBuilder.getQueryParams()));    signableRequest.setHeaders(headerArrayToMap(request.getAllHeaders()));    // Sign it    signer.sign(signableRequest, awsCredentialsProvider.getCredentials());    // Now copy everything back    request.setHeaders(mapToHeaderArray(signableRequest.getHeaders()));    if (request instanceof HttpEntityEnclosingRequest) {      HttpEntityEnclosingRequest httpEntityEnclosingRequest =          (HttpEntityEnclosingRequest) request;      if (httpEntityEnclosingRequest.getEntity() != null) {        BasicHttpEntity basicHttpEntity = new BasicHttpEntity();        basicHttpEntity.setContent(signableRequest.getContent());        httpEntityEnclosingRequest.setEntity(basicHttpEntity);      }    }  }
private boolean checkFieldOrderByList(SOQLParser.FieldOrderByListContext fieldOrderByList, String fieldName) {    return fieldOrderByList.fieldOrderByElement(0).fieldElement().getText().equalsIgnoreCase(fieldName);  }
private boolean checkConditionExpressions(      SOQLParser.ConditionExpressionsContext conditionExpressions,      String fieldName  ) {    for (SOQLParser.ConditionExpressionContext ce : conditionExpressions.conditionExpression()) {      if ((ce.conditionExpressions() != null && checkConditionExpressions(ce.conditionExpressions(), fieldName))          || (ce.fieldExpression() != null && ce.fieldExpression().fieldElement().getText().equalsIgnoreCase(fieldName))) {        return true;      }    }    return false;  }
@Override  public void destroy() {    // SDC-6258 - destroy() is called from a different thread, so we    // need to signal produce() to terminate early    destroyed.set(true);    if (job != null) {      try {        try {          bulkConnection.abortJob(job.getId());        } catch (AsyncApiException e) {          ForceUtils.renewSession(bulkConnection, e);          bulkConnection.abortJob(job.getId());        }        job = null;      } catch (AsyncApiException e) {        LOG.error("Exception while aborting job", e);      }    }    job = null;    if (forceConsumer != null) {      try {        forceConsumer.stop();        forceConsumer = null;      } catch (Exception e) {        LOG.error("Exception while stopping ForceStreamConsumer.", e);      }      if (!messageQueue.isEmpty()) {        LOG.error("Queue still had {} entities at shutdown.", messageQueue.size());      } else {        LOG.info("Queue was empty at shutdown. No data lost.");      }    }    if (recordCreator != null) {      recordCreator.destroy();    }    // Clean up any open resources.    super.destroy();  }
@Override  public String produce(String lastSourceOffset, int maxBatchSize, BatchMaker batchMaker) throws StageException {    String nextSourceOffset = null;    LOG.debug("lastSourceOffset: {}", lastSourceOffset);    // send event only once for each time we run out of data.    if(shouldSendNoMoreDataEvent) {      CommonEvents.NO_MORE_DATA.create(getContext()).createAndSend();      shouldSendNoMoreDataEvent = false;      return lastSourceOffset;    }    int batchSize = Math.min(conf.basicConfig.maxBatchSize, maxBatchSize);    if (!conf.queryExistingData ||        (null != lastSourceOffset && lastSourceOffset.startsWith(EVENT_ID_OFFSET_PREFIX))) {      if (conf.subscribeToStreaming) {        nextSourceOffset = streamingProduce(lastSourceOffset, batchSize, batchMaker);      } else {        // We're done reading existing data, but we don't want to subscribe to Streaming API        return null;      }    } else if (conf.queryExistingData) {      if (!queryInProgress()) {        long now = System.currentTimeMillis();        long delay = Math.max(0, (lastQueryCompletedTime + (1000 * conf.queryInterval)) - now);        if (delay > 0) {          // Sleep in one second increments so we don't tie up the app.          LOG.info("{}ms remaining until next fetch.", delay);          ThreadUtil.sleep(Math.min(delay, 1000));          return lastSourceOffset;        }      }      if (conf.useBulkAPI) {        nextSourceOffset = bulkProduce(lastSourceOffset, batchSize, batchMaker);      } else {        nextSourceOffset = soapProduce(lastSourceOffset, batchSize, batchMaker);      }    } else if (conf.subscribeToStreaming) {      // No offset, and we're not querying existing data, so switch to streaming      nextSourceOffset = READ_EVENTS_FROM_NOW;    }    LOG.debug("nextSourceOffset: {}", nextSourceOffset);    return nextSourceOffset;  }
public static long getOffsetLagForFile(String fileOffsetString) throws IOException {    long offset = FileContextProviderUtil.getLongOffsetFromFileOffset(fileOffsetString);    //We are refreshing the live file here because we are going to get the size by using path.    LiveFile file = FileContextProviderUtil.getRefreshedLiveFileFromFileOffset(fileOffsetString);    long fileSizeInBytes = Files.size(file.getPath().toAbsolutePath());    return (fileSizeInBytes - offset);  }
public static void premain(String args, Instrumentation instrumentation) {    if (BootstrapMain.instrumentation == null) {      BootstrapMain.instrumentation = instrumentation;    } else {      throw new IllegalStateException("Premain method cannot be called twice (" + BootstrapMain.instrumentation + ")");    }  }
public static Set<String> getWhiteList(String configDir, String property) {    Set<String> set = null;    File whiteListFile = new File(configDir, WHITE_LIST_FILE).getAbsoluteFile();    if (whiteListFile.exists()) {      try (InputStream is = new FileInputStream(whiteListFile)) {        Properties props = new Properties();        props.load(is);        String whiteList = props.getProperty(property);        if (whiteList == null) {          throw new IllegalArgumentException(String.format(WHITE_LIST_PROPERTY_MISSING_MSG, property, whiteListFile));        }        whiteList = whiteList.trim();        if (!whiteList.equals(ALL_VALUES)) {          set = new HashSet<>();          for (String name : whiteList.split(",")) {            name = name.trim();            if (!name.isEmpty()) {              set.add("+" + name.trim());            }          }        }      } catch (IOException ex) {        throw new IllegalArgumentException(String.format(WHITE_LIST_COULD_NOT_LOAD_FILE_MSG,                                                         whiteListFile, ex.toString()), ex);      }    }    return set;  }
public static Map<String, List<URL>> getStageLibrariesClasspaths(String stageLibrariesDir, String librariesExtraDir,      final Set<String> stageLibs, String libsCommonLibDir) throws Exception {    Map<String, List<URL>> map = new LinkedHashMap<String, List<URL>>();    File baseDir = new File(stageLibrariesDir).getAbsoluteFile();    if (baseDir.exists()) {      File[] libDirs = baseDir.listFiles(createStageLibFilter(stageLibs));      StringBuilder commonLibJars = new StringBuilder();      if (libsCommonLibDir != null) {        commonLibJars.append(new File(libsCommonLibDir).getAbsolutePath()).append(FILE_SEPARATOR).append(JARS_WILDCARD).            append(CLASSPATH_SEPARATOR);      }      for (File libDir : libDirs) {        File jarsDir = new File(libDir, STAGE_LIB_JARS_DIR);        File etc = new File(libDir, STAGE_LIB_CONF_DIR);        if (!jarsDir.exists()) {          throw new IllegalArgumentException(String.format(MISSING_STAGE_LIB_JARS_DIR_MSG, libDir));        }        StringBuilder sb = new StringBuilder();        if (etc.exists()) {          sb.append(etc.getAbsolutePath()).append(FILE_SEPARATOR).append(CLASSPATH_SEPARATOR);        }        sb.append(commonLibJars);        sb.append(jarsDir.getAbsolutePath()).append(FILE_SEPARATOR).append(JARS_WILDCARD);        // add extralibs if avail        if (librariesExtraDir != null) {          File libExtraDir = new File(librariesExtraDir, libDir.getName());          if (libExtraDir.exists()) {            File extraJarsDir = new File(libExtraDir, STAGE_LIB_JARS_DIR);            if (extraJarsDir.exists()) {              sb.append(CLASSPATH_SEPARATOR).append(extraJarsDir.getAbsolutePath()).append(FILE_SEPARATOR).                  append(JARS_WILDCARD);            }            File extraEtc = new File(libExtraDir, STAGE_LIB_CONF_DIR);            if (extraEtc.exists()) {              sb.append(CLASSPATH_SEPARATOR).append(extraEtc.getAbsolutePath());            }          }        }        map.put(libDir.getParentFile().getName() + FILE_SEPARATOR + libDir.getName(), getClasspathUrls(sb.toString()));      }    } else {      throw new IllegalArgumentException(String.format(MISSING_STAGE_LIBRARIES_DIR_MSG, baseDir));    }    return map;  }
public static List<URL> getClasspathUrls(String classPath)      throws Exception {    List<URL> urls = new ArrayList<URL>();    for (String path : classPath.split(CLASSPATH_SEPARATOR)) {      if (!path.isEmpty()) {        if (path.toLowerCase().endsWith(JARS_WILDCARD)) {          path = path.substring(0, path.length() - JARS_WILDCARD.length());          File f = new File(path).getAbsoluteFile();          if (f.exists()) {            File[] jars = f.listFiles(new FileFilter() {              @Override              public boolean accept(File pathname) {                return pathname.getName().toLowerCase().endsWith(JARS_WILDCARD.substring(1));              }            });            for (File jar : jars) {              urls.add(jar.toURI().toURL());            }          } else {            throw new IllegalArgumentException(String.format(CLASSPATH_DIR_DOES_NOT_EXIST_MSG, f));          }        } else {          if (!path.endsWith(FILE_SEPARATOR)) {            path = path + FILE_SEPARATOR;          }          File f = new File(path).getAbsoluteFile();          if (f.exists()) {            if (f.isDirectory()) {              urls.add(f.toURI().toURL());            } else {              throw new IllegalArgumentException(String.format(CLASSPATH_PATH_S_IS_NOT_A_DIR_MSG, f));            }          } else {            throw new IllegalArgumentException(String.format(CLASSPATH_DIR_DOES_NOT_EXIST_MSG, f));          }        }      }    }    return urls;  }
public int getParallelism() throws StageException {    if (originParallelism == 0) {      //origin parallelism is not yet calculated      originParallelism = kafkaValidationUtil.getPartitionCount(          conf.metadataBrokerList,          conf.topic,          new HashMap<String, Object>(conf.kafkaConsumerConfigs),          3,          1000      );      if(originParallelism < 1) {        throw new StageException(KafkaErrors.KAFKA_42, conf.topic);      }    }    return originParallelism;  }
static List<URL> bringStageAndProtoLibsToFront(String stageLibName, List<URL> urls) {    List<URL> otherJars = new ArrayList<>();    List<URL> protolibJars = new ArrayList<>();    List<URL> stageLibjars = new ArrayList<>();    for (URL url : urls) {      String str = url.toExternalForm();      if (str.endsWith(".jar")) {        int nameIdx = str.lastIndexOf("/");        if (nameIdx > -1) {          String jarName = str.substring(nameIdx + 1);          if (jarName.contains("-protolib-")) {            // adding only protolib jars            protolibJars.add(url);          } else if (jarName.contains(stageLibName)) {            stageLibjars.add(url);          } else {            otherJars.add(url);          }        } else {          otherJars.add(url);        }      } else {        otherJars.add(url);      }    }    List<URL> allJars = new ArrayList<>();    if (stageLibjars.size() != 1) {      throw new ExceptionInInitializerError("Expected exactly 1 stage lib jar but found " + stageLibjars.size() +          " with name " + stageLibName);    }    allJars.addAll(stageLibjars);    allJars.addAll(protolibJars);    allJars.addAll(otherJars);    return allJars;  }
public TableResult runQuery(QueryJobConfiguration queryConfig, long timeout, long pageSize) throws      StageException {    checkArgument(timeout >= 1000, "Timeout must be at least one second.");    Instant maxTime = Instant.now().plusMillis(timeout);    // Create a job ID so that we can safely retry.    JobId jobId = JobId.of(UUID.randomUUID().toString());    JobInfo jobInfo = JobInfo.newBuilder(queryConfig).setJobId(jobId).build();    Job queryJob = bigquery.create(jobInfo);    // Check for errors    if (queryJob == null) {      LOG.error("Job no longer exists: {}", jobInfo);      throw new RuntimeException("Job no longer exists: "+jobInfo);    } else if (queryJob.getStatus().getError() != null) {      BigQueryError error = queryJob.getStatus().getError();      LOG.error("Query Job execution error: {}", error);      throw new StageException(Errors.BIGQUERY_02, error);    }    //Should consider using .waitFor(RetryOption.totalTimeout())    while(!queryJob.isDone()) {      if (Instant.now(clock).isAfter(maxTime) || !ThreadUtil.sleep(100)) {        if (bigquery.cancel(queryJob.getJobId())) {          LOG.info("Job {} cancelled successfully.", queryJob.getJobId());        } else {          LOG.warn("Job {} not found", queryJob.getJobId());        }        throw new StageException(Errors.BIGQUERY_00);      }    }    if (queryJob.getStatus().getError() != null) {      String errorMsg = queryJob.getStatus().getError().toString();      throw new StageException(Errors.BIGQUERY_02, errorMsg);    }    // Get the results.    TableResult result = null;    try {      result = queryJob.getQueryResults(QueryResultsOption.pageSize(pageSize));    } catch (InterruptedException e) {      String errorMsg = e.getMessage();      throw new StageException(Errors.BIGQUERY_02, errorMsg);    }    return result;  }
public Field.Type asRecordFieldType(com.google.cloud.bigquery.Field field) {    Field.Type type = asRecordFieldTypeFunction.apply(field);    return checkNotNull(type, Utils.format("Unsupported type '{}'", field.getType()));  }
public LinkedHashMap<String, Field> fieldsToMap( // NOSONAR      List<com.google.cloud.bigquery.Field> schema,      List<FieldValue> values  ) {    checkState(        schema.size() == values.size(),        "Schema '{}' and Values '{}' sizes do not match.",        schema.size(),        values.size()    );    LinkedHashMap<String, Field> root = new LinkedHashMap<>();    for (int i = 0; i < values.size(); i++) {      FieldValue value = values.get(i);      com.google.cloud.bigquery.Field field = schema.get(i);      if (value.getAttribute().equals(FieldValue.Attribute.PRIMITIVE)) {        root.put(field.getName(), fromPrimitiveField(field, value));      } else if (value.getAttribute().equals(FieldValue.Attribute.RECORD)) {        root.put(            field.getName(),            Field.create(fieldsToMap(field.getSubFields(), value.getRecordValue()))        );      } else if (value.getAttribute().equals(FieldValue.Attribute.REPEATED)) {        root.put(field.getName(), Field.create(fromRepeatedField(field, value.getRepeatedValue())));      }    }    return root;  }
public List<Field> fromRepeatedField(com.google.cloud.bigquery.Field schema,      List<FieldValue> repeatedValue) {    if (repeatedValue.isEmpty()) {      return Collections.emptyList();    }    FieldValue.Attribute repeatedFieldType = repeatedValue.get(0).getAttribute();    BiFunction<com.google.cloud.bigquery.Field, FieldValue, Field> transform =        transforms.get(repeatedFieldType);    return repeatedValue        .stream()        .map( v -> transform.apply(schema, v))        .collect(Collectors.toList());  }
private List<String> getTableDescription() throws GPUdbException {    List<List<String>> descriptions = showTableResponse.getTableDescriptions();    if (descriptions == null || descriptions.size() != 1) {      throw new GPUdbException("Error getting description for table " + tableName);    }    return descriptions.get(0);  }
private void validateTableAcceptsInserts() throws GPUdbException {    for (String s : tableDescription) {      if (s.equalsIgnoreCase("COLLECTION")) {        throw new GPUdbException("Error: table " + tableName + " is a Collection");      } else if (s.equalsIgnoreCase("VIEW")) {        throw new GPUdbException("Error: table " + tableName + " is a View");      } else if (s.equalsIgnoreCase("JOIN")) {        throw new GPUdbException("Error: table " + tableName + " is a Join Table");      } else if (s.equalsIgnoreCase("RESULT_TABLE")) {        throw new GPUdbException("Error: table " + tableName + " is a Result Table");      }    }  }
private Class<?> getColumnType(JSONObject field) throws GPUdbException {    Class<?> columnType = null;    // The Avro "type" element might be an array if the type is nullable    if (field.get("type") instanceof JSONArray) {      JSONArray columnTypes = field.getJSONArray("type");      for (int j = 0; j < columnTypes.length(); j++) {        String ct = (String) columnTypes.get(j);        if (!ct.equals("null")) {          columnType = getClassForType(ct);          break;        }      }    } else {      columnType = getClassForType(field.getString("type"));    }    if (columnType == null) {      throw new GPUdbException("Error getting column type for field: " + field.toString());    }    return columnType;  }
private boolean typeIsNullable(JSONObject field) throws GPUdbException {    if (field.get("type") instanceof JSONArray) {      JSONArray columnTypes = field.getJSONArray("type");      for (int j = 0; j < columnTypes.length(); j++) {        String ct = (String) columnTypes.get(j);        if (ct.equals("null")) {          return true;        }      }    }    return false;  }
private JSONObject getTableSchema(String tableName, ShowTableResponse showTableResponse) throws GPUdbException {    List<String> schemas = showTableResponse.getTypeSchemas();    if (schemas == null || schemas.size() != 1) {      throw new GPUdbException("Error getting schema for table " + tableName);    }    return new JSONObject(schemas.get(0));  }
private Map<String, List<String>> getColumnProperties(String tableName, ShowTableResponse showTableResponse)      throws GPUdbException {    List<Map<String, List<String>>> columnPropertiesList = showTableResponse.getProperties();    if (columnPropertiesList == null || columnPropertiesList.size() != 1) {      throw new GPUdbException("Error getting properties for table " + tableName);    }    return columnPropertiesList.get(0);  }
private Class<?> getClassForType(String typeName) throws GPUdbException {    typeName = typeName.replace(" ", "");    if (typeName.equalsIgnoreCase(STRING_TYPE_NAME)) {      return String.class;    } else if (typeName.equalsIgnoreCase(LONG_TYPE_NAME)) {      return Long.class;    } else if (typeName.equalsIgnoreCase(INTEGER_TYPE_NAME)) {      return Integer.class;    } else if (typeName.equalsIgnoreCase(FLOAT_TYPE_NAME)) {      return Float.class;    } else if (typeName.equalsIgnoreCase(DOUBLE_TYPE_NAME)) {      return Double.class;    } else if (typeName.equalsIgnoreCase(BYTES_TYPE_NAME)) {      return ByteBuffer.class;    } else {      throw new GPUdbException("Error: unknown type '" + typeName + "' in table schema");    }  }
public void init(Target.Context context, List<Target.ConfigIssue> issues) {    List<Host> hosts = getAerospikeHosts(issues, connectionString, Groups.AEROSPIKE.getLabel(), "aerospikeBeanConfig.connectionString", context);    ClientPolicy cp = new ClientPolicy();    try {      client = new AerospikeClient(cp, hosts.toArray(new Host[hosts.size()]));      int retries = 0;      while (!client.isConnected() && retries <= maxRetries) {        if (retries > maxRetries) {          issues.add(context.createConfigIssue(Groups.AEROSPIKE.getLabel(), "aerospikeBeanConfig.connectionString", AerospikeErrors.AEROSPIKE_03, connectionString));          return;        }        retries++;        try {          Thread.sleep(100);        } catch (InterruptedException ignored) {        }      }    } catch (AerospikeException ex) {      issues.add(context.createConfigIssue(Groups.AEROSPIKE.getLabel(), "aerospikeBeanConfig.connectionString", AerospikeErrors.AEROSPIKE_03, connectionString));    }  }
String getTopic(Record record) throws StageException {    String result = publisherConf.topic;    if (publisherConf.runtimeTopicResolution) {      RecordEL.setRecordInContext(topicVars, record);      try {        result = topicEval.eval(topicVars, publisherConf.topicExpression, String.class);        if (isEmpty(result)) {          throw new StageException(Errors.MQTT_08, publisherConf.topicExpression, record.getHeader().getSourceId());        }        if (!allowedTopics.contains(result) && !allowAllTopics) {          throw new StageException(Errors.MQTT_09, result, record.getHeader().getSourceId());        }      } catch (ELEvalException e) {        throw new StageException(            Errors.MQTT_10,            publisherConf.topicExpression,            record.getHeader().getSourceId(),            e.toString()        );      }    }    return result;  }
public String convertDateFormat( String pattern ) {        boolean inside = false;        boolean mark = false;        boolean modifiedCommand = false;        StringBuilder buf = new StringBuilder();        for(int i = 0; i < pattern.length(); i++) {            char c = pattern.charAt(i);            if ( c=='%' && !mark ) {                mark=true;            } else {                if ( mark ) {                    if ( modifiedCommand ) {                        //don't do anything--we just wanted to skip a char                        modifiedCommand = false;                        mark = false;                    } else {                        inside = translateCommand( buf, pattern, i, inside );                        //It's a modifier code                        if ( c=='O' || c=='E' ) {                            modifiedCommand = true;                        } else {                            mark=false;                        }                    }                } else {                    if ( !inside && c != ' ' ) {                        //We start a literal, which we need to quote                        buf.append("'");                        inside = true;                    }                    buf.append(c);                }            }        }        if ( buf.length() > 0 ) {            char lastChar = buf.charAt( buf.length() - 1 );            if( lastChar!='\'' && inside ) {                buf.append('\'');            }        }        return buf.toString();    }
protected boolean translateCommand( StringBuilder buf, String pattern, int index, boolean oldInside ) {        char firstChar = pattern.charAt( index );        boolean newInside = oldInside;        //O and E are modifiers, they mean to present an alternative representation of the next char        //we just handle the next char as if the O or E wasn't there        if ( firstChar == 'O' || firstChar == 'E' ) {            if ( index + 1 < pattern.length() ) {                newInside = translateCommand( buf, pattern, index + 1, oldInside );            } else {                buf.append( quote("%" + firstChar, oldInside ) );            }        } else {            String command = translate.getProperty( String.valueOf( firstChar ) );            //If we don't find a format, treat it as a literal--That's what apache does            if ( command == null ) {                buf.append( quote( "%" + firstChar, oldInside ) );            } else {                //If we were inside quotes, close the quotes                if ( oldInside ) {                    buf.append( '\'' );                }                buf.append( command );                newInside = false;            }        }        return newInside;    }
public void init(      Stage.Context context,      String configPrefix,      ProxyConfig proxyConfig,      List<Stage.ConfigIssue> issues,      int maxErrorRetries  ) {    this.maxErrorRetries = maxErrorRetries;    commonPrefix = AWSUtil.normalizePrefix(commonPrefix, delimiter);    try {      createConnection(context, configPrefix, proxyConfig, issues, maxErrorRetries);    } catch (StageException ex) {      LOG.debug(Errors.S3_SPOOLDIR_20.getMessage(), ex.toString(), ex);      issues.add(          context.createConfigIssue(              Groups.S3.name(),              configPrefix + S3ConnectionBaseConfig.AWS_CONFIG_PREFIX + "awsAccessKeyId",              Errors.S3_SPOOLDIR_20,              ex.toString()          )      );    }  }
private static void upgradeV5ToV6(List<Config> configs, Context context) {    List<Config> dataFormatConfigs = configs.stream()      .filter(c -> c.getName().startsWith("dataFormat"))      .collect(Collectors.toList());    // Remove those configs    configs.removeAll(dataFormatConfigs);    // There is an interesting history with compression - at some point (version 2), we explicitly added it, then    // we have hidden it. So this config might or might not exists, depending on the version in which the pipeline    // was created. However the service is expecting it and thus we need to ensure that it's there.    if(dataFormatConfigs.stream().noneMatch(c -> "dataFormatConfig.compression".equals(c.getName()))) {      dataFormatConfigs.add(new Config("dataFormatConfig.compression", "NONE"));    }    // And finally register new service    context.registerService(DataFormatParserService.class, dataFormatConfigs);  }
public static List<String> evaluateMatchingFieldPaths(      String fieldExpression,      ELEval elEval,      ELVars elVars,      Record record,      Iterable<String> recordEscapedFieldPaths  ) throws ELEvalException {    if (isFieldPathExpressionFast(fieldExpression)) {      // this field path expression actually does contain an EL expression, so need to evaluate against all fields      return evaluateMatchingFieldPathsImpl(fieldExpression, elEval, elVars, record);    } else {      // else it does NOT contain one, so the field regex util (which is faster) can be used      return FieldRegexUtil.getMatchingFieldPaths(fieldExpression, recordEscapedFieldPaths);    }  }
private static boolean pathMatches(      Record record,      String fieldPath,      String fieldExpression,      ELEval elEval,      ELVars elVars  ) throws ELEvalException {    List<PathElement> actualPathElements = PathElement.parse(fieldPath, true);    List<PathElement> matcherPathElements = PathElement.parse(fieldExpression, false, true);    Iterator<PathElement> currentPathIter = actualPathElements.iterator();    Iterator<PathElement> matcherPathIter = matcherPathElements.iterator();    PathElement currentMatcher = null;    PathElement currentPath = null;    Field currentField = null;    StringBuilder currentFieldPath = new StringBuilder();    while (matcherPathIter.hasNext()) {      currentMatcher = matcherPathIter.next();      switch (currentMatcher.getType()) {        case MAP:          if (!currentPathIter.hasNext()) {            // we are expecting to match a MAP, but there are no more elements in the path            return false;          }          currentPath = currentPathIter.next();          // see if the name matches the pattern          String childName = currentPath.getName();          String patternName = currentMatcher.getName();          if (FieldRegexUtil.hasWildCards(patternName)) {            patternName = FieldRegexUtil.transformFieldPathRegex(patternName);          }          if (childName.matches(patternName)) {            currentField = currentField.getValueAsMap().get(childName);            currentFieldPath.append("/");            currentFieldPath.append(childName);          } else {            return false;          }          break;        case LIST:          // see if the index matches the pattern          if (!currentPathIter.hasNext()) {            // we are expecting to match a LIST, but there are no more elements in the path            return false;          }          currentPath = currentPathIter.next();          int childIndex = currentPath.getIndex();          final int matchInd = currentMatcher.getIndex();          if (matchInd == PathElement.WILDCARD_INDEX_ANY_LENGTH              || (matchInd == PathElement.WILDCARD_INDEX_SINGLE_CHAR && childIndex < 10)              || matchInd == childIndex) {            currentField = currentField.getValueAsList().get(childIndex);            currentFieldPath.append("[");            currentFieldPath.append(childIndex);            currentFieldPath.append("]");          } else {            return false;          }          break;        case ROOT:          if (!currentPathIter.hasNext()) {            // we are expecting to match the ROOT, but there are no more elements in the path            return false;          }          currentPath = currentPathIter.next();          if (currentPath.getType() != PathElement.Type.ROOT) {            // we are expecting to match the ROOT, the root element wasn't for some reason            return false;          }          currentField = record.get();          break;        case FIELD_EXPRESSION:          // see if the current field matches the given expression          FieldEL.setFieldInContext(elVars, currentFieldPath.toString(), currentPath.getName(), currentField);          String expression = currentMatcher.getName();          final boolean result = elEval.eval(elVars, expression, Boolean.class);          if (LOG.isDebugEnabled()) {            LOG.debug(                "Result of evaluating expression {} on field {} with path {} was {}",                expression,                currentField,                currentFieldPath,                result            );          }          if (!result) {            return false;          }          break;      }    }    return !currentPathIter.hasNext();  }
public void release() {    CounterLock lock;    synchronized (DataStore.class) {      lock = FILE_LOCKS.get(file);      if(lock == null) {        LOG.error("Trying to release unlocked file {}", file);        return;      }      lock.dec();      if(lock.counter == 0) {        FILE_LOCKS.remove(file);      }    }    LOG.trace("Releasing the lock {} for '{}'", lock, file);    lock.unlock();    LOG.trace("Released the lock {} for '{}'", lock, file);  }
public InputStream getInputStream() throws IOException {    acquireLock();    try {      isClosed = false;      forWrite = false;      LOG.trace("Starts read '{}'", file);      verifyAndRecover();      InputStream is = new ProxyInputStream(new FileInputStream(file.toFile())) {        @Override        public void close() throws IOException {          if (isClosed) {            return;          }          try {            super.close();          } finally {            release();            isClosed = true;            stream = null;          }          LOG.trace("Finishes read '{}'", file);        }      };      stream = is;      return is;    } catch (Exception ex) {      release();      throw ex;    }  }
public OutputStream getOutputStream() throws IOException {    acquireLock();    try {      isClosed = false;      forWrite = true;      LOG.trace("Starts write '{}'", file);      verifyAndRecover();      if (Files.exists(file)) {        Files.move(file, fileOld);        LOG.trace("Starting write, move '{}' to '{}'", file, fileOld);      }      OutputStream os = new ProxyOutputStream(new FileOutputStream(fileTmp.toFile())) {        @Override        public void close() throws IOException {          if (isClosed) {            return;          }          try {            super.close();          } finally {            isClosed = true;            stream = null;          }          LOG.trace("Finishes write '{}'", file);        }      };      stream = os;      return os;    } catch (Exception ex) {      release();      throw ex;    }  }
public void commit(OutputStream out) throws IOException {    // close the stream in order to flush the contents into the disk    Utils.checkNotNull(out, "Argument output stream cannot be null");    Utils.checkState(stream == out, "The argument output stream must be the same as the output stream obtained " +      "from this data store instance");    out.close();    Files.move(fileTmp, fileNew);    LOG.trace("Committing write, move '{}' to '{}'", fileTmp, fileNew);    Files.move(fileNew, file);    LOG.trace("Committing write, move '{}' to '{}'", fileNew, file);    if (Files.exists(fileOld)) {      Files.delete(fileOld);      LOG.trace("Committing write, deleting '{}'", fileOld);    }    LOG.trace("Committed");  }
public boolean exists() throws IOException {    acquireLock();    try {      verifyAndRecover();      return Files.exists(file) && Files.size(file) > 0;    } finally {      release();    }  }
@Override  @VisibleForTesting  int getOperationFromRecord(      Record record,      int defaultOpCode,      UnsupportedOperationAction unsupportedAction,      List<OnRecordErrorException> errorRecords ) {    int opCode = -1; // -1 is invalid and not used in OperationType.    String op = null;    try {      // Try sdc.operation.type first      op = record.getHeader().getAttribute(OperationType.SDC_OPERATION_TYPE);      // If not set, look for "__$operation" in record.      if (StringUtils.isBlank(op)) {        if (record.has(MSOperationCode.getOpField())) {          int intOp = record.get(MSOperationCode.getOpField()).getValueAsInteger();          // Convert the MS specific operation code to SDC standard operation code          opCode = MSOperationCode.convertToJDBCCode(intOp);        }      } else {        opCode = JDBCOperationType.convertToIntCode(op);      }      if (opCode == -1) { // Both MS code and sdc code are not set. Use default.        opCode = defaultOpCode;      }    } catch (NumberFormatException | UnsupportedOperationException ex) {      LOG.debug(          "Operation obtained from record is not supported: {}. Handle by UnsupportedOpertaionAction {}. {}",          ex.getMessage(),          unsupportedAction.getLabel(),          ex      );      switch (unsupportedAction) {        case DISCARD:          LOG.debug("Discarding record with unsupported operation {}", op);          break;        case SEND_TO_ERROR:          LOG.debug("Sending record to error due to unsupported operation {}", op);          errorRecords.add(new OnRecordErrorException(record, JdbcErrors.JDBC_70, op));          break;        case USE_DEFAULT:          opCode = defaultOpCode;          break;        default: //unknown action          LOG.debug("Sending record to error due to unknown operation: {}", op);      }    }    return opCode;  }
public static FsPermission parseFsPermission(String permissions) throws IllegalArgumentException {    try {      // Octal or symbolic representation      return new FsPermission(permissions);    } catch (IllegalArgumentException e) {      // FsPermission.valueOf will work with unix style permissions which is 10 characters      // where the first character says the type of file      if (permissions.length() == 9) {        // This means it is a posix standard without the first character for file type        // We will simply set it to '-' suggesting regular file        permissions = "-" + permissions;      }      // Try to parse unix style format.      return FsPermission.valueOf(permissions);    }  }
@VisibleForTesting void validateRequiredStageLibraries() {    // Name of all installed libraries    Set<String> installedLibraries = stageLibraries.stream()      .map(StageLibraryDefinition::getName)      .collect(Collectors.toSet());    // Required libraries    Set<String> requiredLibraries = new HashSet<>();    String config = configuration.get(SdcConfiguration.REQUIRED_STAGELIBS, DEFAULT_REQUIRED_STAGELIBS);    for(String stageLib : config.split(",")) {      if(!stageLib.isEmpty()) {        requiredLibraries.add(stageLib);      }    }    Set<String> missingLibraries = Sets.difference(requiredLibraries, installedLibraries);    if(!missingLibraries.isEmpty()) {      throw new RuntimeException(Utils.format(        "Some required stage libraries are missing: {}",        StringUtils.join(missingLibraries, ", ")      ));    }  }
private void validateAllServicesAvailable() {    // Firstly validate that all stages have satisfied service dependencies    List<String> missingServices = new LinkedList<>();    for(StageDefinition stage : stageList) {      for(ServiceDependencyDefinition service : stage.getServices()) {        if(!serviceMap.containsKey(service.getService())) {          missingServices.add(Utils.format("Stage {} is missing service {}", stage.getName(), service.getService().getName()));        }      }    }    if(!missingServices.isEmpty()) {      throw new RuntimeException("Missing services: " + StringUtils.join(missingServices, ", "));    }    // Secondly ensure that all loaded services are compatible with what is supported by our runtime engine    List<String> unsupportedServices = new LinkedList<>();    for(ServiceDefinition serviceDefinition : serviceList) {      if(!ServiceRuntime.supports(serviceDefinition.getProvides())) {        unsupportedServices.add(serviceDefinition.getProvides().toString());      }    }    if(!unsupportedServices.isEmpty()) {      throw new RuntimeException("Unsupported services: " + StringUtils.join(unsupportedServices, ", "));    }  }
@SuppressWarnings("unchecked")  public <A extends SimpleAggregator> A createSimple(String name, Class<? extends Aggregator> klass) {    Utils.checkState(!started, "Already started");    try {      A aggregator = (A) CONSTRUCTORS.get(klass).newInstance(name);      dataProvider.addAggregator(aggregator);      aggregator.setDataProvider(dataProvider);      return aggregator;    } catch (Exception ex) {      throw new RuntimeException(ex);    }  }
<A extends SimpleAggregator, T> Class<? extends Number> getAggregatorUnit(Class<A> klass) {    try {      A aggregator = (A) CONSTRUCTORS.get(klass).newInstance("forAggregatorTypeDiscoveryOnly");      return aggregator.getValueType();    } catch (Exception ex) {      throw new RuntimeException(ex);    }  }
<A extends SimpleAggregator, T> AggregatorData<A, T> createAggregatorData(      Class<A> klass,      String name,      long timeWindowMillis) {    try {      A aggregator = (A) CONSTRUCTORS.get(klass).newInstance(name);      return aggregator.createAggregatorData(timeWindowMillis);    } catch (Exception ex) {      throw new RuntimeException(ex);    }  }
@SuppressWarnings("unchecked")  public <A extends SimpleAggregator, N extends Number> GroupByAggregator<A, N> createGroupBy(      String name, Class<? extends Aggregator> aKlass  ) {    Utils.checkState(!started, "Already started");    GroupByAggregator<A, N> aggregator = new GroupByAggregator(name, aKlass, this);    dataProvider.addAggregator(aggregator);    aggregator.setDataProvider(dataProvider);    return aggregator;  }
public void start(long newDataWindowEndTimeMillis) {    Utils.checkState(!started, "Already started");    Utils.checkState(!stopped, "Already stopped");    dataProvider.start(newDataWindowEndTimeMillis);    started = true;  }
public Map<Aggregator, AggregatorData> stop() {    Utils.checkState(started, "Already started");    Utils.checkState(!stopped, "Already stopped");    Map<Aggregator, AggregatorData> aggregatorDataMap = dataProvider.stop();    stopped = true;    return aggregatorDataMap;  }
public Map<Aggregator, AggregatorData> roll(long newDataWindowEndTimeMillis) {    Utils.checkState(started, "Not started");    Utils.checkState(!stopped, "Already stopped");    return dataProvider.roll(newDataWindowEndTimeMillis);  }
private static int resolveScaleOrPrecisionExpression(      String type,      Field field,      String attributeName,      String fieldPath  ) throws JdbcStageCheckedException {    String stringValue = field.getAttribute(attributeName);    try {      return Integer.parseInt(stringValue);    } catch (NumberFormatException e) {      throw new JdbcStageCheckedException(JdbcErrors.JDBC_304, type, fieldPath, attributeName, stringValue, e);    }  }
public static final LoginManager acquireLoginManager(LoginType loginType, Map<String, ?> configs) throws IOException, LoginException {        synchronized (LoginManager.class) {            LoginManager loginManager = CACHED_INSTANCES.get(loginType);            if (loginManager == null) {                loginManager = new LoginManager(loginType, configs);                CACHED_INSTANCES.put(loginType, loginManager);            }            return loginManager.acquire();        }    }
public void release() {        synchronized (LoginManager.class) {            if (refCount == 0)                throw new IllegalStateException("release called on LoginManager with refCount == 0");            else if (refCount == 1) {                CACHED_INSTANCES.remove(loginType);                login.shutdown();            }            --refCount;        }    }
public static void closeAll() {        synchronized (LoginManager.class) {            for (LoginType loginType : new ArrayList<>(CACHED_INSTANCES.keySet())) {                LoginManager loginManager = CACHED_INSTANCES.remove(loginType);                loginManager.login.shutdown();            }        }    }
private static String globToRegex(String glob) {    if (glob.charAt(0) == '.' || glob.contains("/") || glob.contains("~")) {      throw new IllegalArgumentException("Invalid character in file glob");    }    // treat dot as a literal.    glob = glob.replace(".", "\\.");    glob = glob.replace("*", ".+");    glob = glob.replace("?", ".{1}+");    return glob;  }
public void decodeStandaloneBuffer(      ByteBuf buf,      List<BaseNetflowMessage> resultMessages,      InetSocketAddress sender,      InetSocketAddress recipient  ) throws OnRecordErrorException {    final List<Object> results = new LinkedList<>();    try {      decode(null, buf, results, sender, recipient, true);      for (Object result : results) {        if (result == null) {          LOG.warn("null result found from decoding standalone Netflow buffer; skipping");          continue;        }        if (result instanceof BaseNetflowMessage) {          resultMessages.add((BaseNetflowMessage) result);        } else {          throw new IllegalStateException(String.format(              "Found unexpected object type in results: %s",              result.getClass().getName())          );        }      }    } finally {      resetStateVariables();    }  }
static List<S3ObjectSummary> listObjectsLexicographically(      AmazonS3 s3Client,      S3ConfigBean s3ConfigBean,      AntPathMatcher pathMatcher,      S3Offset s3Offset,      int fetchSize  ) {    // Incrementally scan objects after the marker (s3Offset).    List<S3ObjectSummary> list = new ArrayList<>(fetchSize);    ListObjectsRequest listObjectsRequest = new ListObjectsRequest();    listObjectsRequest.setBucketName(s3ConfigBean.s3Config.bucket);    listObjectsRequest.setPrefix(s3ConfigBean.s3Config.commonPrefix);    listObjectsRequest.setMaxKeys(BATCH_SIZE);    if (s3Offset.getKey() != null) {      listObjectsRequest.setMarker(s3Offset.getKey());    }    ObjectListing objectListing = s3Client.listObjects(listObjectsRequest);    while (true) {      for (S3ObjectSummary s : objectListing.getObjectSummaries()) {        String fullPrefix = s.getKey();        String remainingPrefix = fullPrefix.substring(s3ConfigBean.s3Config.commonPrefix.length(), fullPrefix.length());        if (!remainingPrefix.isEmpty()) {          if (pathMatcher.match(s3ConfigBean.s3FileConfig.prefixPattern, remainingPrefix)) {            list.add(s);          }          // We've got enough objects.          if (list.size() == fetchSize) {            return list;          }        }      }      // Listing is complete. No more objects to be listed.      if (!objectListing.isTruncated()) {        break;      }      objectListing = s3Client.listNextBatchOfObjects(objectListing);    }    return list;  }
static List<S3ObjectSummary> listObjectsChronologically(      AmazonS3 s3Client,      S3ConfigBean s3ConfigBean,      AntPathMatcher pathMatcher,      S3Offset s3Offset,      int fetchSize  ) {    //Algorithm:    // - Full scan all objects that match the file name pattern and which are later than the file in the offset    // - Select the oldest "fetchSize" number of files and return them.    TreeSet<S3ObjectSummary> treeSet = new TreeSet<>((o1, o2) -> {      int result = o1.getLastModified().compareTo(o2.getLastModified());      if(result != 0) {        //same modified time. Use name to sort        return result;      }      return o1.getKey().compareTo(o2.getKey());    });    S3Objects s3ObjectSummaries = S3Objects      .withPrefix(s3Client, s3ConfigBean.s3Config.bucket, s3ConfigBean.s3Config.commonPrefix);    // SDC-9413: since the s3ObjectSummaries is in lexical order, we should get all list of files in one api call    for (S3ObjectSummary s : s3ObjectSummaries) {      String fullPrefix = s.getKey();      String remainingPrefix = fullPrefix.substring(s3ConfigBean.s3Config.commonPrefix.length(), fullPrefix.length());      if (!remainingPrefix.isEmpty()) {        // remainingPrefix can be empty.        // If the user manually creates a prefix "myFolder/mySubFolder" in bucket "myBucket" and uploads "myObject",        // then the first objects returned here are:        // myFolder/mySubFolder        // myFolder/mySubFolder/myObject        //        // All is good when pipeline is run but preview returns with no data. So we should ignore the empty file as it        // has no data        if (pathMatcher.match(s3ConfigBean.s3FileConfig.prefixPattern, remainingPrefix) && isEligible(s, s3Offset)) {          treeSet.add(s);        }        if (treeSet.size() > fetchSize) {          treeSet.pollLast();        }      }    }    return new ArrayList<>(treeSet);  }
@Override  protected String[] loadRoleInfo(UserPrincipal user)  {    UserIdentity id = _userStore.getUserIdentity(user.getName());    if (id == null)      return null;    Set<RolePrincipal> roles = id.getSubject().getPrincipals(RolePrincipal.class);    if (roles == null)      return null;    List<String> list = roles.stream()        .map(RolePrincipal::getName)        .collect(  Collectors.toList() );    return list.toArray(new String[roles.size()]);  }
@Override  protected UserPrincipal loadUserInfo(String userName)  {    UserIdentity id = _userStore.getUserIdentity(userName);    if (id != null)    {      return (UserPrincipal)id.getUserPrincipal();    }    return null;  }
@Override  public void destroy(    SourcePipe originPipe,    List<PipeRunner> pipeRunners,    BadRecordsHandler badRecordsHandler,    StatsAggregationHandler statsAggregationHandler  ) throws StageException, PipelineRuntimeException {    // We're no longer running    running = false;    // There are two ways a runner can be in use - used by real runner (e.g. when origin produced data) or when it's    // processing "empty" batch when the runner was idle for too long. The first case is guarded by the framework - this    // method won't be called until the execution successfully finished. However the second way with idle drivers is run    // from a separate thread and hence we have to ensure here that it's "done" before moving on with the destroy phase.    try {      destroyLock.lock();      // Firstly destroy the runner, to make sure that any potential run away thread from origin will be denied      // further processing.      if (runnerPool != null) {        runnerPool.destroy();      }      int batchSize = configuration.get(Constants.MAX_BATCH_SIZE_KEY, Constants.MAX_BATCH_SIZE_DEFAULT);      long lastBatchTime = offsetTracker.getLastBatchTime();      long start = System.currentTimeMillis();      FullPipeBatch pipeBatch;      // Destroy origin pipe      pipeBatch = new FullPipeBatch(null, null, batchSize, false);      try {        LOG.trace("Destroying origin pipe");        pipeBatch.skipStage(originPipe);        originPipe.destroy(pipeBatch);      } catch (RuntimeException e) {        LOG.warn("Exception throw while destroying pipe", e);      }      // Now destroy the pipe runners      //      // We're destroying them in reverser order to make sure that the last runner to destroy is the one with id '0'      // that holds reference to all class loaders. Runners with id >0 do not own their class loaders and hence needs to      // be destroyed before the runner with id '0'.      for (PipeRunner pipeRunner : Lists.reverse(pipeRunners)) {        final FullPipeBatch finalPipeBatch = pipeBatch;        pipeRunner.executeBatch(null, null, start, pipe -> {          // Set the last batch time in the stage context of each pipe          ((StageContext) pipe.getStage().getContext()).setLastBatchTime(lastBatchTime);          String instanceName = pipe.getStage().getConfiguration().getInstanceName();          if (pipe instanceof StagePipe) {            // Stage pipes are processed only if they are in event path            if (pipe.getStage().getConfiguration().isInEventPath()) {              LOG.trace("Stage pipe {} is in event path, running last process", instanceName);              pipe.process(finalPipeBatch);            } else {              LOG.trace("Stage pipe {} is in data path, skipping it's processing.", instanceName);              finalPipeBatch.skipStage(pipe);            }          } else {            // Non stage pipes are executed always            LOG.trace("Non stage pipe {}, running last process", instanceName);            pipe.process(finalPipeBatch);          }          // And finally destroy the pipe          try {            LOG.trace("Running destroy for {}", instanceName);            pipe.destroy(finalPipeBatch);          } catch (RuntimeException e) {            LOG.warn("Exception throw while destroying pipe", e);          }        });        badRecordsHandler.handle(null, null, pipeBatch.getErrorSink(), pipeBatch.getSourceResponseSink());        // Next iteration should have new and empty PipeBatch        pipeBatch = new FullPipeBatch(null, null, batchSize, false);        pipeBatch.skipStage(originPipe);      }      if (isStatsAggregationEnabled()) {        List<Record> stats = new ArrayList<>();        statsAggregatorRequests.drainTo(stats);        Object timeSeriesString = pipelineConfigBean.constants.get(MetricsEventRunnable.TIME_SERIES_ANALYSIS);        boolean timeSeriesAnalysis = (timeSeriesString != null) ? (Boolean) timeSeriesString : true;        String metricRegistryStr;        try {          metricRegistryStr = ObjectMapperFactory.get().writer().writeValueAsString(metrics);        } catch (Exception e) {          throw new RuntimeException(Utils.format("Error converting metric json to string: {}", e), e);        }        LOG.info("Queueing last batch of record to be sent to stats aggregator");        stats.add(AggregatorUtil.createMetricJsonRecord(            runtimeInfo.getId(),            runtimeInfo.getMasterSDCId(),            pipelineConfiguration.getMetadata(),            false,            timeSeriesAnalysis,            true,            metricRegistryStr        ));        statsAggregationHandler.handle(null, null, stats);      }    } finally {        destroyLock.unlock();    }  }
public void stop() throws PipelineException {    this.stop = true;    if(batchesToCapture > 0) {      cancelSnapshot(this.snapshotName);      snapshotStore.deleteSnapshot(pipelineName, revision, snapshotName);    }  }
public int produceEmptyBatchesForIdleRunners(long idleTime) throws PipelineException, StageException {    LOG.debug("Checking if any active runner is idle");    // The empty batch is suppose to be fast - almost as a zero time. It could however happened that from some reason it    // will take a long time (possibly more then idleTime). To avoid infinite loops, this method will only processes up    // to total number of runners before returning.    int counter = 0;    try {      destroyLock.lock();      while(running && counter < pipes.size()) {        counter++;        PipeRunner runner = null;        try {          runner = runnerPool.getIdleRunner(idleTime);          // No more idle runners, simply stop the idle execution now          if(runner == null) {            return counter;          }          LOG.debug("Generating empty batch for runner: {}", runner.getRunnerId());          pipeContext.getRuntimeStats().incIdleBatchCount();          // Pipe batch to keep the batch info          FullPipeBatch pipeBatch = new FullPipeBatch(null, null, 0, false);          pipeBatch.setIdleBatch(true);          // We're explicitly skipping origin because this is framework generated, empty batch          pipeBatch.skipStage(originPipe);          executeRunner(            runner,            System.currentTimeMillis(),            pipeBatch,            null,            null,            new HashMap<>(),            new HashMap<>()          );        } finally {          if(runner != null) {            runnerPool.returnRunner(runner);          }        }      }    } finally {      destroyLock.unlock();    }    return counter;  }
private void createFailureBatch(FullPipeBatch pipeBatch) {    if(!pipelineConfigBean.shouldCreateFailureSnapshot) {      return;    }    try {      for(SnapshotInfo info : snapshotStore.getSummaryForPipeline(pipelineName, revision)) {        // Allow only one failure snapshot to be present on a pipeline        if(info.isFailureSnapshot()) {          LOG.trace("Skipping creation of failure snapshot as {} already exists.", info.getId());          return;        }      }      String snapshotName = "Failure_" + UUID.randomUUID().toString();      String snapshotLabel = "Failure at " + LocalDateTime.now().toString();      snapshotStore.create("", pipelineName, revision, snapshotName, snapshotLabel, true);      snapshotStore.save(pipelineName, revision, snapshotName, -1, ImmutableList.of(pipeBatch.createFailureSnapshot()));    } catch (PipelineException ex) {      LOG.error("Can't serialize failure snapshot", ex);    }  }
@SuppressWarnings("unchecked")  private BoundStatement recordToBoundStatement(Record record) throws StageException {    ImmutableList.Builder<Object> values = new ImmutableList.Builder<>();    SortedSet<String> columnsPresent = Sets.newTreeSet(columnMappings.keySet());    for (Map.Entry<String, String> mapping : columnMappings.entrySet()) {      String columnName = mapping.getKey();      String fieldPath = mapping.getValue();      // If we're missing fields, skip them.      // If a field is present, but null, also remove it from columnsPresent since we can't write nulls.      if (!record.has(fieldPath) || record.get(fieldPath).getValue() == null) {        columnsPresent.remove(columnName);        continue;      }      final Object value = record.get(fieldPath).getValue();      // Special cases for handling SDC Lists and Maps,      // basically unpacking them into raw types.      if (value instanceof List) {        List<Object> unpackedList = new ArrayList<>();        for (Field item : (List<Field>) value) {          unpackedList.add(item.getValue());        }        values.add(unpackedList);      } else if (value instanceof Map) {        Map<Object, Object> unpackedMap = new HashMap<>();        for (Map.Entry<String, Field> entry : ((Map<String, Field>) value).entrySet()) {          unpackedMap.put(entry.getKey(), entry.getValue().getValue());        }        values.add(unpackedMap);      } else {        values.add(value);      }    }    PreparedStatement stmt = statementCache.getUnchecked(columnsPresent);    // .toArray required to pass in a list to a varargs method.    Object[] valuesArray = values.build().toArray();    BoundStatement boundStmt = null;    try {      boundStmt = stmt.bind(valuesArray);    } catch (CodecNotFoundException | InvalidTypeException | NullPointerException e) {      // NPE can occur if one of the values is a collection type with a null value inside it. Thus, it's a record      // error. Note that this runs the risk of mistakenly treating a bug as a record error.      // CodecNotFound is caused when there is no type conversion definition available from the provided type      // to the target type.      errorRecordHandler.onError(          new OnRecordErrorException(              record,              Errors.CASSANDRA_06,              record.getHeader().getSourceId(),              e.toString(),              e          )      );    }    return boundStmt;  }
@Override  protected List<ConfigIssue> init() {    // Validate configuration values and open any required resources.    List<ConfigIssue> issues = super.init();    Target.Context context = getContext();    Optional        .ofNullable(conf.init(context, CONF_PREFIX))        .ifPresent(issues::addAll);    errorRecordHandler = new DefaultErrorRecordHandler(context);    sObjectNameVars = getContext().createELVars();    sObjectNameEval = context.createELEval(SOBJECT_NAME);    ELUtils.validateExpression(conf.sObjectNameTemplate,        context,        Groups.FORCE.getLabel(),        SOBJECT_NAME,        Errors.FORCE_12, issues    );    externalIdFieldVars = getContext().createELVars();    externalIdFieldEval = context.createELEval(EXTERNAL_ID_NAME);    ELUtils.validateExpression(conf.externalIdField,        context,        Groups.FORCE.getLabel(),        EXTERNAL_ID_NAME,        Errors.FORCE_24, issues    );    if (issues.isEmpty()) {      fieldMappings = new TreeMap<>();      for (ForceFieldMapping mapping : conf.fieldMapping) {        // SDC-7446 Allow colon as well as period as field separator        String salesforceField = conf.useBulkAPI            ? mapping.salesforceField.replace(':', '.')            : mapping.salesforceField;        fieldMappings.put(salesforceField, mapping.sdcField);      }      try {        ConnectorConfig partnerConfig = ForceUtils.getPartnerConfig(conf, new ForceSessionRenewer());        partnerConnection = Connector.newConnection(partnerConfig);        if (conf.mutualAuth.useMutualAuth) {          ForceUtils.setupMutualAuth(partnerConfig, conf.mutualAuth);        }        bulkConnection = ForceUtils.getBulkConnection(partnerConfig, conf);        LOG.info("Successfully authenticated as {}", conf.username);      } catch (ConnectionException | AsyncApiException | StageException | URISyntaxException ce) {        LOG.error("Can't connect to SalesForce", ce);        issues.add(getContext().createConfigIssue(Groups.FORCE.name(),            "connectorConfig",            Errors.FORCE_00,            ForceUtils.getExceptionCode(ce) + ", " + ForceUtils.getExceptionMessage(ce)        ));      }      if (conf.useBulkAPI) {        writer = new ForceBulkWriter(fieldMappings, bulkConnection, getContext());      } else {        writer = new ForceSoapWriter(fieldMappings, partnerConnection);      }    }    // If issues is not empty, the UI will inform the user of each configuration issue in the list.    return issues;  }
@Override  public void write(Batch batch) throws StageException {    Multimap<String, Record> partitions = ELUtils.partitionBatchByExpression(sObjectNameEval,        sObjectNameVars,        conf.sObjectNameTemplate,        batch    );    Set<String> sObjectNames = partitions.keySet();    for (String sObjectName : sObjectNames) {      List<OnRecordErrorException> errors = writer.writeBatch(          sObjectName,          partitions.get(sObjectName),          this      );      for (OnRecordErrorException error : errors) {        errorRecordHandler.onError(error);      }    }  }
public void set(Map<String, String> newConfiguration) {    for(Map.Entry<String, String> entry : newConfiguration.entrySet()) {      if(entry.getValue() == null) {        this.unset(entry.getKey());      } else {        this.set(entry.getKey(), entry.getValue());      }    }  }
@Override  protected void process(Record record, SingleLaneProcessor.SingleLaneBatchMaker batchMaker) throws StageException {    RecordEL.setRecordInContext(tableNameVars, record);    String tableName = tableNameEval.eval(tableNameVars, conf.kuduTableTemplate, String.class);    if (!conf.caseSensitive) {      tableName = tableName.toLowerCase();    }    LOG.trace("Processing record:{}  TableName={}", record.toString(), tableName);    try {      try {        KuduLookupKey key = generateLookupKey(record, tableName);        List<Map<String, Field>> values = cache.get(key);        if (values.isEmpty()) {          // No record found          if (conf.missingLookupBehavior == MissingValuesBehavior.SEND_TO_ERROR) {            errorRecordHandler.onError(new OnRecordErrorException(record, Errors.KUDU_31));          } else {            // Configured to 'Send to next stage' and 'pass as it is'            batchMaker.addRecord(record);          }        } else {          switch (conf.multipleValuesBehavior) {            case FIRST_ONLY:              setFieldsInRecord(record, values.get(0));              batchMaker.addRecord(record);              break;            case SPLIT_INTO_MULTIPLE_RECORDS:              for(Map<String, Field> lookupItem : values) {                Record newRecord = getContext().cloneRecord(record);                setFieldsInRecord(newRecord, lookupItem);                batchMaker.addRecord(newRecord);              }              break;            default:              throw new IllegalStateException("Unknown multiple value behavior: " + conf.multipleValuesBehavior);          }        }      } catch (ExecutionException e) {        Throwables.propagateIfPossible(e.getCause(), StageException.class);        Throwables.propagateIfPossible(e.getCause(), OnRecordErrorException.class);        throw new IllegalStateException(e); // The cache loader shouldn't throw anything that isn't a StageException.      }    } catch (OnRecordErrorException error) { // NOSONAR      errorRecordHandler.onError(new OnRecordErrorException(record, error.getErrorCode(), error.getParams()));    }  }
private KuduLookupKey generateLookupKey(final Record record, final String tableName) throws OnRecordErrorException{    Map<String, Field> keyList = new HashMap<>();    for (Map.Entry<String, String> key : columnToField.entrySet()){      String fieldName = key.getValue();      if (!record.has(fieldName)) {        throw new OnRecordErrorException(record, Errors.KUDU_32, fieldName);      }      keyList.put(key.getKey(), record.get(fieldName));    }    return new KuduLookupKey(tableName, keyList);  }
private Properties getKafkaProperties(Stage.Context context) {    Properties props = new Properties();    props.putAll(conf.kafkaOptions);    props.setProperty("bootstrap.servers", conf.brokerURI);    props.setProperty("group.id", conf.consumerGroup);    props.setProperty("max.poll.records", String.valueOf(batchSize));    props.setProperty(KafkaConstants.KEY_DESERIALIZER_CLASS_CONFIG, conf.keyDeserializer.getKeyClass());    props.setProperty(KafkaConstants.VALUE_DESERIALIZER_CLASS_CONFIG, conf.valueDeserializer.getValueClass());    props.setProperty(KafkaConstants.CONFLUENT_SCHEMA_REGISTRY_URL_CONFIG, StringUtils.join(conf.dataFormatConfig.schemaRegistryUrls, ","));    props.setProperty(KafkaConstants.AUTO_COMMIT_OFFEST, "false");    if(context.isPreview()) {      props.setProperty(KafkaConstants.AUTO_OFFSET_RESET_CONFIG, KafkaConstants.AUTO_OFFSET_RESET_PREVIEW_VALUE);    }    return props;  }
private void handlePartitioningTurnedOffOrOn(      SortedSetMultimap<TableContext, TableRuntimeContext> reconstructedPartitions  ) {    for (TableContext tableContext : reconstructedPartitions.keySet()) {      final SortedSet<TableRuntimeContext> partitions = reconstructedPartitions.get(tableContext);      final TableRuntimeContext lastPartition = partitions.last();      final TableContext sourceTableContext = lastPartition.getSourceTableContext();      Utils.checkState(          sourceTableContext.equals(tableContext),          String.format(              "Source table context for %s should match TableContext map key of %s",              lastPartition.getDescription(),              tableContext.getQualifiedName()          )      );      final boolean partitioningTurnedOff = lastPartition.isPartitioned()          && sourceTableContext.getPartitioningMode() == PartitioningMode.DISABLED;      final boolean partitioningTurnedOn = !lastPartition.isPartitioned()          && sourceTableContext.isPartitionable()          && sourceTableContext.getPartitioningMode() != PartitioningMode.DISABLED;      if (!partitioningTurnedOff && !partitioningTurnedOn) {        continue;      }      final Map<String, String> nextStartingOffsets = new HashMap<>();      final Map<String, String> nextMaxOffsets = new HashMap<>();      final int newPartitionSequence = lastPartition.getPartitionSequence() > 0 ? lastPartition.getPartitionSequence() + 1 : 1;      if (partitioningTurnedOff) {        LOG.info(            "Table {} has switched from partitioned to non-partitioned; partition sequence {} will be the last (with" +                " no max offsets)",            sourceTableContext.getQualifiedName(),            newPartitionSequence        );        lastPartition.getStartingPartitionOffsets().forEach(            (col, off) -> {              String basedOnStartOffset = lastPartition.generateNextPartitionOffset(col, off);              nextStartingOffsets.put(col, basedOnStartOffset);            }        );      } else if (partitioningTurnedOn) {        lastPartition.getStartingPartitionOffsets().forEach(            (col, off) -> {              String basedOnStoredOffset = lastPartition.getInitialStoredOffsets().get(col);              nextStartingOffsets.put(col, basedOnStoredOffset);            }        );        nextStartingOffsets.forEach(            (col, off) -> nextMaxOffsets.put(col, lastPartition.generateNextPartitionOffset(col, off))        );        if (!reconstructedPartitions.remove(sourceTableContext, lastPartition)) {          throw new IllegalStateException(String.format(              "Failed to remove partition %s for table %s in switching partitioning from off to on",              lastPartition.getDescription(),              sourceTableContext.getQualifiedName()          ));        }        LOG.info(            "Table {} has switched from non-partitioned to partitioned; using last stored offsets as the starting" +                " offsets for the new partition {}",            sourceTableContext.getQualifiedName(),            newPartitionSequence        );      }      final TableRuntimeContext nextPartition = new TableRuntimeContext(          sourceTableContext,          lastPartition.isUsingNonIncrementalLoad(),          (lastPartition.isPartitioned() && !partitioningTurnedOff) || partitioningTurnedOn,          newPartitionSequence,          nextStartingOffsets,          nextMaxOffsets      );      reconstructedPartitions.put(sourceTableContext, nextPartition);    }  }
@VisibleForTesting  void acquireTableAsNeeded(int threadNumber) throws InterruptedException {    if (!getOwnedTablesQueue().isEmpty() && batchTableStrategy == BatchTableStrategy.SWITCH_TABLES) {      final TableRuntimeContext lastOwnedPartition = getOwnedTablesQueue().pollLast();      if (getTableContextMap().containsValue(lastOwnedPartition.getSourceTableContext())) {        sharedAvailableTablesQueue.offer(lastOwnedPartition);      }      TableContext lastOwnedTable = lastOwnedPartition.getSourceTableContext();      // need to cycle off all partitions from the same table to the end of the queue      TableRuntimeContext first = sharedAvailableTablesQueue.peek();      while (first != null && first.getSourceTableContext().equals(lastOwnedTable)          && !first.equals(lastOwnedPartition)) {        if (LOG.isDebugEnabled()) {          LOG.debug(              "Moving partition {} to end of shared queue to comply with BatchTableStrategy of {}",              first.getDescription(),              batchTableStrategy.getLabel()          );        }        // poll() should never return null since it is actually returning 'first' as we want to move it from the head        // of the queue, that's why we are calling offer, to basically remove it from the head but keep it in the queue        TableRuntimeContext toMove = sharedAvailableTablesQueue.poll();        sharedAvailableTablesQueue.offer(toMove);        // Get the new head of the queue        first = sharedAvailableTablesQueue.peek();      }    }    if (getOwnedTablesQueue().isEmpty()) {      TableRuntimeContext head = sharedAvailableTablesQueue.poll();      if (head != null) {        offerToOwnedTablesQueue(head, threadNumber);      }    }    partitionFirstSharedQueueItemIfNeeded();  }
@VisibleForTesting  void partitionFirstSharedQueueItemIfNeeded() {    final TableRuntimeContext headPartition = getOwnedTablesQueue().peek();    if (headPartition != null) {      synchronized (partitionStateLock) {        keepPartitioningIfNeeded(headPartition);      }    } else if (LOG.isTraceEnabled()) {      LOG.trace("No item at head of shared partition queue");    }  }
public TableRuntimeContext nextTable(int threadNumber) throws InterruptedException {    synchronized (partitionStateLock) {      acquireTableAsNeeded(threadNumber);      final TableRuntimeContext partition = getOwnedTablesQueue().pollFirst();      if (partition != null) {        offerToOwnedTablesQueue(partition, threadNumber);      }      return partition;    }  }
public void reportDataOrNoMoreData(      TableRuntimeContext tableRuntimeContext,      int recordCount,      int batchSize,      boolean resultSetEndReached,      AtomicBoolean tableFinished,      AtomicBoolean schemaFinished,      List<String> schemaFinishedTables  ) {    final TableContext sourceContext = tableRuntimeContext.getSourceTableContext();    // When we see a table with data, we mark isNoMoreDataEventGeneratedAlready to false    // so we can generate event again if we don't see data from all tables.    if(recordCount > 0) {      isNoMoreDataEventGeneratedAlready = false;      tablesWithNoMoreData.remove(tableRuntimeContext.getSourceTableContext());      remainingSchemasToTableContexts.put(sourceContext.getSchema(), sourceContext);      completedSchemasToTableContexts.remove(sourceContext.getSchema(), sourceContext);    }    // we need to account for the activeRuntimeContexts here    // if there are still other active contexts in process, then this should do "nothing"    // if there are not other contexts, we need to figure out what the highest offset completed by the last batch was    final boolean noMoreData = recordCount == 0 || resultSetEndReached;    if (noMoreData) {      tableRuntimeContext.setMarkedNoMoreData(true);    }    if (recordCount > 0) {      maxPartitionWithDataPerTable.put(sourceContext, tableRuntimeContext.getPartitionSequence());    }    boolean tableExhausted = removePartitionIfNeeded(tableRuntimeContext);    if (noMoreData) {      if (tableExhausted) {        synchronized (this) {          if (LOG.isDebugEnabled()) {            LOG.debug(                "Table {} exhausted",                sourceContext.getQualifiedName()            );          }          final boolean newlyFinished = tablesWithNoMoreData.add(sourceContext);          if (newlyFinished && tableFinished != null) {            tableFinished.set(true);          }          final boolean remainingSchemaChanged = remainingSchemasToTableContexts.remove(sourceContext.getSchema(), sourceContext);          completedSchemasToTableContexts.put(sourceContext.getSchema(), sourceContext);          if (remainingSchemaChanged && remainingSchemasToTableContexts.get(sourceContext.getSchema()).isEmpty() && schemaFinished != null) {            schemaFinished.set(true);            if (schemaFinishedTables != null) {              completedSchemasToTableContexts.get(sourceContext.getSchema()).forEach(                  t -> schemaFinishedTables.add(t.getTableName())              );            }          }        }      }    }    if (LOG.isTraceEnabled()) {      LOG.trace(          "Just released table {}; Number of Tables With No More Data {}",          tableRuntimeContext.getDescription(),          tablesWithNoMoreData.size()      );    }  }
public synchronized boolean shouldGenerateNoMoreDataEvent() {    boolean noMoreData = (        !isNoMoreDataEventGeneratedAlready &&            tablesWithNoMoreData.size() == tableContextMap.size());    if (noMoreData) {      isNoMoreDataEventGeneratedAlready = true;    }    return noMoreData;  }
private int readAhead(Map<String, Field> fieldsFromLogLine, StringBuilder stackTrace)    throws DataParserException, IOException {    StringBuilder multilineLog = new StringBuilder();    int read = readLine(multilineLog);    int numberOfLinesRead = 0;    while (read > -1) {      try {        Map<String, Field> stringFieldMap = parseLogLine(multilineLog);        fieldsFromLogLine.putAll(stringFieldMap);        currentLine.append(multilineLog);        //If the line can be parsed successfully, do not read further        //This line will be used in the current record if this is the first line being read        //or stored for the next round if there is a line from the previous round.        break;      } catch (DataParserException e) {        //is this the first line being read? Yes -> throw exception        if (previousLine.length() == 0 || maxStackTraceLines == -1) {          throw e;        }        //otherwise read until we get a line that matches pattern        if(numberOfLinesRead < maxStackTraceLines) {          if(numberOfLinesRead != 0) {            stackTrace.append("\n");          }          stackTrace.append(multilineLog.toString());        }        numberOfLinesRead++;        multilineLog.setLength(0);        read = readLine(multilineLog);      }    }    return read;  }
int readLine(StringBuilder sb) throws IOException {    int c = reader.read();    int count = (c == -1) ? -1 : 0;    while (c > -1 && !isOverMaxObjectLen(count) && !checkEolAndAdjust(c)) {      count++;      sb.append((char) c);      c = reader.read();    }    if (isOverMaxObjectLen(count)) {      sb.setLength(sb.length() - 1);      while (c > -1 && c != '\n' && c != '\r') {        count++;        c = reader.read();      }      checkEolAndAdjust(c);    }    return count;  }
public UsageTimer roll() {    int multiplier;    synchronized (this) {      multiplier = getMultiplier();      changeMultiplier(-multiplier); //stopAll;    }    return new UsageTimer().setName(getName()).changeMultiplier(multiplier);  }
public static void enableDPM(DPMInfoJson dpmInfo, Context context) throws IOException {    Utils.checkNotNull(dpmInfo, "DPMInfo");    String dpmBaseURL = normalizeDpmBaseURL(dpmInfo.getBaseURL());    // Since we support enabling/Disabling DPM, first check if token already exists for the given DPM URL.    // If token exists skip first 3 steps    String currentDPMBaseURL = context.configuration.get(RemoteSSOService.DPM_BASE_URL_CONFIG, "");    String currentAppAuthToken = context.configuration.get(RemoteSSOService.SECURITY_SERVICE_APP_AUTH_TOKEN_CONFIG, "").trim();    if (!currentDPMBaseURL.equals(dpmBaseURL) ||  currentAppAuthToken.length() == 0) {      // 1. Login to DPM to get user auth token      String userAuthToken = retrieveUserToken(dpmBaseURL, dpmInfo.getUserID(), dpmInfo.getUserPassword());      String appAuthToken = null;      // 2. Create Data Collector application token      Response response = null;      try {        Map<String, Object> newComponentJson = new HashMap<>();        newComponentJson.put("organization", dpmInfo.getOrganization());        newComponentJson.put("componentType", "dc");        newComponentJson.put("numberOfComponents", 1);        newComponentJson.put("active", true);        response = ClientBuilder.newClient()            .target(dpmBaseURL + "/security/rest/v1/organization/" + dpmInfo.getOrganization() + "/components")            .register(new CsrfProtectionFilter("CSRF"))            .request()            .header(SSOConstants.X_USER_AUTH_TOKEN, userAuthToken)            .put(Entity.json(newComponentJson));        if (response.getStatus() != Response.Status.CREATED.getStatusCode()) {          throw new RuntimeException(Utils.format("DPM Create Application Token failed, status code '{}': {}",              response.getStatus(),              response.readEntity(String.class)          ));        }        List<Map<String, Object>> newComponent = response.readEntity(new GenericType<List<Map<String,Object>>>() {});        if (newComponent.size() > 0) {          appAuthToken = (String) newComponent.get(0).get("fullAuthToken");        } else {          throw new RuntimeException("DPM Create Application Token failed: No token data from DPM Server.");        }      } finally {        if (response != null) {          response.close();        }        // Logout from DPM        logout(dpmBaseURL, userAuthToken);      }      // 3. Update App Token file      updateTokenFile(context, appAuthToken);    }    // 4. Update dpm.properties file    updateDpmProperties(context, dpmBaseURL, dpmInfo.getLabels(), true);  }
public static void disableDPM(String username, String password, String organizationId, Context context) throws IOException {    String dpmBaseURL = normalizeDpmBaseURL(context.configuration.get(RemoteSSOService.DPM_BASE_URL_CONFIG, ""));    String userToken = retrieveUserToken(dpmBaseURL, username, password);    try {      disableDPM(userToken, organizationId, context);    } finally {      logout(dpmBaseURL, userToken);    }  }
public static void disableDPM(String userAuthToken, String organizationId, Context context) throws IOException {    // check if DPM enabled    if (!context.runtimeInfo.isDPMEnabled()) {      throw new RuntimeException("disableDPM is supported only when DPM is enabled");    }    String dpmBaseURL = normalizeDpmBaseURL(context.configuration.get(RemoteSSOService.DPM_BASE_URL_CONFIG, ""));    String componentId = context.runtimeInfo.getId();    // 2. Deactivate Data Collector System Component    Response response = null;    try {      response = ClientBuilder.newClient()          .target(dpmBaseURL + "/security/rest/v1/organization/" + organizationId + "/components/deactivate")          .register(new CsrfProtectionFilter("CSRF"))          .request()          .header(SSOConstants.X_USER_AUTH_TOKEN, userAuthToken)          .header(SSOConstants.X_REST_CALL, true)          .post(Entity.json(ImmutableList.of(componentId)));      if (response.getStatus() != Response.Status.OK.getStatusCode()) {        throw new RuntimeException(Utils.format(            " Deactivate Data Collector System Component from DPM failed, status code '{}': {}",            response.getStatus(),            response.readEntity(String.class)        ));      }    } finally {      if (response != null) {        response.close();      }    }    // 3. Delete Data Collector System Component    try {      response = ClientBuilder.newClient()          .target(dpmBaseURL + "/security/rest/v1/organization/" + organizationId + "/components/delete")          .register(new CsrfProtectionFilter("CSRF"))          .request()          .header(SSOConstants.X_USER_AUTH_TOKEN, userAuthToken)          .header(SSOConstants.X_REST_CALL, true)          .post(Entity.json(ImmutableList.of(componentId)));      if (response.getStatus() != Response.Status.OK.getStatusCode()) {        throw new RuntimeException(Utils.format(            " Deactivate Data Collector System Component from DPM failed, status code '{}': {}",            response.getStatus(),            response.readEntity(String.class)        ));      }    } finally {      if (response != null) {        response.close();      }    }    // 4. Delete from Job Runner SDC list    try {      response = ClientBuilder.newClient()          .target(dpmBaseURL + "/jobrunner/rest/v1/sdc/" + componentId)          .register(new CsrfProtectionFilter("CSRF"))          .request()          .header(SSOConstants.X_USER_AUTH_TOKEN, userAuthToken)          .header(SSOConstants.X_REST_CALL, true)          .delete();      if (response.getStatus() != Response.Status.OK.getStatusCode()) {        throw new RuntimeException(Utils.format(            "Delete from DPM Job Runner SDC list failed, status code '{}': {}",            response.getStatus(),            response.readEntity(String.class)        ));      }    } finally {      if (response != null) {        response.close();      }    }    // 5. Update App Token file    updateTokenFile(context, "");    // 4. Update dpm.properties file    updateDpmProperties(context, dpmBaseURL, null, false);  }
private static String normalizeDpmBaseURL(String url) {    if (url.endsWith("/")) {      url = url.substring(0, url.length() - 1);    }    return url;  }
private static String retrieveUserToken(String url, String username, String password) {    Response response = null;    try {      Map<String, String> loginJson = new HashMap<>();      loginJson.put("userName", username);      loginJson.put("password", password);      response = ClientBuilder.newClient()          .target(url + "/security/public-rest/v1/authentication/login")          .register(new CsrfProtectionFilter("CSRF"))          .request()          .post(Entity.json(loginJson));      if (response.getStatus() != Response.Status.OK.getStatusCode()) {        throw new RuntimeException(Utils.format("DPM Login failed, status code '{}': {}",            response.getStatus(),            response.readEntity(String.class)        ));      }    } finally {      if (response != null) {        response.close();      }    }   return response.getHeaderString(SSOConstants.X_USER_AUTH_TOKEN);  }
private static void logout(String dpmBaseURL, String userAuthToken) {    Response response = null;    try {      response = ClientBuilder.newClient()          .target(dpmBaseURL + "/security/_logout")          .register(new CsrfProtectionFilter("CSRF"))          .request()          .header(SSOConstants.X_USER_AUTH_TOKEN, userAuthToken)          .cookie(SSOConstants.AUTHENTICATION_COOKIE_PREFIX + "LOGIN", userAuthToken)          .get();    } finally {      if (response != null) {        response.close();      }    }  }
private static void updateTokenFile(Context context, String appAuthToken) throws IOException {    File tokenFile = context.tokenFilePath == null ? new File(context.runtimeInfo.getConfigDir(), APP_TOKEN_FILE) : new File(context.tokenFilePath);    DataStore dataStore = new DataStore(tokenFile);    try (OutputStream os = dataStore.getOutputStream()) {      IOUtils.write(appAuthToken, os);      dataStore.commit(os);    } finally {      dataStore.release();    }  }
private static void updateDpmProperties(Context context, String dpmBaseURL, List<String> labels, boolean enableSch) {    if(context.skipUpdatingDpmProperties) {      return;    }    try {      FileBasedConfigurationBuilder<PropertiesConfiguration> builder =          new FileBasedConfigurationBuilder<>(PropertiesConfiguration.class)              .configure(new Parameters().properties()                  .setFileName(context.runtimeInfo.getConfigDir() + "/dpm.properties")                  .setThrowExceptionOnMissing(true)                  .setListDelimiterHandler(new DefaultListDelimiterHandler(';'))                  .setIncludesAllowed(false));      PropertiesConfiguration config = null;      config = builder.getConfiguration();      config.setProperty(RemoteSSOService.DPM_ENABLED, Boolean.toString(enableSch));      config.setProperty(RemoteSSOService.DPM_BASE_URL_CONFIG, dpmBaseURL);      config.setProperty(RemoteSSOService.SECURITY_SERVICE_APP_AUTH_TOKEN_CONFIG, APP_TOKEN_FILE_PROP_VAL);      if (labels != null && labels.size() > 0) {        config.setProperty(RemoteEventHandlerTask.REMOTE_JOB_LABELS, StringUtils.join(labels, ','));      } else {        config.setProperty(RemoteEventHandlerTask.REMOTE_JOB_LABELS, "");      }      builder.save();    } catch (ConfigurationException e) {      throw new RuntimeException(Utils.format("Updating dpm.properties file failed: {}", e.getMessage()), e);    }  }
@Override  public void createAndAddRecord(      ResultSet rs,      TableRuntimeContext tableRuntimeContext,      BatchContext batchContext  ) throws SQLException, StageException {    ResultSetMetaData md = rs.getMetaData();    LinkedHashMap<String, Field> fields = jdbcUtil.resultSetToFields(        rs,        commonSourceConfigBean,        errorRecordHandler,        tableJdbcConfigBean.unknownTypeAction,        recordHeader,        DatabaseVendor.SQL_SERVER    );    Map<String, String> columnOffsets = new HashMap<>();    // Generate Offset includes primary keys, sys_change_version, and sys_change_operation    for (String key : tableRuntimeContext.getSourceTableContext().getOffsetColumns()) {      String value = rs.getString(key);      if (Strings.isNullOrEmpty(value)) {        value = fields.get(key) != null ? fields.get(key).getValueAsString() : "";      }      columnOffsets.put(key, value);    }    columnOffsets.put(SYS_CHANGE_OPERATION, rs.getString(SYS_CHANGE_OPERATION));    String offsetFormat = OffsetQueryUtil.getOffsetFormat(columnOffsets);    Record record = context.createRecord(tableRuntimeContext.getQualifiedName() + "::" + offsetFormat);    record.set(Field.createListMap(fields));    //Set Column Headers    jdbcUtil.setColumnSpecificHeaders(        record,        Collections.singleton(tableRuntimeContext.getSourceTableContext().getTableName()),        md,        JDBC_NAMESPACE_HEADER    );    //Set Operation Headers    int op = MSOperationCode.convertToJDBCCode(rs.getString(SYS_CHANGE_OPERATION));    record.getHeader().setAttribute(OperationType.SDC_OPERATION_TYPE, String.valueOf(op));    for (String fieldName : recordHeader) {      record.getHeader().setAttribute(JDBC_NAMESPACE_HEADER + fieldName, rs.getString(fieldName) != null ? rs.getString(fieldName) : "NULL" );    }    int columns = rs.getMetaData().getColumnCount();    if (fields.size() != columns) {      errorRecordHandler.onError(JdbcErrors.JDBC_35, fields.size(), columns);      return; // Don't output this record.    } else {      batchContext.getBatchMaker().addRecord(record);    }    offsets.put(tableRuntimeContext.getOffsetKey(), offsetFormat);  }
private Field pullMap(XMLEventReader reader) throws StageException, XMLStreamException {    LinkedHashMap<String, Field> map = new LinkedHashMap<>();    String type = null;    String fieldValue = null;    while (reader.hasNext()) {      XMLEvent event = reader.nextEvent();      if (event.isStartElement()) {        if (event.asStartElement().getName().getLocalPart().equals(TYPE)) {          // Move to content          event = reader.nextEvent();          type = event.asCharacters().getData().toLowerCase();          // Consume closing tag          reader.nextEvent();        } else {          String fieldName = event.asStartElement().getName().getLocalPart();          Attribute attr = event.asStartElement().getAttributeByName(XSI_TYPE);          if (attr != null && attr.getValue().equals(S_OBJECT)) {            // Element is a nested record            map.put(fieldName, pullMap(reader));          } else {            event = reader.nextEvent();            fieldValue = null;            switch (event.getEventType()) {              case XMLEvent.START_ELEMENT:                // Element is a nested list of records                // Advance over <done>, <queryLocator> to record list                while (!(event.isStartElement() && event.asStartElement().getName().getLocalPart().equals(RECORDS))) {                  event = reader.nextEvent();                }                // Read record list                List<Field> recordList = new ArrayList<>();                while (event.isStartElement() && event.asStartElement().getName().getLocalPart().equals(RECORDS)) {                  recordList.add(pullMap(reader));                  event = reader.nextEvent();                }                map.put(fieldName, Field.create(recordList));                break;              case XMLEvent.CHARACTERS:                // Element is a field value                fieldValue = event.asCharacters().getData();                // Consume closing tag                reader.nextEvent();                // Intentional fall through to next case!              case XMLEvent.END_ELEMENT:                // Create the SDC field                if (type == null) {                  throw new StageException(Errors.FORCE_38);                }                // Is this a relationship to another object?                com.sforce.soap.partner.Field sfdcField = metadataCache.get(type).getFieldFromRelationship(fieldName);                if (sfdcField != null) {                  // See if we already added fields from the related record                  if (map.get(fieldName) != null) {                    // We already created this node - don't overwrite it!                    sfdcField = null;                  }                } else {                  sfdcField = getFieldMetadata(type, fieldName);                }                if (sfdcField != null) {                  Field field = createField(fieldValue, sfdcField);                  if (conf.createSalesforceNsHeaders) {                    setHeadersOnField(field, getFieldMetadata(type, fieldName));                  }                  map.put(fieldName, field);                }                break;              default:                throw new StageException(Errors.FORCE_41, event.getEventType());            }          }        }      } else if (event.isEndElement()) {        // Done with record        return Field.createListMap(map);      }    }    throw new StageException(Errors.FORCE_39);  }
protected Authentication returnUnauthorized(      HttpServletRequest httpReq, HttpServletResponse httpRes, String principalId, String logMessageTemplate  ) throws ServerAuthException {    return returnUnauthorized(httpReq, httpRes, UNAUTHORIZED_JSON, principalId, logMessageTemplate);  }
private Schema.Field schemaFieldForType(      String fieldPath,      Record record,      String fieldName,      Field field  ) throws OnRecordErrorException {    Schema simpleSchema = simpleSchemaForType(fieldPath, record, field);    Schema finalSchema = simpleSchema;    // If Nullable check box was selected, wrap the whole schema in union with null    if(getConfig().avroNullableFields) {      finalSchema = Schema.createUnion(ImmutableList.of(        Schema.create(Schema.Type.NULL),        simpleSchema      ));    }    return new Schema.Field(      fieldName,      finalSchema,      null,      getDefaultValue(simpleSchema)    );  }
private Schema complexSchemaForType(      String fieldPath,      Record record,      Field field  ) throws OnRecordErrorException {    Schema simpleSchema = simpleSchemaForType(fieldPath, record, field);    Schema finalSchema = simpleSchema;    if(getConfig().avroNullableFields) {      finalSchema = Schema.createUnion(ImmutableList.of(        Schema.create(Schema.Type.NULL),        simpleSchema      ));    }    JsonNode defaultValue = getDefaultValue(simpleSchema);    if(defaultValue != null) {      finalSchema.addProp("defaultValue", defaultValue);    }    return finalSchema;  }
private Schema simpleSchemaForType(String fieldPath, Record record, Field field) throws OnRecordErrorException {    switch (field.getType()) {      // Primitive types      case BOOLEAN:        return Schema.create(Schema.Type.BOOLEAN);      case INTEGER:        return Schema.create(Schema.Type.INT);      case LONG:        return Schema.create(Schema.Type.LONG);      case FLOAT:        return Schema.create(Schema.Type.FLOAT);      case DOUBLE:        return Schema.create(Schema.Type.DOUBLE);      case STRING:        return Schema.create(Schema.Type.STRING);      case BYTE_ARRAY:        return Schema.create(Schema.Type.BYTES);      // Logical types      case DECIMAL:        int precision = getDecimalScaleOrPrecision(record, field, getConfig().precisionAttribute, getConfig().defaultPrecision, 1);        int scale = getDecimalScaleOrPrecision(record, field, getConfig().scaleAttribute, getConfig().defaultScale, 0);        Schema decimalSchema = Schema.create(Schema.Type.BYTES);        decimalSchema.addProp(AvroTypeUtil.LOGICAL_TYPE, AvroTypeUtil.LOGICAL_TYPE_DECIMAL);        decimalSchema.addProp(AvroTypeUtil.LOGICAL_TYPE_ATTR_PRECISION, new IntNode(precision));        decimalSchema.addProp(AvroTypeUtil.LOGICAL_TYPE_ATTR_SCALE, new IntNode(scale));        return decimalSchema;      case DATE:        Schema dateSchema = Schema.create(Schema.Type.INT);        dateSchema.addProp(AvroTypeUtil.LOGICAL_TYPE, AvroTypeUtil.LOGICAL_TYPE_DATE);        return dateSchema;      case TIME:        Schema timeSchema = Schema.create(Schema.Type.INT);        timeSchema.addProp(AvroTypeUtil.LOGICAL_TYPE, AvroTypeUtil.LOGICAL_TYPE_TIME_MILLIS);        return timeSchema;      case DATETIME:        Schema dateTimeSchema = Schema.create(Schema.Type.LONG);        dateTimeSchema.addProp(AvroTypeUtil.LOGICAL_TYPE, AvroTypeUtil.LOGICAL_TYPE_TIMESTAMP_MILLIS);        return dateTimeSchema;      // Complex types      case LIST:        // In avro list must be of the same type - which is not true with our records        // We can't generate the list type from empty list        if(field.getValueAsList().isEmpty()) {          throw new OnRecordErrorException(record, Errors.SCHEMA_GEN_0006, fieldPath);        }        // And all items in the list must have the same schema        Schema itemSchema = null;        int index = 0;        for(Field listItem : field.getValueAsList()) {          Schema currentListItemSchema = complexSchemaForType(fieldPath + "[" + index + "]", record, listItem);          if(itemSchema == null) {            itemSchema = currentListItemSchema;          } else if (!itemSchema.equals(currentListItemSchema)) {            throw new OnRecordErrorException(record, Errors.SCHEMA_GEN_0005, fieldPath, itemSchema, currentListItemSchema);          }          index++;        }        return Schema.createArray(itemSchema);      case MAP:      case LIST_MAP:        // In avro maps must have key of string (same as us) and value must be the same for all items - which        // is different then our records.        // We can't generate the map value type from null or empty map        if(field.getValueAsMap() == null || field.getValueAsMap().isEmpty()) {          throw new OnRecordErrorException(record, Errors.SCHEMA_GEN_0008, fieldPath);        }        // And all values in the map must be the same        Schema mapSchema = null;        for(Map.Entry<String, Field> item : field.getValueAsMap().entrySet()) {          Schema currentListItemSchema = complexSchemaForType(fieldPath + "/" + item.getKey(), record, item.getValue());          if(mapSchema == null) {            mapSchema = currentListItemSchema;          } else if (!mapSchema.equals(currentListItemSchema)) {            throw new OnRecordErrorException(record, Errors.SCHEMA_GEN_0007, fieldPath, mapSchema, currentListItemSchema);          }        }        return Schema.createMap(mapSchema);      // Types that does not have direct equivalent in Avro      case SHORT:        if(getConfig().avroExpandTypes) {          return Schema.create(Schema.Type.INT);        }        // fall through      case CHAR:        if(getConfig().avroExpandTypes) {          return Schema.create(Schema.Type.STRING);        }        // fall through      // Not supported data types:      case BYTE:      case FILE_REF:      default:        throw new OnRecordErrorException(record, Errors.SCHEMA_GEN_0002, field.getType());    }  }
private int getDecimalScaleOrPrecision(      Record record,      Field field,      String attributeName,      int defaultValue,      int minAllowed  ) throws OnRecordErrorException {    int finalValue = -1; // Invalid value    // Firstly try the field attribute    String stringValue = field.getAttribute(attributeName);    if(!StringUtils.isEmpty(stringValue)) {      finalValue = Integer.valueOf(stringValue);    }    // If it's invalid, then use the default value    if(finalValue < minAllowed) {      finalValue = defaultValue;    }    // If even the default value is invalid, then send the record to error    if(finalValue < minAllowed) {      throw new OnRecordErrorException(record, Errors.SCHEMA_GEN_0004, finalValue, field);    }    return finalValue;  }
private JsonNode getDefaultValue(Schema schema) {    if(getConfig().avroNullableFields && getConfig().avroDefaultNullable) {      return NullNode.getInstance();    }    if(!getConfig().avroNullableFields && defaultValuesForTypes.containsKey(schema.getType())) {      return defaultValuesForTypes.get(schema.getType());    }    return null;  }
@SuppressWarnings("unchecked")  public static synchronized void initMetricsIfNeeded(ProtoConfigurableEntity.Context context) {    Gauge<Map<String, Object>> gauge = context.getGauge(fileStatisticGaugeName(context));    if(gauge == null) {      gauge = context.createGauge(fileStatisticGaugeName(context), Comparator.comparing(GAUGE_MAP_ORDERING::get));      Map<String, Object> gaugeStatistics = gauge.getValue();      //File name is populated at the MetricEnabledWrapperStream.      gaugeStatistics.put(FileRefUtil.FILE, "");      gaugeStatistics.put(FileRefUtil.TRANSFER_THROUGHPUT, 0L);      gaugeStatistics.put(FileRefUtil.SENT_BYTES, String.format(FileRefUtil.BRACKETED_TEMPLATE, 0, 0));      gaugeStatistics.put(FileRefUtil.REMAINING_BYTES, 0L);      gaugeStatistics.put(FileRefUtil.COMPLETED_FILE_COUNT, 0L);    }    Meter dataTransferMeter = context.getMeter(FileRefUtil.TRANSFER_THROUGHPUT_METER);    if (dataTransferMeter == null) {      context.createMeter(FileRefUtil.TRANSFER_THROUGHPUT_METER);    }  }
public int compare(WrappedFile path1, WrappedFile path2, boolean useLastModified) {    // why not just check if the file exists? Well, there is a possibility file gets moved/archived/deleted right after    // that check. In that case we will still fail. So fail, and recover.    try {      if (useLastModified && !exists(path2)) {        return 1;      }      return getComparator(useLastModified).compare(path1, path2);    } catch (RuntimeException ex) {      Throwable cause = ex.getCause();      // Happens only in timestamp ordering.      // Very unlikely this will happen, new file has to be added to the queue at the exact time when      // the currentFile was consumed and archived while a new file has not yet been picked up for processing.      // Ignore - we just add the new file, since this means this file is indeed newer      // (else this would have been consumed and archived first)      if (cause != null && cause instanceof NoSuchFileException) {        LOG.debug("Starting file may have already been archived.", cause);        return 1;      }      LOG.warn("Error while comparing files", ex);      throw ex;    }  }
public int indexOf(String groupName, int index) {        int idx = -1;        if (groupInfo.containsKey(groupName)) {            List<GroupInfo> list = groupInfo.get(groupName);            idx = list.get(index).groupIndex();        }        return idx;    }
public List<String> groupNames() {        if (groupNames == null) {            groupNames = new ArrayList<String>(groupInfo.keySet());        }        return groupNames;    }
static private boolean isEscapedChar(String s, int pos) {        return isSlashEscapedChar(s, pos) || isQuoteEscapedChar(s, pos);    }
static private boolean isSlashEscapedChar(String s, int pos) {        // Count the backslashes preceding this position. If it's        // even, there is no escape and the slashes are just literals.        // If it's odd, one of the slashes (the last one) is escaping        // the character at the given position.        int numSlashes = 0;        while (pos > 0 && (s.charAt(pos - 1) == '\\')) {            pos--;            numSlashes++;        }        return numSlashes % 2 != 0;    }
static private boolean isQuoteEscapedChar(String s, int pos) {        boolean openQuoteFound = false;        boolean closeQuoteFound = false;        // find last non-escaped open-quote        String s2 = s.substring(0, pos);        int posOpen = pos;        while ((posOpen = s2.lastIndexOf("\\Q", posOpen - 1)) != -1) {            if (!isSlashEscapedChar(s2, posOpen)) {                openQuoteFound = true;                break;            }        }        if (openQuoteFound) {            // search remainder of string (after open-quote) for a close-quote;            // no need to check that it's slash-escaped because it can't be            // (the escape character itself is part of the literal when quoted)            if (s2.indexOf("\\E", posOpen) != -1) {                closeQuoteFound = true;            }        }        return openQuoteFound && !closeQuoteFound;    }
static private boolean isInsideCharClass(String s, int pos) {        boolean openBracketFound = false;        boolean closeBracketFound = false;        // find last non-escaped open-bracket        String s2 = s.substring(0, pos);        int posOpen = pos;        while ((posOpen = s2.lastIndexOf('[', posOpen - 1)) != -1) {            if (!isEscapedChar(s2, posOpen)) {                openBracketFound = true;                break;            }        }        if (openBracketFound) {            // search remainder of string (after open-bracket) for a close-bracket            String s3 = s.substring(posOpen, pos);            int posClose = -1;            while ((posClose = s3.indexOf(']', posClose + 1)) != -1) {                if (!isEscapedChar(s3, posClose)) {                    closeBracketFound = true;                    break;                }            }        }        return openBracketFound && !closeBracketFound;    }
static private boolean isNoncapturingParen(String s, int pos) {        //int len = s.length();        boolean isLookbehind = false;        // code-coverage reports show that pos and the text to        // check never exceed len in this class, so it's safe        // to not test for it, which resolves uncovered branches        // in Cobertura        /*if (pos >= 0 && pos + 4 < len)*/ {            String pre = s.substring(pos, pos+4);            isLookbehind = pre.equals("(?<=") || pre.equals("(?<!");        }        return /*(pos >= 0 && pos + 2 < len) &&*/               s.charAt(pos + 1) == '?' &&               (isLookbehind || s.charAt(pos + 2) != '<');    }
static private int countOpenParens(String s, int pos) {        java.util.regex.Pattern p = java.util.regex.Pattern.compile("\\(");        java.util.regex.Matcher m = p.matcher(s.subSequence(0, pos));        int numParens = 0;        while (m.find()) {            // ignore parentheses inside character classes: [0-9()a-f]            // which are just literals            if (isInsideCharClass(s, m.start())) {                continue;            }            // ignore escaped parens            if (isEscapedChar(s, m.start())) continue;            if (!isNoncapturingParen(s, m.start())) {                numParens++;            }        }        return numParens;    }
static public Map<String,List<GroupInfo> > extractGroupInfo(String namedPattern) {        Map<String,List<GroupInfo> > groupInfo = new LinkedHashMap<String,List<GroupInfo> >();        java.util.regex.Matcher matcher = NAMED_GROUP_PATTERN.matcher(namedPattern);        while(matcher.find()) {            int pos = matcher.start();            // ignore escaped paren            if (isEscapedChar(namedPattern, pos)) continue;            String name = matcher.group(INDEX_GROUP_NAME);            int groupIndex = countOpenParens(namedPattern, pos);            List<GroupInfo> list;            if (groupInfo.containsKey(name)) {                list = groupInfo.get(name);            } else {                list = new ArrayList<GroupInfo>();            }            list.add(new GroupInfo(groupIndex, pos));            groupInfo.put(name, list);        }        return groupInfo;    }
static private StringBuilder replace(StringBuilder input, java.util.regex.Pattern pattern, String replacement) {        java.util.regex.Matcher m = pattern.matcher(input);        while (m.find()) {            if (isEscapedChar(input.toString(), m.start())) {                continue;            }            // since we're replacing the original string being matched,            // we have to reset the matcher so that it searches the new            // string            input.replace(m.start(), m.end(), replacement);            m.reset(input);        }        return input;    }
private StringBuilder replaceGroupNameWithIndex(StringBuilder input, java.util.regex.Pattern pattern, String prefix) {        java.util.regex.Matcher m = pattern.matcher(input);        while (m.find()) {            if (isEscapedChar(input.toString(), m.start())) {                continue;            }            int index = indexOf(m.group(INDEX_GROUP_NAME));            if (index >= 0) {                index++;            } else {                throw new PatternSyntaxException("unknown group name", input.toString(), m.start(INDEX_GROUP_NAME));            }            // since we're replacing the original string being matched,            // we have to reset the matcher so that it searches the new            // string            input.replace(m.start(), m.end(), prefix + index);            m.reset(input);        }        return input;    }
private java.util.regex.Pattern buildStandardPattern(String namedPattern, Integer flags) {        // replace the named-group construct with left-paren but        // make sure we're actually looking at the construct (ignore escapes)        StringBuilder s = new StringBuilder(namedPattern);        s = replace(s, NAMED_GROUP_PATTERN, "(");        s = replaceGroupNameWithIndex(s, BACKREF_NAMED_GROUP_PATTERN, "\\");        return java.util.regex.Pattern.compile(s.toString(), flags);    }
@Override  public void doGet(HttpServletRequest request, HttpServletResponse response) {    try {      JsonGenerator jg = null;      String jsonpcb = null;      PrintWriter writer = null;      try {        writer = response.getWriter();        // "callback" parameter implies JSONP outpout        jsonpcb = request.getParameter(CALLBACK_PARAM);        if (jsonpcb != null) {          response.setContentType("application/javascript; charset=utf8");          writer.write(jsonpcb + "(");        } else {          response.setContentType("application/json; charset=utf8");        }        jg = jsonFactory.createGenerator(writer);        jg.disable(JsonGenerator.Feature.AUTO_CLOSE_TARGET);        jg.useDefaultPrettyPrinter();        jg.writeStartObject();        // query per mbean attribute        String getmethod = request.getParameter("get");        if (getmethod != null) {          String[] splitStrings = getmethod.split("\\:\\:");          if (splitStrings.length != 2) {            jg.writeStringField("result", "ERROR");            jg.writeStringField("message", "query format is not as expected.");            jg.flush();            response.setStatus(HttpServletResponse.SC_BAD_REQUEST);            return;          }          listBeans(jg, new ObjectName(splitStrings[0]), splitStrings[1],                    response);          return;        }        // query per mbean        String qry = request.getParameter("qry");        if (qry == null) {          qry = "*:*";        }        listBeans(jg, new ObjectName(qry), null, response);      } finally {        if (jg != null) {          jg.close();        }        if (jsonpcb != null) {          writer.write(");");        }        if (writer != null) {          writer.close();        }      }    } catch (IOException e) {      response.setStatus(HttpServletResponse.SC_INTERNAL_SERVER_ERROR);    } catch (MalformedObjectNameException e) {      response.setStatus(HttpServletResponse.SC_BAD_REQUEST);    }  }
private void listBeans(JsonGenerator jg, ObjectName qry, String attribute,      HttpServletResponse response)      throws IOException {    Set<ObjectName> names = null;    names = mBeanServer.queryNames(qry, null);    jg.writeArrayFieldStart("beans");    Iterator<ObjectName> it = names.iterator();    while (it.hasNext()) {      ObjectName oname = it.next();      MBeanInfo minfo;      String code = "";      Object attributeinfo = null;      try {        minfo = mBeanServer.getMBeanInfo(oname);        code = minfo.getClassName();        String prs = "";        try {          if ("org.apache.commons.modeler.BaseModelMBean".equals(code)) {            prs = "modelerType";            code = (String) mBeanServer.getAttribute(oname, prs);          }          if (attribute!=null) {            prs = attribute;            attributeinfo = mBeanServer.getAttribute(oname, prs);          }        } catch (AttributeNotFoundException e) {          // If the modelerType attribute was not found, the class name is used          // instead.        } catch (MBeanException e) {          // The code inside the attribute getter threw an exception so          // and fall back on the class name        } catch (RuntimeException e) {          // For some reason even with an MBeanException available to them          // Runtime exceptionscan still find their way through, so treat them          // the same as MBeanException        } catch ( ReflectionException e ) {          // This happens when the code inside the JMX bean (setter?? from the          // java docs) threw an exception, so          // class name        }      } catch (InstanceNotFoundException e) {        //Ignored for some reason the bean was not found so don't output it        continue;      } catch ( IntrospectionException e ) {        // This is an internal error, something odd happened with reflection so        //        continue;      } catch ( ReflectionException e ) {        // This happens when the code inside the JMX bean threw an exception, so        //        continue;      }      jg.writeStartObject();      jg.writeStringField("name", oname.toString());      jg.writeStringField("modelerType", code);      if ((attribute != null) && (attributeinfo == null)) {        jg.writeStringField("result", "ERROR");        jg.writeStringField("message", "No attribute with name " + attribute                                       + " was found.");        jg.writeEndObject();        jg.writeEndArray();        jg.close();        response.setStatus(HttpServletResponse.SC_NOT_FOUND);        return;      }      if (attribute != null) {        writeAttribute(jg, attribute, attributeinfo);      } else {        MBeanAttributeInfo attrs[] = minfo.getAttributes();        for (int i = 0; i < attrs.length; i++) {          writeAttribute(jg, oname, attrs[i]);        }      }      jg.writeEndObject();    }    jg.writeEndArray();  }
private boolean refreshSchema(BigDecimal scnDecimal, SchemaAndTable schemaAndTable) throws SQLException {    try {      if (!tableSchemaLastUpdate.containsKey(schemaAndTable) || scnDecimal.compareTo(tableSchemaLastUpdate.get(schemaAndTable)) > 0) {        if (containerized) {          try (Statement switchToPdb = connection.createStatement()) {            switchToPdb.execute("ALTER SESSION SET CONTAINER = " + configBean.pdb);          }        }        tableSchemas.put(schemaAndTable, getTableSchema(schemaAndTable));        tableSchemaLastUpdate.put(schemaAndTable, scnDecimal);        return true;      }      return false;    } finally {      alterSession();    }  }
@VisibleForTesting  String getListOfSchemasAndTables(List<SchemaAndTable> schemaAndTables) {    Map<String, List<String>> schemas = new HashMap<>();    for (SchemaAndTable schemaAndTable : schemaAndTables) {      if (schemas.containsKey(schemaAndTable.getSchema())) {        schemas.get(schemaAndTable.getSchema()).add(schemaAndTable.getTable());      } else {        List<String> tbls = new ArrayList<>();        tbls.add(schemaAndTable.getTable());        schemas.put(schemaAndTable.getSchema(), tbls);      }    }    List<String> queries = new ArrayList<>();    for (Map.Entry<String, List<String>> entry : schemas.entrySet()) {      List<String> tables = new ArrayList<>();      int fromIndex = 0;      int range = 1000;      int maxIndex = entry.getValue().size();      int toIndex = range < maxIndex ? range : maxIndex;      while (fromIndex < toIndex) {        tables.add(Utils.format(            "TABLE_NAME IN ({})", formatTableList(entry.getValue().subList(fromIndex, toIndex))));        fromIndex = toIndex;        toIndex = (toIndex + range) < maxIndex ? (toIndex + range) : maxIndex;      }      queries.add(Utils.format("(SEG_OWNER='{}' AND ({}))", entry.getKey(), String.join(" OR ", tables)));    }    return "( " + String.join(" OR ", queries) + " )";  }
private boolean expired(Map.Entry<TransactionIdKey, HashQueue<RecordSequence>> entry, LocalDateTime startTime) {    return startTime != null && // Can be null if starting from SCN and first batch is not complete yet.        entry.getKey().txnStartTime.isBefore(startTime.minusSeconds(configBean.txnWindow)) &&        entry.getValue().peek().seq == 1;  }
@Override  public long getOffset() {    Utils.checkState(open, Utils.formatL("LiveFileReder for '{}' is not open", currentFile));    return (truncateMode) ? -offset : offset;  }
private boolean fastForward() throws IOException {    try {      boolean stillTruncate;      buffer.clear();      if (channel.read(buffer) > -1 || isEof()) {        //set the buffer into read from mode        buffer.flip();        //we have data, lets look for the first EOL in it.        int firstEolIdx = findEndOfFirstLine(buffer);        if (firstEolIdx > -1) {          // set position to position after first EOL          buffer.position(firstEolIdx + 1);          // set the buffer back into write into mode keeping data after first EOL          buffer.compact();          stillTruncate = false;          offset = channel.position() - buffer.position();        } else {          // no EOL yet          // whatever was read will be discarded on next next() call          stillTruncate = true;          offset = channel.position();        }      } else {        // no data read        // whatever was read will be discarded on next next() call        stillTruncate = true;        offset = channel.position();      }      return stillTruncate;    } catch (IOException ex) {      closeChannel();      throw ex;    }  }
private static void initRabbitConf(Channel channel, BaseRabbitConfigBean conf) throws IOException{    // Channel is always bound to the default exchange. When specified, we must declare the exchange.    for (RabbitExchangeConfigBean exchange : conf.exchanges) {      channel.exchangeDeclare(          exchange.name,          exchange.type.getValue(),          exchange.durable,          exchange.autoDelete,          exchange.declarationProperties      );    }    channel.queueDeclare(        conf.queue.name,        conf.queue.durable,        conf.queue.exclusive,        conf.queue.autoDelete,        conf.queue.properties    );    for (RabbitExchangeConfigBean exchange : conf.exchanges) {      bindQueue(channel, conf, exchange);    }  }
@Path("/detachedstage")  @GET  @ApiOperation(value = "Returns empty envelope for detached stage.",    response = DetachedStageConfigurationJson.class,    authorizations = @Authorization(value = "basic")  )  @Produces(MediaType.APPLICATION_JSON)  @RolesAllowed({      AuthzRole.CREATOR, AuthzRole.ADMIN, AuthzRole.CREATOR_REMOTE, AuthzRole.ADMIN_REMOTE  })  public Response createDetachedStageEnvelope() throws PipelineException {    DetachedStageConfigurationJson detachedStage = new DetachedStageConfigurationJson(new DetachedStageConfiguration());    return Response.ok().entity(detachedStage).build();  }
static byte[] extract(InputStream is, ByteArrayOutputStream overflowBuffer, int limit) throws IOException {    // the inputstream we get has been already stripped of the magic byte if first call    byte[] message;    if (copy(is, overflowBuffer, limit - overflowBuffer.size())) {      // got rest of payload without exceeding the max message size      if (overflowBuffer.size() == 0) {        // there is no more payload        message = null;      } else {        // extract the rest payload and prefix it with the magic byte        byte[] data = overflowBuffer.toByteArray();        message = new byte[data.length + 1];        message[0] = JSON1_MAGIC_NUMBER;        System.arraycopy(data, 0, message, 1, data.length);        overflowBuffer.reset();      }    } else {      // got partial payload, exceeded the max message size      byte[] data = overflowBuffer.toByteArray();      // find last full record in partial payload      int lastEOL = findEndOfLastLineBeforeLimit(data, limit);      if (lastEOL == -1) {        throw new IOException(Utils.format("Maximum message size '{}' exceeded", limit));      }      // extract payload up to last EOL and prefix with the magic byte      message = new byte[lastEOL + 1];      message[0] = JSON1_MAGIC_NUMBER;      System.arraycopy(data, 0, message, 1, lastEOL);      // put back in the stream buffer the portion of the payload that did not make it to the message      overflowBuffer.reset();      overflowBuffer.write(data, lastEOL, data.length - lastEOL);    }    return message;  }
@Override  public RecordReader createRecordReader(      InputStream inputStream,      long initialPosition,      int maxObjectLen  ) throws IOException {    return RecordWriterReaderFactory.createRecordReader(inputStream, initialPosition, maxObjectLen);  }
private static Object convertStringToAppropriateNumber(String value) {    if(value.contains(".")) {      return Double.valueOf(value);    } else {      return Long.valueOf(value);    }  }
private int parsePart(int startOffset, ByteBuf buf, Map<String, Field> fields) throws OnRecordErrorException {    int offset = startOffset;    int type = buf.getUnsignedShort(offset); // 0-1    offset += 2;    final int length = buf.getUnsignedShort(offset); // 2-3    offset += 2;    switch (type) {      case HOST:      case PLUGIN:      case PLUGIN_INSTANCE:      case TYPE:      case TYPE_INSTANCE:      case MESSAGE:        pruneFields(type);        fields.put(PART_TYPES.get(type), Field.create(parseString(offset, length, buf)));        offset += length - 4;        break;      case TIME_HIRES:      case INTERVAL_HIRES:        if (type != INTERVAL_HIRES || !excludeInterval) {          long value = parseNumeric(offset, buf);          if (convertTime) {            value *= (Math.pow(2, -30) * 1000);            type = type == TIME_HIRES ? TIME : INTERVAL;          }          fields.put(PART_TYPES.get(type), Field.create(value));        }        offset += 8;        break;      case TIME:      case INTERVAL:      case SEVERITY:        if (type != INTERVAL || !excludeInterval) {          fields.put(PART_TYPES.get(type), Field.create(parseNumeric(offset, buf)));        }        offset += 8;        break;      case VALUES:        offset = parseValues(offset, buf);        startNewRecord();        break;      case SIGNATURE:        if (!verifySignature(offset, length, buf)) {          throw new OnRecordErrorException(Errors.COLLECTD_02);        }        offset += length - 4;        break;      case ENCRYPTION:        String user = parseUser(offset, buf);        offset += (2 + user.length());        byte[] iv = parseIv(offset, buf);        offset += 16;        decrypt(offset, length, buf, user, iv);        // Skip the checksum and continue processing.        offset += 20;        break;      default:        // Don't recognize this part type, so skip it        LOG.warn("Unrecognized part type: {}", type);        offset += length - 4;        break;    }    return offset;  }
private int parseValues(int startOffset, ByteBuf buf) throws OnRecordErrorException {    int offset = startOffset;    // N Values    // For each Value:    // 1 byte data type code    int numValues = buf.getUnsignedShort(offset); // 4-5    offset += 2;    List<Byte> types = new ArrayList<>(numValues);    while (numValues-- > 0) {      types.add(buf.getByte(offset));      offset += 1;    }    for (int i = 0; i < types.size(); i++) {      Byte type = types.get(i);      String label = getValueLabel(i, type);      switch (type) {        case COUNTER:          fields.put(label, Field.create(buf.getUnsignedInt(offset)));          offset += 8;          break;        case GAUGE:          fields.put(              label,              Field.create(buf.order(ByteOrder.LITTLE_ENDIAN).getDouble(offset))          );          offset += 8;          break;        case DERIVE:          fields.put(label, Field.create(buf.getLong(offset)));          offset += 8;          break;        case ABSOLUTE:          fields.put(label, Field.create(buf.getUnsignedInt(offset)));          offset += 8;          break;        default:          // error          throw new OnRecordErrorException(Errors.COLLECTD_01, type);      }    }    return offset;  }
public static Field getUnsignedShortField(byte[] bytes) {    Utils.checkState(bytes.length == 2, "2 bytes required to parse an unsigned short");    final short shortVal = Shorts.fromByteArray(bytes);    int intVal = shortVal >= 0 ? shortVal : 0x10000 + shortVal;    return Field.create(intVal);  }
@Override  public String inferSchema(Map<String, HiveTypeInfo> record)      throws StageException  {    Map<String, Schema> fields = new LinkedHashMap<>();    for(Map.Entry<String, HiveTypeInfo> pair:  record.entrySet()) {      if(!HiveMetastoreUtil.validateObjectName(pair.getKey())) {        throw new HiveStageCheckedException(Errors.HIVE_30, pair.getKey());      }      Schema columnSchema = Schema.createUnion(ImmutableList.of(Schema.create(Schema.Type.NULL), traverse(pair)));      // We always set default value to null      columnSchema.addProp("default", NullNode.getInstance());      fields.put(pair.getKey(), columnSchema);    }    Schema schema =  buildSchema(fields);    return schema.toString();  }
public static String nameForType(DatabaseVendor vendor, int jdbcType) {    for( JDBCType sqlType : JDBCType.class.getEnumConstants()) {      if(jdbcType == sqlType.getVendorTypeNumber())        return sqlType.name();    }    switch (vendor) {      case ORACLE:        switch (jdbcType) {          case -101: return "TIMESTAMP WITH TIME ZONE";          case -102: return "TIMESTAMP WITH LOCAL TIME ZONE";        }        break;    }    return "Unknown";  }
public static String getQualifiedTableName(String schema, String tableName) {    return StringUtils.isEmpty(schema) ? tableName : schema + "." + tableName ;  }
public static String getQuotedQualifiedTableName(String schema, String tableName, String qC) {    String quotedTableName = String.format(OffsetQueryUtil.QUOTED_NAME, qC, tableName, qC);    return StringUtils.isEmpty(schema) ?        quotedTableName: String.format(OffsetQueryUtil.QUOTED_NAME, qC, schema, qC)  + "." + quotedTableName ;  }
private void populateInitialOffset(      PushSource.Context context,      List<Stage.ConfigIssue> issues,      Map<String, String> configuredColumnToInitialOffset,      TableJdbcELEvalContext tableJdbcELEvalContext,      Map<String, String> offsetColumnToStartOffset  ) throws StageException {    for (Map.Entry<String, String> partitionColumnInitialOffsetEntry : configuredColumnToInitialOffset.entrySet()) {      String value;      try {        value = tableJdbcELEvalContext.evaluateAsString(            "offsetColumnToInitialOffsetValue",            partitionColumnInitialOffsetEntry.getValue()        );        if (value == null) {          issues.add(context.createConfigIssue(              Groups.TABLE.name(),              TableJdbcConfigBean.TABLE_CONFIG,              JdbcErrors.JDBC_73,              partitionColumnInitialOffsetEntry.getValue(),              Utils.format("Expression returned date as null. Check Expression")          ));          return;        }      } catch (ELEvalException e) {        issues.add(context.createConfigIssue(            Groups.TABLE.name(),            TableJdbcConfigBean.TABLE_CONFIG,            JdbcErrors.JDBC_73,            partitionColumnInitialOffsetEntry.getValue(),            e        ));        return;      }      offsetColumnToStartOffset.put(          partitionColumnInitialOffsetEntry.getKey(),          value      );    }  }
public Map<String, TableContext> listTablesForConfig(      DatabaseVendor vendor,      PushSource.Context context,      List<Stage.ConfigIssue> issues,      Connection connection,      TableConfigBean tableConfigBean,      TableJdbcELEvalContext tableJdbcELEvalContext,      QuoteChar quoteChar  ) throws SQLException, StageException {    Map<String, TableContext> tableContextMap = new LinkedHashMap<>();    Pattern tableExclusion =        StringUtils.isEmpty(tableConfigBean.tableExclusionPattern)?            null : Pattern.compile(tableConfigBean.tableExclusionPattern);    Pattern schemaExclusion =        StringUtils.isEmpty(tableConfigBean.schemaExclusionPattern)?            null : Pattern.compile(tableConfigBean.schemaExclusionPattern);    try (ResultSet rs = jdbcUtil.getTableAndViewMetadata(connection, tableConfigBean.schema, tableConfigBean.tablePattern)) {      while (rs.next()) {        String schemaName = rs.getString(TABLE_METADATA_TABLE_SCHEMA_CONSTANT);        String tableName = rs.getString(TABLE_METADATA_TABLE_NAME_CONSTANT);        if (            (tableExclusion == null || !tableExclusion.matcher(tableName).matches()) &&            (schemaExclusion == null || !schemaExclusion.matcher(schemaName).matches())        ) {          TableContext tableContext = createTableContext(              vendor,              context,              issues,              connection,              schemaName,              tableName,              tableConfigBean,              tableJdbcELEvalContext,              quoteChar          );          if (tableContext != null) {            tableContextMap.put(                getQualifiedTableName(schemaName, tableName),                tableContext            );          }        }      }    }    return tableContextMap;  }
void lookupPrimaryKeys() throws StageException {    Connection connection = null;    try {      connection = dataSource.getConnection();      primaryKeyColumns = jdbcUtil.getPrimaryKeys(connection, schema, tableName);    } catch (SQLException e) {      String formattedError = jdbcUtil.formatSqlException(e);      LOG.error(formattedError, e);      throw new StageException(JdbcErrors.JDBC_17, tableName, formattedError);    } finally {      if (connection != null) {        try {          connection.close();        } catch (SQLException e) {          String formattedError = jdbcUtil.formatSqlException(e);          LOG.error(formattedError, e);        }      }    }  }
private void createDefaultFieldMappings() throws StageException {    try (Connection connection = dataSource.getConnection()) {      try (ResultSet res = jdbcUtil.getTableMetadata(connection, schema, tableName)) {        if (!res.next()) {          throw new StageException(JdbcErrors.JDBC_16, getTableName());        }      }      try (ResultSet columns = jdbcUtil.getColumnMetadata(connection, schema, tableName)) {        while (columns.next()) {          String columnName = columns.getString(COLUMN_NAME);          columnsToFields.put(columnName, "/" + columnName); // Default implicit field mappings          columnsToParameters.put(columnName, "?");          columnType.put(columnName, columns.getInt(DATA_TYPE));        }      }    } catch (SQLException e) {      String errorMessage = jdbcUtil.formatSqlException(e);      LOG.error(errorMessage);      LOG.debug(errorMessage, e);      throw new StageException(JdbcErrors.JDBC_09, tableName);    }  }
private void createCustomFieldMappings() {    for (JdbcFieldColumnParamMapping mapping : customMappings) {      LOG.debug("Custom mapping field {} to column {}", mapping.field, mapping.columnName);      if (columnsToFields.containsKey(mapping.columnName)) {        LOG.debug("Mapping field {} to column {}", mapping.field, mapping.columnName);        columnsToFields.put(mapping.columnName, mapping.field);        columnsToParameters.put(mapping.columnName, mapping.paramValue);      }    }  }
static String getSQLTypeName(Field.Type type) throws OnRecordErrorException {    switch (type) {      case BOOLEAN:        return "BOOLEAN";      case CHAR:        return "CHAR";      case BYTE:        return "BINARY";      case SHORT:        return "SMALLINT";      case INTEGER:        return "INTEGER";      case LONG:        return "BIGINT";      case FLOAT:        return "FLOAT";      case DOUBLE:        return "DOUBLE";      case DATE:        return "DATE";      case TIME:        return "TIME";      case DATETIME:        return "TIMESTAMP";      case DECIMAL:        return "DECIMAL";      case STRING:        return "VARCHAR";      case BYTE_ARRAY:        return "VARBINARY";      case LIST_MAP:      case MAP:        throw new OnRecordErrorException(JdbcErrors.JDBC_05, "Unsupported list or map type: MAP");      case LIST:        return "ARRAY";      default:        throw new OnRecordErrorException(JdbcErrors.JDBC_05, "Unsupported type: " + type.name());    }  }
protected String getTableName() {    if (!Strings.isNullOrEmpty(schema)) {      if (caseSensitive) {        return "\"" + schema + "\"." + "\"" + tableName + "\"";      } else {        return schema + "." + tableName;      }    }    if (caseSensitive) {      return "\"" + tableName + "\"";    }    return tableName;  }
int setPrimaryKeys(int index, final Record record, PreparedStatement statement, int opCode)      throws OnRecordErrorException {    for (String key : getPrimaryKeyColumns()) {      Field field = record.get(recordReader.getFieldPath(key, getColumnsToFields(), opCode));      if(field == null){        LOG.error("Primary key {} is missing in record", key);        throw new OnRecordErrorException(record, JdbcErrors.JDBC_19, key);      }      Object value = field.getValue();      try {        statement.setObject(index, value, getColumnType(key));      } catch (SQLException ex){        LOG.error("SQLException thrown: {}", ex.getMessage());        throw new OnRecordErrorException(record, JdbcErrors.JDBC_19, key, ex);      }      ++index;    }    return index;  }
void handleSqlException(SQLException e) throws StageException {    String formattedError = jdbcUtil.formatSqlException(e);    LOG.error(formattedError, e);    throw new StageException(JdbcErrors.JDBC_14, e.getSQLState(), e.getErrorCode(), e.getMessage(), formattedError, e);  }
protected int getOperationCode(Record record, List<OnRecordErrorException> errorRecords) {    return recordReader.getOperationFromRecord(        record,        defaultOpCode,        unsupportedAction,        errorRecords);  }
public Multimap<SchemaAndTable, Record> classify(Batch batch) throws OnRecordErrorException {    Multimap<SchemaAndTable, Record> partitions = ArrayListMultimap.create();    Iterator<Record> batchIterator = batch.getRecords();    while (batchIterator.hasNext()) {      Record record = batchIterator.next();      String schemaName = schemaNameExpr;      String tableName = tableNameExpr;      if (dynamicSchemaName) {        try {          RecordEL.setRecordInContext(schemaNameVars, record);          schemaName = schemaNameEval.eval(schemaNameVars, schemaNameExpr, String.class);          LOG.debug("Expression '{}' is evaluated to '{}' : ", schemaNameExpr, schemaName);        } catch (ELEvalException e) {          LOG.error("Failed to evaluate expression '{}' : ", schemaNameExpr, e.toString(), e);          throw new OnRecordErrorException(record, e.getErrorCode(), e.getParams());        }      }      if (dynamicTableName) {        try {          RecordEL.setRecordInContext(tableNameVars, record);          tableName = tableNameEval.eval(tableNameVars, tableNameExpr, String.class);          LOG.debug("Expression '{}' is evaluated to '{}' : ", tableNameExpr, tableName);        } catch (ELEvalException e) {          LOG.error("Failed to evaluate expression '{}' : ", tableNameExpr, e.toString(), e);          throw new OnRecordErrorException(record, e.getErrorCode(), e.getParams());        }      }      SchemaAndTable partitionKey = new SchemaAndTable(schemaName, tableName);      partitions.put(partitionKey, record);    }    return partitions;  }
public void process(    Map<String, String> offsets,    int batchSize,    ReportErrorDelegate reportErrorDelegate  ) throws StageException, PipelineRuntimeException {    this.reportErrorDelegate = reportErrorDelegate;    getStage().setReportErrorDelegate(this);    try {      MDC.put(LogConstants.STAGE, getStage().getInfo().getInstanceName());      getStage().execute(offsets, batchSize);    } finally {      MDC.put(LogConstants.STAGE, "");    }  }
public void prepareBatchContext(BatchContextImpl batchContext) {    PipeBatch pipeBatch = batchContext.getPipeBatch();    // Start stage in the pipe batch and persist reference to batch maker in the batch context    BatchMakerImpl batchMaker = pipeBatch.startStage(this);    batchContext.setBatchMaker(batchMaker);    batchContext.setOriginStageName(      getStage().getInfo().getInstanceName(),      getStage().getInfo().getLabel()    );  }
public Map<String, Object> finishBatchContext(BatchContextImpl batchContext) throws StageException {    return finishBatchAndCalculateMetrics(      batchContext.getStartTime(),      batchContext.getPipeBatch(),      (BatchMakerImpl) batchContext.getBatchMaker(),      batchContext.getPipeBatch().getBatch(this),      batchContext.getPipeBatch().getErrorSink(),      batchContext.getPipeBatch().getEventSink(),      null    );  }
private Map<String, Field> flattenEntireRecord(Field rootField) {    Map<String, Field> ret = new LinkedHashMap<>();    switch (rootField.getType()) {      case MAP:      case LIST_MAP:        flattenMap("", rootField.getValueAsMap(), ret);        break;      case LIST:        flattenList("", rootField.getValueAsList(), ret);        break;      default:        break;    }    return ret;  }
public static<T> DetachedStageRuntime<? extends T> create(    StageBean bean,    Stage.Info info,    Stage.Context context,    Class<T> klass  ) {    switch (bean.getDefinition().getType()) {      case PROCESSOR:        return new DetachedStageRuntime.DetachedProcessor(bean, info, context);      case TARGET:      case EXECUTOR:        return new DetachedStageRuntime.DetachedTarget(bean, info, context);      default:        throw new RuntimeException("Unsupported stage type: " + bean.getDefinition().getType());    }  }
private void execute(Record record) throws OnRecordErrorException {    // This is a contrived example, normally you may be performing an operation that could throw    // an exception or produce an error condition. In that case you can throw an OnRecordErrorException    // to send this record to the error pipeline with some details.    if (!record.has("/someField")) {      throw new OnRecordErrorException(Errors.SAMPLE_01, record, "exception detail message.");    }    // TODO: execute action  }
@Override  public SortedMap<String, String> getColumnsToParameters(      final Record record, int op,      Map<String, String> parameters,      Map<String, String> columnsToFields)  {    SortedMap<String, String> columnsToParameters = new TreeMap<>();    for (Map.Entry<String, String> entry : columnsToFields.entrySet()) {      String columnName = entry.getKey();      String fieldPath = entry.getValue();      if(op == OperationType.DELETE_CODE){        fieldPath = fieldPath.replace(DATA_FIELD, OLD_DATA_FIELD);      }      if (record.has(fieldPath)) {        columnsToParameters.put(columnName, parameters.get(columnName));      }    }    return columnsToParameters;  }
@Override  String getFieldPath(String columnName, Map<String, String> columnsToField, int op) {    if (op == OperationType.DELETE_CODE){      String fieldPath = columnsToField.get(columnName);      if (fieldPath == null){        LOG.error("Column name {} is not defined in column-filed mapping", columnName);        return null;      }      return fieldPath.replace("/Data", "/OldData");    }    // For insert and update, ok to use the field name set by column-field mapping    return columnsToField.get(columnName);  }
public static Pair<String, List<Pair<Integer, String>>> buildAndReturnQueryAndParamValToSet(      TableRuntimeContext tableRuntimeContext,      String lastOffset,      String quoteChar,      TableJdbcELEvalContext tableJdbcELEvalContext  ) throws ELEvalException {    final TableContext tableContext = tableRuntimeContext.getSourceTableContext();    StringBuilder queryBuilder = new StringBuilder();    List<Pair<Integer, String>> paramValueToSet = new ArrayList<>();    queryBuilder.append(buildBaseTableQuery(tableRuntimeContext, quoteChar));    Map<String, String> storedTableToOffset = getColumnsToOffsetMapFromOffsetFormat(lastOffset);    final boolean noStoredOffsets = storedTableToOffset.isEmpty();    //Determines whether an initial offset is specified in the config and there is no stored offset.    boolean isOffsetOverriden = tableContext.isOffsetOverriden() && noStoredOffsets;    OffsetComparison minComparison = OffsetComparison.GREATER_THAN;    Map<String, String> offset = null;    if (isOffsetOverriden) {      //Use the offset in the configuration      offset = tableContext.getOffsetColumnToStartOffset();    } else if (tableRuntimeContext.isPartitioned() && noStoredOffsets) {      // use partitioned starting offsets      offset = tableRuntimeContext.getStartingPartitionOffsets();      minComparison = OffsetComparison.GREATER_THAN_OR_EQUALS;    } else {      // if offset is available      // get the stored offset (which is of the form partitionName=value) and strip off 'offsetColumns=' prefix      // else null      // offset = storedOffsets;      offset = storedTableToOffset;    }    Map<String, String> maxOffsets = new HashMap<>();    if (tableRuntimeContext.isPartitioned()) {      maxOffsets.putAll(tableRuntimeContext.getMaxPartitionOffsets());    }    List<String> finalAndConditions = new ArrayList<>();    //Apply last offset conditions    if (offset != null && !offset.isEmpty()) {      List<String> finalOrConditions = new ArrayList<>();      List<String> preconditions = new ArrayList<>();      List<Pair<Integer, String>> preconditionParamVals = new ArrayList<>();      //For partition columns p1, p2 and p3 with offsets o1, o2 and o3 respectively, the query will look something like      //select * from tableName where (p1 > o1) or (p1 = o1 and p2 > o2) or (p1 = o1 and p2 = o2 and p3 > o3) order by p1, p2, p3.      for (String partitionColumn : tableContext.getOffsetColumns()) {        int partitionSqlType = tableContext.getOffsetColumnType(partitionColumn);        String partitionOffset = offset.get(partitionColumn);        String thisPartitionColumnMax = null;        boolean hasMaxOffset = false;        // add max value for partition column (if applicable)        if (maxOffsets.containsKey(partitionColumn)) {          final String maxOffset = maxOffsets.get(partitionColumn);          if (!Strings.isNullOrEmpty(maxOffset)) {            Pair<Integer, String> paramValForCurrentOffsetColumnMax = Pair.of(partitionSqlType, maxOffset);            // add for current partition column max value            paramValueToSet.add(paramValForCurrentOffsetColumnMax);            thisPartitionColumnMax =                getConditionForPartitionColumn(                    partitionColumn,                    OffsetComparison.LESS_THAN,                    preconditions,                    quoteChar                );            hasMaxOffset = true;          }        }        final String thisPartitionColumnMin = getConditionForPartitionColumn(partitionColumn,            minComparison,            preconditions,            quoteChar        );        String conditionForThisPartitionColumn;        if (hasMaxOffset) {          conditionForThisPartitionColumn = String.format(              AND_CONDITION_FORMAT,              // add max condition first, since its param to set was already added              thisPartitionColumnMax,              thisPartitionColumnMin          );        } else {          conditionForThisPartitionColumn = String.format(CONDITION_FORMAT, thisPartitionColumnMin);        }        //Add for preconditions (EX: composite keys)        paramValueToSet.addAll(new ArrayList<>(preconditionParamVals));        Pair<Integer, String> paramValForCurrentOffsetColumn = Pair.of(partitionSqlType, partitionOffset);        //Add for current partition column        paramValueToSet.add(paramValForCurrentOffsetColumn);        finalOrConditions.add(conditionForThisPartitionColumn);        preconditions.add(            getConditionForPartitionColumn(                partitionColumn,                OffsetComparison.EQUALS,                Collections.emptyList(),                quoteChar            )        );        preconditionParamVals.add(paramValForCurrentOffsetColumn);      }      finalAndConditions.add(String.format(CONDITION_FORMAT, OR_JOINER.join(finalOrConditions)));    }    if (!StringUtils.isEmpty(tableContext.getExtraOffsetColumnConditions())) {      //Apply extra offset column conditions configured which will be appended as AND on the query      String condition =          tableJdbcELEvalContext.evaluateAsString(              "extraOffsetColumnConditions",              tableContext.getExtraOffsetColumnConditions()          );      finalAndConditions.add(String.format(CONDITION_FORMAT, condition));    }    if (!finalAndConditions.isEmpty()) {      queryBuilder.append(String.format(WHERE_CLAUSE, AND_JOINER.join(finalAndConditions)));    }    Collection<String> quotedOffsetColumns =        tableContext.getOffsetColumns().stream().map(            offsetCol -> String.format(QUOTED_NAME, quoteChar, offsetCol, quoteChar)        ).collect(Collectors.toList());    queryBuilder.append(String.format(ORDER_BY_CLAUSE, COMMA_SPACE_JOINER.join(quotedOffsetColumns)));    return Pair.of(queryBuilder.toString(),paramValueToSet);  }
private static String getConditionForPartitionColumn(      String partitionColumn,      OffsetComparison comparison,      List<String> preconditions,      String quoteChar  ) {    String conditionTemplate = comparison.getQueryCondition();    List<String> finalConditions = new ArrayList<>(preconditions);    finalConditions.add(        String.format(            conditionTemplate,            String.format(QUOTED_NAME, quoteChar, partitionColumn, quoteChar),            PREPARED_STATEMENT_POSITIONAL_PARAMETER        )    );    return AND_JOINER.join(finalConditions);  }
public static Map<String, String> getColumnsToOffsetMapFromOffsetFormat(String lastOffset) {    Map<String, String> offsetColumnsToOffsetMap = new HashMap<>();    if (StringUtils.isNotBlank(lastOffset)) {      Iterator<String> offsetColumnsAndOffsetIterator = OFFSET_COLUMN_SPLITTER.split(lastOffset).iterator();      while (offsetColumnsAndOffsetIterator.hasNext()) {        String offsetColumnAndOffset = offsetColumnsAndOffsetIterator.next();        String[] offsetColumnOffsetSplit = offsetColumnAndOffset.split("=");        String offsetColumn = offsetColumnOffsetSplit[0];        String offset = offsetColumnOffsetSplit[1];        offsetColumnsToOffsetMap.put(offsetColumn, offset);      }    }    return offsetColumnsToOffsetMap;  }
public static String getOffsetFormatFromColumns(TableRuntimeContext tableContext, Map<String, Field> fields) throws StageException {    return getOffsetFormat(getOffsetsFromColumns(tableContext, fields));  }
public static Map<String, String> getOffsetsFromSourceKeyRepresentation(String offsets) {    final Map<String, String> offsetMap = new HashMap<>();    if (StringUtils.isNotBlank(offsets)) {      for (String col : StringUtils.splitByWholeSeparator(offsets, OFFSET_KEY_COLUMN_SEPARATOR)) {        final String[] parts = StringUtils.splitByWholeSeparator(col, OFFSET_KEY_COLUMN_NAME_VALUE_SEPARATOR, 2);        if (parts.length != 2) {          throw new IllegalArgumentException(String.format(              "Invalid column offset of \"%s\" seen.  Expected colName%svalue.  Full offsets representation: %s",              col,              OFFSET_KEY_COLUMN_NAME_VALUE_SEPARATOR,              offsets          ));        }        offsetMap.put(parts[0], parts[1]);      }    }    return offsetMap;  }
public static Map<String, String> validateStoredAndSpecifiedOffset(TableContext tableContext, String offset) throws StageException {    Set<String> expectedColumns = Sets.newHashSet(tableContext.getOffsetColumns());    final Map<String, String> actualOffsets = getColumnsToOffsetMapFromOffsetFormat(offset);    // only perform the actual validation below if there ARE stored offsets    if (actualOffsets.size() == 0) {      return actualOffsets;    }    Set<String> actualColumns = actualOffsets.keySet();    Set<String> expectedSetDifference = Sets.difference(expectedColumns, actualColumns);    Set<String> actualSetDifference = Sets.difference(actualColumns, expectedColumns);    if (expectedSetDifference.size() > 0 || actualSetDifference.size() >  0) {      throw new StageException(          JdbcErrors.JDBC_71,          tableContext.getQualifiedName(),          COMMA_SPACE_JOINER.join(actualColumns),          COMMA_SPACE_JOINER.join(expectedColumns)      );    }    return actualOffsets;  }
public SupportBundle generateNewBundle(List<String> generators, BundleType bundleType) throws IOException {    List<BundleContentGeneratorDefinition> defs = getRequestedDefinitions(generators);    return generateNewBundleFromInstances(defs.stream().map(BundleContentGeneratorDefinition::createInstance).collect(Collectors.toList()), bundleType);  }
public SupportBundle generateNewBundleFromInstances(    List<BundleContentGenerator> generators,    BundleType bundleType  ) throws IOException {    PipedInputStream inputStream = new PipedInputStream();    PipedOutputStream outputStream = new PipedOutputStream();    inputStream.connect(outputStream);    ZipOutputStream zipOutputStream = new ZipOutputStream(outputStream);    executor.submit(() -> generateNewBundleInternal(generators, bundleType, zipOutputStream));    String bundleName = generateBundleName(bundleType);    String bundleKey = generateBundleDate(bundleType) + "/" + bundleName;    return new SupportBundle(      bundleKey,      bundleName,      inputStream    );  }
public void uploadNewBundle(List<String> generators, BundleType bundleType) throws IOException {    List<BundleContentGeneratorDefinition> defs = getRequestedDefinitions(generators);    uploadNewBundleFromInstances(      defs.stream()        .map(BundleContentGeneratorDefinition::createInstance)        .collect(Collectors.toList()        ),      bundleType    );  }
public void uploadNewBundleFromInstances(List<BundleContentGenerator> generators, BundleType bundleType) throws IOException {    // Generate bundle    SupportBundle bundle = generateNewBundleFromInstances(generators, bundleType);    boolean enabled = configuration.get(Constants.UPLOAD_ENABLED, Constants.DEFAULT_UPLOAD_ENABLED);    String accessKey = configuration.get(Constants.UPLOAD_ACCESS, Constants.DEFAULT_UPLOAD_ACCESS);    String secretKey = configuration.get(Constants.UPLOAD_SECRET, Constants.DEFAULT_UPLOAD_SECRET);    String bucket = configuration.get(Constants.UPLOAD_BUCKET, Constants.DEFAULT_UPLOAD_BUCKET);    int bufferSize = configuration.get(Constants.UPLOAD_BUFFER_SIZE, Constants.DEFAULT_UPLOAD_BUFFER_SIZE);    if(!enabled) {      throw new IOException("Uploading support bundles was disabled by administrator.");    }    AWSCredentialsProvider credentialsProvider = new StaticCredentialsProvider(new BasicAWSCredentials(accessKey, secretKey));    AmazonS3Client s3Client = new AmazonS3Client(credentialsProvider, new ClientConfiguration());    s3Client.setS3ClientOptions(new S3ClientOptions().withPathStyleAccess(true));    s3Client.setRegion(Region.getRegion(Regions.US_WEST_2));    // Object Metadata    ObjectMetadata s3Metadata = new ObjectMetadata();    for(Map.Entry<Object, Object> entry: getMetadata(bundleType).entrySet()) {      s3Metadata.addUserMetadata((String)entry.getKey(), (String)entry.getValue());    }    List<PartETag> partETags;    InitiateMultipartUploadResult initResponse = null;    try {      // Uploading part by part      LOG.info("Initiating multi-part support bundle upload");      partETags = new ArrayList<>();      InitiateMultipartUploadRequest initRequest = new InitiateMultipartUploadRequest(bucket, bundle.getBundleKey());      initRequest.setObjectMetadata(s3Metadata);      initResponse = s3Client.initiateMultipartUpload(initRequest);    } catch (AmazonClientException e) {      LOG.error("Support bundle upload failed: ", e);      throw new IOException("Support bundle upload failed", e);    }    try {      byte[] buffer = new byte[bufferSize];      int partId = 1;      int size = -1;      while ((size = readFully(bundle.getInputStream(), buffer)) != -1) {        LOG.debug("Uploading part {} of size {}", partId, size);        UploadPartRequest uploadRequest = new UploadPartRequest()          .withBucketName(bucket)          .withKey(bundle.getBundleKey())          .withUploadId(initResponse.getUploadId())          .withPartNumber(partId++)          .withInputStream(new ByteArrayInputStream(buffer))          .withPartSize(size);        partETags.add(s3Client.uploadPart(uploadRequest).getPartETag());      }      CompleteMultipartUploadRequest compRequest = new CompleteMultipartUploadRequest(        bucket,        bundle.getBundleKey(),        initResponse.getUploadId(),        partETags      );      s3Client.completeMultipartUpload(compRequest);      LOG.info("Support bundle upload finished");    } catch (Exception e) {      LOG.error("Support bundle upload failed", e);      s3Client.abortMultipartUpload(new AbortMultipartUploadRequest(        bucket,        bundle.getBundleKey(),        initResponse.getUploadId())      );      throw new IOException("Can't upload support bundle", e);    } finally {      // Close the client      s3Client.shutdown();    }  }
public void uploadNewBundleOnError() {    boolean enabled = configuration.get(Constants.UPLOAD_ON_ERROR, Constants.DEFAULT_UPLOAD_ON_ERROR);    LOG.info("Upload bundle on error: {}", enabled);    // We won't upload the bundle unless it's explicitly allowed    if(!enabled) {      return;    }    try {      uploadNewBundle(Collections.emptyList(), BundleType.SUPPORT);    } catch (IOException e) {      LOG.error("Failed to upload error bundle", e);    }  }
private int readFully(InputStream inputStream, byte []buffer) throws IOException {    int readBytes = 0;    while(readBytes < buffer.length) {      int loaded = inputStream.read(buffer, readBytes, buffer.length - readBytes);      if(loaded == -1) {        return readBytes == 0 ? -1 : readBytes;      }      readBytes += loaded;    }    return readBytes;  }
private List<BundleContentGeneratorDefinition> getRequestedDefinitions(List<String> generators) {    Stream<BundleContentGeneratorDefinition> stream = definitions.stream();    if(generators == null || generators.isEmpty()) {      // Filter out default generators      stream = stream.filter(BundleContentGeneratorDefinition::isEnabledByDefault);    } else {      stream = stream.filter(def -> generators.contains(def.getId()));    }    return stream      .sorted(Comparator.comparingInt(BundleContentGeneratorDefinition::getOrder))      .collect(Collectors.toList());  }
@VisibleForTesting  protected static Map<String, String[]> getQueryParameters(HttpServletRequest request) {    Map<String, String[]> queryParameters = new HashMap<>();    String queryString = request.getQueryString();    if (StringUtils.isEmpty(queryString)) {      return queryParameters;    }    String[] parameters = queryString.split("&");    for (String parameter : parameters) {      String[] keyValuePair = parameter.split("=");      String[] values = queryParameters.get(keyValuePair[0]);      values = ArrayUtils.add(values, keyValuePair.length == 1 ? "" : keyValuePair[1]); //length is one if no value is available.      queryParameters.put(keyValuePair[0], values);    }    return queryParameters;  }
@Override  public String getFieldPath(String fieldPath, int operation) {    if (operation == OperationType.DELETE_CODE) {      return fieldPath.replace(DATA_FIELD, OLDDATA_FIELD);    }    return fieldPath;  }
private String[] getNonEmptyArgs(List<String> appArgs) {    List<String> nonEmpty = new ArrayList<>();    appArgs.forEach((String val) -> {      if (!StringUtils.isEmpty(val)) {        nonEmpty.add(val);      }    });    return nonEmpty.toArray(new String[nonEmpty.size()]);  }
protected Operation getOperation(KuduTable table, int op) throws UnsupportedOperationException {    Operation operation = null;    switch (op) {      case OperationType.INSERT_CODE:        operation = table.newInsert();        break;      case OperationType.UPSERT_CODE:        operation = table.newUpsert();        break;      case OperationType.UPDATE_CODE:        operation = table.newUpdate();        break;      case OperationType.DELETE_CODE:        operation = table.newDelete();        break;      default:        LOG.error("Operation {} not supported", op);        throw new UnsupportedOperationException(String.format("Unsupported Operation: %s", op));    }    return operation;  }
static String convertBytesToDisplayFormat(double bytes) {    int unitIdx = 0;    double unitChangedBytes = bytes;    while (unitIdx < UNITS.length - 1 && Math.floor(unitChangedBytes / 1024) > 0) {      unitChangedBytes = unitChangedBytes / 1024;      unitIdx++;    }    return df.format(unitChangedBytes) + " " + UNITS[unitIdx];  }
public LiveFile scan(LiveFile current) throws IOException {    try {      return scanInternal(current);    } catch (NoSuchFileException ex) {      // this could happen because there has been a file rotation/deletion after the search/filter/sort and before      // the creation of the nen current. Lets sleep for 50ms and try again, if fails again give up.      ThreadUtil.sleep(50);      return scanInternal(current);    }  }
public long getPendingFiles(LiveFile current) throws IOException{    //Current will not be acceptable for roll files (if active file is without a counter/date pattern)    //and will be later renamed to a file with counter/date suffix, if that is the case we should    //return 0 as number of pending files    if (current == null || rollMode.isCurrentAcceptable(current.getPath().getFileName().toString())) {      return findToBeProcessedMatchingFiles(current!=null? current.refresh() : null).size();    }    return 0;  }
public static boolean isWhitelisted(    String name,    Properties specificWhitelist,    Map<String, List<Dependency>> dependencies  ) {    if(specificWhitelist != null && specificWhitelist.containsKey(name)) {      return versionsMatch(specificWhitelist.getProperty(name), dependencies.keySet());    }    // Otherwise try hardcoded rules:    WhitelistRule rule = WHITELIST_RULES.get(name);    return rule != null && rule.isWhitelisted(dependencies);  }
private static boolean versionsMatch(String expectedVersions, Set<String> versions) {    Set<String> expectedSet = Sets.newHashSet(expectedVersions.split(","));    return Sets.symmetricDifference(expectedSet, versions).isEmpty();  }
public void init(Stage.Context context, String groupName, String prefix, List<Stage.ConfigIssue> issues) {    if (!trustStorePath.isEmpty()) {      if (Files.notExists(Paths.get(trustStorePath))) {        issues.add(context.createConfigIssue(groupName, prefix + "trustStorePath", HTTP_04, trustStorePath));      }      try {        if (trustStorePassword.get().isEmpty()) {          issues.add(context.createConfigIssue(groupName, prefix + "trustStorePassword", HTTP_05));        }      } catch (StageException e) {        issues.add(context.createConfigIssue(groupName, prefix + "trustStorePassword", HTTP_29, e.toString()));      }    }    if (!keyStorePath.isEmpty()) {      if (Files.notExists(Paths.get(keyStorePath))) {        issues.add(context.createConfigIssue(groupName, prefix + "keyStorePath", HTTP_04, keyStorePath));      }      try {        if (keyStorePassword.get().isEmpty()) {          issues.add(context.createConfigIssue(groupName, prefix + "keyStorePassword", HTTP_05));        }      } catch (StageException e) {        issues.add(context.createConfigIssue(groupName, prefix + "keyStorePassword", HTTP_29, e.toString()));      }    }  }
public static boolean isSnapshotOutputUsable(List<StageOutput> stagesOutput) {    // In case that the snapshot actually does not exists    if(stagesOutput == null) {      return false;    }    // We're looking for at least one output lane that is not empty. In most cases the first stage in the list will    // be origin that generated some data and hence the loop will terminate fast. In the worst case scenario we will    // iterate over all stages in attempt to find at least one record in the snapshot.    for(StageOutput output : stagesOutput) {      if (CollectionUtils.isNotEmpty(output.getErrorRecords()) ||          CollectionUtils.isNotEmpty(output.getEventRecords()) ||          CollectionUtils.isNotEmpty(output.getStageErrors())) {        return true;      }      for(Map.Entry<String, List<Record>> entry : output.getOutput().entrySet()) {        if(!entry.getValue().isEmpty()) {          return true;        }      }    }    return false;  }
public static void main(String[] args) throws Exception {    SparkStreamingBinding binding = null;    try {      binding = SparkStreamingBindingFactory.build(BootstrapCluster.getProperties());      binding.init();      BootstrapCluster.createTransformers(binding.getStreamingContext().sparkContext(), binding.getSparkSession());      binding.startContext();      binding.awaitTermination();    } catch (Throwable error) {      String msg = "Error trying to invoke BootstrapClusterStreaming.main: " + error;      System.err.println(new Date()+ ": " + msg);      error.printStackTrace(System.err); // required as in local mode the following seems to be lost      LOG.error(msg, error);      throw new IllegalStateException(msg, error);    } finally {      try {        if (binding != null) {          binding.close();        }      } catch (Exception ex) {        LOG.warn("Error on binding close: " + ex, ex);      }    }  }
@Override  protected List<ConfigIssue> init() {    // Validate configuration values and open any required resources.    List<ConfigIssue> issues = super.init();    Optional        .ofNullable(conf.init(getContext(), CONF_PREFIX ))        .ifPresent(issues::addAll);    try {      ConnectorConfig partnerConfig = ForceUtils.getPartnerConfig(conf, new WaveSessionRenewer());      connection = Connector.newConnection(partnerConfig);      LOG.info("Successfully authenticated as {}", conf.username);      if (conf.mutualAuth.useMutualAuth) {        ForceUtils.setupMutualAuth(partnerConfig, conf.mutualAuth);      }      String soapEndpoint = connection.getConfig().getServiceEndpoint();      restEndpoint = soapEndpoint.substring(0, soapEndpoint.indexOf("services/Soap/"));      httpClient = new HttpClient(ForceUtils.makeSslContextFactory(conf));      if (conf.useProxy) {        ForceUtils.setProxy(httpClient, conf);      }      httpClient.start();    } catch (Exception e) {      LOG.error("Exception during init()", e);      issues.add(getContext().createConfigIssue(Groups.FORCE.name(),          ForceConfigBean.CONF_PREFIX + "authEndpoint",          Errors.WAVE_00,          ForceUtils.getExceptionCode(e) + ", " + ForceUtils.getExceptionMessage(e)      ));    }    // If issues is not empty, the UI will inform the user of each configuration issue in the list.    return issues;  }
@Override  public void write(Batch batch) throws StageException {    if (batch.getRecords().hasNext()) {      if (datasetID == null) {        LOG.info("Opening dataset");        try {          openDataset();        } catch (ConnectionException ce) {          throw new StageException(Errors.WAVE_01, ce);        }      }      LOG.info("Writing batch to dataset");      writeToDataset(batch);      try {        commitDataset();      } catch (ConnectionException | IOException e) {        throw new StageException(Errors.WAVE_01, e);      }    }  }
private void propagateRuntimeConfiguration() {    // If pipeline wasn't loaded or there if there are no stages, there is nothing to propagate    if(pipelineBean == null || pipelineBean.getPipelineStageBeans() == null) {      return;    }    for(StageBean stageBean : pipelineBean.getPipelineStageBeans().getStages()) {      for(ServiceDependencyDefinition serviceDependency: stageBean.getDefinition().getServices()) {        ServiceBean stageService = stageBean.getService(serviceDependency.getService());        if (stageService == null){          continue;        }        ServiceConfiguration serviceConfiguration = stageService.getConf();        List<Config> configs = serviceConfiguration.getConfiguration();        // Simply remove all RUNTIME configs        configs.removeAll(            serviceDependency.getConfiguration().keySet().stream()                .map(serviceConfiguration::getConfig)                .collect(Collectors.toList())        );        // And insert them with the stage-instance-constant values        serviceDependency.getConfiguration().forEach((key, value) -> configs.add(new Config(key, value)));        // And overwrite the new state        serviceConfiguration.setConfig(configs);      }    }  }
@Override  protected List<ConfigIssue> init() {    // Validate configuration values and open any required resources.    List<ConfigIssue> issues = super.init();    if (issues.isEmpty()) {      jdbcUtil = UtilsProvider.getJdbcUtil();    }    errorRecordHandler = new DefaultErrorRecordHandler(getContext());    Processor.Context context = getContext();    queryEval = getContext().createELEval("query");    issues = hikariConfigBean.validateConfigs(context, issues);    if (context.getRunnerId() == 0) {      if (issues.isEmpty() && null == dataSource) {        try {          dataSource = jdbcUtil.createDataSourceForRead(hikariConfigBean);          context.getStageRunnerSharedMap().put("jdbcLookupProcessor.dataSource", dataSource);        } catch (StageException e) {          issues.add(context.createConfigIssue(Groups.JDBC.name(), CONNECTION_STRING, JdbcErrors.JDBC_00, e.toString()));        }      }    } else {      dataSource = (HikariDataSource) context.getStageRunnerSharedMap().get("jdbcLookupProcessor.dataSource");    }    if(issues.isEmpty()) {      this.defaultValue = calculateDefault(context, issues);    }    if (issues.isEmpty()) {      cache = buildCache();      cacheCleaner = new CacheCleaner(cache, "JdbcLookupProcessor", 10 * 60 * 1000);      if (cacheConfig.enabled) {        preprocessThreads = Math.min(hikariConfigBean.minIdle, Runtime.getRuntime().availableProcessors()-1);        preprocessThreads = Math.max(preprocessThreads, 1);      }    }    if (context.getRunnerId() == 0) {      if (issues.isEmpty() && generationExecutor == null) {        generationExecutor = new SafeScheduledExecutorService(            hikariConfigBean.maximumPoolSize,            "JDBC Lookup Cache Warmer"        );        context.getStageRunnerSharedMap().put("jdbcLookupProcessor.generationExecutor", generationExecutor);      }    } else {      generationExecutor = (SafeScheduledExecutorService) context.getStageRunnerSharedMap().get(          "jdbcLookupProcessor.generationExecutor");    }    // If issues is not empty, the UI will inform the user of each configuration issue in the list.    return issues;  }
@Override  public void destroy() {    if (getContext().getRunnerId() == 0) {      if (generationExecutor != null) {        generationExecutor.shutdown();        try {          if (!generationExecutor.awaitTermination(5, TimeUnit.SECONDS)) {            generationExecutor.shutdownNow();          }        } catch (InterruptedException ex) {          LOG.error("Interrupted while attempting to shutdown Generator Executor: ", ex);          Thread.currentThread().interrupt();        }      }      // close dataSource after closing threadpool executor as we could have queries running before closing the executor      if (jdbcUtil != null) {        jdbcUtil.closeQuietly(dataSource);      }    }    super.destroy();  }
@Override  protected void process(Record record, SingleLaneBatchMaker batchMaker) throws StageException {    try {      ELVars elVars = getContext().createELVars();      RecordEL.setRecordInContext(elVars, record);      String preparedQuery = queryEval.eval(elVars, query, String.class);      Optional<List<Map<String, Field>>> entry = cache.get(preparedQuery);      if (!entry.isPresent()) {        // No results        switch (missingValuesBehavior) {          case SEND_TO_ERROR:            LOG.error(JdbcErrors.JDBC_04.getMessage(), preparedQuery);            errorRecordHandler.onError(new OnRecordErrorException(record, JdbcErrors.JDBC_04, preparedQuery));            break;          case PASS_RECORD_ON:            batchMaker.addRecord(record);            break;          default:            throw new IllegalStateException("Unknown missing value behavior: " + missingValuesBehavior);        }      } else {        List<Map<String, Field>> values = entry.get();        switch (multipleValuesBehavior) {          case FIRST_ONLY:            setFieldsInRecord(record, values.get(0));            batchMaker.addRecord(record);            break;          case SPLIT_INTO_MULTIPLE_RECORDS:            for(Map<String, Field> lookupItem : values) {              Record newRecord = getContext().cloneRecord(record);              setFieldsInRecord(newRecord, lookupItem);              batchMaker.addRecord(newRecord);            }            break;          case ALL_AS_LIST:            Map<String, List<Field>> valuesMap = new HashMap<>();            for (Map<String, Field> lookupItem : values) {              lookupItem.forEach((k, v) -> {                if (valuesMap.get(k) == null) {                  List<Field> lookupValue = new ArrayList<>();                  valuesMap.put(k, lookupValue);                }                valuesMap.get(k).add(v);              });            }            Map<String, Field> valueMap = new HashMap<>();            valuesMap.forEach( (k,v) -> valueMap.put(k, Field.create(v)));            setFieldsInRecord(record, valueMap);            batchMaker.addRecord(record);            break;          default:            throw new IllegalStateException("Unknown multiple value behavior: " + multipleValuesBehavior);        }      }    } catch (ELEvalException e) {      LOG.error(JdbcErrors.JDBC_01.getMessage(), query, e);      throw new OnRecordErrorException(record, JdbcErrors.JDBC_01, query);    } catch (ExecutionException e) {      Throwables.propagateIfPossible(e.getCause(), StageException.class);      throw new IllegalStateException(e); // The cache loader shouldn't throw anything that isn't a StageException.    } catch (OnRecordErrorException error) { // NOSONAR      errorRecordHandler.onError(new OnRecordErrorException(record, error.getErrorCode(), error.getParams()));    }  }
private void validateReportDescription(List<ConfigIssue> issues){    if(!jsonMapper.isValidJson(this.reportDescription)) {      issues.add(          getContext().createConfigIssue(              Groups.REPORT.name(),              "reportDescription",              Errors.OMNITURE_03          ));    }  }
private String escapeValue(String str, boolean escapeSpace) {    int len = str.length();    int bufLen = len * 2;    if (bufLen < 0) {      bufLen = Integer.MAX_VALUE;    }    StringBuilder outBuffer = new StringBuilder(bufLen);    for(int x=0; x<len; x++) {      char aChar = str.charAt(x);      // Handle common case first, selecting largest block that      // avoids the specials below      if ((aChar > 61) && (aChar < 127)) {        if (aChar == '\\') {          outBuffer.append('\\'); outBuffer.append('\\');          continue;        }        outBuffer.append(aChar);        continue;      }      switch(aChar) {        case ' ':          if (x == 0 || escapeSpace)            outBuffer.append('\\');          outBuffer.append(' ');          break;        case '\t':outBuffer.append('\\'); outBuffer.append('t');          break;        case '\n':outBuffer.append('\\'); outBuffer.append('n');          break;        case '\r':outBuffer.append('\\'); outBuffer.append('r');          break;        case '\f':outBuffer.append('\\'); outBuffer.append('f');          break;        case '=': // Fall through        case ':': // Fall through        case '#': // Fall through        case '!':          outBuffer.append('\\'); outBuffer.append(aChar);          break;        default:          outBuffer.append(aChar);      }    }    return outBuffer.toString();  }
public static JdbcRecordWriter createJdbcRecordWriter(      String connectionString,      HikariDataSource dataSource,      String schema,      String tableName,      List<JdbcFieldColumnParamMapping> customMappings,      boolean rollbackOnError,      boolean useMultiRowOp,      int maxPrepStmtParameters,      int defaultOpCode,      UnsupportedOperationAction unsupportedAction,      DuplicateKeyAction duplicateKeyAction,      JdbcRecordReader recordReader,      boolean caseSensitive,      List<String> customDataSqlStateCodes  ) throws StageException {    if (defaultOpCode == OperationType.LOAD_CODE) {      return new JdbcLoadRecordWriter(          connectionString,          dataSource,          schema,          tableName,          customMappings,          duplicateKeyAction,          recordReader,          caseSensitive,          customDataSqlStateCodes      );    } else {      return createJdbcRecordWriter(          connectionString,          dataSource,          schema,          tableName,          customMappings,          null,          rollbackOnError,          useMultiRowOp,          maxPrepStmtParameters,          defaultOpCode,          unsupportedAction,          recordReader,          caseSensitive,          customDataSqlStateCodes      );    }  }
public static JdbcRecordWriter createJdbcRecordWriter(       String connectionString,       HikariDataSource dataSource,       String schema,       String tableName,       List<JdbcFieldColumnParamMapping> customMappings,       List<JdbcFieldColumnMapping> generatedColumnMappings,       boolean rollbackOnError,       boolean useMultiRowOp,       int maxPrepStmtParameters,       int defaultOpCode,       UnsupportedOperationAction unsupportedAction,       JdbcRecordReader recordReader,       boolean caseSensitive,       List<String> customDataSqlStateCodes  ) throws StageException {    JdbcRecordWriter recordWriter;    if (useMultiRowOp) {      recordWriter = new JdbcMultiRowRecordWriter(          connectionString,          dataSource,          schema,          tableName,          rollbackOnError,          customMappings,          maxPrepStmtParameters,          defaultOpCode,          unsupportedAction,          generatedColumnMappings,          recordReader,          caseSensitive,          customDataSqlStateCodes      );    } else {      recordWriter = new JdbcGenericRecordWriter(          connectionString,          dataSource,          schema,          tableName,          rollbackOnError,          customMappings,          defaultOpCode,          unsupportedAction,          generatedColumnMappings,          recordReader,          caseSensitive,          customDataSqlStateCodes      );    }    return recordWriter;  }
private void upgradeV1toV2(List<Config> configs) {    configs.removeIf(config -> (config.getName().equals(IMPLICIT_FIELD_MAPPING_CONFIG) ||        config.getName().equals(BIG_QUERY_IMPLICIT_FIELD_MAPPING_CONFIG)));    configs.add(new Config(MAX_CACHE_SIZE, -1));  }
public Map<String, String> extractNamedGroups(final CharSequence rawData) {    Matcher matcher = compiledPattern.matcher(rawData);    if (matcher.find()) {      MatchResult r = matcher.toMatchResult();      if (r != null && r.namedGroups() != null) {        return r.namedGroups();      }    }    return null;  }
public void consumerCommit(String offset) {    Object offsetValue = offset;    if (offsetValue == null) {      offsetValue = new NullOffset();    }    LOG.trace("Commit Offset: '{}'", offsetValue);    try {      producerQueue.put(new Message(MessageType.CONSUMER_COMMIT, offsetValue));    } catch (InterruptedException e) {      LOG.info("Interrupted while queuing '{}'", MessageType.CONSUMER_COMMIT.name(), offsetValue);      Thread.currentThread().interrupt();    }  }
@SuppressWarnings("unchecked")  protected EmbeddedSDC create() throws Exception {    Utils.checkState(open, "Not open");    final EmbeddedSDC embeddedSDC = new EmbeddedSDC();    Object source;    // post-batch runnable    Object pipelineStartResult = BootstrapCluster.startPipeline(() -> LOG.debug("Batch completed"));    source = pipelineStartResult.getClass().getDeclaredField("source").get(pipelineStartResult);    if (source instanceof DSource) {      long startTime = System.currentTimeMillis();      long endTime = startTime;      long diff = 0;      Source actualSource = ((DSource) source).getSource();      while (actualSource == null && diff < 60000) {        Thread.sleep(100);        actualSource = ((DSource) source).getSource();        endTime = System.currentTimeMillis();        diff = endTime - startTime;      }      if (actualSource == null) {        throw new IllegalStateException("Actual source is null, pipeline may not have been initialized");      }      source = actualSource;    }    if (!(source instanceof ClusterSource)) {        throw new IllegalArgumentException("Source is not of type ClusterSource: " + source.getClass().getName());    }    embeddedSDC.setSource((ClusterSource) source);    embeddedSDC.setSparkProcessors(        (List<Object>)pipelineStartResult.getClass().getDeclaredField("sparkProcessors").get(pipelineStartResult));    return embeddedSDC;  }
private EmbeddedSDC fastForward(int id) throws Exception {    if (id == sparkProcessorCount) {      return null;    }    LOG.info("No SDC was found at ID: " + id + ". Fast-forwarding..");    EmbeddedSDC sdc;    // If there are not SDCs that are just idling, create a new one, else return one from the not started pool.    if (notStarted.isEmpty()) {      sdc = create();    } else {      sdc = getNotStartedSDC();    }    Class<?> clusterFunctionClass = Class.forName("com.streamsets.pipeline.cluster.ClusterFunctionImpl");    Method getBatch = clusterFunctionClass.getMethod("getNextBatch", int.class, EmbeddedSDC.class);    Method forward =        clusterFunctionClass.getMethod("doForward", Iterator.class, int.class, EmbeddedSDC.class);    sdc.getSource().put(Collections.emptyList());    getBatch.invoke(null, 0, sdc);    for (int i = 0; i <= id - 1; i++) {      forward.invoke(null, Collections.emptyIterator(), i, sdc);    }    return sdc;  }
private void setFieldsInRecord(Record record, Map<String, Field> fields) {    record.set(configBean.resultField, Field.createListMap(new LinkedHashMap<>(fields)));  }
@Override  public List<PipelineAndValidationStatus> getRemotePipelinesWithChanges() throws PipelineException {    List<PipelineAndValidationStatus> pipelineAndValidationStatuses = new ArrayList<>();    for (Pair<PipelineState, Map<String, String>> pipelineStateAndOffset: stateEventListener.getPipelineStateEvents()) {      PipelineState pipelineState = pipelineStateAndOffset.getLeft();      Map<String, String> offset = pipelineStateAndOffset.getRight();      String name = pipelineState.getPipelineId();      String rev = pipelineState.getRev();      boolean isClusterMode = (pipelineState.getExecutionMode() != ExecutionMode.STANDALONE) ? true : false;      List<WorkerInfo> workerInfos = new ArrayList<>();      String title;      int runnerCount = 0;      if (pipelineStore.hasPipeline(name)) {        title = pipelineStore.getInfo(name).getTitle();        Runner runner = manager.getRunner(name, rev);        if (isClusterMode) {          workerInfos = getWorkers(runner.getSlaveCallbackList(CallbackObjectType.METRICS));        }        runnerCount = runner.getRunnerCount();      } else {        title = null;      }      pipelineAndValidationStatuses.add(new PipelineAndValidationStatus(          getSchGeneratedPipelineName(name, rev),          title,          rev,          pipelineState.getTimeStamp(),          true,          pipelineState.getStatus(),          pipelineState.getMessage(),          workerInfos,          isClusterMode,          getSourceOffset(name, offset),          null,          runnerCount      ));    }    return pipelineAndValidationStatuses;  }
public static RemoteDataCollectorResult futureAck(Future<AckEvent> futureResult) {    return new RemoteDataCollectorResult(futureResult, null, false, null);  }
@Override  @VisibleForTesting  int getOperationFromRecord(      Record record,      int defaultOpCode,      UnsupportedOperationAction unsupportedAction,      List<OnRecordErrorException> errorRecords ) {    int opCode = -1; // -1 is invalid and not used in OperationType.    String op = null;    try {      // Try sdc.operation.type first      op = record.getHeader().getAttribute(OperationType.SDC_OPERATION_TYPE);      // If not set, look for oracle.cdc.operation in record header.      if (StringUtils.isBlank(op)) {          op = record.getHeader().getAttribute(OracleCDCOperationCode.OPERATION);          if (op != null) {            // Convert the Oracle specific operation code to SDC standard operation code            opCode = OracleCDCOperationCode.convertFromOracleToSDCCode(op);          }      } else {        opCode = JDBCOperationType.convertToIntCode(op);      }      if (opCode == -1){        opCode = defaultOpCode;      }    } catch (NumberFormatException | UnsupportedOperationException ex) {      LOG.debug(          "Operation obtained from record is not supported: {}. Handle by UnsupportedOpertaionAction {}. {}",          ex.getMessage(),          unsupportedAction.getLabel(),          ex      );      switch (unsupportedAction) {        case DISCARD:          LOG.debug("Discarding record with unsupported operation {}", op);          break;        case SEND_TO_ERROR:          LOG.debug("Sending record to error due to unsupported operation {}", op);          errorRecords.add(new OnRecordErrorException(record, JdbcErrors.JDBC_70, op));          break;        case USE_DEFAULT:          opCode = defaultOpCode;          break;        default: //unknown action          LOG.debug("Sending record to error due to unknown operation: {}", op);      }    }    return opCode;  }
public static Gauge<Map<String, Object>> createGauge(MetricRegistry metrics, String name, Gauge gauge, final String pipelineName, final String pipelineRev) {    return create(      metrics,      gauge,      metricName(name, GAUGE_SUFFIX),      pipelineName,      pipelineRev    );  }
private static boolean remove(final MetricRegistry metrics, final String name, String pipelineName, String pipelineRev) {    final String jmxNamePrefix = jmxPipelinePrefix(pipelineName, pipelineRev);    final MetricRegistry metricRegistry = sdcMetrics;    if (metricRegistry != null) {      AccessController.doPrivileged(new PrivilegedAction<Void>() {        @Override        public Void run() {          metricRegistry.remove(jmxNamePrefix  + name);          return null;        }      });    }    return metrics.remove(name);  }
@Override  public SortedMap<String, String> getColumnsToParameters(      final Record record, int op,      Map<String, String> parameters,      Map<String, String> columnsToFields)  {    SortedMap<String, String> columnsToParameters = new TreeMap<>();    for (Map.Entry<String, String> entry : columnsToFields.entrySet()) {      String columnName = entry.getKey();      String fieldPath = getFieldPath(columnName, columnsToFields, op);      if (record.has(fieldPath)) {        columnsToParameters.put(columnName, parameters.get(columnName));      } else {        LOG.trace("Record is missing a field for column {} for the operation code {}", columnName, op);      }    }    return columnsToParameters;  }
@Override  String getFieldPath(String columnName, Map<String, String> columnsToField, int op) {    if (op == OperationType.UPDATE_CODE){      String fieldPath = columnsToField.get(columnName);      if (fieldPath == null){        LOG.error("Column name {} is not defined in column-filed mapping", columnName);        return null;      }      if (fieldPath.contains(ID_FIELD)) {        // _id is stored in "/o2/column_name for update records. Need to change the fieldpath"        return fieldPath.replace(OP_FIELD, OP2_FIELD);      } else {        // column and values are stored in "/o/$set/column_name". Need to change the fieldpath        return fieldPath.replaceFirst(OP_FIELD, String.format("%s/%s", OP_FIELD, SET_FIELD));      }    }    return columnsToField.get(columnName);  }
private Map<String, Object> generateHeaderAttrs(Path file) throws StageException {    try {      Map<String, Object> recordHeaderAttr = new HashMap<>();      recordHeaderAttr.put(HeaderAttributeConstants.FILE, file.toAbsolutePath());      recordHeaderAttr.put(HeaderAttributeConstants.FILE_NAME, file.getFileName());      recordHeaderAttr.put(HeaderAttributeConstants.SIZE, Files.size(file));      recordHeaderAttr.put(HeaderAttributeConstants.LAST_MODIFIED_TIME, Files.getLastModifiedTime(file));      return recordHeaderAttr;    } catch (IOException e) {      throw new TransformerStageCheckedException(Errors.CONVERT_09, e.toString(), e);    }  }
private void validateRecord(Record record) throws StageException {    try {      FileRefUtil.validateWholeFileRecord(record);    } catch (IllegalArgumentException e) {      throw new TransformerStageCheckedException(Errors.CONVERT_01, e.toString(), e);    }  }
@VisibleForTesting  Path getAndValidateTempFilePath(Record record, String sourceFileName) throws StageException {    RecordEL.setRecordInContext(variables, record);    String dirPath;    try {      dirPath = resolveEL(tempDirElEval, variables, jobConfig.tempDir, String.class);    } catch (ELEvalException ex) {      throw new TransformerStageCheckedException(Errors.CONVERT_04, jobConfig.tempDir);    }    if (Strings.isNullOrEmpty(dirPath)) {      throw new TransformerStageCheckedException(Errors.CONVERT_02, jobConfig.tempDir);    }    if (Strings.isNullOrEmpty(sourceFileName)) {      throw new TransformerStageCheckedException(Errors.CONVERT_03, FILENAME);    }    String fileName = jobConfig.uniquePrefix + sourceFileName + jobConfig.fileNameSuffix;    Path tempParquetFile = Paths.get(dirPath, fileName);    if (!tempParquetFile.isAbsolute()) {      throw new TransformerStageCheckedException(Errors.CONVERT_05, tempParquetFile);    }    try {      if (!Files.exists(tempParquetFile.getParent())) {        Files.createDirectories(Paths.get(dirPath));      }    } catch (IOException ex) {      throw new TransformerStageCheckedException(Errors.CONVERT_10, tempParquetFile.toString(), ex);    }    // handle old temp files    try {      handleOldTempFiles(tempParquetFile);    } catch (IOException ex) {      throw new TransformerStageCheckedException(Errors.CONVERT_06, tempParquetFile.toString(), ex);    }    return tempParquetFile;  }
private void handleOldTempFiles(Path tempParquetFile) throws IOException {    if (tempParquetFile == null) {      LOG.warn("temporary parquet file is empty");      return;    }    Files.deleteIfExists(tempParquetFile);  }
private InputStream getAvroInputStream(Record record) throws StageException {    try {      FileRef fileRef = record.get(FileRefUtil.FILE_REF_FIELD_PATH).getValueAsFileRef();      // get avro reader      final boolean includeChecksumInTheEvents = false;      InputStream is = FileRefUtil.getReadableStream(          getContext(),          fileRef,          InputStream.class,          includeChecksumInTheEvents,          null,          null      );      return is;    } catch (IOException ex) {      throw new TransformerStageCheckedException(Errors.CONVERT_07, ex.toString(), ex);    }  }
private DataFileStream<GenericRecord> getFileReader(InputStream is, String sourceFileName) throws StageException {    try {      DatumReader<GenericRecord> reader = new GenericDatumReader<>();      DataFileStream<GenericRecord> fileReader = new DataFileStream<>(is, reader);      return fileReader;    } catch (IOException ex) {      throw new TransformerStageCheckedException(Errors.CONVERT_11, sourceFileName, ex);    }  }
private void writeParquet(String sourceFileName, DataFileStream<GenericRecord> fileReader, Path tempParquetFile) throws StageException {    long recordCount = 0;    GenericRecord avroRecord;    Schema schema = fileReader.getSchema();    LOG.debug("Start reading input file : {}", sourceFileName);    try {      // initialize parquet writer      Configuration jobConfiguration = new Configuration();      String compressionCodecName = compressionElEval.eval(variables, jobConfig.avroParquetConfig.compressionCodec, String.class);      jobConfiguration.set(AvroParquetConstants.COMPRESSION_CODEC_NAME, compressionCodecName);      jobConfiguration.setInt(AvroParquetConstants.ROW_GROUP_SIZE, jobConfig.avroParquetConfig.rowGroupSize);      jobConfiguration.setInt(AvroParquetConstants.PAGE_SIZE, jobConfig.avroParquetConfig.pageSize);      jobConfiguration.setInt(AvroParquetConstants.DICTIONARY_PAGE_SIZE, jobConfig.avroParquetConfig.dictionaryPageSize);      jobConfiguration.setInt(AvroParquetConstants.MAX_PADDING_SIZE, jobConfig.avroParquetConfig.maxPaddingSize);      // Parquet writer      ParquetWriter.Builder builder = AvroToParquetConverterUtil.initializeWriter(          new org.apache.hadoop.fs.Path(tempParquetFile.toString()),          schema,          jobConfiguration      );      parquetWriter = builder.build();      while (fileReader.hasNext()) {        avroRecord = fileReader.next();        parquetWriter.write(avroRecord);        recordCount++;      }      parquetWriter.close();    } catch (IOException ex) {      throw new TransformerStageCheckedException(          Errors.CONVERT_08,          sourceFileName,          recordCount,          ex      );    }    LOG.debug("Finished writing {} records to {}", recordCount, tempParquetFile.getFileName());  }
@Override  public void destroy() {    // Clean up any open resources.    if (null != redisClient) {      redisClient.disconnect();      redisClient.close();      redisClient = null;    }    super.destroy();  }
void validateClass(String name) {    // python scripting engine generates __*__ classes under all packages (including SDC api package)    if (!(name.endsWith("__"))) {      for (String blacklistedPackage : blacklistedPackages) {        if (name.startsWith(blacklistedPackage)) {          throw new IllegalArgumentException(String.format("Class '%s' cannot be present in %s",            name, toString()));        }      }    }  }
void validateResource(String name) {    for (String blacklistedPackage : blacklistedDirs) {      if (name.startsWith(blacklistedPackage)) {        throw new IllegalArgumentException(String.format("Resource '%s' cannot be present in %s",                                                         name, toString()));      }    }  }
public Optional<Field> checkInputEncrypt(Record record, Field field) {    if (UNSUPPORTED_TYPES.contains(field.getType())) {      getContext().toError(record, CRYPTO_03, field.getType());      return Optional.empty();    }    return Optional.of(field);  }
public Optional<Field> checkInputEncrypt(Field field) throws StageException {    if (UNSUPPORTED_TYPES.contains(field.getType())) {      throw new StageException(CRYPTO_03, field.getType());    }    return Optional.of(field);  }
public Optional<Field> checkInputDecrypt(Record record, Field field) {    if (field.getType() != Field.Type.BYTE_ARRAY) {      getContext().toError(record, CRYPTO_02, field.getType());      return Optional.empty();    }    return Optional.of(field);  }
public Optional<Field> checkInputDecrypt(Field field) throws StageException {    if (field.getType() != Field.Type.BYTE_ARRAY) {      throw new StageException(CRYPTO_02, field.getType());    }    return Optional.of(field);  }
public byte[] prepareEncrypt(Field field, Map<String, String> context) {    context.put(SDC_FIELD_TYPE, field.getType().name());    if (field.getType() == Field.Type.BYTE_ARRAY) {      return field.getValueAsByteArray();    } else {      // Treat all other data as strings      return field.getValueAsString().getBytes(Charsets.UTF_8);    }  }
public Field createResultFieldDecrypt(CryptoResult<byte[], ?> result) {    Field.Type fieldType = Field.Type.valueOf(        result.getEncryptionContext().getOrDefault(SDC_FIELD_TYPE, Field.Type.BYTE_ARRAY.name())    );    // Field API prohibits STRING to BYTE_ARRAY conversion so this is a special case    if (fieldType == Field.Type.BYTE_ARRAY) {      return Field.create(result.getResult());    }    // Field API supports STRING to other primitive types.    return Field.create(        fieldType,        new String(result.getResult())    );  }
public String generateBatch(WrappedFile file, String offset, int maxBatchSize, BatchMaker batchMaker) throws      StageException,      BadSpoolFileException {    if (offset == null) {      offset = "0";    }    String sourceFile = file.getFileName();    try {      if (parser == null) {        parser = SpoolDirUtil.getParser(            fs,            file,            conf.dataFormat,            parserFactory,            offset,            conf.dataFormatConfig.wholeFileMaxObjectLen,            rateLimitElEval,            rateLimitElVars,            conf.dataFormatConfig.rateLimit        );      }      Map<String, Object> recordHeaderAttr = generateHeaderAttrs(file);      for (int i = 0; i < maxBatchSize; i++) {        try {          Record record;          try {            record = parser.parse();          } catch(RecoverableDataParserException ex) {            // Propagate partially parsed record to error stream            record = ex.getUnparsedRecord();            recordHeaderAttr.put(HeaderAttributeConstants.OFFSET, offset);            setHeaders(record, recordHeaderAttr);            errorRecordHandler.onError(new OnRecordErrorException(record, ex.getErrorCode(), ex.getParams()));            perFileErrorCount++;            noMoreDataErrorCount++;            // We'll simply continue reading once this            continue;          }          if (record != null) {            recordHeaderAttr.put(HeaderAttributeConstants.OFFSET, offset);            setHeaders(record, recordHeaderAttr);            batchMaker.addRecord(record);            offset = parser.getOffset();            if (offset == null) {              offset = "0";            }            noMoreDataRecordCount++;            perFileRecordCount++;          } else {            parser.close();            parser = null;            offset = MINUS_ONE;            break;          }        } catch (ObjectLengthException ex) {          String exOffset = offset;          offset = (parser != null) ? parser.getOffset() : MINUS_ONE;          if (offset == null) {            offset = "0";          }          errorRecordHandler.onError(Errors.SPOOLDIR_02, sourceFile, exOffset, ex);          perFileErrorCount++;          noMoreDataErrorCount++;        }      }    } catch (IOException |DataParserException ex) {      if (ex instanceof ClosedByInterruptException || ex.getCause() instanceof ClosedByInterruptException) {        //If the pipeline was stopped, we may get a ClosedByInterruptException while reading avro data.        //This is because the thread is interrupted when the pipeline is stopped.        //Instead of sending the file to error, publish batch and move one.      } else {        offset = MINUS_ONE;        String exOffset;        if (ex instanceof OverrunException) {          exOffset = String.valueOf(((OverrunException) ex).getStreamOffset());        } else {          try {            exOffset = (parser != null) ? parser.getOffset() : MINUS_ONE;          } catch (IOException ex1) {            LOG.warn("Could not get the file offset to report with error, reason: {}", ex1.toString(), ex);            exOffset = MINUS_ONE;          }        }        switch (context.getOnErrorRecord()) {          case DISCARD:            break;          case TO_ERROR:            // we failed to produce a record, which leaves the input file in an unknown state. all we can do here is            // throw an exception.            throw new BadSpoolFileException(file.getAbsolutePath(), exOffset, ex);          case STOP_PIPELINE:            context.reportError(Errors.SPOOLDIR_04, sourceFile, exOffset, ex.toString(), ex);            throw new StageException(Errors.SPOOLDIR_04, sourceFile, exOffset, ex.toString());          default:            throw new IllegalStateException(Utils.format("Unknown OnError value '{}'",                context.getOnErrorRecord(), ex));        }      }    } finally {      if (MINUS_ONE.equals(offset)) {        if (parser != null) {          try {            parser.close();            parser = null;          } catch (IOException ex) {            //NOP          }        }      }    }    return offset;  }
private void initGaugeIfNeeded() {    gaugeMap.put(THREAD_NAME, Thread.currentThread().getName());    gaugeMap.put(STATUS, "");    gaugeMap.put(CURRENT_FILE, "");  }
private void handleStageError(ErrorCode errorCode, Exception e) {    final String errorMessage = "Failure Happened";    LOG.error(errorMessage, e);    try {      errorRecordHandler.onError(errorCode, e);    } catch (StageException se) {      LOG.error("Error when routing to stage error", se);      //Way to throw stage exception from runnable to main source thread      Throwables.propagate(se);    }  }
boolean isGraphCyclic() {    for (V vertex : directedGraph.vertices()) {      boolean areThereCycles = findCycles(new LinkedHashSet<V>(), vertex);      if (areThereCycles) {        return true;      }    }    return false;  }
public Matcher usePattern(Pattern newPattern) {        if (newPattern == null) {            throw new IllegalArgumentException("newPattern cannot be null");        }        this.parentPattern = newPattern;        matcher.usePattern(newPattern.pattern());        return this;    }
public Matcher appendReplacement(StringBuffer sb, String replacement) {        matcher.appendReplacement(sb, parentPattern.replaceProperties(replacement));        return this;    }
@Override    public Map<String, String> namedGroups() {        Map<String, String> result = new LinkedHashMap<String, String>();        if (matcher.find(0)) {            for (String groupName : parentPattern.groupNames()) {                String groupValue = matcher.group(groupIndex(groupName));                result.put(groupName, groupValue);            }        }        return result;    }
public String replaceAll(String replacement) {        String r = parentPattern.replaceProperties(replacement);        return matcher.replaceAll(r);    }
private Properties getKafkaProperties() {    Properties props = new Properties();    props.putAll(conf.streamsOptions);    props.setProperty("group.id", conf.consumerGroup);    props.setProperty("max.poll.records", String.valueOf(batchSize));    props.setProperty("enable.auto.commit", "true");    props.setProperty("auto.commit.interval.ms", "1000");    props.setProperty("key.deserializer", "org.apache.kafka.common.serialization.ByteArrayDeserializer");    props.setProperty("value.deserializer", "com.mapr.db.cdc.ChangeDataRecordDeserializer");    return props;  }
public static String getLastFieldNameFromPath(String path) {    String [] pathSplit = (path != null) ? path.split("/") : null;    if(pathSplit != null && pathSplit.length > 0) {      String lastFieldName = pathSplit[pathSplit.length - 1];      //handle special case field name containing slash eg. /'foo/bar'      boolean singleQuoted = lastFieldName.charAt(0) == QUOTE_CHAR          && lastFieldName.charAt(lastFieldName.length() - 1) == QUOTE_CHAR;      if(lastFieldName.contains("'") && !singleQuoted) {        //If path contains slash inside name, split it by "/'"        pathSplit = path.split("/'");        if(pathSplit.length > 0) {          lastFieldName = "'" + pathSplit[pathSplit.length - 1];          singleQuoted = true;        }      }      if (singleQuoted) {        return singleQuoteUnescape(lastFieldName);      } else {        return lastFieldName;      }    }    return path;  }
private static String escapeQuotesAndBackSlash(String path, boolean isSingleQuoteEscape) {    String quoteChar = isSingleQuoteEscape? "'" : "\"";    StringBuilder sb = new StringBuilder(path.length() * 2).append(quoteChar);    char[] chars = path.toCharArray();    for (char c : chars) {      if (c == '\\') {        sb.append("\\\\");      } else if (c == '"') {        sb.append(isSingleQuoteEscape? "\\\"" : "\\\\\"");      } else if (c == '\'') {        sb.append(isSingleQuoteEscape? "\\\\\'" : "\\\'");      } else {        sb.append(c);      }    }    return sb.append(quoteChar).toString();  }
private static String unescapeQuotesAndBackSlash(String path, boolean isSingleQuoteUnescape) {    path = (isSingleQuoteUnescape)? path.replace("\\\"", "\"").replace("\\\\\'", "'")        : path.replace("\\\\\"", "\"").replace("\\\'", "'");    return path.replace("\\\\", "\\");  }
public static String standardizePathForParse(String path, boolean isSingleQuoteEscape) {    path = isSingleQuoteEscape? path.replace("\\\\\'", "\\'") : path.replace("\\\\\"", "\\\"");    return path.replace("\\\\", "\\");  }
public static void ensureAvroSchemaExists(List<Config> configs, String prefix) {    Optional<Config> avroSchema = findByName(configs, "avroSchema");    if (!avroSchema.isPresent()) {      configs.add(new Config(prefix + ".avroSchema", null));    }  }
public static String getGlobalVariable(DataSource dataSource, String variable) throws SQLException {    try (Connection conn = dataSource.getConnection()) {      try (        Statement stmt = conn.createStatement();        ResultSet rs = stmt.executeQuery(String.format("show global variables like '%s'", variable));      ) {        if (rs.next()) {          return rs.getString(2);        } else {          return "";        }      }    }  }
public static StatusJson wrapState(PipelineStatus status) {    if(status == null) {      return null;    }    switch(status) {      case STOPPED:        return StatusJson.STOPPED;      case STOPPING:        return StatusJson.STOPPING;      case RUNNING:        return StatusJson.RUNNING;      case RUN_ERROR:        return StatusJson.RUN_ERROR;      case FINISHED:        return StatusJson.FINISHED;      case CONNECTING:        return StatusJson.CONNECTING;      case CONNECT_ERROR:        return StatusJson.CONNECT_ERROR;      case DISCONNECTED:        return StatusJson.DISCONNECTED;      case DISCONNECTING:        return StatusJson.DISCONNECTING;      case EDITED:        return StatusJson.EDITED;      case FINISHING:        return StatusJson.FINISHING;      case KILLED:        return StatusJson.KILLED;      case RUNNING_ERROR:        return StatusJson.RUNNING_ERROR;      case STARTING:        return StatusJson.STARTING;      case STARTING_ERROR:        return StatusJson.STARTING_ERROR;      case START_ERROR:        return StatusJson.START_ERROR;      case RETRY:        return StatusJson.RETRY;      case STOP_ERROR:        return StatusJson.STOP_ERROR;      case STOPPING_ERROR:        return StatusJson.STOPPING_ERROR;      case DELETED:        return StatusJson.DELETED;      default:        throw new IllegalArgumentException("Unrecognized state" + status);    }  }
private Record createStartEvent() {    Preconditions.checkState(startEventStage != null, "Start Event Stage is not set!");    EventRecord eventRecord = new EventRecordImpl(      "pipeline-start",      1,      startEventStage.getInfo().getInstanceName(),      "",      null,      null    );    Map<String, Field> rootField = new LinkedHashMap<>();    rootField.put("user", Field.create(Field.Type.STRING, userContext.getUser()));    rootField.put("pipelineId", Field.create(Field.Type.STRING, name));    rootField.put("pipelineTitle", Field.create(Field.Type.STRING, pipelineConf.getTitle()));    // Pipeline parameters    Map<String, Field> parameters = new LinkedHashMap<>();    if(runtimeParameters != null) {      for (Map.Entry<String, Object> entry : runtimeParameters.entrySet()) {        parameters.put(          entry.getKey(),          Field.create(Field.Type.STRING, entry.getValue().toString())        );      }    }    rootField.put("parameters", Field.create(parameters));    eventRecord.set(Field.create(rootField));    return eventRecord;  }
private Record createStopEvent(PipelineStopReason stopReason) {    Preconditions.checkState(stopEventStage != null, "Stop Event Stage is not set!");    EventRecord eventRecord = new EventRecordImpl(      "pipeline-stop",      1,      stopEventStage.getInfo().getInstanceName(),      "",      null,      null    );    Map<String, Field> rootField = new LinkedHashMap<>();    rootField.put("reason", Field.create(Field.Type.STRING, stopReason.name()));    rootField.put("pipelineId", Field.create(Field.Type.STRING, name));    rootField.put("pipelineTitle", Field.create(Field.Type.STRING, pipelineConf.getTitle()));    eventRecord.set(Field.create(rootField));    return eventRecord;  }
private void getAllReferences(      PartnerConnection partnerConnection,      Map<String, ObjectMetadata> metadataMap,      List<List<Pair<String, String>>> references,      String[] allTypes,      int depth  ) throws ConnectionException {    if (depth < 0) {      return;    }    List<String> next = new ArrayList<>();    for (int typeIndex = 0; typeIndex < allTypes.length; typeIndex += MAX_METADATA_TYPES) {      int copyTo = Math.min(typeIndex + MAX_METADATA_TYPES, allTypes.length);      String[] types = Arrays.copyOfRange(allTypes, typeIndex, copyTo);      // Special case - we prepopulate the cache with the root sobject type - don't repeat      // ourselves      if (types.length > 1 || !metadataMap.containsKey(types[0])) {        for (DescribeSObjectResult result : partnerConnection.describeSObjects(types)) {          Map<String, Field> fieldMap = new LinkedHashMap<>();          Map<String, Field> relationshipMap = new LinkedHashMap<>();          for (Field field : result.getFields()) {            fieldMap.put(field.getName().toLowerCase(), field);            String relationshipName = field.getRelationshipName();            if (relationshipName != null) {              relationshipMap.put(relationshipName.toLowerCase(), field);            }          }          Map<String, String> childRelationships = new LinkedHashMap<>();          for (ChildRelationship child : result.getChildRelationships()) {            if (child.getRelationshipName() != null) {              childRelationships.put(child.getRelationshipName().toLowerCase(),                  child.getChildSObject().toLowerCase());            }          }          metadataMap.put(result.getName().toLowerCase(), new ObjectMetadata(fieldMap,              relationshipMap, childRelationships));        }      }      if (references != null) {        for (List<Pair<String, String>> path : references) {          // Top field name in the path should be in the metadata now          if (!path.isEmpty()) {            Pair<String, String> top = path.get(0);            Field field = metadataMap.get(top.getLeft()).getFieldFromRelationship(top.getRight());            Set<String> sobjectNames = metadataMap.keySet();            for (String ref : field.getReferenceTo()) {              ref = ref.toLowerCase();              if (!sobjectNames.contains(ref) && !next.contains(ref)) {                next.add(ref);              }              if (path.size() > 1) {                path.set(1, Pair.of(ref, path.get(1).getRight()));              }            }            // SDC-10422 Polymorphic references have an implicit reference to the Name object type            if (field.isPolymorphicForeignKey()) {              next.add(NAME);            }            path.remove(0);          }        }      }    }    if (!next.isEmpty()) {      getAllReferences(partnerConnection, metadataMap, references, next.toArray(new String[0]), depth - 1);    }  }
protected String fixOffset(String offsetColumn, String offset) {    com.sforce.soap.partner.Field sfdcField = getFieldMetadata(sobjectType, offsetColumn);    if (SobjectRecordCreator.DECIMAL_TYPES.contains(sfdcField.getType().toString())        && offset.contains("E")) {      BigDecimal val = new BigDecimal(offset);      offset = val.toPlainString();      if (val.compareTo(MAX_OFFSET_INT) > 0 && !offset.contains(".")) {        // We need the ".0" suffix since Salesforce doesn't like integer        // bigger than 2147483647        offset += ".0";      }    }    return offset;  }
private Object extractAsRuntime(Field field, String valueStr) {     if (field.getType() == Byte.TYPE || field.getType() == Byte.class ||         field.getType() == Short.TYPE || field.getType() == Short.class ||         field.getType() == Integer.TYPE || field.getType() == Integer.class ||         field.getType() == Long.TYPE || field.getType() == Long.class ||         field.getType() == Float.TYPE || field.getType() == Float.class ||         field.getType() == Double.TYPE || field.getType() == Double.class) {       return extractAsNumber(field, valueStr);    } else if (String.class.isAssignableFrom(field.getType())) {       return valueStr;    }    throw new IllegalArgumentException(Utils.format("Invalid type for RUNTIME type: {}", field.getType()));  }
public void executeAlterTableAddPartitionQuery(      String qualifiedTableName,      LinkedHashMap<String, String> partitionNameValueMap,      Map<String, HiveTypeInfo> partitionTypeMap,      String partitionPath  ) throws StageException {    String sql = buildPartitionAdditionQuery(qualifiedTableName, partitionNameValueMap, partitionTypeMap, partitionPath);    execute(sql);  }
public void executeAlterTableSetTblPropertiesQuery(      String qualifiedTableName,      String partitionPath  ) throws StageException {    String sql = buildSetTablePropertiesQuery(qualifiedTableName, partitionPath);    execute(sql);  }
public Set<PartitionInfoCacheSupport.PartitionValues> executeShowPartitionsQuery(String qualifiedTableName) throws StageException {    String sql = buildShowPartitionsQuery(qualifiedTableName);    return executeQuery(sql, new WithResultSet<Set<PartitionInfoCacheSupport.PartitionValues>>() {      @Override      public Set<PartitionInfoCacheSupport.PartitionValues> run(ResultSet rs) throws SQLException, StageException {        Set<PartitionInfoCacheSupport.PartitionValues> partitionValuesSet = new HashSet<>();        while(rs.next()) {          String partitionInfoString = rs.getString(1);          String[] partitionInfoSplit = partitionInfoString.split(HiveMetastoreUtil.SEP);          LinkedHashMap<String, String> vals = new LinkedHashMap<>();          for (String partitionValInfo : partitionInfoSplit) {            String[] partitionNameVal = partitionValInfo.split("=");            vals.put(partitionNameVal[0], partitionNameVal[1]);          }          partitionValuesSet.add(new PartitionInfoCacheSupport.PartitionValues(vals));        }        return partitionValuesSet;      }    });  }
public Pair<LinkedHashMap<String, HiveTypeInfo>, LinkedHashMap<String, HiveTypeInfo>> executeDescTableQuery(      String qualifiedTableName  ) throws StageException {    String sql = buildDescTableQuery(qualifiedTableName);    return executeQuery(sql, new WithResultSet<Pair<LinkedHashMap<String, HiveTypeInfo>, LinkedHashMap<String, HiveTypeInfo>>>() {      @Override      public Pair<LinkedHashMap<String, HiveTypeInfo>, LinkedHashMap<String, HiveTypeInfo>> run(ResultSet rs) throws SQLException, StageException {        LinkedHashMap<String, HiveTypeInfo> columnTypeInfo  = extractTypeInfo(rs);        processDelimiter(rs, "#");        processDelimiter(rs, "#");        processDelimiter(rs, "");        LinkedHashMap<String, HiveTypeInfo> partitionTypeInfo = extractTypeInfo(rs);        //Remove partition columns from the columns map.        for (String partitionCol : partitionTypeInfo.keySet()) {          columnTypeInfo.remove(partitionCol);        }        return Pair.of(columnTypeInfo, partitionTypeInfo);      }    });  }
public String executeDescribeDatabase(String dbName) throws StageException {    String sql = buildDescribeDatabase(dbName);    return executeQuery(sql, rs -> {      if(!rs.next()) {        throw new HiveStageCheckedException(Errors.HIVE_35, "Database doesn't exists.");      }      return HiveMetastoreUtil.stripHdfsHostAndPort(rs.getString(RESULT_SET_LOCATION));    });  }
public Pair<Boolean, Boolean> executeShowTBLPropertiesQuery(      String qualifiedTableName  ) throws StageException {    String sql = String.format(SHOW_TBLPROPERTIES, qualifiedTableName);    return executeQuery(sql, new WithResultSet<Pair<Boolean, Boolean>>() {      @Override      public Pair<Boolean, Boolean> run(ResultSet rs) throws SQLException {        boolean isExternal = false, useAsAvro = true;        while (rs.next()) {          String propName = rs.getString(RESULT_SET_PROP_NAME);          String propValue = rs.getString(RESULT_SET_PROP_VALUE);          if (propName.toUpperCase().equals(EXTERNAL)) {            isExternal = Boolean.valueOf(propValue);          } else if (propName.equals(AVRO_SCHEMA_URL)) {            useAsAvro = false;          }        }        return Pair.of(isExternal, useAsAvro);      }    });  }
private void execute(String query) throws StageException {    LOG.debug("Executing SQL: {}", query);    Timer.Context t = updateTimer.time();    try(Statement statement = hiveConfigBean.getHiveConnection().createStatement()) {      statement.execute(query);    } catch (Exception e) {      LOG.error("Exception while processing query: {}", query, e);      throw new HiveStageCheckedException(Errors.HIVE_20, query, e.getMessage());    } finally {      long time = t.stop();      LOG.debug("Query '{}' took {} nanoseconds", query, time);      updateMeter.mark();    }  }
private<T> T executeQuery(String query, WithResultSet<T> execution) throws StageException {    LOG.debug("Executing SQL:  {}", query);    Timer.Context t = selectTimer.time();    try(      Statement statement = hiveConfigBean.getHiveConnection().createStatement();      ResultSet rs = statement.executeQuery(query);    ) {      // Stop timer immediately so that we're calculating only query execution time and not the processing time      long time = t.stop();      LOG.debug("Query '{}' took {} nanoseconds", query, time);      t = null;      return execution.run(rs);    } catch(Exception e) {      LOG.error("Exception while processing query: {}", query, e);      throw new HiveStageCheckedException(Errors.HIVE_20, query, e.getMessage());    } finally {      // If the timer wasn't stopped due to exception yet, stop it now      if(t != null) {        long time = t.stop();        LOG.debug("Query '{}' took {} nanoseconds", query, time);      }      selectMeter.mark();    }  }
@Override  public String produce(String lastSourceOffset, int maxBatchSize, BatchMaker batchMaker) throws StageException {    // Offsets can vary depending on the data source. Here we use an integer as an example only.    long nextSourceOffset = 0;    if (lastSourceOffset != null) {      nextSourceOffset = Long.parseLong(lastSourceOffset);    }    int numRecords = 0;    // TODO: As the developer, implement your logic that reads from a data source in this method.    // Create records and add to batch. Records must have a string id. This can include the source offset    // or other metadata to help uniquely identify the record itself.    while (numRecords < maxBatchSize) {      Record record = getContext().createRecord("some-id::" + nextSourceOffset);      Map<String, Field> map = new HashMap<>();      map.put("fieldName", Field.create("Some Value"));      record.set(Field.create(map));      batchMaker.addRecord(record);      ++nextSourceOffset;      ++numRecords;    }    return String.valueOf(nextSourceOffset);  }
public void executeBatch(      String offsetKey,      String offsetValue,      long batchStartTime,      ThrowingConsumer<Pipe> consumer  ) throws PipelineRuntimeException, StageException {    MDC.put(LogConstants.RUNNER, String.valueOf(runnerId));    // Persist static information for the batch (this won't change as the batch progresses)    this.runtimeMetricGauge.put(METRIC_BATCH_START_TIME, batchStartTime);    this.runtimeMetricGauge.put(METRIC_OFFSET_KEY, Optional.ofNullable(offsetKey).orElse(""));    this.runtimeMetricGauge.put(METRIC_OFFSET_VALUE, Optional.ofNullable(offsetValue).orElse(""));    this.runtimeMetricGauge.put(METRIC_STAGE_START_TIME, System.currentTimeMillis());    try {      // Run one pipe at a time      for(Pipe p : pipes) {        String instanceName = p.getStage().getInfo().getInstanceName();        this.runtimeMetricGauge.put(METRIC_CURRENT_STAGE, instanceName);        MDC.put(LogConstants.STAGE, instanceName);        if (p instanceof StagePipe) {          this.runtimeMetricGauge.put(METRIC_STAGE_START_TIME, System.currentTimeMillis());        }        acceptConsumer(consumer, p);      }      // We've successfully finished batch      this.runtimeMetricGauge.computeIfPresent(METRIC_BATCH_COUNT, (key, value) -> ((long)value) + 1);    } finally {      resetBatchSpecificMetrics();      MDC.put(LogConstants.RUNNER, "");      MDC.put(LogConstants.STAGE, "");    }  }
public void forEach(ThrowingConsumer<Pipe> consumer) {    try {      MDC.put(LogConstants.RUNNER, String.valueOf(runnerId));      try {        for(Pipe p : pipes) {          MDC.put(LogConstants.STAGE, p.getStage().getInfo().getInstanceName());          acceptConsumer(consumer, p);        }      } finally {        MDC.put(LogConstants.RUNNER, "");        MDC.put(LogConstants.STAGE, "");      }    } catch (PipelineException|StageException e) {      throw new RuntimeException(e);    }  }
public OffsetCommitTrigger getOffsetCommitTrigger() {    for (Pipe pipe : pipes) {      Stage stage = pipe.getStage().getStage();      if (stage instanceof Target && stage instanceof OffsetCommitTrigger) {        return (OffsetCommitTrigger) stage;      }    }    return null;  }
public boolean onRecordErrorStopPipeline() {    for(Pipe pipe : pipes) {      StageContext stageContext = pipe.getStage().getContext();      if(stageContext.getOnErrorRecord() == OnRecordError.STOP_PIPELINE) {        return true;      }    }    return false;  }
private void acceptConsumer(ThrowingConsumer<Pipe> consumer, Pipe p) throws PipelineRuntimeException, StageException {    try {      // Process pipe      consumer.accept(p);    } catch (Throwable t) {      String instanceName = p.getStage().getInfo().getInstanceName();      LOG.error("Failed executing stage '{}': {}", instanceName, t.toString(), t);      Throwables.propagateIfInstanceOf(t, PipelineRuntimeException.class);      Throwables.propagateIfInstanceOf(t, StageException.class);      Throwables.propagate(t);    }  }
private String getInsertIdForRecord(ELVars elVars, Record record) throws OnRecordErrorException {    String recordId = null;    RecordEL.setRecordInContext(elVars, record);    try {      if (!(StringUtils.isEmpty(conf.rowIdExpression))) {        recordId = rowIdELEval.eval(elVars, conf.rowIdExpression, String.class);        if (StringUtils.isEmpty(recordId)) {          throw new OnRecordErrorException(record, Errors.BIGQUERY_15);        }      }    } catch (ELEvalException e) {      LOG.error("Error evaluating Row Expression EL", e);      throw new OnRecordErrorException(record, Errors.BIGQUERY_10,e);    }    return recordId;  }
private Map<String, Object> convertToRowObjectFromRecord(Record record) throws OnRecordErrorException {    Field rootField = record.get();    Map<String, Object> rowObject = new LinkedHashMap<>();    if (rootField.getType().isOneOf(Field.Type.MAP, Field.Type.LIST_MAP)) {      Map<String, Field> fieldMap = rootField.getValueAsMap();      for (Map.Entry<String, Field> fieldEntry : fieldMap.entrySet()) {        Field field = fieldEntry.getValue();        //Skip null value fields        if (field.getValue() != null){          try {            rowObject.put(fieldEntry.getKey(), getValueFromField("/" + fieldEntry.getKey(), field));          } catch (IllegalArgumentException e) {            throw new OnRecordErrorException(record, Errors.BIGQUERY_13, e.getMessage());          }        }      }    } else {      throw new OnRecordErrorException(record,  Errors.BIGQUERY_16);    }    return rowObject;  }
private Object getValueFromField(String fieldPath, Field field) {    LOG.trace("Visiting Field Path '{}' of type '{}'", fieldPath, field.getType());    switch (field.getType()) {      case LIST:        //REPEATED        List<Field> listField = field.getValueAsList();        //Convert the list to map with indices as key and Field as value (Map<Integer, Field>)        Map<Integer, Field> fields =            IntStream.range(0, listField.size()).boxed()                .collect(Collectors.toMap(Function.identity(), listField::get));        //filter map to remove fields with null value        fields = fields.entrySet().stream()            .filter(e -> e.getValue().getValue() != null)            .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));        //now use the map index to generate field path and generate object for big query write        return fields.entrySet().stream()            .map(e -> getValueFromField(fieldPath + "[" + e.getKey() + "]", e.getValue()))            .collect(Collectors.toList());      case MAP:      case LIST_MAP:        //RECORD        return field.getValueAsMap().entrySet().stream()            .filter(me -> me.getValue().getValue() != null)            .collect(                Collectors.toMap(                    Map.Entry::getKey,                    e -> getValueFromField(fieldPath + "/" + e.getKey(), e.getValue())                )            );      case DATE:        return dateFormat.format(field.getValueAsDate());      case TIME:        return timeFormat.format(field.getValueAsTime());      case DATETIME:        return dateTimeFormat.format(field.getValueAsDatetime());      case BYTE_ARRAY:        return Base64.getEncoder().encodeToString(field.getValueAsByteArray());      case DECIMAL:      case BYTE:      case CHAR:      case FILE_REF:        throw new IllegalArgumentException(Utils.format(Errors.BIGQUERY_12.getMessage(), fieldPath, field.getType()));      default:        //Boolean -> Map to Boolean in big query        //Float, Double -> Map to Float in big query        //String -> maps to String in big query        //Short, Integer, Long -> Map to integer in big query        return field.getValue();    }  }
private void checkValidPorts() {    if ((conf.get(HTTP_PORT_KEY, HTTP_PORT_DEFAULT) == 0 && conf.get(HTTPS_PORT_KEY,      HTTPS_PORT_DEFAULT) != -1)        || (conf.get(HTTPS_PORT_KEY, HTTPS_PORT_DEFAULT) == 0 && conf.get(HTTP_PORT_KEY,          HTTP_PORT_DEFAULT) != -1)) {      throw new IllegalArgumentException(          "Invalid port combination for http and https, If http port is set to 0 (random), then https should be "              + "set to -1 or vice versa");    }  }
private <T> Observable<T> handleError(Record record, Errors error, Throwable ex, boolean passable) {    errors.put(record, new ErrorRecord(error, ex, passable));    return Observable.empty();  }
private <T> Observable<T> handleError(Record record, Errors error, boolean passable) {    return handleError(record, error, new RuntimeException(), passable);  }
private Observable<Record> setFragmentInRecord(Record record, DocumentFragment<Lookup> frag) {    if(frag.content(0) == null) {      LOG.debug("Sub-document path not found");      return handleError(record, Errors.COUCHBASE_25, true);    }    for(SubdocMappingConfig subdocMapping : config.subdocMappingConfigs) {     Object fragJson = frag.content(subdocMapping.subdocPath);      if(fragJson == null) {        return handleError(record, Errors.COUCHBASE_25, true);      }      try {        record.set(subdocMapping.sdcField, jsonToField(fragJson));        record.getHeader().setAttribute(config.CAS_HEADER_ATTRIBUTE, String.valueOf(frag.cas()));      } catch (IOException e) {        try {          record.set(subdocMapping.sdcField, jsonToField(JsonObject.fromJson(fragJson.toString()).toMap()));          record.getHeader().setAttribute(config.CAS_HEADER_ATTRIBUTE, String.valueOf(frag.cas()));        } catch (IOException ex) {          return handleError(record, Errors.COUCHBASE_19, ex, false);        }      }    }    return Observable.just(record);  }
private Observable<Record> setDocumentInRecord(Record record, JsonDocument doc) {    if(doc.content() == null) {      LOG.debug("Document does not exist: {}", doc.id());      return handleError(record, Errors.COUCHBASE_26, true);    }    try {      record.set(config.outputField, jsonToField(doc.content().toMap()));      record.getHeader().setAttribute(config.CAS_HEADER_ATTRIBUTE, String.valueOf(doc.cas()));      return Observable.just(record);    } catch (IOException e) {      LOG.debug("Unable to set KV lookup in record for: {}", doc.id());      return handleError(record, Errors.COUCHBASE_19, e, false);    }  }
private Observable<Record> setN1QLRowInRecord(Record record, AsyncN1qlQueryRow row) {    for(N1QLMappingConfig n1qlMapping : config.n1qlMappingConfigs) {      if (config.multipleValueOperation == MultipleValueType.FIRST && record.get(n1qlMapping.sdcField) != null) {        LOG.debug("Only populating output field with first record. Skipping additional result.");        return Observable.empty();      }      Object property = row.value().get(n1qlMapping.property);      if (property == null) {        LOG.debug("Requested property not returned: {}", n1qlMapping.property);        return handleError(record, Errors.COUCHBASE_27, true);      }      try {        record.set(n1qlMapping.sdcField, jsonToField(property));      } catch (IOException e) {        try {          record.set(n1qlMapping.sdcField, jsonToField(JsonObject.fromJson(property.toString()).toMap()));        } catch (IOException ex) {          LOG.debug("Unable to set N1QL property in record");          return handleError(record, Errors.COUCHBASE_19, ex, false);        }      }    }    return Observable.just(record);  }
public static int convertToJDBCCode(int op)  {    if (CRUD_MAP.containsKey(op)){      return CRUD_MAP.get(op);    }    throw new UnsupportedOperationException(Utils.format("Operation code {} is not supported", op));  }
private void handleWholeFileDataFormat(S3ObjectSummary s3ObjectSummary, String recordId) throws StageException {    S3Object partialS3ObjectForMetadata;    //partialObject with fetchSize 1 byte.    //This is mostly used for extracting metadata and such.    partialS3ObjectForMetadata = AmazonS3Util.getObjectRange(s3Client,        s3ConfigBean.s3Config.bucket,        s3ObjectSummary.getKey(),        1,        s3ConfigBean.sseConfig.useCustomerSSEKey,        s3ConfigBean.sseConfig.customerKey,        s3ConfigBean.sseConfig.customerKeyMd5    );    S3FileRef.Builder s3FileRefBuilder = new S3FileRef.Builder().s3Client(s3Client)                                                                .s3ObjectSummary(s3ObjectSummary)                                                                .useSSE(s3ConfigBean.sseConfig.useCustomerSSEKey)                                                                .customerKey(s3ConfigBean.sseConfig.customerKey)                                                                .customerKeyMd5(s3ConfigBean.sseConfig.customerKeyMd5)                                                                .bufferSize((int) dataParser.suggestedWholeFileBufferSize())                                                                .createMetrics(true)                                                                .totalSizeInBytes(s3ObjectSummary.getSize())                                                                .rateLimit(dataParser.wholeFileRateLimit());    if (dataParser.isWholeFileChecksumRequired()) {      s3FileRefBuilder.verifyChecksum(true).checksumAlgorithm(HashingUtil.HashType.MD5)                      //128 bit hex encoded md5 checksum.                      .checksum(partialS3ObjectForMetadata.getObjectMetadata().getETag());    }    Map<String, Object> metadata = AmazonS3Util.getMetaData(partialS3ObjectForMetadata);    metadata.put(S3Constants.BUCKET, s3ObjectSummary.getBucketName());    metadata.put(S3Constants.OBJECT_KEY, s3ObjectSummary.getKey());    metadata.put(S3Constants.OWNER, s3ObjectSummary.getOwner());    metadata.put(S3Constants.SIZE, s3ObjectSummary.getSize());    metadata.put(HeaderAttributeConstants.FILE_NAME, s3ObjectSummary.getKey());    metadata.remove(S3Constants.CONTENT_LENGTH);    parser = dataParser.getParser(recordId, metadata, s3FileRefBuilder.build());    //Object is assigned so that setHeaders() function can use this to get metadata    //information about the object    object = partialS3ObjectForMetadata;  }
private void initGaugeIfNeeded() {    gaugeMap.put(S3Constants.THREAD_NAME, Thread.currentThread().getName());    gaugeMap.put(S3Constants.STATUS, "");    gaugeMap.put(S3Constants.BUCKET, "");    gaugeMap.put(S3Constants.OBJECT_KEY, "");  }
public boolean incompleteTransactionsContain(String gtid, long seqNo) {    Long s = incompleteTransactions.get(gtid);    return s != null && s >= seqNo;  }
public static <T> T withClassLoader(      ClassLoader classLoader,      ExceptionSupplier<T> supplier   ) {     try {       return withClassLoaderInternal(classLoader, supplier);     } catch (Exception e) {       Throwables.propagate(e);     }     return null;   }
public static <T, E1 extends Exception> T withClassLoader(      ClassLoader classLoader,      Class<E1> e1,      ExceptionSupplier<T> supplier   ) throws E1 {     try {       return withClassLoaderInternal(classLoader, supplier);     } catch (Exception e) {       Throwables.propagateIfPossible(e, e1);       Throwables.propagate(e);     }     return null;   }
public static <T> T privilegedWithClassLoader(      ClassLoader classLoader,      ExceptionSupplier<T> supplier  ) {    try {      return AccessController.doPrivileged((PrivilegedExceptionAction<T>) () -> withClassLoaderInternal(classLoader, supplier));    } catch (PrivilegedActionException e) {      Throwables.propagate(e);    }    return null;  }
public static <T, E1 extends Exception> T privilegedWithClassLoader(      ClassLoader classLoader,      Class<E1> e1,      ExceptionSupplier<T> supplier  ) throws E1 {    try {      return AccessController.doPrivileged((PrivilegedExceptionAction<T>) () -> withClassLoaderInternal(classLoader, supplier));    } catch (PrivilegedActionException e) {      Throwables.propagateIfPossible(e.getCause(), e1);      Throwables.propagate(e);    }    return null;  }
private static <T> T withClassLoaderInternal(      ClassLoader classLoader,      ExceptionSupplier<T> supplier  ) throws Exception {    ClassLoader previousClassLoader = Thread.currentThread().getContextClassLoader();    try {      Thread.currentThread().setContextClassLoader(classLoader);      return supplier.get();    } finally {      Thread.currentThread().setContextClassLoader(previousClassLoader);    }  }
public void setStageCreator(String stateCreator) {    Preconditions.checkNotNull(stateCreator, "stateCreator cannot be null");    map.put(STAGE_CREATOR_INSTANCE_ATTR, stateCreator);  }
public Map<String, Object> getUserAttributes() {    return map.entrySet()        .stream()        .filter(map -> !map.getKey().startsWith(RESERVED_PREFIX))        .collect(Collectors.toMap(map -> map.getKey(), map -> map.getValue()));  }
public Map<String, Object> setUserAttributes(Map<String, Object> newAttributes) {    // ImmutableMap can't have null values and our map could have, so use unmodifiable map    Map<String, Object> old = Collections.unmodifiableMap(getUserAttributes());    //Set current map to just the Reserved System Attributes    map = getSystemAttributes();    // Add and validate each of the new user attributes    newAttributes.forEach((k,v) -> setAttribute(k, v.toString()));    return old;  }
public synchronized void login() {    if (subject != null) {      throw new IllegalStateException(Utils.format("Service already login, Principal '{}'",                                                   subject.getPrincipals()));    }    if (securityConfiguration.isKerberosEnabled()) {      try {        loginContext = createLoginContext();        subject = loginContext.getSubject();      } catch (Exception ex) {        throw new RuntimeException(Utils.format("Could not get Kerberos credentials: {}", ex.toString()), ex);      }      if (renewalThread == null) {        renewalThread = new Thread() {          @Override          public void run() {            LOG.debug("Starting renewal thread");            if (!SecurityContext.this.sleep(THIRTY_SECONDS_MS)) {              LOG.info("Interrupted, exiting renewal thread");              return;            }            while (true) {              LOG.trace("Renewal check starts");              try {                KerberosTicket lastExpiringTGT = getNewestTGT();                if (lastExpiringTGT == null) {                  LOG.warn(                      "Could not obtain kerberos ticket, it may have expired already or it was logged out, will wait" +                      "30 secs to attempt a relogin"                  );                  LOG.trace("Ticket not found, sleeping 30 secs and trying to login");                  if (!SecurityContext.this.sleep(THIRTY_SECONDS_MS)) {                    LOG.info("Interrupted, exiting renewal thread");                    return;                  }                } else {                  long renewalTimeMs = calculateRenewalTime(lastExpiringTGT) - THIRTY_SECONDS_MS;                  LOG.trace("Ticket found time to renewal '{}ms', sleeping that time", renewalTimeMs);                  if (renewalTimeMs > 0) {                    if (!SecurityContext.this.sleep(renewalTimeMs)) {                      LOG.info("Interrupted, exiting renewal thread");                      return;                    }                  }                }                LOG.debug("Triggering relogin");                Set<KerberosTicket> oldTickets = getSubject().getPrivateCredentials(KerberosTicket.class);                relogin(3);                // Remove all old private credentials, since we only need the new one we just added                getSubject().getPrivateCredentials().removeAll(oldTickets);              } catch (Exception exception) {                LOG.error("Stopping renewal thread because of exception: " + exception, exception);                return;              }              catch (Throwable throwable) {                LOG.error("Error in renewal thread: " + throwable, throwable);                return;              }            }          }        };        List<String> principals = new ArrayList<>();        for (Principal p : subject.getPrincipals()) {          principals.add(p.getName());        }        renewalThread.setName("Kerberos-Renewal-Thread-" + Joiner.on(",").join(principals));        renewalThread.setContextClassLoader(Thread.currentThread().getContextClassLoader());        renewalThread.setDaemon(true);        renewalThread.start();      }    } else {      subject = new Subject();    }    LOG.debug("Login. Kerberos enabled '{}', Principal '{}'", securityConfiguration.isKerberosEnabled(),      subject.getPrincipals());  }
public synchronized void logout() {    if (subject != null) {      LOG.debug("Logout. Kerberos enabled '{}', Principal '{}'", securityConfiguration.isKerberosEnabled(),        subject.getPrincipals());      if (loginContext != null) {        try {          loginContext.logout();        } catch (LoginException ex) {          LOG.warn("Error while doing logout from Kerberos: {}", ex.toString(), ex);        } finally {          loginContext = null;        }      }      subject = null;    }  }
private void setExceptions(Configuration configuration) {    this.exceptions.clear();    this.stageLibExceptions.clear();    // Load general exceptions    for(String path : configuration.get(PROPERTY_EXCEPTIONS, "").split(",")) {      this.exceptions.add(replaceVariables(path));    }    // Load Stage library specific exceptions    Configuration stageSpecific = configuration.getSubSetConfiguration(PROPERTY_STAGE_EXCEPTIONS, true);    for(Map.Entry<String, String> entry : stageSpecific.getValues().entrySet()) {      Set<String> stageExceptions = new HashSet<>();      for(String path : entry.getValue().split(",")) {        stageExceptions.add(replaceVariables(path));      }      this.stageLibExceptions.put(entry.getKey(), stageExceptions);    }  }
private String replaceVariables(String path) {    return path.replace("$SDC_DATA", dataDir)      .replace("$SDC_CONF", configDir)      .replace("$SDC_RESOURCES", resourcesDir)      ;  }
private void ensureProperPermissions(String path) {    ClassLoader cl = Thread.currentThread().getContextClassLoader();    // 1) Container can access anything    if(cl instanceof ContainerClassLoader) {        return;    }    // 2. Some files are whitelisted globally for all stage libraries    if(exceptions.contains(path)) {      return;    }    // 3. Some stage libraries have some files whitelisted globally    if(cl instanceof SDCClassLoader) {      String libraryName = ((SDCClassLoader)cl).getName();      if(stageLibExceptions.containsKey(libraryName) && stageLibExceptions.get(libraryName).contains(path)) {        return;      }    }    // No whitelist, no fun, go away    throw new SecurityException(Utils.format(      "Classloader {} is not allowed access to Data Collector internal directories ({}).",      cl.toString(),      path    ));  }
public Field generateJdbcTypeInfoFieldForMetadataRecord(JdbcTypeInfo jdbcTypeInfo) {    Map<String, Field> fields = new HashMap<>();    fields.put(TYPE, Field.create(jdbcTypeInfo.getJdbcType().name()));    fields.put(EXTRA_INFO, generateExtraInfoFieldForMetadataRecord(jdbcTypeInfo));    return Field.create(fields);  }
@SuppressWarnings("unchecked")  public JdbcTypeInfo generateJdbcTypeInfoFromMetadataField(Field jdbcTypeInfoField, JdbcSchemaWriter schemaWriter) throws StageException {    if (jdbcTypeInfoField.getType() == Field.Type.MAP) {      Map<String, Field> fields = (Map<String, Field>) jdbcTypeInfoField.getValue();      if (!fields.containsKey(TYPE)          || !fields.containsKey(EXTRA_INFO)) {        throw new StageException(JdbcErrors.JDBC_308, TYPE_INFO);      }      JdbcType jdbcType = JdbcType.getJdbcTypeFromString(fields.get(TYPE).getValueAsString());      return generateJdbcTypeInfoFromMetadataField(jdbcType, fields.get(EXTRA_INFO), schemaWriter);    } else {      throw new StageException(JdbcErrors.JDBC_308, TYPE_INFO);    }  }
public String generateColumnTypeDefinition(JdbcTypeInfo jdbcTypeInfo, String columnName) {    return String.format(      COLUMN_TYPE,      columnName,      jdbcTypeInfo.toString()    );  }
public static /*PipelineStartResult*/ Object startPipeline(Runnable postBatchRunnable) throws Exception {    BootstrapCluster.initialize();    ClassLoader originalClassLoader = Thread.currentThread().getContextClassLoader();    try {      Thread.currentThread().setContextClassLoader(containerCL);      Class embeddedPipelineFactoryClz = Class.forName("com.streamsets.datacollector.EmbeddedDataCollectorFactory", true,        containerCL);      Method createPipelineMethod = embeddedPipelineFactoryClz.getMethod("startPipeline", Runnable.class);      return createPipelineMethod.invoke(null, postBatchRunnable);    } catch (Exception ex) {      String msg = "Error trying to create pipeline: " + ex;      throw new IllegalStateException(msg, ex);    } finally {      Thread.currentThread().setContextClassLoader(originalClassLoader);    }  }
public static void main(String[] args) throws Exception {    EmrBinding binding = null;    try {      binding = new EmrBinding(args);      binding.init();      binding.awaitTermination(); // killed by ClusterProviderImpl before returning    } catch (Exception ex) {      String msg = "Error trying to invoke BootstrapEmrBatch.main: " + ex;      throw new IllegalStateException(msg, ex);    } finally {      try {        if (binding != null) {          binding.close();        }      } catch (Exception ex) {        LOG.warn("Error on binding close: " + ex, ex);      }    }  }
String getDirPath(Date date, Record record) throws StageException {    if(dirPathTemplateInHeader) {      // We're not validating if the header exists as that job is already done      return record.getHeader().getAttribute(HdfsTarget.TARGET_DIRECTORY_HEADER);    }    return pathResolver.resolvePath(date, record);  }
Path renameToFinalName(FileSystem fs, Path tempPath) throws IOException, StageException {    return fsHelper.renameAndGetPath(fs, tempPath);  }
public void issueCachedEvents() throws IOException {    Path closedPath;    while((closedPath = closedPaths.poll()) != null) {      produceCloseFileEvent(fs, closedPath);    }  }
public int handleAlreadyExistingFiles() throws StageException, IOException {    int result = 0;    String globPath = dirPathTemplate;    final String staticExpReg = "\\$\\{(sdc:|pipeline:|runtime:)[a-zA-Z0-9\\(\\)]*\\}";    Pattern pattern = Pattern.compile(staticExpReg);    Matcher matcher = pattern.matcher(globPath);    ELEval eval = context.createELEval("dirPathTemplate");    ELVars vars = context.createELVars();    while (matcher.find()) {      String expressionString = eval.eval(vars, matcher.group(), String.class);      globPath = globPath.replace(matcher.group(), expressionString);    }    final String expReg = "\\$\\{[^}]*\\}";    pattern = Pattern.compile(expReg);    matcher = pattern.matcher(globPath);    while (matcher.find()) {      globPath = globPath.replace(matcher.group(), "*");    }    globPath = globPath.replaceAll("\\*+", "*");    globPath = globPath + "/" + TMP_FILE_PREFIX + uniquePrefix + "*";    LOG.info("Created the following glob path for file recovery: {}", globPath);    FileStatus[] fileStatuses = fs.globStatus(new Path(globPath));    for (FileStatus fileStatus : fileStatuses) {      fsHelper.handleAlreadyExistingFile(fs, fileStatus.getPath());      result++;    }    return result;  }
public Path commitWriter(RecordWriter writer) throws IOException, StageException {    Path path = null;    if ((!writer.isClosed() || writer.isIdleClosed()) && !writer.isRenamed()) {      // Unset the interrupt flag before close(). InterruptedIOException makes close() fail      // resulting that the tmp file never gets renamed when stopping the pipeline.      boolean interrupted = Thread.interrupted();      try {        // Since this method is always called from exactly one thread, and        // we checked to make sure that it was not closed or it was idle closed, this method either closes        // the file or pushes us into the catch block.        writer.close();      } catch (IdleClosedException e) {        LOG.info("Writer for {} was idle closed, renaming.." , writer.getPath());      }      LOG.debug("Path[{}] - Committing Writer", writer.getPath());      path = renameToFinalName(fs, writer.getPath());      writer.setRenamed(true);      LOG.debug("Path[{}] - Committed Writer to '{}'", writer.getPath(), path);      // Reset the interrupt flag back.      if (interrupted) {        Thread.currentThread().interrupt();      }    }    return path;  }
public boolean shouldRoll(RecordWriter writer, Record record) {    if (rollIfHeader && record.getHeader().getAttribute(rollHeaderName) != null) {      LOG.debug("Path[{}] - will be rolled because of roll attribute '{}' set to '{}' in the record : '{}'", writer.getPath(), rollHeaderName, record.getHeader().getAttribute(rollHeaderName), record.getHeader().getSourceId());      return true;    }    return false;  }
@Override  public String produce(String lastSourceOffset, int maxBatchSize, BatchMaker batchMaker) throws StageException {    int recordCounter = 0;    long startTime = System.currentTimeMillis();    maxBatchSize = Math.min(conf.batchSize, maxBatchSize);    // deserializing offsets of all directories    Map<String, String> offsetMap = deserializeOffsetMap(lastSourceOffset);    boolean offsetSet = false;    while (!offsetSet) {      try {        multiDirReader.setOffsets(offsetMap);        offsetSet = true;      } catch (IOException ex) {        LOG.warn("Error while creating reading previous offset: {}", ex.toString(), ex);        multiDirReader.purge();      }    }    while (recordCounter < maxBatchSize && !isTimeout(startTime)) {      LiveFileChunk chunk = multiDirReader.next(getRemainingWaitTime(startTime));      if (chunk != null) {        String tag = chunk.getTag();        tag = (tag != null && tag.isEmpty()) ? null : tag;        String liveFileStr = chunk.getFile().serialize();        List<FileLine> lines = chunk.getLines();        int truncatedLine = chunk.isTruncated() ? lines.size()-1 : -1;        for (int i = 0; i < lines.size(); i++) {          FileLine line = lines.get(i);          String sourceId = liveFileStr + "::" + line.getFileOffset();          try (DataParser parser = parserFactory.getParser(sourceId, line.getText())) {            if(i == truncatedLine) {              //set truncated              parser.setTruncated();            }            Record record = parser.parse();            if (record != null) {              if (tag != null) {                record.getHeader().setAttribute("tag", tag);              }              record.getHeader().setAttribute(HeaderAttributeConstants.FILE, chunk.getFile().getPath().toString());              record.getHeader().setAttribute(HeaderAttributeConstants.FILE_NAME, chunk.getFile().getPath().getFileName().toString());              record.getHeader().setAttribute(HeaderAttributeConstants.OFFSET, String.valueOf(line.getFileOffset()));              record.getHeader().setAttribute(                HeaderAttributeConstants.LAST_MODIFIED_TIME,                String.valueOf(Files.getLastModifiedTime(chunk.getFile().getPath()).toMillis())              );              batchMaker.addRecord(record, outputLane);              recordCounter++;            }          } catch (IOException | DataParserException ex) {            errorRecordHandler.onError(Errors.TAIL_12, sourceId, ex.toString(), ex);          }        }      }    }    boolean metadataGenerationFailure = false;    Date now = new Date(startTime);    for (FileEvent event : multiDirReader.getEvents()) {      try {        LiveFile file = event.getFile().refresh();        Record metadataRecord = getContext().createRecord("");        Map<String, Field> map = new HashMap<>();        map.put("fileName", Field.create(file.getPath().toString()));        map.put("inode", Field.create(file.getINode()));        map.put("time", Field.createDate(now));        map.put("event", Field.create((event.getAction().name())));        metadataRecord.set(Field.create(map));        batchMaker.addRecord(metadataRecord, metadataLane);        // We're also sending the same information on event lane        String eventRecordSourceId =            Utils.format("event:{}:{}:{}", event.getAction().name(), 1, file.getPath().toString());        EventRecord eventRecord = getContext().createEventRecord(event.getAction().name(), 1, eventRecordSourceId);        eventRecord.set(Field.create(map));        getContext().toEvent(eventRecord);      } catch (IOException ex) {        LOG.warn("Error while creating metadata records: {}", ex.toString(), ex);        metadataGenerationFailure = true;      }    }    if (metadataGenerationFailure) {      multiDirReader.purge();    }    boolean offsetExtracted = false;    while (!offsetExtracted) {      try {        offsetMap = multiDirReader.getOffsets();        offsetExtracted = true;      } catch (IOException ex) {        LOG.warn("Error while creating creating new offset: {}", ex.toString(), ex);        multiDirReader.purge();      }    }    //Calculate Offset lag Metric.    calculateOffsetLagMetric(offsetMap);    //Calculate Pending Files Metric    calculatePendingFilesMetric();    // serializing offsets of all directories    return serializeOffsetMap(offsetMap);  }
public void setPathSeparator(String pathSeparator) {    this.pathSeparator = (pathSeparator != null ? pathSeparator : DEFAULT_PATH_SEPARATOR);    this.pathSeparatorPatternCache = new PathSeparatorPatternCache(this.pathSeparator);  }
protected String[] tokenizePattern(String pattern) {    String[] tokenized = null;    Boolean cachePatterns = this.cachePatterns;    if (cachePatterns == null || cachePatterns.booleanValue()) {      tokenized = this.tokenizedPatternCache.get(pattern);    }    if (tokenized == null) {      tokenized = tokenizePath(pattern);      if (cachePatterns == null && this.tokenizedPatternCache.size() >= CACHE_TURNOFF_THRESHOLD) {        // Try to adapt to the runtime situation that we're encountering:        // There are obviously too many different patterns coming in here...        // So let's turn off the cache since the patterns are unlikely to be reoccurring.        deactivatePatternCache();        return tokenized;      }      if (cachePatterns == null || cachePatterns.booleanValue()) {        this.tokenizedPatternCache.put(pattern, tokenized);      }    }    return tokenized;  }
private static String[] toStringArray(Collection<String> collection) {    if (collection == null) {      return null;    }    return collection.toArray(new String[collection.size()]);  }
private boolean matchStrings(String pattern, String str, Map<String, String> uriTemplateVariables) {    return getStringMatcher(pattern).matchStrings(str, uriTemplateVariables);  }
public void setOffsets(Map<String, String> offsets) throws IOException {    Utils.checkState(open, "Not open");    fileContextProvider.setOffsets(offsets);    // we reset the events on every setOffsets().    events.clear();  }
public Map<String, String> getOffsets() throws IOException {    Utils.checkState(open, "Not open");    return fileContextProvider.getOffsets();  }
private long getRemainingWaitTime(long startTime, long maxWaitTimeMillis) {    long remaining = maxWaitTimeMillis - (System.currentTimeMillis() - startTime);    return (remaining > 0) ? remaining : 0;  }
public LiveFileChunk next(long waitMillis) {    Utils.checkState(open, "Not open");    waitMillis = (waitMillis > 0) ? waitMillis : 0;    long startTime = System.currentTimeMillis();    LiveFileChunk chunk = null;    boolean exit = false;    fileContextProvider.startNewLoop();    while (!exit) {      if (!fileContextProvider.didFullLoop()) {        FileContext fileContext = fileContextProvider.next();        try {          LiveFileReader reader = fileContext.getReader();          if (reader != null) {            if (reader.hasNext()) {              chunk = reader.next(0);              if (LOG.isTraceEnabled()) {                LOG.trace("next(): directory '{}', file '{}', offset '{}' got data '{}'",                    fileContext.getMultiFileInfo().getFileFullPath(),                    reader.getLiveFile(), reader.getOffset(), chunk != null);              }            } else {              if (LOG.isTraceEnabled()) {                LOG.trace("next(): directory '{}', file '{}', offset '{}' EOF reached",                    fileContext.getMultiFileInfo().getFileFullPath(),                    reader.getLiveFile(), reader.getOffset());              }            }            fileContext.releaseReader(false);          } else {            if (LOG.isTraceEnabled()) {              LOG.trace("next(): directory '{}', no reader available",                  fileContext.getMultiFileInfo().getFileFullPath());            }          }        } catch (IOException ex) {          LOG.error("Error while reading file: {}", ex.toString(), ex);          try {            fileContext.releaseReader(true);          } catch (IOException ex1) {            LOG.warn("Error while releasing reader in error: {}", ex1.toString(), ex1);          }        }      }      // check exit conditions (we have a chunk, or we timed-out waitMillis)      exit = chunk != null;      if (!exit) {        // if we looped thru all dir contexts in this call we yield CPU        if (fileContextProvider.didFullLoop()) {          exit = isTimeout(startTime, waitMillis);          if (!exit && LOG.isTraceEnabled()) {            LOG.trace("next(): looped through all directories, yielding CPU");          }          exit = exit || !ThreadUtil.sleep(Math.min(getRemainingWaitTime(startTime, waitMillis), MAX_YIELD_TIME));          fileContextProvider.startNewLoop();        }      }    }    return chunk;  }
public Map<String, Long> getOffsetsLag(Map<String, String> offsetMap) throws IOException{    return fileContextProvider.getOffsetsLag(offsetMap);  }
public <R> R createAndInitialize(    StageLibraryTask stageLib,    Configuration configuration,    String stageLibraryName,    Class<R> exportedInterface  ) {    StageLibraryDelegate instance = create(      stageLib,      stageLibraryName,      exportedInterface    );    if(instance == null) {      return null;    }    // Create & set context    StageLibraryDelegateContext context = new StageLibraryDelegateContext(      configuration    );    instance.setContext(context);    return (R)new StageLibraryDelegateRuntime(      instance.getClass().getClassLoader(),      instance    );  }
public StageLibraryDelegate create(    StageLibraryTask stageLib,    String stageLibraryName,    Class exportedInterface  ) {    StageLibraryDelegateDefinitition def = stageLib.getStageLibraryDelegateDefinition(stageLibraryName, exportedInterface);    if(def == null) {      return null;    }    return createInstance(def);  }
private StageLibraryDelegate createInstance(StageLibraryDelegateDefinitition def) {    StageLibraryDelegate instance  = null;    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();    try {      Thread.currentThread().setContextClassLoader(def.getClassLoader());      instance = def.getKlass().newInstance();    } catch (InstantiationException | IllegalAccessException ex) {      LOG.error("Can't create instance of delegator: " + ex.toString(), ex);    } finally {      Thread.currentThread().setContextClassLoader(classLoader);    }    return instance;  }
public void configure(DefaultHttpClient httpClient, SolrParams config) {    super.configure(httpClient, config);    // Begin change for SDC-2962    // Instead of checking existence of JAAS file, do the following if solr kerberos is enabled    //if (System.getProperty(LOGIN_CONFIG_PROP) != null) {      //String configValue = System.getProperty(LOGIN_CONFIG_PROP);      //if (configValue != null) {       // logger.info("Setting up SPNego auth with config: " + configValue);        final String useSubjectCredsProp = "javax.security.auth.useSubjectCredsOnly";        String useSubjectCredsVal = System.getProperty(useSubjectCredsProp);        // "javax.security.auth.useSubjectCredsOnly" should be false so that the underlying        // authentication mechanism can load the credentials from the JAAS configuration.        if (useSubjectCredsVal == null) {          System.setProperty(useSubjectCredsProp, "false");        }        else if (!useSubjectCredsVal.toLowerCase(Locale.ROOT).equals("false")) {          // Don't overwrite the prop value if it's already been written to something else,          // but log because it is likely the Credentials won't be loaded correctly.          logger.warn("System Property: " + useSubjectCredsProp + " set to: " + useSubjectCredsVal              + " not false.  SPNego authentication may not be successful.");        }        // Change for SDC-2962        //javax.security.auth.login.Configuration.setConfiguration(jaasConfig);        //Enable only SPNEGO authentication scheme.        AuthSchemeRegistry registry = new AuthSchemeRegistry();        registry.register(AuthSchemes.SPNEGO, new SPNegoSchemeFactory(true, false));        httpClient.setAuthSchemes(registry);        // Get the credentials from the JAAS configuration rather than here        Credentials useJaasCreds = new Credentials() {          public String getPassword() {            return null;          }          public Principal getUserPrincipal() {            return null;          }        };        SolrPortAwareCookieSpecFactory cookieFactory = new SolrPortAwareCookieSpecFactory();        httpClient.getCookieSpecs().register(cookieFactory.POLICY_NAME, cookieFactory);        httpClient.getParams().setParameter(ClientPNames.COOKIE_POLICY, cookieFactory.POLICY_NAME);        httpClient.getCredentialsProvider().setCredentials(AuthScope.ANY, useJaasCreds);        httpClient.addRequestInterceptor(bufferedEntityInterceptor);      //} else {        //httpClient.getCredentialsProvider().clear();      //}   // }  }
public String getAccessToken() {    if (System.currentTimeMillis() > getExpireTime()) {      try {        synchronized (this) {          if (System.currentTimeMillis() > getExpireTime()) {            accessToken = fetchAccessToken();            if (accessToken != null && !accessToken.isEmpty()) {              expires = (System.currentTimeMillis() + expires);            }          }        }      } catch (Exception e) {        LOG.debug("Error in fetching the access token: {} ", e);      }    }    return accessToken;  }
public static Object getMetricValue(    MetricRegistry metrics,    String metricId,    MetricType metricType,    MetricElement metricElement  ) throws ObserverException {    // We moved the logic of CURRENT_BATCH_AGE and TIME_IN_CURRENT_STAGE due to multi-threaded framework    if(metricElement.isOneOf(MetricElement.CURRENT_BATCH_AGE, MetricElement.TIME_IN_CURRENT_STAGE)) {      switch (metricElement) {        case CURRENT_BATCH_AGE:          return getTimeFromRunner(metrics, PipeRunner.METRIC_BATCH_START_TIME);        case TIME_IN_CURRENT_STAGE:          return getTimeFromRunner(metrics, PipeRunner.METRIC_STAGE_START_TIME);        default:          throw new IllegalStateException(Utils.format("Unknown metric type '{}'", metricType));      }    }    // Default path    Metric metric = getMetric(        metrics,        metricId,        metricType    );    if(metric != null) {      return getMetricValue(metricElement, metricType, metric);    }    return null;  }
private static long getTimeFromRunner(    MetricRegistry metrics,    String runnerMetricName  ) {    // First get number of total runners from the runtime gauge    RuntimeStats runtimeStats = (RuntimeStats) ((Gauge)getMetric(metrics, "RuntimeStatsGauge.gauge", MetricType.GAUGE)).getValue();    long totalRunners = runtimeStats.getTotalRunners();    long currentTime = System.currentTimeMillis();    long maxTime = 0;    // Then iterate over all runners and find the biggest time difference    for(int runnerId = 0; runnerId < totalRunners; runnerId++) {      Map<String, Object> runnerMetrics = (Map<String, Object>) ((Gauge)getMetric(metrics, "runner." + runnerId, MetricType.GAUGE)).getValue();      // Get current value      long value = (long) runnerMetrics.getOrDefault(runnerMetricName, 0L);      // Zero means that the runner is not in use at all and thus calculating running time makes no sense      if(value == 0) {        continue;      }      long runTime = currentTime - value;      if(maxTime < runTime) {        maxTime = runTime;      }    }    return maxTime;  }
public static void main(String[] args) {        // Defaults        int port = 8080;        String host = null; // bind to all interfaces by default        List<File> rootDirs = new ArrayList<File>();        boolean quiet = false;        String cors = null;        Map<String, String> options = new HashMap<String, String>();        // Parse command-line, with short and long versions of the options.        for (int i = 0; i < args.length; ++i) {            if ("-h".equalsIgnoreCase(args[i]) || "--host".equalsIgnoreCase(args[i])) {                host = args[i + 1];            } else if ("-p".equalsIgnoreCase(args[i]) || "--port".equalsIgnoreCase(args[i])) {                port = Integer.parseInt(args[i + 1]);            } else if ("-q".equalsIgnoreCase(args[i]) || "--quiet".equalsIgnoreCase(args[i])) {                quiet = true;            } else if ("-d".equalsIgnoreCase(args[i]) || "--dir".equalsIgnoreCase(args[i])) {                rootDirs.add(new File(args[i + 1]).getAbsoluteFile());            } else if (args[i].startsWith("--cors")) {                cors = "*";                int equalIdx = args[i].indexOf('=');                if (equalIdx > 0) {                    cors = args[i].substring(equalIdx + 1);                }            } else if ("--licence".equalsIgnoreCase(args[i])) {                System.out.println(SimpleWebServer.LICENCE + "\n");            } else if (args[i].startsWith("-X:")) {                int dot = args[i].indexOf('=');                if (dot > 0) {                    String name = args[i].substring(0, dot);                    String value = args[i].substring(dot + 1, args[i].length());                    options.put(name, value);                }            }        }        if (rootDirs.isEmpty()) {            rootDirs.add(new File(".").getAbsoluteFile());        }        options.put("host", host);        options.put("port", "" + port);        options.put("quiet", String.valueOf(quiet));        StringBuilder sb = new StringBuilder();        for (File dir : rootDirs) {            if (sb.length() > 0) {                sb.append(":");            }            try {                sb.append(dir.getCanonicalPath());            } catch (IOException ignored) {            }        }        options.put("home", sb.toString());        ServiceLoader<WebServerPluginInfo> serviceLoader = ServiceLoader.load(WebServerPluginInfo.class);        for (WebServerPluginInfo info : serviceLoader) {            String[] mimeTypes = info.getMimeTypes();            for (String mime : mimeTypes) {                String[] indexFiles = info.getIndexFilesForMimeType(mime);                if (!quiet) {                    System.out.print("# Found plugin for Mime type: \"" + mime + "\"");                    if (indexFiles != null) {                        System.out.print(" (serving index files: ");                        for (String indexFile : indexFiles) {                            System.out.print(indexFile + " ");                        }                    }                    System.out.println(").");                }                registerPluginForMimeType(indexFiles, mime, info.getWebServerPlugin(mime), options);            }        }        ServerRunner.executeInstance(new SimpleWebServer(host, port, rootDirs, quiet, cors));    }
Response serveFile(String uri, Map<String, String> header, File file, String mime) {        Response res;        try {            // Calculate etag            String etag = Integer.toHexString((file.getAbsolutePath() + file.lastModified() + "" + file.length()).hashCode());            // Support (simple) skipping:            long startFrom = 0;            long endAt = -1;            String range = header.get("range");            if (range != null) {                if (range.startsWith("bytes=")) {                    range = range.substring("bytes=".length());                    int minus = range.indexOf('-');                    try {                        if (minus > 0) {                            startFrom = Long.parseLong(range.substring(0, minus));                            endAt = Long.parseLong(range.substring(minus + 1));                        }                    } catch (NumberFormatException ignored) {                    }                }            }            // get if-range header. If present, it must match etag or else we            // should ignore the range request            String ifRange = header.get("if-range");            boolean headerIfRangeMissingOrMatching = (ifRange == null || etag.equals(ifRange));            String ifNoneMatch = header.get("if-none-match");            boolean headerIfNoneMatchPresentAndMatching = ifNoneMatch != null && ("*".equals(ifNoneMatch) || ifNoneMatch.equals(etag));            // Change return code and add Content-Range header when skipping is            // requested            long fileLen = file.length();            if (headerIfRangeMissingOrMatching && range != null && startFrom >= 0 && startFrom < fileLen) {                // range request that matches current etag                // and the startFrom of the range is satisfiable                if (headerIfNoneMatchPresentAndMatching) {                    // range request that matches current etag                    // and the startFrom of the range is satisfiable                    // would return range from file                    // respond with not-modified                    res = newFixedLengthResponse(Status.NOT_MODIFIED, mime, "");                    res.addHeader("ETag", etag);                } else {                    if (endAt < 0) {                        endAt = fileLen - 1;                    }                    long newLen = endAt - startFrom + 1;                    if (newLen < 0) {                        newLen = 0;                    }                    FileInputStream fis = new FileInputStream(file);                    fis.skip(startFrom);                    res = Response.newFixedLengthResponse(Status.PARTIAL_CONTENT, mime, fis, newLen);                    res.addHeader("Accept-Ranges", "bytes");                    res.addHeader("Content-Length", "" + newLen);                    res.addHeader("Content-Range", "bytes " + startFrom + "-" + endAt + "/" + fileLen);                    res.addHeader("ETag", etag);                }            } else {                if (headerIfRangeMissingOrMatching && range != null && startFrom >= fileLen) {                    // return the size of the file                    // 4xx responses are not trumped by if-none-match                    res = newFixedLengthResponse(Status.RANGE_NOT_SATISFIABLE, NanoHTTPD.MIME_PLAINTEXT, "");                    res.addHeader("Content-Range", "bytes */" + fileLen);                    res.addHeader("ETag", etag);                } else if (range == null && headerIfNoneMatchPresentAndMatching) {                    // full-file-fetch request                    // would return entire file                    // respond with not-modified                    res = newFixedLengthResponse(Status.NOT_MODIFIED, mime, "");                    res.addHeader("ETag", etag);                } else if (!headerIfRangeMissingOrMatching && headerIfNoneMatchPresentAndMatching) {                    // range request that doesn't match current etag                    // would return entire (different) file                    // respond with not-modified                    res = newFixedLengthResponse(Status.NOT_MODIFIED, mime, "");                    res.addHeader("ETag", etag);                } else {                    // supply the file                    res = newFixedFileResponse(file, mime);                    res.addHeader("Content-Length", "" + fileLen);                    res.addHeader("ETag", etag);                }            }        } catch (IOException ioe) {            res = getForbiddenResponse("Reading file failed.");        }        return res;    }
private void decodeHeader(BufferedReader in, Map<String, String> pre, Map<String, List<String>> parms, Map<String, String> headers) throws ResponseException {        try {            // Read the request line            String inLine = in.readLine();            if (inLine == null) {                return;            }            StringTokenizer st = new StringTokenizer(inLine);            if (!st.hasMoreTokens()) {                throw new ResponseException(Status.BAD_REQUEST, "BAD REQUEST: Syntax error. Usage: GET /example/file.html");            }            pre.put("method", st.nextToken());            if (!st.hasMoreTokens()) {                throw new ResponseException(Status.BAD_REQUEST, "BAD REQUEST: Missing URI. Usage: GET /example/file.html");            }            String uri = st.nextToken();            // Decode parameters from the URI            int qmi = uri.indexOf('?');            if (qmi >= 0) {                decodeParms(uri.substring(qmi + 1), parms);                uri = NanoHTTPD.decodePercent(uri.substring(0, qmi));            } else {                uri = NanoHTTPD.decodePercent(uri);            }            // If there's another token, its protocol version,            // followed by HTTP headers.            // NOTE: this now forces header names lower case since they are            // case insensitive and vary by client.            if (st.hasMoreTokens()) {                protocolVersion = st.nextToken();            } else {                protocolVersion = "HTTP/1.1";                NanoHTTPD.LOG.log(Level.FINE, "no protocol version specified, strange. Assuming HTTP/1.1.");            }            String line = in.readLine();            while (line != null && !line.trim().isEmpty()) {                int p = line.indexOf(':');                if (p >= 0) {                    headers.put(line.substring(0, p).trim().toLowerCase(Locale.US), line.substring(p + 1).trim());                }                line = in.readLine();            }            pre.put("uri", uri);        } catch (IOException ioe) {            throw new ResponseException(Status.INTERNAL_ERROR, "SERVER INTERNAL ERROR: IOException: " + ioe.getMessage(), ioe);        }    }
private void decodeMultipartFormData(ContentType contentType, ByteBuffer fbuf, Map<String, List<String>> parms, Map<String, String> files) throws ResponseException {        int pcount = 0;        try {            int[] boundaryIdxs = getBoundaryPositions(fbuf, contentType.getBoundary().getBytes());            if (boundaryIdxs.length < 2) {                throw new ResponseException(Status.BAD_REQUEST, "BAD REQUEST: Content type is multipart/form-data but contains less than two boundary strings.");            }            byte[] partHeaderBuff = new byte[MAX_HEADER_SIZE];            for (int boundaryIdx = 0; boundaryIdx < boundaryIdxs.length - 1; boundaryIdx++) {                fbuf.position(boundaryIdxs[boundaryIdx]);                int len = (fbuf.remaining() < MAX_HEADER_SIZE) ? fbuf.remaining() : MAX_HEADER_SIZE;                fbuf.get(partHeaderBuff, 0, len);                BufferedReader in =                        new BufferedReader(new InputStreamReader(new ByteArrayInputStream(partHeaderBuff, 0, len), Charset.forName(contentType.getEncoding())), len);                int headerLines = 0;                // First line is boundary string                String mpline = in.readLine();                headerLines++;                if (mpline == null || !mpline.contains(contentType.getBoundary())) {                    throw new ResponseException(Status.BAD_REQUEST, "BAD REQUEST: Content type is multipart/form-data but chunk does not start with boundary.");                }                String partName = null, fileName = null, partContentType = null;                // Parse the reset of the header lines                mpline = in.readLine();                headerLines++;                while (mpline != null && mpline.trim().length() > 0) {                    Matcher matcher = NanoHTTPD.CONTENT_DISPOSITION_PATTERN.matcher(mpline);                    if (matcher.matches()) {                        String attributeString = matcher.group(2);                        matcher = NanoHTTPD.CONTENT_DISPOSITION_ATTRIBUTE_PATTERN.matcher(attributeString);                        while (matcher.find()) {                            String key = matcher.group(1);                            if ("name".equalsIgnoreCase(key)) {                                partName = matcher.group(2);                            } else if ("filename".equalsIgnoreCase(key)) {                                fileName = matcher.group(2);                                // add these two line to support multiple                                // files uploaded using the same field Id                                if (!fileName.isEmpty()) {                                    if (pcount > 0)                                        partName = partName + String.valueOf(pcount++);                                    else                                        pcount++;                                }                            }                        }                    }                    matcher = NanoHTTPD.CONTENT_TYPE_PATTERN.matcher(mpline);                    if (matcher.matches()) {                        partContentType = matcher.group(2).trim();                    }                    mpline = in.readLine();                    headerLines++;                }                int partHeaderLength = 0;                while (headerLines-- > 0) {                    partHeaderLength = scipOverNewLine(partHeaderBuff, partHeaderLength);                }                // Read the part data                if (partHeaderLength >= len - 4) {                    throw new ResponseException(Status.INTERNAL_ERROR, "Multipart header size exceeds MAX_HEADER_SIZE.");                }                int partDataStart = boundaryIdxs[boundaryIdx] + partHeaderLength;                int partDataEnd = boundaryIdxs[boundaryIdx + 1] - 4;                fbuf.position(partDataStart);                List<String> values = parms.get(partName);                if (values == null) {                    values = new ArrayList<String>();                    parms.put(partName, values);                }                if (partContentType == null) {                    // Read the part into a string                    byte[] data_bytes = new byte[partDataEnd - partDataStart];                    fbuf.get(data_bytes);                    values.add(new String(data_bytes, contentType.getEncoding()));                } else {                    // Read it into a file                    String path = saveTmpFile(fbuf, partDataStart, partDataEnd - partDataStart, fileName);                    if (!files.containsKey(partName)) {                        files.put(partName, path);                    } else {                        int count = 2;                        while (files.containsKey(partName + count)) {                            count++;                        }                        files.put(partName + count, path);                    }                    values.add(fileName);                }            }        } catch (ResponseException re) {            throw re;        } catch (Exception e) {            throw new ResponseException(Status.INTERNAL_ERROR, e.toString());        }    }
private void decodeParms(String parms, Map<String, List<String>> p) {        if (parms == null) {            this.queryParameterString = "";            return;        }        this.queryParameterString = parms;        StringTokenizer st = new StringTokenizer(parms, "&");        while (st.hasMoreTokens()) {            String e = st.nextToken();            int sep = e.indexOf('=');            String key = null;            String value = null;            if (sep >= 0) {                key = NanoHTTPD.decodePercent(e.substring(0, sep)).trim();                value = NanoHTTPD.decodePercent(e.substring(sep + 1));            } else {                key = NanoHTTPD.decodePercent(e).trim();                value = "";            }            List<String> values = p.get(key);            if (values == null) {                values = new ArrayList<String>();                p.put(key, values);            }            values.add(value);        }    }
private int findHeaderEnd(final byte[] buf, int rlen) {        int splitbyte = 0;        while (splitbyte + 1 < rlen) {            // RFC2616            if (buf[splitbyte] == '\r' && buf[splitbyte + 1] == '\n' && splitbyte + 3 < rlen && buf[splitbyte + 2] == '\r' && buf[splitbyte + 3] == '\n') {                return splitbyte + 4;            }            // tolerance            if (buf[splitbyte] == '\n' && buf[splitbyte + 1] == '\n') {                return splitbyte + 2;            }            splitbyte++;        }        return 0;    }
private int[] getBoundaryPositions(ByteBuffer b, byte[] boundary) {        int[] res = new int[0];        if (b.remaining() < boundary.length) {            return res;        }        int search_window_pos = 0;        byte[] search_window = new byte[4 * 1024 + boundary.length];        int first_fill = (b.remaining() < search_window.length) ? b.remaining() : search_window.length;        b.get(search_window, 0, first_fill);        int new_bytes = first_fill - boundary.length;        do {            // Search the search_window            for (int j = 0; j < new_bytes; j++) {                for (int i = 0; i < boundary.length; i++) {                    if (search_window[j + i] != boundary[i])                        break;                    if (i == boundary.length - 1) {                        // Match found, add it to results                        int[] new_res = new int[res.length + 1];                        System.arraycopy(res, 0, new_res, 0, res.length);                        new_res[res.length] = search_window_pos + j;                        res = new_res;                    }                }            }            search_window_pos += new_bytes;            // Copy the end of the buffer to the start            System.arraycopy(search_window, search_window.length - boundary.length, search_window, 0, boundary.length);            // Refill search_window            new_bytes = search_window.length - boundary.length;            new_bytes = (b.remaining() < new_bytes) ? b.remaining() : new_bytes;            b.get(search_window, boundary.length, new_bytes);        } while (new_bytes > 0);        return res;    }
public long getBodySize() {        if (this.headers.containsKey("content-length")) {            return Long.parseLong(this.headers.get("content-length"));        } else if (this.splitbyte < this.rlen) {            return this.rlen - this.splitbyte;        }        return 0;    }
private String saveTmpFile(ByteBuffer b, int offset, int len, String filename_hint) {        String path = "";        if (len > 0) {            FileOutputStream fileOutputStream = null;            try {                ITempFile tempFile = this.tempFileManager.createTempFile(filename_hint);                ByteBuffer src = b.duplicate();                fileOutputStream = new FileOutputStream(tempFile.getName());                FileChannel dest = fileOutputStream.getChannel();                src.position(offset).limit(offset + len);                dest.write(src.slice());                path = tempFile.getName();            } catch (Exception e) { // Catch exception if any                throw new Error(e); // we won't recover, so throw an error            } finally {                NanoHTTPD.safeClose(fileOutputStream);            }        }        return path;    }
public static SSLServerSocketFactory makeSSLSocketFactory(KeyStore loadedKeyStore, KeyManager[] keyManagers) throws IOException {        SSLServerSocketFactory res = null;        try {            TrustManagerFactory trustManagerFactory = TrustManagerFactory.getInstance(TrustManagerFactory.getDefaultAlgorithm());            trustManagerFactory.init(loadedKeyStore);            SSLContext ctx = SSLContext.getInstance("TLS");            ctx.init(keyManagers, trustManagerFactory.getTrustManagers(), null);            res = ctx.getServerSocketFactory();        } catch (Exception e) {            throw new IOException(e.getMessage());        }        return res;    }
public static SSLServerSocketFactory makeSSLSocketFactory(KeyStore loadedKeyStore, KeyManagerFactory loadedKeyFactory) throws IOException {        try {            return makeSSLSocketFactory(loadedKeyStore, loadedKeyFactory.getKeyManagers());        } catch (Exception e) {            throw new IOException(e.getMessage());        }    }
public static SSLServerSocketFactory makeSSLSocketFactory(String keyAndTrustStoreClasspathPath, char[] passphrase) throws IOException {        try {            KeyStore keystore = KeyStore.getInstance(KeyStore.getDefaultType());            InputStream keystoreStream = NanoHTTPD.class.getResourceAsStream(keyAndTrustStoreClasspathPath);            if (keystoreStream == null) {                throw new IOException("Unable to load keystore from classpath: " + keyAndTrustStoreClasspathPath);            }            keystore.load(keystoreStream, passphrase);            KeyManagerFactory keyManagerFactory = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());            keyManagerFactory.init(keystore, passphrase);            return makeSSLSocketFactory(keystore, keyManagerFactory);        } catch (Exception e) {            throw new IOException(e.getMessage());        }    }
public static String getMimeTypeForFile(String uri) {        int dot = uri.lastIndexOf('.');        String mime = null;        if (dot >= 0) {            mime = mimeTypes().get(uri.substring(dot + 1).toLowerCase());        }        return mime == null ? "application/octet-stream" : mime;    }
public Response handle(IHTTPSession session) {        for (IHandler<IHTTPSession, Response> interceptor : interceptors) {            Response response = interceptor.handle(session);            if (response != null)                return response;        }        return httpHandler.handle(session);    }
@Deprecated    protected Response serve(IHTTPSession session) {        return Response.newFixedLengthResponse(Status.NOT_FOUND, NanoHTTPD.MIME_PLAINTEXT, "Not Found");    }
public void stop() {        try {            safeClose(this.myServerSocket);            this.asyncRunner.closeAll();            if (this.myThread != null) {                this.myThread.join();            }        } catch (Exception e) {            NanoHTTPD.LOG.log(Level.SEVERE, "Could not stop all connections", e);        }    }
public void addMappings() {        router.setNotImplemented(NotImplementedHandler.class);        router.setNotFoundHandler(Error404UriHandler.class);        router.addRoute("/", Integer.MAX_VALUE / 2, IndexHandler.class);        router.addRoute("/index.html", Integer.MAX_VALUE / 2, IndexHandler.class);    }
public void send(OutputStream outputStream) {        SimpleDateFormat gmtFrmt = new SimpleDateFormat("E, d MMM yyyy HH:mm:ss 'GMT'", Locale.US);        gmtFrmt.setTimeZone(TimeZone.getTimeZone("GMT"));        try {            if (this.status == null) {                throw new Error("sendResponse(): Status can't be null.");            }            PrintWriter pw = new PrintWriter(new BufferedWriter(new OutputStreamWriter(outputStream, new ContentType(this.mimeType).getEncoding())), false);            pw.append("HTTP/1.1 ").append(this.status.getDescription()).append(" \r\n");            if (this.mimeType != null) {                printHeader(pw, "Content-Type", this.mimeType);            }            if (getHeader("date") == null) {                printHeader(pw, "Date", gmtFrmt.format(new Date()));            }            for (Entry<String, String> entry : this.header.entrySet()) {                printHeader(pw, entry.getKey(), entry.getValue());            }            for (String cookieHeader : this.cookieHeaders) {                printHeader(pw, "Set-Cookie", cookieHeader);            }            if (getHeader("connection") == null) {                printHeader(pw, "Connection", (this.keepAlive ? "keep-alive" : "close"));            }            if (getHeader("content-length") != null) {                setUseGzip(false);            }            if (useGzipWhenAccepted()) {                printHeader(pw, "Content-Encoding", "gzip");                setChunkedTransfer(true);            }            long pending = this.data != null ? this.contentLength : 0;            if (this.requestMethod != Method.HEAD && this.chunkedTransfer) {                printHeader(pw, "Transfer-Encoding", "chunked");            } else if (!useGzipWhenAccepted()) {                pending = sendContentLengthHeaderIfNotAlreadyPresent(pw, pending);            }            pw.append("\r\n");            pw.flush();            sendBodyWithCorrectTransferAndEncoding(outputStream, pending);            outputStream.flush();            NanoHTTPD.safeClose(this.data);        } catch (IOException ioe) {            NanoHTTPD.LOG.log(Level.SEVERE, "Could not send response to the client", ioe);        }    }
private void sendBody(OutputStream outputStream, long pending) throws IOException {        long BUFFER_SIZE = 16 * 1024;        byte[] buff = new byte[(int) BUFFER_SIZE];        boolean sendEverything = pending == -1;        while (pending > 0 || sendEverything) {            long bytesToRead = sendEverything ? BUFFER_SIZE : Math.min(pending, BUFFER_SIZE);            int read = this.data.read(buff, 0, (int) bytesToRead);            if (read <= 0) {                break;            }            try {                outputStream.write(buff, 0, read);            } catch (Exception e) {                if(this.data != null) {                    this.data.close();                }            }            if (!sendEverything) {                pending -= read;            }        }    }
public static Response newChunkedResponse(IStatus status, String mimeType, InputStream data) {        return new Response(status, mimeType, data, -1);    }
public static Response newFixedLengthResponse(IStatus status, String mimeType, InputStream data, long totalBytes) {        return new Response(status, mimeType, data, totalBytes);    }
public static Response newFixedLengthResponse(IStatus status, String mimeType, String txt) {        ContentType contentType = new ContentType(mimeType);        if (txt == null) {            return newFixedLengthResponse(status, mimeType, new ByteArrayInputStream(new byte[0]), 0);        } else {            byte[] bytes;            try {                CharsetEncoder newEncoder = Charset.forName(contentType.getEncoding()).newEncoder();                if (!newEncoder.canEncode(txt)) {                    contentType = contentType.tryUTF8();                }                bytes = txt.getBytes(contentType.getEncoding());            } catch (UnsupportedEncodingException e) {                NanoHTTPD.LOG.log(Level.SEVERE, "encoding problem, responding nothing", e);                bytes = new byte[0];            }            return newFixedLengthResponse(status, contentType.getContentTypeHeader(), new ByteArrayInputStream(bytes), bytes.length);        }    }
public static Response newFixedLengthResponse(String msg) {        return newFixedLengthResponse(Status.OK, NanoHTTPD.MIME_HTML, msg);    }
public boolean useGzipWhenAccepted() {        if (gzipUsage == GzipUsage.DEFAULT)            return getMimeType() != null && (getMimeType().toLowerCase().contains("text/") || getMimeType().toLowerCase().contains("/json"));        else            return gzipUsage == GzipUsage.ALWAYS;    }
private void readWebsocket() {        try {            while (this.state == State.OPEN) {                handleWebsocketFrame(WebSocketFrame.read(this.in));            }        } catch (CharacterCodingException e) {            onException(e);            doClose(CloseCode.InvalidFramePayloadData, e.toString(), false);        } catch (IOException e) {            onException(e);            if (e instanceof WebSocketException) {                doClose(((WebSocketException) e).getCode(), ((WebSocketException) e).getReason(), false);            }        } finally {            doClose(CloseCode.InternalServerError, "Handler terminated without closing the connection.", false);        }    }
private static String encodeBase64(byte[] buf) {        int size = buf.length;        char[] ar = new char[(size + 2) / 3 * 4];        int a = 0;        int i = 0;        while (i < size) {            byte b0 = buf[i++];            byte b1 = i < size ? buf[i++] : 0;            byte b2 = i < size ? buf[i++] : 0;            int mask = 0x3F;            ar[a++] = NanoWSD.ALPHABET[b0 >> 2 & mask];            ar[a++] = NanoWSD.ALPHABET[(b0 << 4 | (b1 & 0xFF) >> 4) & mask];            ar[a++] = NanoWSD.ALPHABET[(b1 << 2 | (b2 & 0xFF) >> 6) & mask];            ar[a++] = NanoWSD.ALPHABET[b2 & mask];        }        switch (size % 3) {            case 1:                ar[--a] = '=';            case 2:                ar[--a] = '=';        }        return new String(ar);    }
public String getTextPayload() {        if (this._payloadString == null) {            try {                this._payloadString = binary2Text(getBinaryPayload());            } catch (CharacterCodingException e) {                throw new RuntimeException("Undetected CharacterCodingException", e);            }        }        return this._payloadString;    }
private void readPayloadInfo(InputStream in) throws IOException {        byte b = (byte) checkedRead(in.read());        boolean masked = (b & 0x80) != 0;        this._payloadLength = (byte) (0x7F & b);        if (this._payloadLength == 126) {            // checkedRead must return int for this to work            this._payloadLength = (checkedRead(in.read()) << 8 | checkedRead(in.read())) & 0xFFFF;            if (this._payloadLength < 126) {                throw new WebSocketException(CloseCode.ProtocolError, "Invalid data frame 2byte length. (not using minimal length encoding)");            }        } else if (this._payloadLength == 127) {            long _payloadLength =                    (long) checkedRead(in.read()) << 56 | (long) checkedRead(in.read()) << 48 | (long) checkedRead(in.read()) << 40 | (long) checkedRead(in.read()) << 32                            | checkedRead(in.read()) << 24 | checkedRead(in.read()) << 16 | checkedRead(in.read()) << 8 | checkedRead(in.read());            if (_payloadLength < 65536) {                throw new WebSocketException(CloseCode.ProtocolError, "Invalid data frame 4byte length. (not using minimal length encoding)");            }            if (_payloadLength < 0 || _payloadLength > Integer.MAX_VALUE) {                throw new WebSocketException(CloseCode.MessageTooBig, "Max frame length has been exceeded.");            }            this._payloadLength = (int) _payloadLength;        }        if (this.opCode.isControlFrame()) {            if (this._payloadLength > 125) {                throw new WebSocketException(CloseCode.ProtocolError, "Control frame with payload length > 125 bytes.");            }            if (this.opCode == OpCode.Close && this._payloadLength == 1) {                throw new WebSocketException(CloseCode.ProtocolError, "Received close frame with payload len 1.");            }        }        if (masked) {            this.maskingKey = new byte[4];            int read = 0;            while (read < this.maskingKey.length) {                read += checkedRead(in.read(this.maskingKey, read, this.maskingKey.length - read));            }        }    }
public void write(OutputStream out) throws IOException {        byte header = 0;        if (this.fin) {            header |= 0x80;        }        header |= this.opCode.getValue() & 0x0F;        out.write(header);        this._payloadLength = getBinaryPayload().length;        if (this._payloadLength <= 125) {            out.write(isMasked() ? 0x80 | (byte) this._payloadLength : (byte) this._payloadLength);        } else if (this._payloadLength <= 0xFFFF) {            out.write(isMasked() ? 0xFE : 126);            out.write(this._payloadLength >>> 8);            out.write(this._payloadLength);        } else {            out.write(isMasked() ? 0xFF : 127);            out.write(this._payloadLength >>> 56 & 0); // integer only                                                       // contains            // 31 bit            out.write(this._payloadLength >>> 48 & 0);            out.write(this._payloadLength >>> 40 & 0);            out.write(this._payloadLength >>> 32 & 0);            out.write(this._payloadLength >>> 24);            out.write(this._payloadLength >>> 16);            out.write(this._payloadLength >>> 8);            out.write(this._payloadLength);        }        if (isMasked()) {            out.write(this.maskingKey);            for (int i = 0; i < this._payloadLength; i++) {                out.write(getBinaryPayload()[i] ^ this.maskingKey[i % 4]);            }        } else {            out.write(getBinaryPayload());        }        out.flush();    }
public void set(String name, String value, int expires) {        this.queue.add(new Cookie(name, value, Cookie.getHTTPTime(expires)));    }
public void unloadQueue(Response response) {        for (Cookie cookie : this.queue) {            response.addCookieHeader(cookie.getHTTPHeader());        }    }
@RequestMapping(value = "/sessions/{sessionIdToDelete}", method = RequestMethod.DELETE)	public String removeSession(Principal principal,			@PathVariable String sessionIdToDelete) {		Set<String> usersSessionIds = this.sessions				.findByPrincipalName(principal.getName()).keySet();		if (usersSessionIds.contains(sessionIdToDelete)) {			this.sessions.deleteById(sessionIdToDelete);		}		return "redirect:/";	}
@Override	public List<String> readCookieValues(HttpServletRequest request) {		Cookie[] cookies = request.getCookies();		List<String> matchingCookieValues = new ArrayList<>();		if (cookies != null) {			for (Cookie cookie : cookies) {				if (this.cookieName.equals(cookie.getName())) {					String sessionId = (this.useBase64Encoding							? base64Decode(cookie.getValue())							: cookie.getValue());					if (sessionId == null) {						continue;					}					if (this.jvmRoute != null && sessionId.endsWith(this.jvmRoute)) {						sessionId = sessionId.substring(0,								sessionId.length() - this.jvmRoute.length());					}					matchingCookieValues.add(sessionId);				}			}		}		return matchingCookieValues;	}
@Override	public void writeCookieValue(CookieValue cookieValue) {		HttpServletRequest request = cookieValue.getRequest();		HttpServletResponse response = cookieValue.getResponse();		StringBuilder sb = new StringBuilder();		sb.append(this.cookieName).append('=');		String value = getValue(cookieValue);		if (value != null && value.length() > 0) {			validateValue(value);			sb.append(value);		}		int maxAge = getMaxAge(cookieValue);		if (maxAge > -1) {			sb.append("; Max-Age=").append(cookieValue.getCookieMaxAge());			OffsetDateTime expires = (maxAge != 0)					? OffsetDateTime.now().plusSeconds(maxAge)					: Instant.EPOCH.atOffset(ZoneOffset.UTC);			sb.append("; Expires=")					.append(expires.format(DateTimeFormatter.RFC_1123_DATE_TIME));		}		String domain = getDomainName(request);		if (domain != null && domain.length() > 0) {			validateDomain(domain);			sb.append("; Domain=").append(domain);		}		String path = getCookiePath(request);		if (path != null && path.length() > 0) {			validatePath(path);			sb.append("; Path=").append(path);		}		if (isSecureCookie(request)) {			sb.append("; Secure");		}		if (this.useHttpOnlyCookie) {			sb.append("; HttpOnly");		}		if (this.sameSite != null) {			sb.append("; SameSite=").append(this.sameSite);		}		response.addHeader("Set-Cookie", sb.toString());	}
private String base64Decode(String base64Value) {		try {			byte[] decodedCookieBytes = Base64.getDecoder().decode(base64Value);			return new String(decodedCookieBytes);		}		catch (Exception ex) {			logger.debug("Unable to Base64 decode value: " + base64Value);			return null;		}	}
private String base64Encode(String value) {		byte[] encodedCookieBytes = Base64.getEncoder().encode(value.getBytes());		return new String(encodedCookieBytes);	}
public void setDomainNamePattern(String domainNamePattern) {		if (this.domainName != null) {			throw new IllegalStateException(					"Cannot set both domainName and domainNamePattern");		}		this.domainNamePattern = Pattern.compile(domainNamePattern,				Pattern.CASE_INSENSITIVE);	}
public void setTableName(String tableName) {		Assert.hasText(tableName, "Table name must not be empty");		this.tableName = tableName.trim();		prepareQueries();	}
@Override	public void onApplicationEvent(AbstractSessionEvent event) {		if (this.listeners.isEmpty()) {			return;		}		HttpSessionEvent httpSessionEvent = createHttpSessionEvent(event);		for (HttpSessionListener listener : this.listeners) {			if (event instanceof SessionDestroyedEvent) {				listener.sessionDestroyed(httpSessionEvent);			}			else if (event instanceof SessionCreatedEvent) {				listener.sessionCreated(httpSessionEvent);			}		}	}
@Bean	public CookieSerializer cookieSerializer() {		DefaultCookieSerializer serializer = new DefaultCookieSerializer();		serializer.setCookieName("JSESSIONID"); // <1>		serializer.setCookiePath("/"); // <2>		serializer.setDomainNamePattern("^.+?\\.(\\w+\\.[a-z]+)$"); // <3>		return serializer;	}
private ObjectMapper objectMapper() {		ObjectMapper mapper = new ObjectMapper();		mapper.registerModules(SecurityJackson2Modules.getModules(this.loader));		return mapper;	}
@Override	public void doFilterInternal(HttpServletRequest request, HttpServletResponse response,			FilterChain chain) throws IOException, ServletException {		chain.doFilter(request, response);		HttpSession session = request.getSession(false);		if (session != null) {			String remoteAddr = getRemoteAddress(request);			String geoLocation = getGeoLocation(remoteAddr);			SessionDetails details = new SessionDetails();			details.setAccessType(request.getHeader("User-Agent"));			details.setLocation(remoteAddr + " " + geoLocation);			session.setAttribute("SESSION_DETAILS", details);		}	}
String getGeoLocation(String remoteAddr) {		try {			CityResponse city = this.reader.city(InetAddress.getByName(remoteAddr));			String cityName = city.getCity().getName();			String countryName = city.getCountry().getName();			if (cityName == null && countryName == null) {				return null;			}			else if (cityName == null) {				return countryName;			}			else if (countryName == null) {				return cityName;			}			return cityName + ", " + countryName;		}		catch (Exception ex) {			return UNKNOWN;		}	}
@Override	public void configure(RedisConnection connection) {		String notifyOptions = getNotifyOptions(connection);		String customizedNotifyOptions = notifyOptions;		if (!customizedNotifyOptions.contains("E")) {			customizedNotifyOptions += "E";		}		boolean A = customizedNotifyOptions.contains("A");		if (!(A || customizedNotifyOptions.contains("g"))) {			customizedNotifyOptions += "g";		}		if (!(A || customizedNotifyOptions.contains("x"))) {			customizedNotifyOptions += "x";		}		if (!notifyOptions.equals(customizedNotifyOptions)) {			connection.setConfig(CONFIG_NOTIFY_KEYSPACE_EVENTS, customizedNotifyOptions);		}	}
@Bean(WebHttpHandlerBuilder.WEB_SESSION_MANAGER_BEAN_NAME)	public WebSessionManager webSessionManager(ReactiveSessionRepository<? extends Session> repository) {		SpringSessionWebSessionStore<? extends Session> sessionStore = new SpringSessionWebSessionStore<>(repository);		DefaultWebSessionManager manager = new DefaultWebSessionManager();		manager.setSessionStore(sessionStore);		if (this.webSessionIdResolver != null) {			manager.setSessionIdResolver(this.webSessionIdResolver);		}		return manager;	}
@Override	public UserDetails loadUserByUsername(String username)			throws UsernameNotFoundException {		User user = this.userRepository.findByEmail(username);		if (user == null) {			throw new UsernameNotFoundException("Could not find user " + username);		}		return new CustomUserDetails(user);	}
protected boolean rememberMeRequested(HttpServletRequest request, String parameter) {		String rememberMe = request.getParameter(parameter);		if (rememberMe != null) {			if (rememberMe.equalsIgnoreCase("true") || rememberMe.equalsIgnoreCase("on")					|| rememberMe.equalsIgnoreCase("yes") || rememberMe.equals("1")) {				return true;			}		}		if (logger.isDebugEnabled()) {			logger.debug("Did not send remember-me cookie (principal did not set "					+ "parameter '" + parameter + "')");		}		return false;	}
protected String name(Object principal) {		if (principal instanceof UserDetails) {			return ((UserDetails) principal).getUsername();		}		if (principal instanceof Principal) {			return ((Principal) principal).getName();		}		return principal.toString();	}
private void insertSessionRepositoryFilter(ServletContext servletContext) {		String filterName = DEFAULT_FILTER_NAME;		DelegatingFilterProxy springSessionRepositoryFilter = new DelegatingFilterProxy(				filterName);		String contextAttribute = getWebApplicationContextAttribute();		if (contextAttribute != null) {			springSessionRepositoryFilter.setContextAttribute(contextAttribute);		}		registerFilter(servletContext, true, filterName, springSessionRepositoryFilter);	}
protected EnumSet<DispatcherType> getSessionDispatcherTypes() {		return EnumSet.of(DispatcherType.REQUEST, DispatcherType.ERROR,				DispatcherType.ASYNC);	}
private static String resolvePrincipal(Session session) {		String principalName = session				.getAttribute(FindByIndexNameSessionRepository.PRINCIPAL_NAME_INDEX_NAME);		if (principalName != null) {			return principalName;		}		SecurityContext securityContext = session				.getAttribute(SPRING_SECURITY_CONTEXT);		if (securityContext != null				&& securityContext.getAuthentication() != null) {			return securityContext.getAuthentication().getName();		}		return "";	}
@Override	public final void doFilter(ServletRequest request, ServletResponse response,			FilterChain filterChain) throws ServletException, IOException {		if (!(request instanceof HttpServletRequest)				|| !(response instanceof HttpServletResponse)) {			throw new ServletException(					"OncePerRequestFilter just supports HTTP requests");		}		HttpServletRequest httpRequest = (HttpServletRequest) request;		HttpServletResponse httpResponse = (HttpServletResponse) response;		boolean hasAlreadyFilteredAttribute = request				.getAttribute(this.alreadyFilteredAttributeName) != null;		if (hasAlreadyFilteredAttribute) {			// Proceed without invoking this filter...			filterChain.doFilter(request, response);		}		else {			// Do invoke this filter...			request.setAttribute(this.alreadyFilteredAttributeName, Boolean.TRUE);			try {				doFilterInternal(httpRequest, httpResponse, filterChain);			}			finally {				// Remove the "already filtered" request attribute for this request.				request.removeAttribute(this.alreadyFilteredAttributeName);			}		}	}
private RedisSession getSession(String id, boolean allowExpired) {		Map<Object, Object> entries = getSessionBoundHashOperations(id).entries();		if (entries.isEmpty()) {			return null;		}		MapSession loaded = loadSession(id, entries);		if (!allowExpired && loaded.isExpired()) {			return null;		}		RedisSession result = new RedisSession(loaded);		result.originalLastAccessTime = loaded.getLastAccessedTime();		return result;	}
private BoundHashOperations<Object, Object, Object> getSessionBoundHashOperations(			String sessionId) {		String key = getSessionKey(sessionId);		return this.sessionRedisOperations.boundHashOps(key);	}
@Override    protected void performRuntime(OperationContext context, ModelNode operation, ModelNode model) throws OperationFailedException {        final PathAddress address = context.getCurrentAddress();        ModelNode fullTree = Resource.Tools.readModel(context.readResource(PathAddress.EMPTY_ADDRESS));        installRuntimeServices(context, address, fullTree);    }
static String getJndiName(final ModelNode modelNode, OperationContext context) throws OperationFailedException {        final String rawJndiName = MailSessionDefinition.JNDI_NAME.resolveModelAttribute(context, modelNode).asString();        return getJndiName(rawJndiName);    }
public static String[] getCanonicalParameterTypes(Method viewMethod) {        Class<?>[] parameterTypes = viewMethod.getParameterTypes();        if (parameterTypes == null) {            return NO_STRINGS;        }        String[] canonicalNames = new String[parameterTypes.length];        for (int i = 0; i < parameterTypes.length; i++) {            canonicalNames[i] = parameterTypes[i].getCanonicalName();        }        return canonicalNames;    }
public void registerInterposedSynchronization(Synchronization synchronization) throws IllegalStateException, SystemException {        int status = ContextTransactionSynchronizationRegistry.getInstance().getTransactionStatus();        switch (status) {            case javax.transaction.Status.STATUS_ACTIVE:            case javax.transaction.Status.STATUS_PREPARING:                break;            case Status.STATUS_MARKED_ROLLBACK:                // do nothing; we can pretend like it was registered, but it'll never be run anyway.                return;            default:                throw TransactionLogger.ROOT_LOGGER.syncsnotallowed(status);        }        if (synchronization.getClass().getName().startsWith("org.jboss.jca")) {            if (TransactionLogger.ROOT_LOGGER.isTraceEnabled()) {                TransactionLogger.ROOT_LOGGER.trace("JCAOrderedLastSynchronizationList.jcaSyncs.add - Class: " + synchronization.getClass() + " HashCode: "                    + synchronization.hashCode() + " toString: " + synchronization);            }            jcaSyncs.add(synchronization);        } else {            if (TransactionLogger.ROOT_LOGGER.isTraceEnabled()) {                TransactionLogger.ROOT_LOGGER.trace("JCAOrderedLastSynchronizationList.preJcaSyncs.add - Class: " + synchronization.getClass() + " HashCode: "                    + synchronization.hashCode() + " toString: " + synchronization);            }            preJcaSyncs.add(synchronization);        }    }
@Override    public void beforeCompletion() {        // This is needed to guard against syncs being registered during the run, otherwise we could have used an iterator        int lastIndexProcessed = 0;        while ((lastIndexProcessed < preJcaSyncs.size())) {            Synchronization preJcaSync = preJcaSyncs.get(lastIndexProcessed);            if (TransactionLogger.ROOT_LOGGER.isTraceEnabled()) {                TransactionLogger.ROOT_LOGGER.trace("JCAOrderedLastSynchronizationList.preJcaSyncs.before_completion - Class: " + preJcaSync.getClass() + " HashCode: "                    + preJcaSync.hashCode()                    + " toString: "                    + preJcaSync);            }            preJcaSync.beforeCompletion();            lastIndexProcessed = lastIndexProcessed + 1;        }        // Do the same for the jca syncs        lastIndexProcessed = 0;        while ((lastIndexProcessed < jcaSyncs.size())) {            Synchronization jcaSync = jcaSyncs.get(lastIndexProcessed);            if (TransactionLogger.ROOT_LOGGER.isTraceEnabled()) {                TransactionLogger.ROOT_LOGGER.trace("JCAOrderedLastSynchronizationList.jcaSyncs.before_completion - Class: " + jcaSync.getClass() + " HashCode: "                    + jcaSync.hashCode()                    + " toString: "                    + jcaSync);            }            jcaSync.beforeCompletion();            lastIndexProcessed = lastIndexProcessed + 1;        }    }
static void init(int slotId, Codec codec, org.omg.PortableInterceptor.Current piCurrent) {        TxServerInterceptor.slotId = slotId;        TxServerInterceptor.codec = codec;        TxServerInterceptor.piCurrent = piCurrent;    }
public static Transaction getCurrentTransaction() {        Transaction tx = null;        if (piCurrent != null) {            // A non-null piCurrent means that a TxServerInterceptor was            // installed: check if there is a transaction propagation context            try {                Any any = piCurrent.get_slot(slotId);                if (any.type().kind().value() != TCKind._tk_null) {                    // Yes, there is a TPC: add the foreign transaction marker                    tx = ForeignTransaction.INSTANCE;                }            } catch (InvalidSlot e) {                throw IIOPLogger.ROOT_LOGGER.errorGettingSlotInTxInterceptor(e);            }        }        return tx;    }
private String rawAttributeText(XMLStreamReader reader, String attributeName, String defaultValue) {        return reader.getAttributeValue("", attributeName) == null                ? defaultValue :                reader.getAttributeValue("", attributeName).trim();    }
@Override    public synchronized void start(StartContext context) throws StartException {        SecurityLogger.ROOT_LOGGER.debugf("Starting SubjectFactoryService");        final ISecurityManagement injectedSecurityManagement = securityManagementValue.getValue();        int i = subjectFactoryClassName.lastIndexOf(":");        if (i == -1)            throw SecurityLogger.ROOT_LOGGER.missingModuleName("subject-factory-class-name attribute");        String moduleSpec = subjectFactoryClassName.substring(0, i);        String className = subjectFactoryClassName.substring(i + 1);        JBossSecuritySubjectFactory subjectFactory = null;        try {            Class<?> subjectFactoryClazz = SecurityActions.getModuleClassLoader(moduleSpec).loadClass(className);            subjectFactory = (JBossSecuritySubjectFactory) subjectFactoryClazz.newInstance();        } catch (Exception e) {            throw SecurityLogger.ROOT_LOGGER.unableToStartException("SubjectFactoryService", e);        }        subjectFactory.setSecurityManagement(injectedSecurityManagement);        this.subjectFactory = subjectFactory;    }
@Override    public void deploy(DeploymentPhaseContext phaseContext) throws DeploymentUnitProcessingException {        final DeploymentUnit unit = phaseContext.getDeploymentUnit();        final List<KernelDeploymentXmlDescriptor> kdXmlDescriptors = unit.getAttachment(KernelDeploymentXmlDescriptor.ATTACHMENT_KEY);        if (kdXmlDescriptors == null || kdXmlDescriptors.isEmpty())            return;        for (KernelDeploymentXmlDescriptor kdxd : kdXmlDescriptors) {            if (kdxd.getBeanFactoriesCount() > 0) {                final ModuleSpecification moduleSpecification = unit.getAttachment(Attachments.MODULE_SPECIFICATION);                final ModuleLoader moduleLoader = Module.getBootModuleLoader();                ModuleDependency dependency = new ModuleDependency(moduleLoader, POJO_MODULE, false, false, false, false);                PathFilter filter = PathFilters.isChildOf(BaseBeanFactory.class.getPackage().getName());                dependency.addImportFilter(filter, true);                dependency.addImportFilter(PathFilters.rejectAll(), false);                moduleSpecification.addSystemDependency(dependency);                return;            }        }    }
protected ArrayList getContainedEntries() {        final ArrayList ret = new ArrayList(constants.length +                attributes.length +                members.length);        for (int i = 0; i < constants.length; ++i)            ret.add(constants[i]);        for (int i = 0; i < attributes.length; ++i)            ret.add(attributes[i]);        for (int i = 0; i < members.length; ++i)            ret.add(members[i]);        return ret;    }
@Override    public boolean doesScopedPersistenceUnitNameIdentifyCacheRegionName(PersistenceUnitMetadata pu) {        String cacheRegionPrefix = pu.getProperties().getProperty(AvailableSettings.CACHE_REGION_PREFIX);        return cacheRegionPrefix == null || cacheRegionPrefix.equals(pu.getScopedPersistenceUnitName());    }
private static List<ServiceName> getServerConfigDependencies(OperationContext context, boolean appclient) {        final List<ServiceName> serviceNames = new ArrayList<ServiceName>();        final Resource subsystemResource = context.readResourceFromRoot(PathAddress.pathAddress(WSExtension.SUBSYSTEM_PATH), false);        readConfigServiceNames(serviceNames, subsystemResource, Constants.CLIENT_CONFIG);        readConfigServiceNames(serviceNames, subsystemResource, Constants.ENDPOINT_CONFIG);        if (!appclient) {            serviceNames.add(CommonWebServer.SERVICE_NAME);        }        return serviceNames;    }
protected void validateCredential(final String username, final SASCurrent credential) throws LoginException {        if (credential.get_incoming_principal_name() == null ||                credential.get_incoming_principal_name().length == 0) {            throw new LoginException();        }    }
public static Collection<MdbValidityStatus> assertEjbClassValidity(final ClassInfo mdbClass)            throws DeploymentUnitProcessingException {        Collection<MdbValidityStatus> mdbComplianceIssueList = new ArrayList<>(MdbValidityStatus.values().length);        final String className = mdbClass.name().toString();        verifyModifiers(className, mdbClass.flags(), mdbComplianceIssueList);        for (MethodInfo method : mdbClass.methods()) {            if ("onMessage".equals(method.name())) {                verifyOnMessageMethod(className, method.flags(), mdbComplianceIssueList);            }            if ("finalize".equals(method.name())) {                EjbLogger.DEPLOYMENT_LOGGER.mdbCantHaveFinalizeMethod(className);                mdbComplianceIssueList.add(MdbValidityStatus.MDB_SHOULD_NOT_HAVE_FINALIZE_METHOD);            }        }        return mdbComplianceIssueList;    }
public static void init(org.omg.CORBA.ORB orb, org.omg.PortableServer.POA rootPoa) {        CorbaNamingContext.orb = orb;        CorbaNamingContext.rootPoa = rootPoa;    }
public void init(POA poa, boolean doPurge, boolean noPing) {        this.poa = poa;        this.doPurge = doPurge;        this.noPing = noPing;    }
public void bind(NameComponent[] nc, org.omg.CORBA.Object obj) throws NotFound, CannotProceed, InvalidName,            AlreadyBound {        if (this.destroyed)            throw new CannotProceed();        if (nc == null || nc.length == 0)            throw new InvalidName();        if (obj == null)            throw new org.omg.CORBA.BAD_PARAM();        Name n = new Name(nc);        Name ctx = n.ctxName();        NameComponent nb = n.baseNameComponent();        if (ctx == null) {            if (this.names.containsKey(n)) {                // if the name is still in use, try to ping the object                org.omg.CORBA.Object ref = (org.omg.CORBA.Object) this.names.get(n);                if (isDead(ref)) {                    rebind(n.components(), obj);                    return;                }                throw new AlreadyBound();            } else if (this.contexts.containsKey(n)) {                // if the name is still in use, try to ping the object                org.omg.CORBA.Object ref = (org.omg.CORBA.Object) this.contexts.get(n);                if (isDead(ref))                    unbind(n.components());                throw new AlreadyBound();            }            if ((this.names.put(n, obj)) != null)                throw new CannotProceed(_this(), n.components());            IIOPLogger.ROOT_LOGGER.debugf("Bound name: %s", n);        } else {            NameComponent[] ncx = new NameComponent[]{nb};            org.omg.CORBA.Object context = this.resolve(ctx.components());            // try first to call the context implementation object directly.            String contextOID = this.getObjectOID(context);            CorbaNamingContext jbossContext = (contextOID == null ? null : contextImpls.get(contextOID));            if (jbossContext != null)                jbossContext.bind(ncx, obj);            else                NamingContextExtHelper.narrow(context).bind(ncx, obj);        }    }
public org.omg.CORBA.Object resolve_str(String n) throws NotFound, CannotProceed, InvalidName {        return resolve(to_name(n));    }
private void cleanup() {        // Check if object purging enabled        if (!this.doPurge)            return;        for (Name key : this.names.keySet()) {            if (isDead(((org.omg.CORBA.Object) this.names.get(key)))) {                this.names.remove(key);            }        }        for (Name key : this.contexts.keySet()) {            org.omg.CORBA.Object object = (org.omg.CORBA.Object) this.contexts.get(key);            if (isDead(object)) {                this.contexts.remove(key);                String oid = this.getObjectOID(object);                if (oid != null)                    contextImpls.remove(oid);            }        }    }
private String getObjectOID(org.omg.CORBA.Object object) {        String oid = null;        try {            byte[] oidBytes = this.poa.reference_to_id(object);            if (oidBytes != null)                oid = new String(oidBytes, StandardCharsets.UTF_8);        } catch (Exception e) {            IIOPLogger.ROOT_LOGGER.debug("Unable to obtain id from object", e);        }        return oid;    }
private boolean isDead(org.omg.CORBA.Object o) {        boolean non_exist;        try {            non_exist = o._non_existent();        } catch (org.omg.CORBA.SystemException e) {            non_exist = true;        }        return non_exist;    }
private void readObject(ObjectInputStream in) throws Exception {        in.defaultReadObject();        /**         * Recreate tables. For serialization, object references have been transformed into strings         */        for (Name key : this.contexts.keySet()) {            String ref = (String) this.contexts.remove(key);            this.contexts.put(key, orb.string_to_object(ref));        }        for (Name key : this.names.keySet()) {            String ref = (String) this.names.remove(key);            this.names.put(key, orb.string_to_object(ref));        }    }
private void writeObject(java.io.ObjectOutputStream out) throws IOException {        /*        * For serialization, object references are transformed into strings        */        for (Name key : this.contexts.keySet()) {            org.omg.CORBA.Object o = (org.omg.CORBA.Object) this.contexts.remove(key);            this.contexts.put(key, orb.object_to_string(o));        }        for (Name key : this.names.keySet()) {            org.omg.CORBA.Object o = (org.omg.CORBA.Object) this.names.remove(key);            this.names.put(key, orb.object_to_string(o));        }        out.defaultWriteObject();    }
private void checkLoopback() {        Integer current = readLockCount.get();        if (current != null) {            assert current.intValue() > 0 : "readLockCount is set, but to 0";            throw EjbLogger.ROOT_LOGGER.failToUpgradeToWriteLock();        }    }
private void decReadLockCount() {        Integer current = readLockCount.get();        int next;        assert current != null : "can't decrease, readLockCount is not set";        next = current.intValue() - 1;        if (next == 0)            readLockCount.remove();        else            readLockCount.set(new Integer(next));    }
private void incReadLockCount() {        Integer current = readLockCount.get();        int next;        if (current == null)            next = 1;        else            next = current.intValue() + 1;        readLockCount.set(new Integer(next));    }
public synchronized void addBeanDeploymentModule(BeanDeploymentModule module) {        for (BeanDeploymentArchiveImpl bda : beanDeploymentArchives) {            bda.addBeanDeploymentArchives(module.beanDeploymentArchives);        }    }
public synchronized void addBeanDeploymentModules(Collection<BeanDeploymentModule> modules) {        for (BeanDeploymentArchiveImpl bda : beanDeploymentArchives) {            for (BeanDeploymentModule bdm : modules) {                bda.addBeanDeploymentArchives(bdm.beanDeploymentArchives);            }        }    }
public synchronized <S extends Service> void addService(Class<S> clazz, S service) {        for (BeanDeploymentArchiveImpl bda : beanDeploymentArchives) {            bda.getServices().add(clazz,service);        }    }
protected String setContextID(final String contextID) {        if (! WildFlySecurityManager.isChecking()) {            final String previousID = PolicyContext.getContextID();            PolicyContext.setContextID(contextID);            return previousID;        } else {            final PrivilegedAction<String> action = new SetContextIDAction(contextID);            return AccessController.doPrivileged(action);        }    }
@Override    public void accept(ModClusterConfiguration modClusterConfiguration) {        if (advertiseSocketDependency != null) {            SocketBinding binding = advertiseSocketDependency.get();            ManagedBinding simpleManagedBinding = ManagedBinding.Factory.createSimpleManagedBinding(binding);            binding.getSocketBindings().getNamedRegistry().unregisterBinding(simpleManagedBinding);        }    }
@Override    public void registerOperations(ManagementResourceRegistration container) {        super.registerOperations(container);        container.registerOperationHandler(ADD_PARAM, WebValveParamAdd.INSTANCE);        container.registerOperationHandler(REMOVE_PARAM, ReloadRequiredRemoveStepHandler.INSTANCE);    }
public void handleRestorationCalculation() {        if(nextExpiration == null) {            return;        }        //next expiration in the future, we don't care        if(nextExpiration.getTime() >= System.currentTimeMillis()) {            return;        }        //just set the next expiration to 1ms in the past        //this means it will run to catch up the missed expiration        //and then the next calculated expiration will be in the future        nextExpiration = new Date(System.currentTimeMillis() - 1);    }
public static Method getTimeoutMethod(TimeoutMethod timeoutMethodInfo, ClassLoader classLoader) {        if(timeoutMethodInfo == null) {            return null;        }        String declaringClass = timeoutMethodInfo.getDeclaringClass();        Class<?> timeoutMethodDeclaringClass = null;        try {            timeoutMethodDeclaringClass = Class.forName(declaringClass, false, classLoader);        } catch (ClassNotFoundException cnfe) {            throw EjbLogger.EJB3_TIMER_LOGGER.failToLoadDeclaringClassOfTimeOut(declaringClass);        }        String timeoutMethodName = timeoutMethodInfo.getMethodName();        String[] timeoutMethodParams = timeoutMethodInfo.getMethodParams();        // load the method param classes        Class<?>[] timeoutMethodParamTypes = new Class<?>[]                {};        if (timeoutMethodParams != null) {            timeoutMethodParamTypes = new Class<?>[timeoutMethodParams.length];            int i = 0;            for (String paramClassName : timeoutMethodParams) {                Class<?> methodParamClass = null;                try {                    methodParamClass = Class.forName(paramClassName, false, classLoader);                } catch (ClassNotFoundException cnfe) {                    throw EjbLogger.EJB3_TIMER_LOGGER.failedToLoadTimeoutMethodParamClass(cnfe, paramClassName);                }                timeoutMethodParamTypes[i++] = methodParamClass;            }        }        // now start looking for the method        Class<?> klass = timeoutMethodDeclaringClass;        while (klass != null) {            Method[] methods = klass.getDeclaredMethods();            for (Method method : methods) {                if (method.getName().equals(timeoutMethodName)) {                    Class<?>[] methodParamTypes = method.getParameterTypes();                    // param length doesn't match                    if (timeoutMethodParamTypes.length != methodParamTypes.length) {                        continue;                    }                    boolean match = true;                    for (int i = 0; i < methodParamTypes.length; i++) {                        // param type doesn't match                        if (!timeoutMethodParamTypes[i].equals(methodParamTypes[i])) {                            match = false;                            break;                        }                    }                    if (match) {                        // match found                        return method;                    }                }            }            klass = klass.getSuperclass();        }        // no match found        return null;    }
public void handle(javax.security.auth.callback.Callback[] callbacks) throws UnsupportedCallbackException, IOException {        if (SUBSYSTEM_RA_LOGGER.isTraceEnabled())            SUBSYSTEM_RA_LOGGER.elytronHandlerHandle(Arrays.toString(callbacks));        // work wrapper calls the callback handler a second time with default callback values after the handler was invoked        // by the RA. We must check if the execution subject already contains an identity and allow for replacement of the        // identity with values found in the default callbacks only if the subject has no identity yet or if the identity        // is the anonymous one.        if (this.executionSubject != null) {            final SecurityIdentity subjectIdentity = this.getPrivateCredential(this.executionSubject, SecurityIdentity.class);            if (subjectIdentity != null && !subjectIdentity.isAnonymous()) {                return;            }        }        if (callbacks != null && callbacks.length > 0)        {            if (this.mappings != null && this.mappings.isMappingRequired())            {                callbacks = this.mappings.mapCallbacks(callbacks);            }            GroupPrincipalCallback groupPrincipalCallback = null;            CallerPrincipalCallback callerPrincipalCallback = null;            PasswordValidationCallback passwordValidationCallback = null;            for (javax.security.auth.callback.Callback callback : callbacks) {                if (callback instanceof GroupPrincipalCallback) {                    groupPrincipalCallback = (GroupPrincipalCallback) callback;                    if (this.executionSubject == null) {                        this.executionSubject = groupPrincipalCallback.getSubject();                    } else if (!this.executionSubject.equals(groupPrincipalCallback.getSubject())) {                        // TODO merge the contents of the subjects?                    }                } else if (callback instanceof CallerPrincipalCallback) {                    callerPrincipalCallback = (CallerPrincipalCallback) callback;                    if (this.executionSubject == null) {                        this.executionSubject = callerPrincipalCallback.getSubject();                    } else if (!this.executionSubject.equals(callerPrincipalCallback.getSubject())) {                        // TODO merge the contents of the subjects?                    }                } else if (callback instanceof PasswordValidationCallback) {                    passwordValidationCallback = (PasswordValidationCallback) callback;                    if (this.executionSubject == null) {                        this.executionSubject = passwordValidationCallback.getSubject();                    } else if (!this.executionSubject.equals(passwordValidationCallback.getSubject())) {                        // TODO merge the contents of the subjects?                    }                } else {                    throw new UnsupportedCallbackException(callback);                }            }            this.handleInternal(callerPrincipalCallback, groupPrincipalCallback, passwordValidationCallback);        }    }
private SecurityIdentity authenticate(final String username, final char[] credential) throws IOException {        final ServerAuthenticationContext context = this.securityDomain.createNewAuthenticationContext();        final PasswordGuessEvidence evidence = new PasswordGuessEvidence(credential != null ? credential : null);        try {            context.setAuthenticationName(username);            if (context.verifyEvidence(evidence)) {                if (context.authorize()) {                    context.succeed();                    return context.getAuthorizedIdentity();                } else {                    context.fail();                    throw new SecurityException("Authorization failed");                }            } else {                context.fail();                throw new SecurityException("Authentication failed");            }        } catch (IllegalArgumentException | IllegalStateException | RealmUnavailableException e) {            context.fail();            throw e;        } finally {            if (!context.isDone()) {                context.fail();            }            evidence.destroy();        }    }
public static PersistenceProviderAdaptor loadPersistenceAdapterModule(final String adapterModule, final Platform platform, JtaManagerImpl manager) throws        ModuleLoadException {        final ModuleLoader moduleLoader = Module.getBootModuleLoader();        if (adapterModule == null) {            return noopAdaptor;        }        PersistenceProviderAdaptor persistenceProviderAdaptor=null;        Module module = moduleLoader.loadModule(ModuleIdentifier.fromString(adapterModule));        final ServiceLoader<PersistenceProviderAdaptor> serviceLoader =            module.loadService(PersistenceProviderAdaptor.class);        if (serviceLoader != null) {            for (PersistenceProviderAdaptor adaptor : serviceLoader) {                if (persistenceProviderAdaptor != null) {                    throw JpaLogger.ROOT_LOGGER.multipleAdapters(adapterModule);                }                persistenceProviderAdaptor = adaptor;                ROOT_LOGGER.debugf("loaded persistence provider adapter %s", adapterModule);            }            if (persistenceProviderAdaptor != null) {                persistenceProviderAdaptor.injectJtaManager(manager);                persistenceProviderAdaptor.injectPlatform(platform);            }        }        return persistenceProviderAdaptor;    }
public static PersistenceProviderAdaptor loadPersistenceAdapter(final PersistenceProvider persistenceProvider, final Platform platform, final JtaManagerImpl jtaManager) {        PersistenceProviderAdaptor persistenceProviderAdaptor=null;        final ServiceLoader<PersistenceProviderAdaptor> serviceLoader =                ServiceLoader.load(PersistenceProviderAdaptor.class, persistenceProvider.getClass().getClassLoader());        if (serviceLoader != null) {            for (PersistenceProviderAdaptor adaptor : serviceLoader) {                if (persistenceProviderAdaptor != null) {                    throw JpaLogger.ROOT_LOGGER.classloaderHasMultipleAdapters(persistenceProvider.getClass().getClassLoader().toString());                }                persistenceProviderAdaptor = adaptor;                ROOT_LOGGER.debugf("loaded persistence provider adapter %s from classloader %s",                        persistenceProviderAdaptor.getClass().getName(),                        persistenceProvider.getClass().getClassLoader().toString());            }            if (persistenceProviderAdaptor != null) {                persistenceProviderAdaptor.injectJtaManager(jtaManager);                persistenceProviderAdaptor.injectPlatform(platform);            }        }        return persistenceProviderAdaptor == null ?                noopAdaptor:                persistenceProviderAdaptor;    }
public void deploy(DeploymentPhaseContext phaseContext) throws DeploymentUnitProcessingException {        final DeploymentUnit deploymentUnit = phaseContext.getDeploymentUnit();        final ModuleSpecification moduleSpecification = deploymentUnit.getAttachment(Attachments.MODULE_SPECIFICATION);        final ModuleLoader moduleLoader = Module.getBootModuleLoader();        if (JPADeploymentMarker.isJPADeployment(deploymentUnit)) {            addSearchDependency(moduleSpecification, moduleLoader, deploymentUnit);        }    }
public Timer getTimer() throws IllegalStateException, EJBException {        if (service == null) {            // get hold of the timer service through the use of timed object id            service = (TimerServiceImpl) currentServiceContainer().getRequiredService(ServiceName.parse(serviceName)).getValue();            if (service == null) {                throw EjbLogger.EJB3_TIMER_LOGGER.timerServiceWithIdNotRegistered(timedObjectId);            }        }        final TimerImpl timer = this.service.getTimer(this);        if (timer == null || !timer.isActive()) {            throw EjbLogger.EJB3_TIMER_LOGGER.timerHandleIsNotActive(this);        }        return timer;    }
private void calculateAccessibilityGraph(Iterable<BeanDeploymentArchiveImpl> beanDeploymentArchives) {        for (BeanDeploymentArchiveImpl from : beanDeploymentArchives) {            for (BeanDeploymentArchiveImpl target : beanDeploymentArchives) {                if (from.isAccessible(target)) {                    from.addBeanDeploymentArchive(target);                }            }        }    }
private void makeTopLevelBdasVisibleFromStaticModules() {        for (BeanDeploymentArchiveImpl bda : beanDeploymentArchives) {            if (bda.getBeanArchiveType().equals(BeanDeploymentArchiveImpl.BeanArchiveType.EXTERNAL) || bda.getBeanArchiveType().equals(BeanDeploymentArchiveImpl.BeanArchiveType.SYNTHETIC)) {                for (BeanDeploymentArchiveImpl topLevelBda : rootBeanDeploymentModule.getBeanDeploymentArchives()) {                    bda.addBeanDeploymentArchive(topLevelBda);                }            }        }    }
public synchronized BeanDeploymentArchive loadBeanDeploymentArchive(final Class<?> beanClass) {        final BeanDeploymentArchive bda = this.getBeanDeploymentArchive(beanClass);        if (bda != null) {            return bda;        }        Module module = Module.forClass(beanClass);        if (module == null) {            // Bean class loaded by the bootstrap class loader            if (bootstrapClassLoaderBeanDeploymentArchive == null) {                bootstrapClassLoaderBeanDeploymentArchive = createAndRegisterAdditionalBeanDeploymentArchive(module, beanClass);            } else {                bootstrapClassLoaderBeanDeploymentArchive.addBeanClass(beanClass);            }            return bootstrapClassLoaderBeanDeploymentArchive;        }        /*         * No, there is no BDA for the class yet. Let's create one.         */        return createAndRegisterAdditionalBeanDeploymentArchive(module, beanClass);    }
JSEArchiveMetaData create(final Deployment dep) {        if (WSLogger.ROOT_LOGGER.isTraceEnabled()) {            WSLogger.ROOT_LOGGER.tracef("Creating JBoss agnostic meta data for POJO webservice deployment: %s", dep.getSimpleName());        }        final JBossWebMetaData jbossWebMD = WSHelper.getRequiredAttachment(dep, JBossWebMetaData.class);        final DeploymentUnit unit = WSHelper.getRequiredAttachment(dep, DeploymentUnit.class);        final List<POJOEndpoint> pojoEndpoints = getPojoEndpoints(unit);        final JSEArchiveMetaData.Builder builder = new JSEArchiveMetaData.Builder();        // set context root        final String contextRoot = getContextRoot(dep, jbossWebMD);        builder.setContextRoot(contextRoot);        WSLogger.ROOT_LOGGER.tracef("Setting context root: %s", contextRoot);        // set servlet url patterns mappings        final Map<String, String> servletMappings = getServletUrlPatternsMappings(jbossWebMD, pojoEndpoints);        builder.setServletMappings(servletMappings);        // set servlet class names mappings        final Map<String, String> servletClassNamesMappings = getServletClassMappings(jbossWebMD, pojoEndpoints);        builder.setServletClassNames(servletClassNamesMappings);        // set security domain        final String securityDomain = jbossWebMD.getSecurityDomain();        builder.setSecurityDomain(securityDomain);        // set wsdl location resolver        final JBossWebservicesMetaData jbossWebservicesMD = WSHelper.getOptionalAttachment(dep, JBossWebservicesMetaData.class);        if (jbossWebservicesMD != null) {            final PublishLocationAdapter resolver = new PublishLocationAdapterImpl(jbossWebservicesMD.getWebserviceDescriptions());            builder.setPublishLocationAdapter(resolver);        }        // set security meta data        final List<JSESecurityMetaData> jseSecurityMDs = getSecurityMetaData(jbossWebMD.getSecurityConstraints());        builder.setSecurityMetaData(jseSecurityMDs);        // set config name and file        setConfigNameAndFile(builder, jbossWebMD, jbossWebservicesMD);        return builder.build();    }
private void setConfigNameAndFile(final JSEArchiveMetaData.Builder builder, final JBossWebMetaData jbossWebMD, final JBossWebservicesMetaData jbossWebservicesMD) {        if (jbossWebservicesMD != null) {           if (jbossWebservicesMD.getConfigName() != null) {              final String configName = jbossWebservicesMD.getConfigName();              builder.setConfigName(configName);              WSLogger.ROOT_LOGGER.tracef("Setting config name: %s", configName);              final String configFile = jbossWebservicesMD.getConfigFile();              builder.setConfigFile(configFile);               WSLogger.ROOT_LOGGER.tracef("Setting config file: %s", configFile);              // ensure higher priority against web.xml context parameters              return;           }        }        final List<ParamValueMetaData> contextParams = jbossWebMD.getContextParams();        if (contextParams != null) {            for (final ParamValueMetaData contextParam : contextParams) {                if (WSConstants.JBOSSWS_CONFIG_NAME.equals(contextParam.getParamName())) {                    final String configName = contextParam.getParamValue();                    builder.setConfigName(configName);                    WSLogger.ROOT_LOGGER.tracef("Setting config name: %s", configName);                }                if (WSConstants.JBOSSWS_CONFIG_FILE.equals(contextParam.getParamName())) {                    final String configFile = contextParam.getParamValue();                    builder.setConfigFile(configFile);                    WSLogger.ROOT_LOGGER.tracef("Setting config file: %s", configFile);                }            }        }    }
private List<JSESecurityMetaData> getSecurityMetaData(final List<SecurityConstraintMetaData> securityConstraintsMD) {        final List<JSESecurityMetaData> jseSecurityMDs = new LinkedList<JSESecurityMetaData>();        if (securityConstraintsMD != null) {            for (final SecurityConstraintMetaData securityConstraintMD : securityConstraintsMD) {                final JSESecurityMetaData.Builder jseSecurityMDBuilder = new JSESecurityMetaData.Builder();                // transport guarantee                jseSecurityMDBuilder.setTransportGuarantee(securityConstraintMD.getTransportGuarantee().name());                // web resources                for (final WebResourceCollectionMetaData webResourceMD : securityConstraintMD.getResourceCollections()) {                    jseSecurityMDBuilder.addWebResource(webResourceMD.getName(), webResourceMD.getUrlPatterns());                }                jseSecurityMDs.add(jseSecurityMDBuilder.build());            }        }        return jseSecurityMDs;    }
private Map<String, String> getServletUrlPatternsMappings(final JBossWebMetaData jbossWebMD, final List<POJOEndpoint> pojoEndpoints) {        final Map<String, String> mappings = new HashMap<String, String>();        final List<ServletMappingMetaData> servletMappings = WebMetaDataHelper.getServletMappings(jbossWebMD);        for (final POJOEndpoint pojoEndpoint : pojoEndpoints) {            mappings.put(pojoEndpoint.getName(), pojoEndpoint.getUrlPattern());            if (!pojoEndpoint.isDeclared()) {                final String endpointName = pojoEndpoint.getName();                final List<String> urlPatterns = WebMetaDataHelper.getUrlPatterns(pojoEndpoint.getUrlPattern());                WebMetaDataHelper.newServletMapping(endpointName, urlPatterns, servletMappings);            }        }        return mappings;    }
private Map<String, String> getServletClassMappings(final JBossWebMetaData jbossWebMD, final List<POJOEndpoint> pojoEndpoints) {        final Map<String, String> mappings = new HashMap<String, String>();        final JBossServletsMetaData servlets = WebMetaDataHelper.getServlets(jbossWebMD);        for (final POJOEndpoint pojoEndpoint : pojoEndpoints) {            final String pojoName = pojoEndpoint.getName();            final String pojoClassName = pojoEndpoint.getClassName();            mappings.put(pojoName, pojoClassName);            if (!pojoEndpoint.isDeclared()) {                final String endpointName = pojoEndpoint.getName();                final String endpointClassName = pojoEndpoint.getClassName();                WebMetaDataHelper.newServlet(endpointName, endpointClassName, servlets);            }        }        return mappings;    }
private void resolve() {        if (!resolved) {            synchronized (this) {                if (!resolved) {                    final Set<ViewDescription> views = getViews();                    final Set<EJBViewDescription> ejbsForViewName = new HashSet<EJBViewDescription>();                    for (final ViewDescription view : views) {                        if (view instanceof EJBViewDescription) {                            final MethodIntf viewType = ((EJBViewDescription) view).getMethodIntf();                            // @EJB injection *shouldn't* consider the @WebService endpoint view or MDBs                            if (viewType == MethodIntf.SERVICE_ENDPOINT || viewType == MethodIntf.MESSAGE_ENDPOINT) {                                continue;                            }                            ejbsForViewName.add((EJBViewDescription) view);                        }                    }                    if (ejbsForViewName.isEmpty()) {                        if (beanName == null) {                            error = EjbLogger.ROOT_LOGGER.ejbNotFound(typeName, bindingName);                        } else {                            error = EjbLogger.ROOT_LOGGER.ejbNotFound(typeName, beanName, bindingName);                        }                    } else if (ejbsForViewName.size() > 1) {                        if (beanName == null) {                            error = EjbLogger.ROOT_LOGGER.moreThanOneEjbFound(typeName, bindingName, ejbsForViewName);                        } else {                            error = EjbLogger.ROOT_LOGGER.moreThanOneEjbFound(typeName, beanName, bindingName, ejbsForViewName);                        }                    } else {                        final EJBViewDescription description = ejbsForViewName.iterator().next();                        final EJBViewDescription ejbViewDescription = (EJBViewDescription) description;                        //for remote interfaces we do not want to use a normal binding                        //we need to bind the remote proxy factory into JNDI instead to get the correct behaviour                        if (ejbViewDescription.getMethodIntf() == MethodIntf.REMOTE || ejbViewDescription.getMethodIntf() == MethodIntf.HOME) {                            final EJBComponentDescription componentDescription = (EJBComponentDescription) description.getComponentDescription();                            final EEModuleDescription moduleDescription = componentDescription.getModuleDescription();                            final String earApplicationName = moduleDescription.getEarApplicationName();                            final Value<ClassLoader> viewClassLoader = new Value<ClassLoader>() {                                @Override                                public ClassLoader getValue() throws IllegalStateException, IllegalArgumentException {                                    final Module module = deploymentUnit.getAttachment(Attachments.MODULE);                                    return module != null ? module.getClassLoader() : null;                                }                            };                            remoteFactory = new RemoteViewManagedReferenceFactory(earApplicationName, moduleDescription.getModuleName(), moduleDescription.getDistinctName(), componentDescription.getComponentName(), description.getViewClassName(), componentDescription.isStateful(), viewClassLoader, appclient);                        }                        final ServiceName serviceName = description.getServiceName();                        resolvedViewName = serviceName;                    }                    resolved = true;                }            }        }    }
@Override    public Node elect(List<Node> nodes) {        int size = nodes.size();        return (size > 0) ? nodes.get(this.random.nextInt(size)) : null;    }
private static Set<String> getAvailableConnectors(final OperationContext context,final ModelNode operation) throws OperationFailedException{        PathAddress address = PathAddress.pathAddress(operation.get(ModelDescriptionConstants.OP_ADDR));        PathAddress active = MessagingServices.getActiveMQServerPathAddress(address);        Set<String> availableConnectors = new HashSet<String>();        Resource subsystemResource = context.readResourceFromRoot(active.getParent(), false);        availableConnectors.addAll(subsystemResource.getChildrenNames(CommonAttributes.REMOTE_CONNECTOR));        Resource activeMQServerResource = context.readResourceFromRoot(active, false);        availableConnectors.addAll(activeMQServerResource.getChildrenNames(CommonAttributes.HTTP_CONNECTOR));        availableConnectors.addAll(activeMQServerResource.getChildrenNames(CommonAttributes.IN_VM_CONNECTOR));        availableConnectors.addAll(activeMQServerResource.getChildrenNames(CommonAttributes.REMOTE_CONNECTOR));        availableConnectors.addAll(activeMQServerResource.getChildrenNames(CommonAttributes.CONNECTOR));        return availableConnectors;    }
public void getResourceValue(final ResolutionContext resolutionContext, final ServiceBuilder<?> serviceBuilder, final DeploymentPhaseContext phaseContext, final Injector<ManagedReferenceFactory> injector) {        if(serviceName != null) {            serviceBuilder.requires(serviceName);        }        final RemoteViewManagedReferenceFactory factory = new RemoteViewManagedReferenceFactory(appName, moduleName, distinctName, beanName, viewClass, stateful, viewClassLoader, appclient);        injector.inject(factory);    }
static void parseCoreEnvironmentElement(final XMLExtendedStreamReader reader, final ModelNode operation) throws XMLStreamException {        final int count = reader.getAttributeCount();        for (int i = 0; i < count; i++) {            requireNoNamespaceAttribute(reader, i);            final String value = reader.getAttributeValue(i);            final Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));            switch (attribute) {                case NODE_IDENTIFIER:                    TransactionSubsystemRootResourceDefinition.NODE_IDENTIFIER.parseAndSetParameter(value, operation, reader);                    break;                case PATH:                case RELATIVE_TO:                    throw TransactionLogger.ROOT_LOGGER.unsupportedAttribute(attribute.getLocalName(), reader.getLocation());                default:                    throw unexpectedAttribute(reader, i);            }        }        // elements        final EnumSet<Element> required = EnumSet.of(Element.PROCESS_ID);        final EnumSet<Element> encountered = EnumSet.noneOf(Element.class);        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {            final Element element = Element.forName(reader.getLocalName());            required.remove(element);            switch (element) {                case PROCESS_ID: {                    if (!encountered.add(element)) {                        throw duplicateNamedElement(reader, reader.getLocalName());                    }                    parseProcessIdEnvironmentElement(reader, operation);                    break;                }                default:                    throw unexpectedElement(reader);            }        }        if (!required.isEmpty()) {            throw missingRequiredElement(reader, required);        }    }
static void parseProcessIdEnvironmentElement(XMLExtendedStreamReader reader, ModelNode coreEnvironmentAdd) throws XMLStreamException {        // no attributes        if (reader.getAttributeCount() > 0) {            throw unexpectedAttribute(reader, 0);        }        // elements        boolean encountered = false;        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {            final Element element = Element.forName(reader.getLocalName());            switch (element) {                case UUID:                    if (encountered) {                        throw unexpectedElement(reader);                    }                    encountered = true;                    if (reader.getAttributeCount() > 0) {                        throw unexpectedAttribute(reader, 0);                    }                    coreEnvironmentAdd.get(TransactionSubsystemRootResourceDefinition.PROCESS_ID_UUID.getName()).set(true);                    requireNoContent(reader);                    break;                case SOCKET: {                    if (encountered) {                        throw unexpectedElement(reader);                    }                    encountered = true;                    parseSocketProcessIdElement(reader, coreEnvironmentAdd);                    break;                }                default:                    throw unexpectedElement(reader);            }        }        if (!encountered) {            throw missingOneOf(reader, EnumSet.of(Element.UUID, Element.SOCKET));        }    }
private EntityManagerFactoryBuilder createContainerEntityManagerFactoryBuilder() {        persistenceProviderAdaptor.beforeCreateContainerEntityManagerFactory(pu);        try {            TwoPhaseBootstrapCapable twoPhaseBootstrapCapable = (TwoPhaseBootstrapCapable)persistenceProviderAdaptor;            return twoPhaseBootstrapCapable.getBootstrap(pu, properties.getValue());        } finally {            try {                persistenceProviderAdaptor.afterCreateContainerEntityManagerFactory(pu);            } finally {                pu.setAnnotationIndex(null);    // close reference to Annotation Index (only needed during call to createContainerEntityManagerFactory)            }        }    }
private boolean isHibernateExtendedBeanManagerSupported() {        try {            Class.forName(HIBERNATE_EXTENDED_BEANMANAGER);            return true;        } catch (ClassNotFoundException ignore) {            return false;        } catch (NoClassDefFoundError ignore) {            return false;        }    }
public static PathAddress getPathAddress(ModelNode operation) {        return PathAddress.pathAddress(operation.require(ModelDescriptionConstants.OP_ADDR));    }
public static void setPathAddress(ModelNode operation, PathAddress address) {        operation.get(ModelDescriptionConstants.OP_ADDR).set(address.toModelNode());    }
public static ModelNode getAttributeValue(ModelNode operation) {        return operation.hasDefined(ModelDescriptionConstants.VALUE) ? operation.get(ModelDescriptionConstants.VALUE) : new ModelNode();    }
public static boolean isIncludeDefaults(ModelNode operation) {        return operation.hasDefined(ModelDescriptionConstants.INCLUDE_DEFAULTS) ? operation.get(ModelDescriptionConstants.INCLUDE_DEFAULTS).asBoolean() : true;    }
public static ModelNode createCompositeOperation(List<ModelNode> operations) {        ModelNode operation = Util.createOperation(ModelDescriptionConstants.COMPOSITE, PathAddress.EMPTY_ADDRESS);        ModelNode steps = operation.get(ModelDescriptionConstants.STEPS);        for (ModelNode step: operations) {            steps.add(step);        }        return operation;    }
public static ModelNode createAddOperation(PathAddress address, Map<Attribute, ModelNode> parameters) {        ModelNode operation = Util.createAddOperation(address);        for (Map.Entry<Attribute, ModelNode> entry : parameters.entrySet()) {            operation.get(entry.getKey().getName()).set(entry.getValue());        }        return operation;    }
public static ModelNode createAddOperation(PathAddress address, int index) {        return createAddOperation(address, index, Collections.emptyMap());    }
public static ModelNode createReadAttributeOperation(PathAddress address, Attribute attribute) {        return createAttributeOperation(ModelDescriptionConstants.READ_ATTRIBUTE_OPERATION, address, attribute);    }
public static ModelNode createWriteAttributeOperation(PathAddress address, Attribute attribute, ModelNode value) {        ModelNode operation = createAttributeOperation(ModelDescriptionConstants.WRITE_ATTRIBUTE_OPERATION, address, attribute);        operation.get(ModelDescriptionConstants.VALUE).set(value);        return operation;    }
public static ModelNode createUndefineAttributeOperation(PathAddress address, Attribute attribute) {        return createAttributeOperation(ModelDescriptionConstants.UNDEFINE_ATTRIBUTE_OPERATION, address, attribute);    }
public T getValue() throws IllegalStateException {        final Context context = contextValue.getValue();        try {            return (T)context.lookup(contextName);        } catch (NamingException e) {            throw NamingLogger.ROOT_LOGGER.entryNotRegistered(e, contextName, context);        }    }
public static synchronized void addUrlContextFactory(final String scheme, ObjectFactory factory) {        Map<String, ObjectFactory> factories = new HashMap<String, ObjectFactory>(urlContextFactories);        factories.put(scheme, factory);        urlContextFactories = Collections.unmodifiableMap(factories);    }
public static synchronized void removeUrlContextFactory(final String scheme, ObjectFactory factory) {        Map<String, ObjectFactory> factories = new HashMap<String, ObjectFactory>(urlContextFactories);        ObjectFactory f = factories.get(scheme);        if (f == factory) {            factories.remove(scheme);            urlContextFactories = Collections.unmodifiableMap(factories);            return;        } else {            throw new IllegalArgumentException();        }    }
@Override    public List<ValidationProvider<?>> getValidationProviders() {        // first try the TCCL        List<ValidationProvider<?>> providers = loadProviders(WildFlySecurityManager.getCurrentContextClassLoaderPrivileged());        if (providers != null && !providers.isEmpty()) {            return providers;        }        // otherwise use the loader of this class        else {            return loadProviders(WildFlySecurityManager.getClassLoaderPrivileged(WildFlyProviderResolver.class));        }    }
private List<ValidationProvider<?>> loadProviders(ClassLoader classLoader) {        @SuppressWarnings("rawtypes")        Iterator<ValidationProvider> providerIterator = ServiceLoader.load(ValidationProvider.class, classLoader).iterator();        LinkedList<ValidationProvider<?>> providers = new LinkedList<ValidationProvider<?>>();        while (providerIterator.hasNext()) {            try {                ValidationProvider<?> provider = providerIterator.next();                // put Hibernate Validator to the beginning of the list                if (provider.getClass().getName().equals("org.hibernate.validator.HibernateValidator")) {                    providers.addFirst(provider);                } else {                    providers.add(provider);                }            } catch (ServiceConfigurationError e) {                // ignore, because it can happen when multiple                // providers are present and some of them are not class loader                // compatible with our API.            }        }        return providers;    }
@Override    public void start(StartContext context) throws StartException {        try {            PolicyConfigurationFactory pcf = getPolicyConfigurationFactory();            synchronized (pcf) { // synchronize on the factory                policyConfiguration = pcf.getPolicyConfiguration(contextId, false);                if (metaData != null) {                    createPermissions(metaData, policyConfiguration);                } else {                    SecurityLogger.ROOT_LOGGER.debugf("Cannot create permissions with 'null' metaData for id=%s", contextId);                }                if (!standalone) {                    PolicyConfiguration parent = parentPolicy.getValue();                    if (parent != null) {                        parent = pcf.getPolicyConfiguration(parent.getContextID(), false);                        parent.linkConfiguration(policyConfiguration);                        policyConfiguration.commit();                        parent.commit();                    } else {                        SecurityLogger.ROOT_LOGGER.debugf("Could not retrieve parent policy for policy %s", contextId);                    }                } else {                    policyConfiguration.commit();                }                // Allow the policy to incorporate the policy configs                Policy.getPolicy().refresh();            }        } catch (Exception e) {            throw SecurityLogger.ROOT_LOGGER.unableToStartException("JaccService", e);        }    }
@Override    public void stop(StopContext context) {        try {            PolicyConfigurationFactory pcf = PolicyConfigurationFactory.getPolicyConfigurationFactory();            synchronized (pcf) { // synchronize on the factory                policyConfiguration = pcf.getPolicyConfiguration(contextId, false);                policyConfiguration.delete();            }        } catch (Exception e) {            SecurityLogger.ROOT_LOGGER.errorDeletingJACCPolicy(e);        }        policyConfiguration = null;    }
private String getCanonicalURI(HttpServletRequest request) {        String canonicalURI = request.getRequestURI().substring(request.getContextPath().length());        if (canonicalURI == null || canonicalURI.equals("/"))            canonicalURI = "";        return canonicalURI;    }
private List<BindingConfiguration> getMessageDestinationRefs(final DeploymentDescriptorEnvironment environment, final ClassLoader classLoader, final DeploymentReflectionIndex deploymentReflectionIndex, final ResourceInjectionTarget resourceInjectionTarget, final DeploymentUnit deploymentUnit) throws DeploymentUnitProcessingException {        final List<BindingConfiguration> bindings = new ArrayList<BindingConfiguration>();        final MessageDestinationReferencesMetaData messageDestinationReferences = environment.getEnvironment().getMessageDestinationReferences();        if (messageDestinationReferences == null) {            return bindings;        }        for (final MessageDestinationReferenceMetaData messageRef : messageDestinationReferences) {            if(messageRef.isDependencyIgnored()) {                continue;            }            final String name;            if (messageRef.getName().startsWith("java:")) {                name = messageRef.getName();            } else {                name = environment.getDefaultContext() + messageRef.getName();            }            Class<?> classType = null;            if (messageRef.getType() != null) {                try {                    classType = classLoader.loadClass(messageRef.getType());                } catch (ClassNotFoundException e) {                    throw EeLogger.ROOT_LOGGER.cannotLoad(e, messageRef.getType());                }            }            // our injection (source) comes from the local (ENC) lookup, no matter what.            final LookupInjectionSource injectionSource = new LookupInjectionSource(name);            classType = processInjectionTargets(resourceInjectionTarget, injectionSource, classLoader, deploymentReflectionIndex, messageRef, classType);            final BindingConfiguration bindingConfiguration;            if (!isEmpty(messageRef.getLookupName())) {                bindingConfiguration = new BindingConfiguration(name, new LookupInjectionSource(messageRef.getLookupName()));                bindings.add(bindingConfiguration);            } else if (!isEmpty(messageRef.getMappedName())) {                bindingConfiguration = new BindingConfiguration(name, new LookupInjectionSource(messageRef.getMappedName()));                bindings.add(bindingConfiguration);            } else if (!isEmpty(messageRef.getLink())) {                final MessageDestinationInjectionSource messageDestinationInjectionSource = new MessageDestinationInjectionSource(messageRef.getLink(), name);                bindingConfiguration = new BindingConfiguration(name, messageDestinationInjectionSource);                deploymentUnit.addToAttachmentList(Attachments.MESSAGE_DESTINATIONS, messageDestinationInjectionSource);                bindings.add(bindingConfiguration);            } else {                ROOT_LOGGER.cannotResolve("message-destination-ref", name);            }        }        return bindings;    }
void modify(final Deployment dep) {        final JBossWebMetaData jbossWebMD = WSHelper.getOptionalAttachment(dep, JBossWebMetaData.class);        if (jbossWebMD != null) {            this.configureEndpoints(dep, jbossWebMD);            this.modifyContextRoot(dep, jbossWebMD);        }    }
private void configureEndpoints(final Deployment dep, final JBossWebMetaData jbossWebMD) {        final String transportClassName = this.getTransportClassName(dep);        WSLogger.ROOT_LOGGER.trace("Modifying servlets");        // get a list of the endpoint bean class names        final Set<String> epNames = new HashSet<String>();        for (Endpoint ep : dep.getService().getEndpoints()) {            epNames.add(ep.getTargetBeanName());        }        // fix servlet class names for endpoints        for (final ServletMetaData servletMD : jbossWebMD.getServlets()) {            final String endpointClassName = ASHelper.getEndpointClassName(servletMD);            if (endpointClassName != null && endpointClassName.length() > 0) { // exclude JSP                if (epNames.contains(endpointClassName)) {                    // set transport servlet                    servletMD.setServletClass(WSFServlet.class.getName());                    WSLogger.ROOT_LOGGER.tracef("Setting transport class: %s for endpoint: %s", transportClassName, endpointClassName);                    final List<ParamValueMetaData> initParams = WebMetaDataHelper.getServletInitParams(servletMD);                    // configure transport class name                    WebMetaDataHelper.newParamValue(WSFServlet.STACK_SERVLET_DELEGATE_CLASS, transportClassName, initParams);                    // configure webservice endpoint                    WebMetaDataHelper.newParamValue(Endpoint.SEPID_DOMAIN_ENDPOINT, endpointClassName, initParams);                } else if (endpointClassName.startsWith("org.apache.cxf")) {                    throw WSLogger.ROOT_LOGGER.invalidWSServlet(endpointClassName);                }            }        }    }
private void modifyContextRoot(final Deployment dep, final JBossWebMetaData jbossWebMD) {        final String contextRoot = dep.getService().getContextRoot();        if (WSLogger.ROOT_LOGGER.isTraceEnabled()) {            WSLogger.ROOT_LOGGER.tracef("Setting context root: %s for deployment: %s", contextRoot, dep.getSimpleName());        }        jbossWebMD.setContextRoot(contextRoot);    }
private String getTransportClassName(final Deployment dep) {        String transportClassName = (String) dep.getProperty(WSConstants.STACK_TRANSPORT_CLASS);        if (transportClassName == null) throw WSLogger.ROOT_LOGGER.missingDeploymentProperty(WSConstants.STACK_TRANSPORT_CLASS);        return transportClassName;    }
@SuppressWarnings("unchecked")    @Override    public synchronized T get(MarshallingContext context) throws IOException, ClassNotFoundException {        if (this.object == null) {            this.context = context;            if (this.bytes != null) {                ByteArrayInputStream input = new ByteArrayInputStream(this.bytes);                ClassLoader loader = setThreadContextClassLoader(this.context.getClassLoader());                try (SimpleDataInput data = new SimpleDataInput(Marshalling.createByteInput(input))) {                    int version = IndexSerializer.VARIABLE.readInt(data);                    try (Unmarshaller unmarshaller = context.createUnmarshaller(version)) {                        unmarshaller.start(data);                        this.object = (T) unmarshaller.readObject();                        unmarshaller.finish();                        this.bytes = null; // Free up memory                    }                } finally {                    setThreadContextClassLoader(loader);                }            }        }        return this.object;    }
public static int getLastDateOfMonth(Calendar calendar) {        Calendar tmpCal = new GregorianCalendar(calendar.getTimeZone());        tmpCal.set(Calendar.YEAR, calendar.get(Calendar.YEAR));        tmpCal.set(Calendar.MONTH, calendar.get(Calendar.MONTH));        tmpCal.set(Calendar.DAY_OF_MONTH, 1);        return tmpCal.getActualMaximum(Calendar.DAY_OF_MONTH);    }
private Properties filterUnknownActivationConfigProperties(final String resourceAdapterName, final Activation activation, final Properties activationConfigProps) {        if (activationConfigProps == null) {            return null;        }        final Map<String, Class<?>> raActivationConfigProps = activation.getConfigProperties();        final Set<String> raRequiredConfigProps = activation.getRequiredConfigProperties();        final Enumeration<?> propNames = activationConfigProps.propertyNames();        final Properties validActivationConfigProps = new Properties();        // initialize to all the activation config properties that have been set on the MDB        validActivationConfigProps.putAll(activationConfigProps);        while (propNames.hasMoreElements()) {            final Object propName = propNames.nextElement();            if (raActivationConfigProps.containsKey(propName) == false && raRequiredConfigProps.contains(propName) == false) {                // not a valid activation config property, so log a WARN and filter it out from the valid activation config properties                validActivationConfigProps.remove(propName);                EjbLogger.ROOT_LOGGER.activationConfigPropertyIgnored(propName, resourceAdapterName);            }        }        return validActivationConfigProps;    }
private Endpoint getEndpoint(final String resourceAdapterName) {        // first get the ra "identifier" (with which it is registered in the resource adapter repository) for the        // ra name        final String raIdentifier = ConnectorServices.getRegisteredResourceAdapterIdentifier(resourceAdapterName);        if (raIdentifier == null) {            throw EjbLogger.ROOT_LOGGER.unknownResourceAdapter(resourceAdapterName);        }        final ResourceAdapterRepository resourceAdapterRepository = resourceAdapterRepositoryInjectedValue.getValue();        if (resourceAdapterRepository == null) {            throw EjbLogger.ROOT_LOGGER.resourceAdapterRepositoryUnAvailable();        }        try {            return resourceAdapterRepository.getEndpoint(raIdentifier);        } catch (NotFoundException nfe) {            throw EjbLogger.ROOT_LOGGER.noSuchEndpointException(resourceAdapterName, nfe);        }    }
static SecurityContext createSecurityContext(final String domain) {        if (WildFlySecurityManager.isChecking()) {            return WildFlySecurityManager.doUnchecked(new PrivilegedAction<SecurityContext>() {                @Override                public SecurityContext run() {                    try {                        return SecurityContextFactory.createSecurityContext(domain);                    } catch (Exception e) {                        throw UndertowLogger.ROOT_LOGGER.failToCreateSecurityContext(e);                    }                }            });        } else {            try {                return SecurityContextFactory.createSecurityContext(domain);            } catch (Exception e) {                throw UndertowLogger.ROOT_LOGGER.failToCreateSecurityContext(e);            }        }    }
static void setSecurityContextOnAssociation(final SecurityContext sc) {        if (WildFlySecurityManager.isChecking()) {            WildFlySecurityManager.doUnchecked(new PrivilegedAction<Void>() {                @Override                public Void run() {                    SecurityContextAssociation.setSecurityContext(sc);                    return null;                }            });        } else {            SecurityContextAssociation.setSecurityContext(sc);        }    }
static SecurityContext getSecurityContext() {        if (WildFlySecurityManager.isChecking()) {            return WildFlySecurityManager.doUnchecked(new PrivilegedAction<SecurityContext>() {                public SecurityContext run() {                    return SecurityContextAssociation.getSecurityContext();                }            });        } else {            return SecurityContextAssociation.getSecurityContext();        }    }
static void clearSecurityContext() {        if (WildFlySecurityManager.isChecking()) {            WildFlySecurityManager.doUnchecked(new PrivilegedAction<Void>() {                public Void run() {                    SecurityContextAssociation.clearSecurityContext();                    return null;                }            });        } else {            SecurityContextAssociation.clearSecurityContext();        }    }
static RunAs setRunAsIdentity(final RunAs principal, final SecurityContext sc) {        if (WildFlySecurityManager.isChecking()) {            return WildFlySecurityManager.doUnchecked(new PrivilegedAction<RunAs>() {                @Override                public RunAs run() {                    if (sc == null) {                        throw UndertowLogger.ROOT_LOGGER.noSecurityContext();                    }                    RunAs old = sc.getOutgoingRunAs();                    sc.setOutgoingRunAs(principal);                    return old;                }            });        } else {            if (sc == null) {                throw UndertowLogger.ROOT_LOGGER.noSecurityContext();            }            RunAs old = sc.getOutgoingRunAs();            sc.setOutgoingRunAs(principal);            return old;        }    }
static RunAs popRunAsIdentity(final SecurityContext sc) {        if (WildFlySecurityManager.isChecking()) {            return AccessController.doPrivileged(new PrivilegedAction<RunAs>() {                @Override                public RunAs run() {                    if (sc == null) {                        throw UndertowLogger.ROOT_LOGGER.noSecurityContext();                    }                    RunAs principal = sc.getOutgoingRunAs();                    sc.setOutgoingRunAs(null);                    return principal;                }            });        } else {            if (sc == null) {                throw UndertowLogger.ROOT_LOGGER.noSecurityContext();            }            RunAs principal = sc.getOutgoingRunAs();            sc.setOutgoingRunAs(null);            return principal;        }    }
void processManagement(final DeploymentUnit unit, JBossWebMetaData metaData) {        final DeploymentResourceSupport deploymentResourceSupport = unit.getAttachment(Attachments.DEPLOYMENT_RESOURCE_SUPPORT);        for (final JBossServletMetaData servlet : metaData.getServlets()) {            try {                final String name = servlet.getName();                final ModelNode node = deploymentResourceSupport.getDeploymentSubModel(UndertowExtension.SUBSYSTEM_NAME, PathElement.pathElement("servlet", name));                node.get("servlet-class").set(servlet.getServletClass());                node.get("servlet-name").set(servlet.getServletName());            } catch (Exception e) {                // Should a failure in creating the mgmt view also make to the deployment to fail?                continue;            }        }    }
private String getJBossAppSecurityDomain(final DeploymentUnit deploymentUnit) {        String securityDomain = null;        DeploymentUnit parent = deploymentUnit.getParent();        if (parent != null) {            final EarMetaData jbossAppMetaData = parent.getAttachment(org.jboss.as.ee.structure.Attachments.EAR_METADATA);            if (jbossAppMetaData instanceof JBossAppMetaData) {                securityDomain = ((JBossAppMetaData) jbossAppMetaData).getSecurityDomain();            }        }        return securityDomain != null ? securityDomain.trim() : null;    }
public Description describe() {        String defined_in_id = "IR";        if (defined_in instanceof ContainedOperations)            defined_in_id = ((ContainedOperations) defined_in).id();        ConstantDescription d =                new ConstantDescription(name, id, defined_in_id, version,                        typeCode, value);        Any any = getORB().create_any();        ConstantDescriptionHelper.insert(any, d);        return new Description(DefinitionKind.dk_Constant, any);    }
public static void installBinderService(final ServiceTarget serviceTarget,                                                 final String name,                                                 final Object obj) {        final BindInfo bindInfo = ContextNames.bindInfoFor(name);        final BinderService binderService = new BinderService(bindInfo.getBindName());        binderService.getManagedObjectInjector().inject(new ValueManagedReferenceFactory(Values.immediateValue(obj)));        serviceTarget.addService(bindInfo.getBinderServiceName(), binderService)                .addDependency(bindInfo.getParentContextServiceName(), ServiceBasedNamingStore.class, binderService.getNamingStoreInjector())                .install();    }
public static void installBinderService(final ServiceTarget serviceTarget,                                            final String name,                                            final Service<?> service,                                            final ServiceName dependency) {        final BindInfo bindInfo = ContextNames.bindInfoFor(name);        final BinderService binderService = new BinderService(bindInfo.getBindName());        binderService.getManagedObjectInjector().inject(new ValueManagedReferenceFactory(service));        final ServiceBuilder serviceBuilder = serviceTarget.addService(bindInfo.getBinderServiceName(), binderService)                .addDependency(bindInfo.getParentContextServiceName(), ServiceBasedNamingStore.class, binderService.getNamingStoreInjector())                // we set it in passive mode so that missing dependencies (which is possible/valid when it's a backup HornetQ server and the services                // haven't been activated on it due to the presence of a different live server) don't cause jms-topic/jms-queue add operations                // to fail                .setInitialMode(ServiceController.Mode.PASSIVE);        if (dependency != null) {            serviceBuilder.requires(dependency);        }        serviceBuilder.install();    }
@Override    protected void registerAddOperation(ManagementResourceRegistration registration, AbstractAddStepHandler handler, OperationEntry.Flag... flags) {        OperationDefinition od = new SimpleOperationDefinitionBuilder(ADD, getResourceDescriptionResolver())                .setParameters(ATTRIBUTES)                .addParameter(DEFAULT_CLUSTERED_SFSB_CACHE)                .withFlags(flags)                .build();        registration.registerOperationHandler(od, handler);    }
@SuppressWarnings("unchecked")    public void inject(Object object, String propertyName, Object propertyValue)            throws NoSuchMethodException, IllegalAccessException, InvocationTargetException {        inject(object, propertyName, propertyValue, null, false);    }
private boolean argumentMatches(String classType, String propertyType) {        return (classType.equals(propertyType))                || (classType.equals("java.lang.Byte") && propertyType.equals("byte"))                || (classType.equals("java.lang.Short") && propertyType.equals("short"))                || (classType.equals("java.lang.Integer") && propertyType.equals("int"))                || (classType.equals("java.lang.Long") && propertyType.equals("long"))                || (classType.equals("java.lang.Float") && propertyType.equals("float"))                || (classType.equals("java.lang.Double") && propertyType.equals("double"))                || (classType.equals("java.lang.Boolean") && propertyType.equals("boolean"))                || (classType.equals("java.lang.Character") && propertyType.equals("char"));    }
protected Method findMethod(Class<?> clz, String methodName, String propertyType) {        while (!clz.equals(Object.class)) {            List<Method> hits = null;            Method[] methods = SecurityActions.getDeclaredMethods(clz);            for (int i = 0; i < methods.length; i++) {                final Method method = methods[i];                if (methodName.equals(method.getName()) && method.getParameterTypes().length == 1) {                    if (propertyType == null || argumentMatches(propertyType, method.getParameterTypes()[0].getName())) {                        if (hits == null)                            hits = new ArrayList<Method>(1);                        SecurityActions.setAccessible(method);                        hits.add(method);                    }                }            }            if (hits != null) {                if (hits.size() == 1) {                    return hits.get(0);                } else {                    Collections.sort(hits, new MethodSorter());                    if (propertyType != null) {                        for (Method m : hits) {                            if (propertyType.equals(m.getParameterTypes()[0].getName()))                                return m;                        }                    }                    return hits.get(0);                }            }            clz = clz.getSuperclass();        }        return null;    }
protected Field findField(Class<?> clz, String fieldName, String fieldType) {        while (!clz.equals(Object.class)) {            List<Field> hits = null;            Field[] fields = SecurityActions.getDeclaredFields(clz);            for (int i = 0; i < fields.length; i++) {                final Field field = fields[i];                if (fieldName.equals(field.getName())) {                    if (fieldType == null || argumentMatches(fieldType, field.getType().getName())) {                        if (hits == null)                            hits = new ArrayList<Field>(1);                        SecurityActions.setAccessible(field);                        hits.add(field);                    }                }            }            if (hits != null) {                if (hits.size() == 1) {                    return hits.get(0);                } else {                    Collections.sort(hits, new FieldSorter());                    if (fieldType != null) {                        for (Field f : hits) {                            if (fieldType.equals(f.getType().getName()))                                return f;                        }                    }                    return hits.get(0);                }            }            clz = clz.getSuperclass();        }        return null;    }
public Object processInvocation(final InterceptorContext context) throws Exception {        final ManagedReference reference = (ManagedReference) context.getPrivateData(ComponentInstance.class).getInstanceData(contextKey);        final Object instance = reference.getInstance();        try {            final Method method = this.method;            if (withContext) {                final Method oldMethod = context.getMethod();                try {                    if (this.lifecycleMethod) {                        // because InvocationContext#getMethod() is expected to return null for lifecycle methods                        context.setMethod(null);                        return method.invoke(instance, context.getInvocationContext());                    } else if (this.changeMethod) {                        context.setMethod(method);                        return method.invoke(instance, context.getInvocationContext());                    } else {                        return method.invoke(instance, context.getInvocationContext());                    }                } finally {                    // reset any changed method on the interceptor context                    context.setMethod(oldMethod);                }            } else {                method.invoke(instance);                return context.proceed();            }        } catch (IllegalAccessException e) {            final IllegalAccessError n = new IllegalAccessError(e.getMessage());            n.setStackTrace(e.getStackTrace());            throw n;        } catch (InvocationTargetException e) {            throw Interceptors.rethrow(e.getCause());        }    }
@Override    public void deploy(DeploymentPhaseContext phaseContext) throws DeploymentUnitProcessingException {        final DeploymentUnit deploymentUnit = phaseContext.getDeploymentUnit();        boolean resolveProperties = Util.shouldResolveJBoss(deploymentUnit);        final PropertyResolver propertyResolver = deploymentUnit.getAttachment(org.jboss.as.ee.metadata.property.Attachments.FINAL_PROPERTY_RESOLVER);        final PropertyReplacer propertyReplacer = deploymentUnit.getAttachment(org.jboss.as.ee.metadata.property.Attachments.FINAL_PROPERTY_REPLACER);        final Set<VirtualFile> files = dataSources(deploymentUnit);        boolean loggedDeprication = false;        for (VirtualFile f : files) {            InputStream xmlStream = null;            try {                xmlStream = new FileInputStream(f.getPhysicalFile());                DsXmlParser parser = new DsXmlParser(propertyResolver, propertyReplacer);                parser.setSystemPropertiesResolved(resolveProperties);                DataSources dataSources = parser.parse(xmlStream);                if (dataSources != null) {                    if (!loggedDeprication) {                        loggedDeprication = true;                        ConnectorLogger.ROOT_LOGGER.deprecated();                    }                    for (DataSource ds : dataSources.getDataSource()) {                        if (ds.getDriver() == null) {                            throw ConnectorLogger.ROOT_LOGGER.FailedDeployDriverNotSpecified(ds.getJndiName());                        }                    }                    deploymentUnit.addToAttachmentList(DATA_SOURCES_ATTACHMENT_KEY, dataSources);                }            } catch (Exception e) {                throw new DeploymentUnitProcessingException(e.getMessage(), e);            } finally {                VFSUtils.safeClose(xmlStream);            }        }    }
private static String escape(String s) {        StringBuffer sb = new StringBuffer(s);        for (int i = 0; i < sb.length(); i++) {            if (sb.charAt(i) == '/' || sb.charAt(i) == '\\' || sb.charAt(i) == '.') {                sb.insert(i, '\\');                i++;            }        }        return sb.toString();    }
private void initOptions() {        options = new Options();        options.addOption("k", KEYSTORE_PARAM, true, SecurityLogger.ROOT_LOGGER.cmdLineKeyStoreURL());        options.addOption("p", KEYSTORE_PASSWORD_PARAM, true, SecurityLogger.ROOT_LOGGER.cmdLineKeyStorePassword());        options.addOption("e", ENC_DIR_PARAM, true, SecurityLogger.ROOT_LOGGER.cmdLineEncryptionDirectory());        options.addOption("s", SALT_PARAM, true, SecurityLogger.ROOT_LOGGER.cmdLineSalt());        options.addOption("i", ITERATION_PARAM, true, SecurityLogger.ROOT_LOGGER.cmdLineIterationCount());        options.addOption("v", ALIAS_PARAM, true, SecurityLogger.ROOT_LOGGER.cmdLineVaultKeyStoreAlias());        options.addOption("b", VAULT_BLOCK_PARAM, true, SecurityLogger.ROOT_LOGGER.cmdLineVaultBlock());        options.addOption("a", ATTRIBUTE_PARAM, true, SecurityLogger.ROOT_LOGGER.cmdLineAttributeName());        options.addOption("t", CREATE_KEYSTORE_PARAM, false, SecurityLogger.ROOT_LOGGER.cmdLineAutomaticallyCreateKeystore());        OptionGroup og = new OptionGroup();        Option x = new Option("x", SEC_ATTR_VALUE_PARAM, true, SecurityLogger.ROOT_LOGGER.cmdLineSecuredAttribute());        Option c = new Option("c", CHECK_SEC_ATTR_EXISTS_PARAM, false, SecurityLogger.ROOT_LOGGER.cmdLineCheckAttribute());        Option r = new Option("r", REMOVE_SEC_ATTR_PARAM, false, SecurityLogger.ROOT_LOGGER.cmdLineRemoveSecuredAttribute());        Option h = new Option("h", HELP_PARAM, false, SecurityLogger.ROOT_LOGGER.cmdLineHelp());        og.addOption(x);        og.addOption(c);        og.addOption(r);        og.addOption(h);        og.setRequired(true);        options.addOptionGroup(og);    }
public Description describe() {        String defined_in_id = "IR";        if (defined_in instanceof ContainedOperations)            defined_in_id = ((ContainedOperations) defined_in).id();        TypeDescription td = new TypeDescription(name, id, defined_in_id,                version, typeCode);        Any any = getORB().create_any();        TypeDescriptionHelper.insert(any, td);        return new Description(DefinitionKind.dk_Typedef, any);    }
@Override    public void readElement(final XMLExtendedStreamReader reader, final List<ModelNode> list) throws XMLStreamException {        ParseUtils.requireNoAttributes(reader);        ParseUtils.requireNoContent(reader);        final ModelNode ejb3Subsystem = new ModelNode();        ejb3Subsystem.get(OP).set(ADD);        ejb3Subsystem.get(OP_ADDR).add(SUBSYSTEM, EJB3Extension.SUBSYSTEM_NAME);        list.add(ejb3Subsystem);    }
private static String deriveUsefulInfo(HttpServletRequest httpRequest) {        StringBuilder sb = new StringBuilder();        sb.append("[").append(httpRequest.getContextPath());        sb.append(":cookies=").append(Arrays.toString(httpRequest.getCookies())).append(":headers=");        // Append Header information        Enumeration<?> en = httpRequest.getHeaderNames();        while (en.hasMoreElements()) {            String headerName = (String) en.nextElement();            sb.append(headerName).append("=");            // Ensure HTTP Basic Password is not logged            if (!headerName.contains("authorization")) { sb.append(httpRequest.getHeader(headerName)).append(","); }        }        sb.append("]");        // Append Request parameter information        sb.append("[parameters=");        Enumeration<?> enparam = httpRequest.getParameterNames();        while (enparam.hasMoreElements()) {            String paramName = (String) enparam.nextElement();            String[] paramValues = httpRequest.getParameterValues(paramName);            int len = paramValues != null ? paramValues.length : 0;            for (int i = 0; i < len; i++) { sb.append(paramValues[i]).append("::"); }            sb.append(",");        }        sb.append("][attributes=");        // Append Request attribute information        Enumeration<?> enu = httpRequest.getAttributeNames();        while (enu.hasMoreElements()) {            String attrName = (String) enu.nextElement();            sb.append(attrName).append("=");            sb.append(httpRequest.getAttribute(attrName)).append(",");        }        sb.append("]");        return sb.toString();    }
@Override    public String getSessionCookieName() {        SessionCookieConfig override = server.getServletContainer().getSessionCookieConfig();        if (override == null || override.getName() == null) {            return io.undertow.server.session.SessionCookieConfig.DEFAULT_SESSION_ID;        }        return override.getName();    }
public JdrReport standaloneCollect(CLI cli, String protocol, String host, int port) throws OperationFailedException {        return new JdrRunner(cli, protocol, host, port, null, null).collect();    }
public JdrReport collect() throws OperationFailedException {        JdrRunner runner = new JdrRunner(true);        serverEnvironment = serverEnvironmentValue.getValue();        runner.setJbossHomeDir(serverEnvironment.getHomeDir().getAbsolutePath());        runner.setReportLocationDir(serverEnvironment.getServerTempDir().getAbsolutePath());        runner.setControllerClient(controllerClient);        runner.setHostControllerName(serverEnvironment.getHostControllerName());        runner.setServerName(serverEnvironment.getServerName());        return runner.collect();    }
public void registerResourceAdapterDeployment(ResourceAdapterDeployment deployment) {        if (deployment == null)            throw new IllegalArgumentException(ConnectorLogger.ROOT_LOGGER.nullVar("Deployment"));        DEPLOYMENT_CONNECTOR_REGISTRY_LOGGER.tracef("Adding deployment: %s", deployment);        deployments.add(deployment);    }
public void unregisterResourceAdapterDeployment(ResourceAdapterDeployment deployment) {        if (deployment == null)            throw new IllegalArgumentException(ConnectorLogger.ROOT_LOGGER.nullVar("Deployment"));        DEPLOYMENT_CONNECTOR_REGISTRY_LOGGER.tracef("Removing deployment: %s", deployment);        deployments.remove(deployment);    }
@Override    protected void performBoottime(OperationContext context, ModelNode operation, Resource resource) throws OperationFailedException {        try {            Class.forName("org.apache.jasper.compiler.JspRuntimeContext", true, this.getClass().getClassLoader());        } catch (ClassNotFoundException e) {            UndertowLogger.ROOT_LOGGER.couldNotInitJsp(e);        }        final ModelNode model = resource.getModel();        final String defaultVirtualHost = UndertowRootDefinition.DEFAULT_VIRTUAL_HOST.resolveModelAttribute(context, model).asString();        final String defaultContainer = UndertowRootDefinition.DEFAULT_SERVLET_CONTAINER.resolveModelAttribute(context, model).asString();        final String defaultServer = UndertowRootDefinition.DEFAULT_SERVER.resolveModelAttribute(context, model).asString();        final boolean stats = UndertowRootDefinition.STATISTICS_ENABLED.resolveModelAttribute(context, model).asBoolean();        final String defaultSecurityDomain = UndertowRootDefinition.DEFAULT_SECURITY_DOMAIN.resolveModelAttribute(context, model).asString();        final ModelNode instanceIdModel = UndertowRootDefinition.INSTANCE_ID.resolveModelAttribute(context, model);        final String instanceId = instanceIdModel.isDefined() ? instanceIdModel.asString() : null;        DefaultDeploymentMappingProvider.instance().clear();//we clear provider on system boot, as on reload it could cause issues.        context.getCapabilityServiceTarget().addCapability(UndertowRootDefinition.UNDERTOW_CAPABILITY, new UndertowService(defaultContainer, defaultServer, defaultVirtualHost, instanceId, stats))                .setInitialMode(ServiceController.Mode.ACTIVE)                .addAliases(UndertowService.UNDERTOW)                .install();        context.addStep(new AbstractDeploymentChainStep() {            @Override            protected void execute(DeploymentProcessorTarget processorTarget) {                final SharedTldsMetaDataBuilder sharedTldsBuilder = new SharedTldsMetaDataBuilder(model.clone());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.STRUCTURE, Phase.STRUCTURE_EXPLODED_MOUNT, new DeploymentRootExplodedMountProcessor());                JBossAllXmlParserRegisteringProcessor.Builder builder = JBossAllXmlParserRegisteringProcessor.builder();                for (SharedSessionConfigSchema schema : EnumSet.allOf(SharedSessionConfigSchema.class)) {                    builder.addParser(schema.getRoot(), SharedSessionManagerConfig.ATTACHMENT_KEY, new SharedSessionConfigParser(schema));                }                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.STRUCTURE, Phase.STRUCTURE_REGISTER_JBOSS_ALL_UNDERTOW_SHARED_SESSION, builder.build());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.STRUCTURE, Phase.STRUCTURE_REGISTER_JBOSS_ALL_WEB, new JBossAllXmlParserRegisteringProcessor<>(WebJBossAllParser.ROOT_ELEMENT, WebJBossAllParser.ATTACHMENT_KEY, new WebJBossAllParser()));                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.STRUCTURE, Phase.STRUCTURE_WAR_DEPLOYMENT_INIT, new WarDeploymentInitializingProcessor());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.STRUCTURE, Phase.STRUCTURE_WAR, new WarStructureDeploymentProcessor(sharedTldsBuilder));                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.PARSE, Phase.PARSE_WEB_DEPLOYMENT, new WebParsingDeploymentProcessor());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.PARSE, Phase.PARSE_WEB_DEPLOYMENT_FRAGMENT, new WebFragmentParsingDeploymentProcessor());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.PARSE, Phase.PARSE_JBOSS_WEB_DEPLOYMENT, new JBossWebParsingDeploymentProcessor());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.PARSE, Phase.PARSE_ANNOTATION_WAR, new WarAnnotationDeploymentProcessor());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.PARSE, Phase.PARSE_EAR_CONTEXT_ROOT, new EarContextRootProcessor());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.PARSE, Phase.PARSE_WEB_MERGE_METADATA, new WarMetaDataProcessor());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.PARSE, Phase.PARSE_WEB_MERGE_METADATA + 1, new TldParsingDeploymentProcessor()); //todo: fix priority                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.PARSE, Phase.PARSE_WEB_MERGE_METADATA + 2, new org.wildfly.extension.undertow.deployment.WebComponentProcessor()); //todo: fix priority                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.PARSE, Phase.PARSE_WEB_MERGE_METADATA + 3, new DefaultSecurityDomainProcessor(defaultSecurityDomain)); //todo: fix priority                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.DEPENDENCIES, Phase.DEPENDENCIES_WAR_MODULE, new UndertowDependencyProcessor());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.POST_MODULE, Phase.POST_MODULE_UNDERTOW_WEBSOCKETS, new UndertowJSRWebSocketDeploymentProcessor());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.POST_MODULE, Phase.POST_MODULE_UNDERTOW_HANDLERS, new UndertowHandlersDeploymentProcessor());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.POST_MODULE, Phase.POST_MODULE_UNDERTOW_HANDLERS + 1, new ExternalTldParsingDeploymentProcessor()); //todo: fix priority                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.POST_MODULE, Phase.POST_MODULE_UNDERTOW_HANDLERS + 2, new UndertowServletContainerDependencyProcessor(defaultContainer)); //todo: fix priority                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.INSTALL, Phase.INSTALL_SHARED_SESSION_MANAGER, new SharedSessionManagerDeploymentProcessor(defaultServer));                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.INSTALL, Phase.INSTALL_SERVLET_INIT_DEPLOYMENT, new ServletContainerInitializerDeploymentProcessor());                processorTarget.addDeploymentProcessor(UndertowExtension.SUBSYSTEM_NAME, Phase.INSTALL, Phase.INSTALL_WAR_DEPLOYMENT, new UndertowDeploymentProcessor(defaultVirtualHost, defaultContainer, defaultServer, defaultSecurityDomain, knownSecurityDomain));            }        }, OperationContext.Stage.RUNTIME);        context.getCapabilityServiceTarget()                .addCapability(HTTP_INVOKER_RUNTIME_CAPABILITY, new RemoteHttpInvokerService())                .install();    }
@Override    public boolean login(final String username, final String password) {        // if there is an AuthConfigProvider for the HttpServlet layer and appContext, this method must throw an exception.        String appContext = this.buildAppContext();        AuthConfigProvider provider = AuthConfigFactory.getFactory().getConfigProvider(layer, appContext, null);        if (provider != null) {            ServletException se = new ServletException("login is not supported by the JASPIC mechanism");            throw new SecurityException(se);        }        return super.login(username, password);    }
@Override    public void logout() {        if (!isAuthenticated())            return;        // call cleanSubject() if there is an AuthConfigProvider for the HttpServlet layer and appContext.        String appContext = this.buildAppContext();        if (AuthConfigFactory.getFactory().getConfigProvider(layer, appContext, null) != null) {            Subject authenticatedSubject = this.getAuthenticatedSubject();            MessageInfo messageInfo = this.buildMessageInfo();            this.manager.cleanSubject(messageInfo, authenticatedSubject, layer, appContext, handler);        }        // following the return from cleanSubject(), logout must perform the regular logout processing.        super.logout();    }
@Override    public Account getAuthenticatedAccount() {        Account account = super.getAuthenticatedAccount();        if (account == null)            account = this.cachedAuthenticatedAccount;        return account;    }
private String buildAppContext() {        final ServletRequestContext requestContext = exchange.getAttachment(ServletRequestContext.ATTACHMENT_KEY);        ServletRequest servletRequest = requestContext.getServletRequest();        return servletRequest.getServletContext().getVirtualServerName() + " " + servletRequest.getServletContext().getContextPath();    }
private MessageInfo buildMessageInfo() {        ServletRequestContext servletRequestContext = exchange.getAttachment(ServletRequestContext.ATTACHMENT_KEY);        GenericMessageInfo messageInfo = new GenericMessageInfo();        messageInfo.setRequestMessage(servletRequestContext.getServletRequest());        messageInfo.setResponseMessage(servletRequestContext.getServletResponse());        // when calling cleanSubject, isMandatory must be set to true.        messageInfo.getMap().put("javax.security.auth.message.MessagePolicy.isMandatory", "true");        return messageInfo;    }
private Subject getAuthenticatedSubject() {        Subject subject = null;        org.jboss.security.SecurityContext picketBoxContext = SecurityActions.getSecurityContext();        if (picketBoxContext != null && picketBoxContext.getSubjectInfo() != null)            subject = picketBoxContext.getSubjectInfo().getAuthenticatedSubject();        return subject != null ? subject : new Subject();    }
static String readNameAttribute(final XMLExtendedStreamReader reader) throws XMLStreamException {        return readRequiredAttributes(reader, EnumSet.of(Attribute.NAME)).get(Attribute.NAME);    }
static String readValueAttribute(final XMLExtendedStreamReader reader) throws XMLStreamException {        return readRequiredAttributes(reader, EnumSet.of(Attribute.VALUE)).get(Attribute.VALUE);    }
static Map<Attribute, String> readRequiredAttributes(final XMLExtendedStreamReader reader, final Set<Attribute> attributes) throws XMLStreamException {        final int attributeCount = reader.getAttributeCount();        final Map<Attribute, String> result = new EnumMap<>(Attribute.class);        for (int i = 0; i < attributeCount; i++) {            final Attribute current = Attribute.forName(reader.getAttributeLocalName(i));            if (attributes.contains(current)) {                if (result.put(current, reader.getAttributeValue(i)) != null) {                    throw ParseUtils.duplicateAttribute(reader, current.getLocalName());                }            } else {                throw ParseUtils.unexpectedAttribute(reader, i, attributes.stream().map(Attribute::getLocalName).collect(Collectors.toSet()));            }        }        if (result.isEmpty()) {            throw ParseUtils.missingRequired(reader, attributes.stream().map(Attribute::getLocalName).collect(Collectors.toSet()));        }        return result;    }
public void deploy(DeploymentPhaseContext phaseContext) throws DeploymentUnitProcessingException {        final DeploymentUnit deploymentUnit = phaseContext.getDeploymentUnit();        final ModuleSpecification moduleSpecification = deploymentUnit.getAttachment(Attachments.MODULE_SPECIFICATION);        final ModuleLoader moduleLoader = Module.getBootModuleLoader();        // all applications get the javax.persistence module added to their deplyoment by default        addDependency(moduleSpecification, moduleLoader, deploymentUnit, JAVAX_PERSISTENCE_API_ID, HIBERNATE_TRANSFORMER_ID);        if (!JPADeploymentMarker.isJPADeployment(deploymentUnit)) {            return; // Skip if there are no persistence use in the deployment        }        addDependency(moduleSpecification, moduleLoader, deploymentUnit, JBOSS_AS_JPA_ID, JBOSS_AS_JPA_SPI_ID);        addPersistenceProviderModuleDependencies(phaseContext, moduleSpecification, moduleLoader);    }
private static void addPUServiceDependencyToComponents(final Collection<ComponentDescription> components, final PersistenceUnitMetadataHolder holder) {        if (components == null || components.isEmpty() || holder == null) {            return;        }        for (PersistenceUnitMetadata pu : holder.getPersistenceUnits()) {            String jpaContainerManaged = pu.getProperties().getProperty(Configuration.JPA_CONTAINER_MANAGED);            boolean deployPU = (jpaContainerManaged == null? true : Boolean.parseBoolean(jpaContainerManaged));            if (deployPU) {                final ServiceName puServiceName = PersistenceUnitServiceImpl.getPUServiceName(pu);                for (final ComponentDescription component : components) {                    ROOT_LOGGER.debugf("Adding dependency on PU service %s for component %s", puServiceName, component.getComponentClassName());                    component.addDependency(puServiceName);                }            }        }    }
protected static void registerTransformers(final SubsystemRegistration subsystem) {        ChainedTransformationDescriptionBuilder chained = ResourceTransformationDescriptionBuilder.Factory.createChainedSubystemInstance(CURRENT_MODEL_VERSION);        ModelVersion MODEL_VERSION_EAP64 = ModelVersion.create(1, 4, 0);        ModelVersion MODEL_VERSION_EAP63 = ModelVersion.create(1, 3, 0);//also EAP6.2        ResourceTransformationDescriptionBuilder builder64 = chained.createBuilder(CURRENT_MODEL_VERSION, MODEL_VERSION_EAP64);        builder64.getAttributeBuilder()                .addRejectCheck(RejectAttributeChecker.DEFINED, JacORBSubsystemDefinitions.PERSISTENT_SERVER_ID)                .setDiscard(new DiscardAttributeChecker.DiscardAttributeValueChecker(JacORBSubsystemDefinitions.PERSISTENT_SERVER_ID.getDefaultValue()), JacORBSubsystemDefinitions.PERSISTENT_SERVER_ID)                .setValueConverter(new AttributeConverter.DefaultValueAttributeConverter(JacORBSubsystemDefinitions.INTEROP_CHUNK_RMI_VALUETYPES),JacORBSubsystemDefinitions.INTEROP_CHUNK_RMI_VALUETYPES);        ResourceTransformationDescriptionBuilder builder63 = chained.createBuilder(MODEL_VERSION_EAP64, MODEL_VERSION_EAP63);        builder63.getAttributeBuilder()                .addRejectCheck(RejectAttributeChecker.DEFINED, IORTransportConfigDefinition.ATTRIBUTES.toArray(new AttributeDefinition[0]))                .addRejectCheck(RejectAttributeChecker.DEFINED, IORASContextDefinition.ATTRIBUTES.toArray(new AttributeDefinition[0]))                .addRejectCheck(RejectAttributeChecker.DEFINED, IORSASContextDefinition.ATTRIBUTES.toArray(new AttributeDefinition[0]))                .end()                .rejectChildResource(IORSettingsDefinition.INSTANCE.getPathElement());        chained.buildAndRegister(subsystem, new ModelVersion[]{                MODEL_VERSION_EAP64,                MODEL_VERSION_EAP63        });    }
public static StubStrategy forMethod(String[] paramTypes,                                         String[] excepIds,                                         String[] excepTypes,                                         String retvalType,                                         ClassLoader cl) {        // This "factory method" exists just because I have found it easier        // to invoke a static method (rather than invoking operator new)        // from a stub class dynamically assembled by an instance of        // org.jboss.proxy.ProxyAssembler.        return new StubStrategy(paramTypes, excepIds,                excepTypes, retvalType, cl);    }
public void writeParams(OutputStream out, Object[] params) {        int len = params.length;        if (len != paramWriters.length) {            throw IIOPLogger.ROOT_LOGGER.errorMashalingParams();        }        for (int i = 0; i < len; i++) {            Object param = params[i];            if (param instanceof PortableRemoteObject) {                try {                    param = PortableRemoteObject.toStub((Remote) param);                } catch (NoSuchObjectException e) {                    throw new RuntimeException(e);                }            }            paramWriters[i].write(out, RemoteObjectSubstitutionManager.writeReplaceRemote(param));        }    }
public Exception readException(String id, InputStream in) {        ExceptionReader exceptionReader = (ExceptionReader) exceptionMap.get(id);        if (exceptionReader == null) {            return new UnexpectedException(id);        } else {            return exceptionReader.read(in);        }    }
public boolean isDeclaredException(Throwable t) {        Iterator<Class<?>> iterator = exceptionList.iterator();        while (iterator.hasNext()) {            if (((Class<?>) iterator.next()).isInstance(t)) {                return true;            }        }        return false;    }
public Object convertLocalRetval(Object obj) {        if (retvalRemoteInterface == null)            return obj;        else            return PortableRemoteObject.narrow(obj, retvalRemoteInterface);    }
@Override    public synchronized void start(StartContext context) throws StartException {        if (createQueue) {            try {                final ActiveMQServer server = this.activeMQServerSupplier.get();                MessagingLogger.ROOT_LOGGER.debugf("Deploying queue on server %s with address: %s ,  name: %s, filter: %s ands durable: %s, temporary: %s",                        server.getNodeID(), new SimpleString(queueConfiguration.getAddress()), new SimpleString(queueConfiguration.getName()),                        SimpleString.toSimpleString(queueConfiguration.getFilterString()), queueConfiguration.isDurable(), temporary);                final SimpleString resourceName = new SimpleString(queueConfiguration.getName());                final SimpleString address = new SimpleString(queueConfiguration.getAddress());                final SimpleString filterString = SimpleString.toSimpleString(queueConfiguration.getFilterString());                server.createQueue(address,                        queueConfiguration.getRoutingType(),                        resourceName,                        filterString,                        queueConfiguration.isDurable(),                        temporary);            } catch (Exception e) {                throw new StartException(e);            }        }    }
@Override    public synchronized void stop(StopContext context) {        try {            final ActiveMQServer server = this.activeMQServerSupplier.get();            server.destroyQueue(new SimpleString(queueConfiguration.getName()), null, false);            MessagingLogger.ROOT_LOGGER.debugf("Destroying queue from server %s queue with name: %s",server.getNodeID() , new SimpleString(queueConfiguration.getName()));        } catch(Exception e) {            MessagingLogger.ROOT_LOGGER.failedToDestroy("queue", queueConfiguration.getName());        }    }
static Set<Class<?>> getPotentialViewInterfaces(Class<?> beanClass) {        Class<?>[] interfaces = beanClass.getInterfaces();        if (interfaces == null) {            return Collections.emptySet();        }        final Set<Class<?>> potentialBusinessInterfaces = new HashSet<Class<?>>();        for (Class<?> klass : interfaces) {            // EJB 3.1 FR 4.9.7 bullet 5.3            if (klass.equals(Serializable.class) ||                    klass.equals(Externalizable.class) ||                    klass.getName().startsWith("javax.ejb.") ||                    klass.getName().startsWith("groovy.lang.")) {                continue;            }            potentialBusinessInterfaces.add(klass);        }        return potentialBusinessInterfaces;    }
static Set<DotName> getPotentialViewInterfaces(ClassInfo beanClass) {        DotName[] interfaces = beanClass.interfaces();        if (interfaces == null) {            return Collections.emptySet();        }        final Set<DotName> names = new HashSet<DotName>();        for (DotName dotName : interfaces) {            String name = dotName.toString();            // EJB 3.1 FR 4.9.7 bullet 5.3            // & FR 5.4.2            if (name.equals(Serializable.class.getName()) ||                    name.equals(Externalizable.class.getName()) ||                    name.startsWith("javax.ejb.") ||                    name.startsWith("groovy.lang.")) {                continue;            }            names.add(dotName);        }        return names;    }
public static void putEntityManagerInTransactionRegistry(String scopedPuName, EntityManager entityManager, TransactionSynchronizationRegistry tsr) {        tsr.putResource(scopedPuName, entityManager);    }
private static void writeFilter(final XMLExtendedStreamWriter writer, final ModelNode node) throws XMLStreamException {        if (node.hasDefined(CommonAttributes.FILTER.getName())) {            writer.writeEmptyElement(CommonAttributes.FILTER.getXmlName());            writer.writeAttribute(CommonAttributes.STRING, node.get(CommonAttributes.FILTER.getName()).asString());        }    }
protected static void resolveOrder(List<WebOrdering> webOrderings, List<String> order) {        List<Ordering> work = new ArrayList<Ordering>();        // Populate the work Ordering list        Iterator<WebOrdering> webOrderingsIterator = webOrderings.iterator();        while (webOrderingsIterator.hasNext()) {            WebOrdering webOrdering = webOrderingsIterator.next();            Ordering ordering = new Ordering();            ordering.ordering = webOrdering;            ordering.afterOthers = webOrdering.isAfterOthers();            ordering.beforeOthers = webOrdering.isBeforeOthers();            if (ordering.afterOthers && ordering.beforeOthers) {                // Cannot be both after and before others                throw new IllegalStateException(UndertowLogger.ROOT_LOGGER.invalidRelativeOrderingBeforeAndAfter(webOrdering.getJar()));            }            work.add(ordering);        }        // Create double linked relationships between the orderings,        // and resolve names        Iterator<Ordering> workIterator = work.iterator();        while (workIterator.hasNext()) {            Ordering ordering = workIterator.next();            WebOrdering webOrdering = ordering.ordering;            Iterator<String> after = webOrdering.getAfter().iterator();            while (after.hasNext()) {                String name = after.next();                Iterator<Ordering> workIterator2 = work.iterator();                boolean found = false;                while (workIterator2.hasNext()) {                    Ordering ordering2 = workIterator2.next();                    if (name.equals(ordering2.ordering.getName())) {                        if (found) {                            // Duplicate name                            throw new IllegalStateException(UndertowLogger.ROOT_LOGGER.invalidRelativeOrderingDuplicateName(webOrdering.getJar()));                        }                        ordering.addAfter(ordering2);                        ordering2.addBefore(ordering);                        found = true;                    }                }                if (!found) {                    // Unknown name                    UndertowLogger.ROOT_LOGGER.invalidRelativeOrderingUnknownName(webOrdering.getJar());                }            }            Iterator<String> before = webOrdering.getBefore().iterator();            while (before.hasNext()) {                String name = before.next();                Iterator<Ordering> workIterator2 = work.iterator();                boolean found = false;                while (workIterator2.hasNext()) {                    Ordering ordering2 = workIterator2.next();                    if (name.equals(ordering2.ordering.getName())) {                        if (found) {                            // Duplicate name                            throw new IllegalStateException(UndertowLogger.ROOT_LOGGER.invalidRelativeOrderingDuplicateName(webOrdering.getJar()));                        }                        ordering.addBefore(ordering2);                        ordering2.addAfter(ordering);                        found = true;                    }                }                if (!found) {                    // Unknown name                    UndertowLogger.ROOT_LOGGER.invalidRelativeOrderingUnknownName(webOrdering.getJar());                }            }        }        // Validate ordering        workIterator = work.iterator();        while (workIterator.hasNext()) {            workIterator.next().validate();        }        // Create three ordered lists that will then be merged        List<Ordering> tempOrder = new ArrayList<Ordering>();        // Create the ordered list of fragments which are before others        workIterator = work.iterator();        while (workIterator.hasNext()) {            Ordering ordering = workIterator.next();            if (ordering.beforeOthers) {                // Insert at the first possible position                int insertAfter = -1;                boolean last = ordering.isLastBeforeOthers();                int lastBeforeOthers = -1;                for (int i = 0; i < tempOrder.size(); i++) {                    if (ordering.isAfter(tempOrder.get(i))) {                        insertAfter = i;                    }                    if (tempOrder.get(i).beforeOthers) {                        lastBeforeOthers = i;                    }                }                int pos = insertAfter;                if (last && lastBeforeOthers > insertAfter) {                    pos = lastBeforeOthers;                }                tempOrder.add(pos + 1, ordering);            } else if (ordering.afterOthers) {                // Insert at the last possible element                int insertBefore = tempOrder.size();                boolean first = ordering.isFirstAfterOthers();                int firstAfterOthers = tempOrder.size();                for (int i = tempOrder.size() - 1; i >= 0; i--) {                    if (ordering.isBefore(tempOrder.get(i))) {                        insertBefore = i;                    }                    if (tempOrder.get(i).afterOthers) {                        firstAfterOthers = i;                    }                }                int pos = insertBefore;                if (first && firstAfterOthers < insertBefore) {                    pos = firstAfterOthers;                }                tempOrder.add(pos, ordering);            } else {                // Insert according to other already inserted elements                int insertAfter = -1;                int insertBefore = tempOrder.size();                for (int i = 0; i < tempOrder.size(); i++) {                    if (ordering.isAfter(tempOrder.get(i)) || tempOrder.get(i).beforeOthers) {                        insertAfter = i;                    }                    if (ordering.isBefore(tempOrder.get(i)) || tempOrder.get(i).afterOthers) {                        insertBefore = i;                    }                }                if (insertAfter > insertBefore) {                    // Conflicting order (probably caught earlier)                    throw new IllegalStateException(UndertowLogger.ROOT_LOGGER.invalidRelativeOrderingConflict(ordering.ordering.getJar()));                }                // Insert somewhere in the range                tempOrder.add(insertAfter + 1, ordering);            }        }        // Create the final ordered list        Iterator<Ordering> tempOrderIterator = tempOrder.iterator();        while (tempOrderIterator.hasNext()) {            Ordering ordering = tempOrderIterator.next();            order.add(ordering.ordering.getJar());        }    }
private static SecurityContext createSecurityContext(final String domain) {        return AccessController.doPrivileged(new PrivilegedAction<SecurityContext>() {            @Override            public SecurityContext run() {                try {                    return SecurityContextFactory.createSecurityContext(domain);                } catch (Exception e) {                    throw new RuntimeException(e);                }            }        });    }
private static void setSecurityContextOnAssociation(final SecurityContext sc) {        AccessController.doPrivileged(new PrivilegedAction<Void>() {            @Override            public Void run() {                SecurityContextAssociation.setSecurityContext(sc);                return null;            }        });    }
public void writeContent(final XMLExtendedStreamWriter writer, final SubsystemMarshallingContext context)            throws XMLStreamException {        context.startSubsystemElement(org.jboss.as.jdr.Namespace.CURRENT.getUriString(), false);        writer.writeEndElement();    }
public CallAS7 param(String key, String val) {        this.parameters.put(key, val);        return this;    }
public CallAS7 resource(String... parts) {        for(String part : parts ) {            this.resource.add(part);        }        return this;    }
private static Object getLockOwner(final TransactionSynchronizationRegistry transactionSynchronizationRegistry) {        Object owner = transactionSynchronizationRegistry.getTransactionKey();        return owner != null ? owner : Thread.currentThread();    }
static void releaseInstance(final StatefulSessionComponentInstance instance, boolean toDiscard) {        try {            if (!instance.isDiscarded() && !toDiscard) {                // mark the SFSB instance as no longer in use                instance.getComponent().getCache().release(instance);            }        } finally {            instance.setSynchronizationRegistered(false);            // release the lock on the SFSB instance            releaseLock(instance);        }    }
static void releaseLock(final StatefulSessionComponentInstance instance) {        instance.getLock().unlock(getLockOwner(instance.getComponent().getTransactionSynchronizationRegistry()));        ROOT_LOGGER.tracef("Released lock: %s", instance.getLock());    }
public void add(InputStream is, String path) {        byte [] buffer = new byte[1024];        try {            String entryName = this.baseName + "/" + path;            ZipEntry ze = new ZipEntry(entryName);            zos.putNextEntry(ze);            int bytesRead = is.read(buffer);            while( bytesRead > -1 ) {                zos.write(buffer, 0, bytesRead);                bytesRead = is.read(buffer);            }        }        catch (ZipException ze) {            ROOT_LOGGER.debugf(ze, "%s is already in the zip", path);        }        catch (Exception e) {            ROOT_LOGGER.debugf(e, "Error when adding %s", path);        }        finally {            try {                zos.closeEntry();            }            catch (Exception e) {                ROOT_LOGGER.debugf(e, "Error when closing entry for %s", path);            }        }    }
public void add(VirtualFile file, InputStream is) throws Exception {        String name = "JBOSS_HOME" + file.getPhysicalFile().getAbsolutePath().substring(this.jbossHome.length());        this.add(is, name);    }
public void add(String content, String path) throws Exception {        StringBuilder name = new StringBuilder("sos_strings/");        name.append(this.env.getProductName().replace(" ", "_").toLowerCase());        name.append("-");        name.append(this.env.getProductVersion().split("\\.")[0]);        name.append("/");        name.append(path);        this.add(new ByteArrayInputStream(content.getBytes(StandardCharsets.UTF_8)), name.toString());    }
public void addAsString(InputStream stream, String path) throws Exception {        StringBuilder name = new StringBuilder("sos_strings/");        name.append(this.env.getProductName().replace(" ", "_").toLowerCase());        name.append("-");        name.append(this.env.getProductVersion().split("\\.")[0]);        name.append("/");        name.append(path);        this.add(stream, name.toString());    }
public void addLog(String content, String logName) throws Exception {        String name = "sos_logs/" + logName;        this.add(new ByteArrayInputStream(content.getBytes(StandardCharsets.UTF_8)), name);    }
static Thread createThread(final Runnable runnable, final String threadName) {        return ! WildFlySecurityManager.isChecking() ? new Thread(runnable, threadName) : doPrivileged(new CreateThreadAction(runnable, threadName));    }
private void addJSFImpl(String jsfVersion,            ModuleSpecification moduleSpecification,            ModuleLoader moduleLoader) {        if (jsfVersion.equals(JsfVersionMarker.WAR_BUNDLES_JSF_IMPL)) return;        ModuleIdentifier jsfModule = moduleIdFactory.getImplModId(jsfVersion);        ModuleDependency jsfImpl = new ModuleDependency(moduleLoader, jsfModule, false, false, true, false);        jsfImpl.addImportFilter(PathFilters.getMetaInfFilter(), true);        moduleSpecification.addSystemDependency(jsfImpl);    }
private void addCDIFlag(WarMetaData warMetaData, DeploymentUnit deploymentUnit) {        JBossWebMetaData webMetaData = warMetaData.getMergedJBossWebMetaData();        if (webMetaData == null) {            webMetaData = new JBossWebMetaData();            warMetaData.setMergedJBossWebMetaData(webMetaData);        }        List<ParamValueMetaData> contextParams = webMetaData.getContextParams();        if (contextParams == null) {            contextParams = new ArrayList<ParamValueMetaData>();        }        boolean isCDI = false;        final CapabilityServiceSupport support = deploymentUnit.getAttachment(Attachments.CAPABILITY_SERVICE_SUPPORT);        if (support.hasCapability(WELD_CAPABILITY_NAME)) {            isCDI = support.getOptionalCapabilityRuntimeAPI(WELD_CAPABILITY_NAME, WeldCapability.class).get()                    .isPartOfWeldDeployment(deploymentUnit);        }        ParamValueMetaData param = new ParamValueMetaData();        param.setParamName(IS_CDI_PARAM);        param.setParamValue(Boolean.toString(isCDI));        contextParams.add(param);        webMetaData.setContextParams(contextParams);    }
protected ComponentView getComponentView() {        ComponentView cv = componentView;        // we need to check both, otherwise it is possible for        // componentView to be initialized before reference        if (cv == null) {            synchronized (this) {                cv = componentView;                if (cv == null) {                    cv = getMSCService(componentViewName, ComponentView.class);                    if (cv == null) {                        throw WSLogger.ROOT_LOGGER.cannotFindComponentView(componentViewName);                    }                    if (reference == null) {                        try {                            reference = cv.createInstance();                        } catch (Exception e) {                            throw new RuntimeException(e);                        }                    }                    componentView = cv;                }            }        }        return cv;    }
public void invoke(final Endpoint endpoint, final Invocation wsInvocation) throws Exception {        try {            if (!EndpointState.STARTED.equals(endpoint.getState())) {                throw WSLogger.ROOT_LOGGER.endpointAlreadyStopped(endpoint.getShortName());            }            SecurityDomainContext securityDomainContext = endpoint.getSecurityDomainContext();            securityDomainContext.runAs((Callable<Void>) () -> {                invokeInternal(endpoint, wsInvocation);                return null;            });        } catch (Throwable t) {            handleInvocationException(t);        } finally {            onAfterInvocation(wsInvocation);        }    }
protected Method getComponentViewMethod(final Method seiMethod, final Collection<Method> viewMethods) {       for (final Method viewMethod : viewMethods) {           if (matches(seiMethod, viewMethod)) {               return viewMethod;           }       }       throw new IllegalStateException();   }
private boolean matches(final Method seiMethod, final Method viewMethod) {       if (!seiMethod.getName().equals(viewMethod.getName())) return false;       final Class<?>[] sourceParams = seiMethod.getParameterTypes();       final Class<?>[] targetParams = viewMethod.getParameterTypes();       if (sourceParams.length != targetParams.length) return false;       for (int i = 0; i < sourceParams.length; i++) {           if (!sourceParams[i].equals(targetParams[i])) return false;       }       return true;   }
public static Resource createManagementStatisticsResource(            final ManagementAdaptor managementAdaptor,            final String scopedPersistenceUnitName,            final DeploymentUnit deploymentUnit) {        synchronized (existingResourceDescriptionResolver) {            final EntityManagerFactoryLookup entityManagerFactoryLookup = new EntityManagerFactoryLookup();            final Statistics statistics = managementAdaptor.getStatistics();            if (false == existingResourceDescriptionResolver.contains(managementAdaptor.getVersion())) {                // setup statistics (this used to be part of JPA subsystem startup)                ResourceDescriptionResolver resourceDescriptionResolver = new StandardResourceDescriptionResolver(                        statistics.getResourceBundleKeyPrefix(), statistics.getResourceBundleName(), statistics.getClass().getClassLoader()){                    private ResourceDescriptionResolver fallback = JPAExtension.getResourceDescriptionResolver();                    //add a fallback in case provider doesn't have all properties properly defined                    @Override                    public String getResourceAttributeDescription(String attributeName, Locale locale, ResourceBundle bundle) {                        if (bundle.containsKey(getBundleKey(attributeName))) {                            return super.getResourceAttributeDescription(attributeName, locale, bundle);                        }else{                            return fallback.getResourceAttributeDescription(attributeName, locale, fallback.getResourceBundle(locale));                        }                    }                };                PathElement subsystemPE = PathElement.pathElement(ModelDescriptionConstants.SUBSYSTEM, JPAExtension.SUBSYSTEM_NAME);                ManagementResourceRegistration deploymentResourceRegistration = deploymentUnit.getAttachment(DeploymentModelUtils.MUTABLE_REGISTRATION_ATTACHMENT);                ManagementResourceRegistration deploymentSubsystemRegistration =                        deploymentResourceRegistration.getSubModel(PathAddress.pathAddress(subsystemPE));                ManagementResourceRegistration subdeploymentSubsystemRegistration =                        deploymentResourceRegistration.getSubModel(PathAddress.pathAddress(PathElement.pathElement(ModelDescriptionConstants.SUBDEPLOYMENT), subsystemPE));                ManagementResourceRegistration providerResource = deploymentSubsystemRegistration.registerSubModel(                        new ManagementResourceDefinition(PathElement.pathElement(managementAdaptor.getIdentificationLabel()), resourceDescriptionResolver, statistics, entityManagerFactoryLookup));                providerResource.registerReadOnlyAttribute(PersistenceUnitServiceHandler.SCOPED_UNIT_NAME, null);                providerResource = subdeploymentSubsystemRegistration.registerSubModel(                        new ManagementResourceDefinition(PathElement.pathElement(managementAdaptor.getIdentificationLabel()), resourceDescriptionResolver, statistics, entityManagerFactoryLookup));                providerResource.registerReadOnlyAttribute(PersistenceUnitServiceHandler.SCOPED_UNIT_NAME, null);                existingResourceDescriptionResolver.add(managementAdaptor.getVersion());            }            // create (per deployment) dynamic Resource implementation that can reflect the deployment specific names (e.g. jpa entity classname/Hibernate region name)            return new DynamicManagementStatisticsResource(statistics, scopedPersistenceUnitName, managementAdaptor.getIdentificationLabel(), entityManagerFactoryLookup);        }    }
@Override    public void readElement(XMLExtendedStreamReader reader, List<ModelNode> list) throws XMLStreamException {        // no attributes        if (reader.getAttributeCount() > 0) {            throw unexpectedAttribute(reader, 0);        }        final ModelNode address = new ModelNode();        address.add(ModelDescriptionConstants.SUBSYSTEM, TransactionExtension.SUBSYSTEM_NAME);        address.protect();        final ModelNode subsystem = new ModelNode();        subsystem.get(OP).set(ADD);        subsystem.get(OP_ADDR).set(address);        list.add(subsystem);        // elements        final EnumSet<Element> required = EnumSet.of(Element.RECOVERY_ENVIRONMENT, Element.CORE_ENVIRONMENT);        final EnumSet<Element> encountered = EnumSet.noneOf(Element.class);        while (reader.hasNext() && reader.nextTag() != END_ELEMENT) {            switch (Namespace.forUri(reader.getNamespaceURI())) {                case TRANSACTIONS_1_1: {                    final Element element = Element.forName(reader.getLocalName());                    required.remove(element);                    if (!encountered.add(element)) {                        throw unexpectedElement(reader);                    }                    switch (element) {                        case RECOVERY_ENVIRONMENT: {                            parseRecoveryEnvironmentElement(reader, subsystem);                            break;                        }                        case CORE_ENVIRONMENT: {                            parseCoreEnvironmentElement(reader, subsystem);                            break;                        }                        case COORDINATOR_ENVIRONMENT: {                            parseCoordinatorEnvironmentElement(reader, subsystem);                            break;                        }                        case OBJECT_STORE: {                            parseObjectStoreEnvironmentElementAndEnrichOperation(reader, subsystem);                            break;                        }                        case JTS: {                            parseJts(reader, subsystem);                            break;                        }                        default: {                            throw unexpectedElement(reader);                        }                    }                    break;                }                default: {                    throw unexpectedElement(reader);                }            }        }        if (!required.isEmpty()) {            throw missingRequiredElement(reader, required);        }        final ModelNode logStoreAddress = address.clone();        final ModelNode operation = new ModelNode();        operation.get(OP).set(ADD);        logStoreAddress.add(LogStoreConstants.LOG_STORE, LogStoreConstants.LOG_STORE);        logStoreAddress.protect();        operation.get(OP_ADDR).set(logStoreAddress);        list.add(operation);    }
public InjectedValue<ExceptionSupplier<CredentialSource, Exception>> getBridgeCredentialSourceSupplierInjector(String name) {        if (bridgeCredentialSource.containsKey(name)) {            return bridgeCredentialSource.get(name);        } else {            InjectedValue<ExceptionSupplier<CredentialSource, Exception>> injector = new InjectedValue<>();            bridgeCredentialSource.put(name, injector);            return injector;        }    }
@Override    public void registerWork(Work work, Xid xid, long timeout) throws WorkCompletedException {        try {            // jca provides timeout in milliseconds, SubordinationManager expects seconds            int timeout_seconds = (int) timeout/1000;            // unlimited timeout for jca means -1 which fails in wfly client            if(timeout_seconds <= 0) timeout_seconds = ContextTransactionManager.getGlobalDefaultTransactionTimeout();            localTransactionContext.findOrImportTransaction(xid, timeout_seconds);        } catch (XAException xae) {            throw TransactionLogger.ROOT_LOGGER.cannotFindOrImportInflowTransaction(xid, work, xae);        }        jbossXATerminator.registerWork(work, xid, timeout);    }
@Override    public void startWork(Work work, Xid xid) throws WorkCompletedException {        LocalTransaction transaction = null;        try {            ImportResult<LocalTransaction> transactionImportResult = localTransactionContext.findOrImportTransaction(xid, 0);            transaction = transactionImportResult.getTransaction();            ContextTransactionManager.getInstance().resume(transaction);        } catch (XAException xae) {            throw TransactionLogger.ROOT_LOGGER.cannotFindOrImportInflowTransaction(xid, work, xae);        } catch (InvalidTransactionException ite) {            throw TransactionLogger.ROOT_LOGGER.importedInflowTransactionIsInactive(xid, work, ite);        } catch (SystemException se) {            throw TransactionLogger.ROOT_LOGGER.cannotResumeInflowTransactionUnexpectedError(transaction, work, se);        }    }
@Override    public void endWork(Work work, Xid xid) {        jbossXATerminator.cancelWork(work, xid);        try {            ContextTransactionManager.getInstance().suspend();        } catch (SystemException se) {            throw TransactionLogger.ROOT_LOGGER.cannotSuspendInflowTransactionUnexpectedError(work, se);        }    }
@Override    public void cancelWork(Work work, Xid xid) {        jbossXATerminator.cancelWork(work, xid);    }
public String getSecurityDomain(final Deployment dep) {        String securityDomain = null;        for (final EJBEndpoint ejbEndpoint : getEjbEndpoints(dep)) {            String nextSecurityDomain = ejbEndpoint.getSecurityDomain();            if (nextSecurityDomain == null || nextSecurityDomain.isEmpty()) {                nextSecurityDomain = null;            }            securityDomain = getDomain(securityDomain, nextSecurityDomain);        }        if (securityDomain == null) {            final DeploymentUnit unit = WSHelper.getRequiredAttachment(dep, DeploymentUnit.class);            if (unit.getParent() != null) {                final EarMetaData jbossAppMD = unit.getParent().getAttachment(Attachments.EAR_METADATA);                return jbossAppMD instanceof JBossAppMetaData ? ((JBossAppMetaData)jbossAppMD).getSecurityDomain() : null;            }        }        return securityDomain;    }
public boolean isSecureWsdlAccess(final Endpoint endpoint) {        final EJBSecurityMetaData ejbSecurityMD = this.getEjbSecurityMetaData(endpoint);        final boolean hasEjbSecurityMD = ejbSecurityMD != null;        return hasEjbSecurityMD ? ejbSecurityMD.getSecureWSDLAccess() : false;    }
public String getTransportGuarantee(final Endpoint endpoint) {        final EJBSecurityMetaData ejbSecurityMD = this.getEjbSecurityMetaData(endpoint);        final boolean hasEjbSecurityMD = ejbSecurityMD != null;        return hasEjbSecurityMD ? ejbSecurityMD.getTransportGuarantee() : null;    }
private EJBSecurityMetaData getEjbSecurityMetaData(final Endpoint endpoint) {        final String ejbName = endpoint.getShortName();        final Deployment dep = endpoint.getService().getDeployment();        final EJBArchiveMetaData ejbArchiveMD = WSHelper.getOptionalAttachment(dep, EJBArchiveMetaData.class);        final EJBMetaData ejbMD = ejbArchiveMD != null ? ejbArchiveMD.getBeanByEjbName(ejbName) : null;        return ejbMD != null ? ejbMD.getSecurityMetaData() : null;    }
private String getDomain(final String oldSecurityDomain, final String nextSecurityDomain) {        if (nextSecurityDomain == null) {            return oldSecurityDomain;        }        if (oldSecurityDomain == null) {            return nextSecurityDomain;        }        ensureSameDomains(oldSecurityDomain, nextSecurityDomain);        return oldSecurityDomain;    }
private void ensureSameDomains(final String oldSecurityDomain, final String newSecurityDomain) {        final boolean domainsDiffer = !oldSecurityDomain.equals(newSecurityDomain);        if (domainsDiffer)            throw WSLogger.ROOT_LOGGER.multipleSecurityDomainsDetected(oldSecurityDomain, newSecurityDomain);    }
public void getResourceValue(final ResolutionContext resolutionContext, final ServiceBuilder<?> serviceBuilder, final DeploymentPhaseContext phaseContext, final Injector<ManagedReferenceFactory> injector) {        final String applicationName = resolutionContext.getApplicationName();        final String moduleName = resolutionContext.getModuleName();        final String componentName = resolutionContext.getComponentName();        final boolean compUsesModule = resolutionContext.isCompUsesModule();        final String scheme = org.jboss.as.naming.InitialContext.getURLScheme(lookupName);        if (scheme == null) {            // relative name, build absolute name and setup normal lookup injection            if (componentName != null && !compUsesModule) {                ContextNames.bindInfoFor(applicationName, moduleName, componentName, "java:comp/env/" + lookupName)                        .setupLookupInjection(serviceBuilder, injector, phaseContext.getDeploymentUnit(), optional);            } else if (compUsesModule) {                ContextNames.bindInfoFor(applicationName, moduleName, componentName, "java:module/env/" + lookupName)                        .setupLookupInjection(serviceBuilder, injector, phaseContext.getDeploymentUnit(), optional);            } else {                ContextNames.bindInfoFor(applicationName, moduleName, componentName, "java:jboss/env/" + lookupName)                        .setupLookupInjection(serviceBuilder, injector, phaseContext.getDeploymentUnit(), optional);            }        } else {            if (scheme.equals("java")) {                // an absolute java name, setup normal lookup injection                if (compUsesModule && lookupName.startsWith("java:comp/")) {                    // switch "comp" with "module"                    ContextNames.bindInfoFor(applicationName, moduleName, componentName, "java:module/" + lookupName.substring(10))                            .setupLookupInjection(serviceBuilder, injector, phaseContext.getDeploymentUnit(), optional);                } else {                    ContextNames.bindInfoFor(applicationName, moduleName, componentName, lookupName)                            .setupLookupInjection(serviceBuilder, injector, phaseContext.getDeploymentUnit(), optional);                }            } else {                // an absolute non java name                final ManagedReferenceFactory managedReferenceFactory;                if (URL_SCHEMES.contains(scheme)) {                    // a Java EE Standard Resource Manager Connection Factory for URLs, using lookup to define value of URL, inject factory that creates URL instances                    managedReferenceFactory = new ManagedReferenceFactory() {                        @Override                        public ManagedReference getReference() {                            try {                                return new ImmediateManagedReference(new URL(lookupName));                            } catch (MalformedURLException e) {                                throw new RuntimeException(e);                            }                        }                    };                } else {                    // lookup for a non java jndi resource, inject factory which does a true jndi lookup                    managedReferenceFactory = new ManagedReferenceFactory() {                        @Override                        public ManagedReference getReference() {                            try {                                return new ImmediateManagedReference(new InitialContext().lookup(lookupName));                            } catch (NamingException e) {                                EeLogger.ROOT_LOGGER.tracef(e, "failed to lookup %s", lookupName);                                return null;                            }                        }                    };                }                injector.inject(managedReferenceFactory);            }        }    }
@Override    public void readElement(final XMLExtendedStreamReader reader, final List<ModelNode> list) throws XMLStreamException {        // Require no attributes or content        requireNoAttributes(reader);        requireNoContent(reader);        list.add(Util.createAddOperation(PathAddress.pathAddress(WeldExtension.PATH_SUBSYSTEM)));    }
void setIDLName(String idlName) {        super.setIDLName(idlName);        // If the first char is an uppercase letter and the second char is not        // an uppercase letter, then convert the first char to lowercase.        if (idlName.charAt(0) >= 0x41 && idlName.charAt(0) <= 0x5a                && (idlName.length() <= 1                || idlName.charAt(1) < 0x41 || idlName.charAt(1) > 0x5a)) {            idlName =                    idlName.substring(0, 1).toLowerCase(Locale.ENGLISH) + idlName.substring(1);        }        if (accessorAnalysis != null)            accessorAnalysis.setIDLName("_get_" + idlName);        if (mutatorAnalysis != null)            mutatorAnalysis.setIDLName("_set_" + idlName);    }
public String getAbsoluteName() {        final StringBuilder absolute = new StringBuilder();        if (parent != null) {            absolute.append(parent).append(ENTRY_SEPARATOR);        }        absolute.append(local);        return absolute.toString();    }
public static JndiName of(final String name) {        if(name == null || name.isEmpty()) throw NamingLogger.ROOT_LOGGER.invalidJndiName(name);        final String[] parts = name.split(ENTRY_SEPARATOR);        JndiName current = null;        for(String part : parts) {            current = new JndiName(current, part);        }        return current;    }
@Override    public void deploy(DeploymentPhaseContext phaseContext) throws DeploymentUnitProcessingException {        final DeploymentUnit deploymentUnit = phaseContext.getDeploymentUnit();        final ResourceRoot resourceRoot = deploymentUnit.getAttachment(Attachments.DEPLOYMENT_ROOT);        final VirtualFile deploymentRoot = resourceRoot.getRoot();        final boolean resolveProperties = Util.shouldResolveJBoss(deploymentUnit);        IronJacamarXmlDescriptor xmlDescriptor = process(deploymentRoot, resolveProperties);        if (xmlDescriptor != null) {            deploymentUnit.putAttachment(IronJacamarXmlDescriptor.ATTACHMENT_KEY, xmlDescriptor);        }    }
@Override    public void handleRequest(HttpServerExchange exchange) throws Exception {        runningCount.increment();        exchange.addExchangeCompleteListener(new ExchangeCompletionListener() {            @Override            public void exchangeEvent(HttpServerExchange exchange, NextListener nextListener) {                runningCount.decrement();                // Proceed to next listener must be called!                nextListener.proceed();            }        });        wrappedHandler.handleRequest(exchange);    }
@Override    JMSContext getDelegate() {        boolean inTx = isInTransaction();        AbstractJMSContext jmsContext = inTx ? transactedJMSContext.get() : requestedJMSContext;        ROOT_LOGGER.debugf("using %s to create the injected JMSContext", jmsContext, id);        ConnectionFactory connectionFactory = getConnectionFactory();        JMSContext contextInstance = jmsContext.getContext(id, info, connectionFactory);        //fix of  WFLY-9501        // CCM tries to clean opened connections before execution of @PreDestroy method on JMSContext - which is executed after completion, see .        // Correct phase to call close is afterCompletion {@see TransactionSynchronizationRegistry.registerInterposedSynchronization}        if(inTx) {            TransactedJMSContext transactedJMSContext = (TransactedJMSContext)jmsContext;            transactedJMSContext.registerCleanUpListener(transactionSynchronizationRegistry, contextInstance);        }        return contextInstance;    }
private boolean isInTransaction() {        TransactionSynchronizationRegistry tsr = getTransactionSynchronizationRegistry();        boolean inTx = tsr.getTransactionStatus() == Status.STATUS_ACTIVE;        return inTx;    }
private TransactionSynchronizationRegistry getTransactionSynchronizationRegistry() {        TransactionSynchronizationRegistry cachedTSR = transactionSynchronizationRegistry;        if (cachedTSR == null) {            cachedTSR = (TransactionSynchronizationRegistry) lookup(TRANSACTION_SYNCHRONIZATION_REGISTRY_LOOKUP);            transactionSynchronizationRegistry = cachedTSR;        }        return cachedTSR;    }
private ConnectionFactory getConnectionFactory() {        ConnectionFactory cachedCF = connectionFactory;        if (cachedCF == null) {            cachedCF = (ConnectionFactory)lookup(info.getConnectionFactoryLookup());            connectionFactory = cachedCF;        }        return cachedCF;    }
public static String getLastComponent(final Name name) {        if(name.size() > 0)            return name.get(name.size() - 1);        return "";    }
public static boolean isEmpty(final Name name) {        return name.isEmpty() || (name.size() == 1 && "".equals(name.get(0)));    }
public static NameNotFoundException nameNotFoundException(final String name, final Name contextName) {        return NamingLogger.ROOT_LOGGER.nameNotFoundInContext(name, contextName);    }
public static NamingException namingException(final String message, final Throwable cause) {        final NamingException exception = new NamingException(message);        if (cause != null) exception.initCause(cause);        return exception;    }
public static NamingException namingException(final String message, final Throwable cause, final Name remainingName) {        final NamingException exception = namingException(message, cause);        exception.setRemainingName(remainingName);        return exception;    }
public static CannotProceedException cannotProceedException(final Object resolvedObject, final Name remainingName) {        final CannotProceedException cpe = new CannotProceedException();        cpe.setResolvedObj(resolvedObject);        cpe.setRemainingName(remainingName);        return cpe;    }
public static <T> NamingEnumeration<T> namingEnumeration(final Collection<T> collection) {        final Iterator<T> iterator = collection.iterator();        return new NamingEnumeration<T>() {            public T next() {                return nextElement();            }            public boolean hasMore() {                return hasMoreElements();            }            public void close() {            }            public boolean hasMoreElements() {                return iterator.hasNext();            }            public T nextElement() {                return iterator.next();            }        };    }
public static void rebind(final Context ctx, final String name, final Object value) throws NamingException {       final Name n = ctx.getNameParser("").parse(name);       rebind(ctx, n, value);    }
public static void unbind(Context ctx, String name) throws NamingException {        unbind(ctx, ctx.getNameParser("").parse(name));    }
protected void handleReadAttribute(String attributeName, OperationContext context, ModelNode operation) throws OperationFailedException {        unsupportedAttribute(attributeName);    }
protected Object handleOperation(String operationName, OperationContext context, ModelNode operation) throws OperationFailedException {        unsupportedOperation(operationName);        throw MessagingLogger.ROOT_LOGGER.unsupportedOperation(operationName);    }
protected final T getActiveMQComponentControl(final OperationContext context, final ModelNode operation, final boolean forWrite) throws OperationFailedException {        final ServiceName artemisServiceName = MessagingServices.getActiveMQServiceName(PathAddress.pathAddress(operation.get(ModelDescriptionConstants.OP_ADDR)));        ServiceController<?> artemisService = context.getServiceRegistry(forWrite).getService(artemisServiceName);        ActiveMQServer server = ActiveMQServer.class.cast(artemisService.getValue());        PathAddress address = PathAddress.pathAddress(operation.require(OP_ADDR));         T control = getActiveMQComponentControl(server, address);         if (control == null) {             throw ControllerLogger.ROOT_LOGGER.managementResourceNotFound(address);         }         return control;    }
private String parseConnectionAttributes_5_0(final XMLExtendedStreamReader reader,  final ModelNode connectionDefinitionNode)            throws XMLStreamException {        String poolName = null;        String jndiName = null;        int attributeSize = reader.getAttributeCount();        for (int i = 0; i < attributeSize; i++) {            ConnectionDefinition.Attribute attribute = ConnectionDefinition.Attribute.forName(reader.getAttributeLocalName(i));            String value = reader.getAttributeValue(i);            switch (attribute) {                case ENABLED: {                    ENABLED.parseAndSetParameter(value, connectionDefinitionNode, reader);                    break;                }                case CONNECTABLE: {                    CONNECTABLE.parseAndSetParameter(value, connectionDefinitionNode, reader);                    break;                }                case TRACKING: {                    TRACKING.parseAndSetParameter(value, connectionDefinitionNode, reader);                    break;                }                case JNDI_NAME: {                    jndiName = value;                    JNDINAME.parseAndSetParameter(jndiName, connectionDefinitionNode, reader);                    break;                }                case POOL_NAME: {                    poolName = value;                    break;                }                case USE_JAVA_CONTEXT: {                    USE_JAVA_CONTEXT.parseAndSetParameter(value, connectionDefinitionNode, reader);                    break;                }                case USE_CCM: {                    USE_CCM.parseAndSetParameter(value, connectionDefinitionNode, reader);                    break;                }                case SHARABLE: {                    SHARABLE.parseAndSetParameter(value, connectionDefinitionNode, reader);                    break;                }                case ENLISTMENT: {                    ENLISTMENT.parseAndSetParameter(value, connectionDefinitionNode, reader);                    break;                }                case CLASS_NAME: {                    CLASS_NAME.parseAndSetParameter(value, connectionDefinitionNode, reader);                    break;                }                case MCP: {                    MCP.parseAndSetParameter(value, connectionDefinitionNode, reader);                    break;                }                case ENLISTMENT_TRACE:                    ENLISTMENT_TRACE.parseAndSetParameter(value, connectionDefinitionNode, reader);                    break;                default:                    throw ParseUtils.unexpectedAttribute(reader, i);            }        }        if (poolName == null || poolName.trim().equals("")) {            if (jndiName != null && jndiName.trim().length() != 0) {                if (jndiName.contains("/")) {                    poolName = jndiName.substring(jndiName.lastIndexOf("/") + 1);                } else {                    poolName = jndiName.substring(jndiName.lastIndexOf(":") + 1);                }            } else {                throw ParseUtils.missingRequired(reader, EnumSet.of(ConnectionDefinition.Attribute.JNDI_NAME));            }        }        return poolName;    }
protected void parseConnectionDefinitions_5_0(final XMLExtendedStreamReader reader, final Map<String, ModelNode> map,                                                  final Map<String, HashMap<String, ModelNode>> configMap, final boolean isXa)            throws XMLStreamException, ParserException, ValidateException {        final ModelNode connectionDefinitionNode = new ModelNode();        connectionDefinitionNode.get(OP).set(ADD);        final String poolName = parseConnectionAttributes_5_0(reader, connectionDefinitionNode);        boolean poolDefined = Boolean.FALSE;        while (reader.hasNext()) {            switch (reader.nextTag()) {                case END_ELEMENT: {                    if (Activation.Tag.forName(reader.getLocalName()) == Activation.Tag.CONNECTION_DEFINITION) {                        map.put(poolName, connectionDefinitionNode);                        return;                    } else {                        if (ConnectionDefinition.Tag.forName(reader.getLocalName()) == ConnectionDefinition.Tag.UNKNOWN) {                            throw ParseUtils.unexpectedEndElement(reader);                        }                    }                    break;                }                case START_ELEMENT: {                    switch (ConnectionDefinition.Tag.forName(reader.getLocalName())) {                        case CONFIG_PROPERTY: {                            if (!configMap.containsKey(poolName)) {                                configMap.put(poolName, new HashMap<String, ModelNode>(0));                            }                            parseConfigProperties(reader, configMap.get(poolName));                            break;                        }                        case SECURITY: {                            parseElytronSupportedSecuritySettings(reader, connectionDefinitionNode);                            break;                        }                        case TIMEOUT: {                            parseTimeOut(reader, isXa, connectionDefinitionNode);                            break;                        }                        case VALIDATION: {                            parseValidation(reader, connectionDefinitionNode);                            break;                        }                        case XA_POOL: {                            if (!isXa) {                                throw ParseUtils.unexpectedElement(reader);                            }                            if (poolDefined) {                                throw new ParserException(bundle.multiplePools());                            }                            parseXaPool(reader, connectionDefinitionNode);                            poolDefined = true;                            break;                        }                        case POOL: {                            if (isXa) {                                throw ParseUtils.unexpectedElement(reader);                            }                            if (poolDefined) {                                throw new ParserException(bundle.multiplePools());                            }                            parsePool(reader, connectionDefinitionNode);                            poolDefined = true;                            break;                        }                        case RECOVERY: {                            parseElytronSupportedRecovery(reader, connectionDefinitionNode);                            break;                        }                        default:                            throw ParseUtils.unexpectedElement(reader);                    }                    break;                }            }        }        throw ParseUtils.unexpectedEndElement(reader);    }
protected void parseConnectionDefinitions_1_0(final XMLExtendedStreamReader reader, final Map<String, ModelNode> map,                                                  final Map<String, HashMap<String, ModelNode>> configMap, final boolean isXa)                throws XMLStreamException, ParserException, ValidateException {            final ModelNode connectionDefinitionNode = new ModelNode();            connectionDefinitionNode.get(OP).set(ADD);            String poolName = null;            String jndiName = null;            int attributeSize = reader.getAttributeCount();            boolean poolDefined = Boolean.FALSE;            for (int i = 0; i < attributeSize; i++) {                ConnectionDefinition.Attribute attribute = ConnectionDefinition.Attribute.forName(reader.getAttributeLocalName(i));                String value = reader.getAttributeValue(i);                switch (attribute) {                    case ENABLED: {                        ENABLED.parseAndSetParameter(value, connectionDefinitionNode, reader);                        break;                    }                    case JNDI_NAME: {                        jndiName = value;                        JNDINAME.parseAndSetParameter(jndiName, connectionDefinitionNode, reader);                        break;                    }                    case POOL_NAME: {                        poolName = value;                        break;                    }                    case USE_JAVA_CONTEXT: {                        USE_JAVA_CONTEXT.parseAndSetParameter(value, connectionDefinitionNode, reader);                        break;                    }                    case USE_CCM: {                        USE_CCM.parseAndSetParameter(value, connectionDefinitionNode, reader);                        break;                    }                    case SHARABLE: {                        SHARABLE.parseAndSetParameter(value, connectionDefinitionNode, reader);                        break;                    }                    case ENLISTMENT: {                        ENLISTMENT.parseAndSetParameter(value, connectionDefinitionNode, reader);                        break;                    }                    case CLASS_NAME: {                        CLASS_NAME.parseAndSetParameter(value, connectionDefinitionNode, reader);                        break;                    }                    default:                        throw ParseUtils.unexpectedAttribute(reader,i);                }            }            if (poolName == null || poolName.trim().equals("")) {                if (jndiName != null && jndiName.trim().length() != 0) {                    if (jndiName.contains("/")) {                        poolName = jndiName.substring(jndiName.lastIndexOf("/") + 1);                    } else {                        poolName = jndiName.substring(jndiName.lastIndexOf(":") + 1);                    }                } else {                    throw ParseUtils.missingRequired(reader, EnumSet.of(ConnectionDefinition.Attribute.JNDI_NAME));                }            }            while (reader.hasNext()) {                switch (reader.nextTag()) {                    case END_ELEMENT: {                        if (Activation.Tag.forName(reader.getLocalName()) == Activation.Tag.CONNECTION_DEFINITION) {                            map.put(poolName, connectionDefinitionNode);                            return;                        } else {                            if (ConnectionDefinition.Tag.forName(reader.getLocalName()) == ConnectionDefinition.Tag.UNKNOWN) {                                throw ParseUtils.unexpectedEndElement(reader);                            }                        }                        break;                    }                    case START_ELEMENT: {                        switch (ConnectionDefinition.Tag.forName(reader.getLocalName())) {                            case CONFIG_PROPERTY: {                                if (!configMap.containsKey(poolName)) {                                    configMap.put(poolName, new HashMap<String, ModelNode>(0));                                }                                parseConfigProperties(reader, configMap.get(poolName));                                break;                            }                            case SECURITY: {                                parseSecuritySettings(reader, connectionDefinitionNode);                                break;                            }                            case TIMEOUT: {                                parseTimeOut(reader, isXa, connectionDefinitionNode);                                break;                            }                            case VALIDATION: {                                parseValidation(reader, connectionDefinitionNode);                                break;                            }                            case XA_POOL: {                                if (!isXa) {                                    throw ParseUtils.unexpectedElement(reader);                                }                                if (poolDefined) {                                    throw new ParserException(bundle.multiplePools());                                }                                parseXaPool(reader, connectionDefinitionNode);                                poolDefined = true;                                break;                            }                            case POOL: {                                if (isXa) {                                    throw ParseUtils.unexpectedElement(reader);                                }                                if (poolDefined) {                                    throw new ParserException(bundle.multiplePools());                                }                                parsePool(reader, connectionDefinitionNode);                                poolDefined = true;                                break;                            }                            case RECOVERY: {                                parseRecovery(reader, connectionDefinitionNode);                                break;                            }                            default:                                throw ParseUtils.unexpectedElement(reader);                        }                        break;                    }                }            }            throw ParseUtils.unexpectedEndElement(reader);        }
protected void parseXaPool(XMLExtendedStreamReader reader, ModelNode node) throws XMLStreamException, ParserException, ValidateException {        while (reader.hasNext()) {            switch (reader.nextTag()) {                case END_ELEMENT: {                    if (XaDataSource.Tag.forName(reader.getLocalName()) == XaDataSource.Tag.XA_POOL) {                        return;                    } else {                        if (XaPool.Tag.forName(reader.getLocalName()) == XaPool.Tag.UNKNOWN) {                            throw ParseUtils.unexpectedEndElement(reader);                        }                    }                    break;                }                case START_ELEMENT: {                    switch (XaPool.Tag.forName(reader.getLocalName())) {                        case MAX_POOL_SIZE: {                            String value = rawElementText(reader);                            MAX_POOL_SIZE.parseAndSetParameter(value, node, reader);                            break;                        }                        case MIN_POOL_SIZE: {                            String value = rawElementText(reader);                            MIN_POOL_SIZE.parseAndSetParameter(value, node, reader);                            break;                        }                        case INITIAL_POOL_SIZE: {                            String value = rawElementText(reader);                            INITIAL_POOL_SIZE.parseAndSetParameter(value, node, reader);                            break;                        }                        case PREFILL: {                            String value = rawElementText(reader);                            POOL_PREFILL.parseAndSetParameter(value, node, reader);                            break;                        }                        case FAIR: {                            String value = rawElementText(reader);                            POOL_FAIR.parseAndSetParameter(value, node, reader);                            break;                        }                        case USE_STRICT_MIN: {                            String value = rawElementText(reader);                            POOL_USE_STRICT_MIN.parseAndSetParameter(value, node, reader);                            break;                        }                        case FLUSH_STRATEGY: {                            String value = rawElementText(reader);                            POOL_FLUSH_STRATEGY.parseAndSetParameter(value, node, reader);                            break;                        }                        case INTERLEAVING: {                            String value = rawElementText(reader);                            //just presence means true                            value = value == null ? "true" : value;                            INTERLEAVING.parseAndSetParameter(value, node, reader);                            break;                        }                        case IS_SAME_RM_OVERRIDE: {                            String value = rawElementText(reader);                            SAME_RM_OVERRIDE.parseAndSetParameter(value, node, reader);                            break;                        }                        case NO_TX_SEPARATE_POOLS: {                            String value = rawElementText(reader);                            //just presence means true                            value = value == null ? "true" : value;                            NOTXSEPARATEPOOL.parseAndSetParameter(value, node, reader);                            break;                        }                        case PAD_XID: {                            String value = rawElementText(reader);                            PAD_XID.parseAndSetParameter(value, node, reader);                            break;                        }                        case WRAP_XA_RESOURCE: {                            String value = rawElementText(reader);                            WRAP_XA_RESOURCE.parseAndSetParameter(value, node, reader);                            break;                        }                        case CAPACITY: {                            parseCapacity(reader, node);                            break;                        }                        default:                            throw ParseUtils.unexpectedElement(reader);                    }                    break;                }            }        }        throw ParseUtils.unexpectedEndElement(reader);    }
public ComponentInstance createInstance(Object instance) {        BasicComponentInstance obj = constructComponentInstance(new ImmediateManagedReference(instance), true);        obj.constructionFinished();        return obj;    }
protected BasicComponentInstance constructComponentInstance(ManagedReference instance, boolean invokePostConstruct) {        return constructComponentInstance(instance, invokePostConstruct, Collections.emptyMap());    }
protected BasicComponentInstance constructComponentInstance(ManagedReference instance, boolean invokePostConstruct, final Map<Object, Object> context) {        waitForComponentStart();        // create the component instance        final BasicComponentInstance basicComponentInstance = this.instantiateComponentInstance(preDestroyInterceptor, interceptorInstanceMap, context);        if(instance != null) {            basicComponentInstance.setInstanceData(BasicComponentInstance.INSTANCE_KEY, instance);        }        if (invokePostConstruct) {            // now invoke the postconstruct interceptors            final InterceptorContext interceptorContext = new InterceptorContext();            interceptorContext.putPrivateData(Component.class, this);            interceptorContext.putPrivateData(ComponentInstance.class, basicComponentInstance);            interceptorContext.putPrivateData(InvocationType.class, InvocationType.POST_CONSTRUCT);            interceptorContext.setContextData(new HashMap<String, Object>());            try {                postConstructInterceptor.processInvocation(interceptorContext);            } catch (Exception e) {                throw EeLogger.ROOT_LOGGER.componentConstructionFailure(e);            }        }        componentInstanceCreated(basicComponentInstance);        // return the component instance        return basicComponentInstance;    }
public void stop() {        if (stopping.compareAndSet(false, true)) {            synchronized (this) {                gate = false;                this.interceptorInstanceMap = null;                this.preDestroyInterceptor = null;                this.postConstructInterceptor = null;            }            //TODO: only run this if there is no instances            //TODO: trigger destruction of all component instances            //TODO: this has lots of potential for race conditions unless we are careful            //TODO: using stopContext.asynchronous() and then executing synchronously is pointless.            // Use org.jboss.as.server.Services#addServerExecutorDependency to inject an executor to do this async        }    }
public static InterceptorClassDescription merge(InterceptorClassDescription existing, InterceptorClassDescription override) {        if (existing == null && override == null) {            return EMPTY_INSTANCE;        }        if (override == null) {            return existing;        }        if (existing == null) {            return override;        }        final Builder builder = builder(existing);        if (override.getAroundInvoke() != null) {            builder.setAroundInvoke(override.getAroundInvoke());        }        if (override.getAroundTimeout() != null) {            builder.setAroundTimeout(override.getAroundTimeout());        }        if (override.getAroundConstruct() != null) {            builder.setAroundConstruct(override.getAroundConstruct());        }        if (override.getPostConstruct() != null) {            builder.setPostConstruct(override.getPostConstruct());        }        if (override.getPreDestroy() != null) {            builder.setPreDestroy(override.getPreDestroy());        }        if (override.getPrePassivate() != null) {            builder.setPrePassivate(override.getPrePassivate());        }        if (override.getPostActivate() != null) {            builder.setPostActivate(override.getPostActivate());        }        return builder.build();    }
protected synchronized VirtualFile getResteasySpringVirtualFile() throws DeploymentUnitProcessingException {        if(resourceRoot != null) {            return resourceRoot;        }        try {            Module module = Module.getBootModuleLoader().loadModule(MODULE);            URL fileUrl = module.getClassLoader().getResource(JAR_LOCATION);            if (fileUrl == null) {                throw JaxrsLogger.JAXRS_LOGGER.noSpringIntegrationJar();            }            File dir = new File(fileUrl.toURI());            File file = null;            for (String jar : dir.list()) {                if (jar.endsWith(".jar")) {                    file = new File(dir, jar);                    break;                }            }            if (file == null) {                throw JaxrsLogger.JAXRS_LOGGER.noSpringIntegrationJar();            }            VirtualFile vf = VFS.getChild(file.toURI());            final Closeable mountHandle = VFS.mountZip(file, vf, TempFileProviderService.provider());            Service<Closeable> mountHandleService = new Service<Closeable>() {                public void start(StartContext startContext) throws StartException {                }                public void stop(StopContext stopContext) {                    VFSUtils.safeClose(mountHandle);                }                public Closeable getValue() throws IllegalStateException, IllegalArgumentException {                    return mountHandle;                }            };            ServiceBuilder<Closeable> builder = serviceTarget.addService(ServiceName.JBOSS.append(SERVICE_NAME),                    mountHandleService);            builder.setInitialMode(ServiceController.Mode.ACTIVE).install();            resourceRoot = vf;            return resourceRoot;        } catch (Exception e) {            throw new DeploymentUnitProcessingException(e);        }    }
protected static String resolveRuntimeName(final OperationContext context, final PathElement address){        final ModelNode runtimeName = context.readResourceFromRoot(PathAddress.pathAddress(address),false).getModel()                .get(ModelDescriptionConstants.RUNTIME_NAME);            return runtimeName.asString();    }
public void deploy(DeploymentPhaseContext phaseContext) throws DeploymentUnitProcessingException {        final DeploymentUnit deploymentUnit = phaseContext.getDeploymentUnit();        final EEResourceReferenceProcessorRegistry registry = deploymentUnit.getAttachment(org.jboss.as.ee.component.Attachments.RESOURCE_REFERENCE_PROCESSOR_REGISTRY);        final EEModuleDescription moduleDescription = deploymentUnit.getAttachment(org.jboss.as.ee.component.Attachments.EE_MODULE_DESCRIPTION);        final CompositeIndex compositeIndex = deploymentUnit.getAttachment(Attachments.COMPOSITE_ANNOTATION_INDEX);        final PropertyReplacer replacer = EJBAnnotationPropertyReplacement.propertyReplacer(deploymentUnit);        if(compositeIndex == null) {            return;        }        final List<AnnotationInstance> instances = compositeIndex.getAnnotations(MANAGED_BEAN_ANNOTATION_NAME);        if (instances == null || instances.isEmpty()) {            return;        }        for (AnnotationInstance instance : instances) {            AnnotationTarget target = instance.target();            if (!(target instanceof ClassInfo)) {                throw EeLogger.ROOT_LOGGER.classOnlyAnnotation("@ManagedBean", target);            }            final ClassInfo classInfo = (ClassInfo) target;            // skip if it's not a valid managed bean class            if (!assertManagedBeanClassValidity(classInfo)) {                continue;            }            final String beanClassName = classInfo.name().toString();            // Get the managed bean name from the annotation            final AnnotationValue nameValue = instance.value();            final String beanName = (nameValue == null || nameValue.asString().isEmpty()) ? beanClassName : replacer.replaceProperties(nameValue.asString());            final ManagedBeanComponentDescription componentDescription = new ManagedBeanComponentDescription(beanName, beanClassName, moduleDescription, deploymentUnit.getServiceName());            // Add the view            ViewDescription viewDescription = new ViewDescription(componentDescription, beanClassName);            viewDescription.getConfigurators().addFirst(new ViewConfigurator() {                public void configure(final DeploymentPhaseContext context, final ComponentConfiguration componentConfiguration, final ViewDescription description, final ViewConfiguration configuration) throws DeploymentUnitProcessingException {                    // Add MB association interceptors                    configuration.addClientPostConstructInterceptor(ManagedBeanCreateInterceptor.FACTORY, InterceptorOrder.ClientPostConstruct.INSTANCE_CREATE);                    final ClassLoader classLoader = componentConfiguration.getModuleClassLoader();                    configuration.addViewInterceptor(AccessCheckingInterceptor.getFactory(), InterceptorOrder.View.CHECKING_INTERCEPTOR);                    configuration.addViewInterceptor(new ImmediateInterceptorFactory(new ContextClassLoaderInterceptor(classLoader)), InterceptorOrder.View.TCCL_INTERCEPTOR);                }            });            viewDescription.getBindingNames().addAll(Arrays.asList("java:module/" + beanName, "java:app/" + moduleDescription.getModuleName() + "/" + beanName));            componentDescription.getViews().add(viewDescription);            moduleDescription.addComponent(componentDescription);            // register an EEResourceReferenceProcessor which can process @Resource references to this managed bean.            registry.registerResourceReferenceProcessor(new ManagedBeanResourceReferenceProcessor(beanClassName));        }    }
