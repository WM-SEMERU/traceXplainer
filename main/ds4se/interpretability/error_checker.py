# AUTOGENERATED! DO NOT EDIT! File to edit: dev/8.1_interpretability.error_checker.ipynb (unless otherwise specified).

__all__ = ['logger', 'fhandler', 'formatter', 'fixed_errors', 'regex_errors', 'fixed_errors', 'regex_errors',
           'named_errors', 'warnings', 'name_coincidence_errors', 'jarWrapper', 'process_chars_for_bpes',
           'JavaErrorChecker', 'selected_errors', 'get_error_columns', 'group_error_df', 'JavaErrorAnalyzer',
           'compute_jaccard_similarity', 'verify_columns', 'compare_jacc_sample_sets']

# Cell

import pandas as pd
import numpy as np

from pathlib import Path
import os, shutil

from subprocess import *

from typing import Optional, List

# Cell

#Logging configuration

import logging
logger = logging.getLogger()
fhandler = logging.FileHandler(filename='mylog.log', mode='a')
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
fhandler.setFormatter(formatter)
logger.addHandler(fhandler)
logger.setLevel(logging.INFO)

# Cell

# Most generic errors --> the ones to be replaced first without loosing most specific errors

fixed_errors = {
    "cannot_find_symbol": "cannot find symbol",
    "non_existing_package": "package [a-zA-Z0-9_\.\$]+ does not exist",
}


# Errors to be found based on regex
regex_errors = {
    "not_visible_package": "package [a-zA-Z0-9_\.]+ is not visible",
    "exception": "^[A-Za-z]+Exception$",
    "special_char_expected": "'?(\(|\)|;|\[|\]|\<|\>)'? expected",
    "non_applicable_method_diff_len": "method .* cannot be applied .* reason: actual and formal argument lists differ in length",
    "non_applicable_method_varargs_mismatch": "method .* cannot be applied .* reason: varargs mismatch",
    "ambiguous_reference": "reference to [A-Za-z]+ is ambiguous",
    "no_suitable_method": "^no suitable method found for",
#     "no_suitable_method_diff_length": "no suitable method found for .* actual and formal argument lists differ in length",
#     "no_suitable_method_varargs_mismatch": "no suitable method found for .* varargs mismatch",
    "non_static_var_from_static_context": "non-static variable .* cannot be referenced from a static context",
    "cannot_be_dereferenced": "<?[A-Za-z]+>? cannot be dereferenced",
    "method_cannot_be_applied_to_given_types": "method .* in class .* cannot be applied to given types",
    "no_suitable_constructor": "^no suitable constructor found for",
    "unexpected_type": "unexpected type(\s)*required:(\s)*([a-zA-Z0-9_]+)(\s)*found:",
    "incomparable_types": "^incomparable types:",
    "deprecated_usage": "has been deprecated and marked for removal$",
    "non_static_method_referenced_from_static_context": "non-static method [a-zA-Z0-9_\.]+\s*\(\s*\)\s*cannot be referenced from a static context",
    "name_clash": "^name clash:",
    "cannot_inherit_from": "^cannot inherit",
    "unclosed_literal": "unclosed [a-zA-Z]+ literal",
    "try_without_catch_finally_declarations": "'try' without 'catch', 'finally' or resource declarations",
}

# Cell

# Most generic errors --> the ones to be replaced first without loosing most specific errors

fixed_errors = {
    "cannot_find_symbol": "cannot find symbol",
    "non_existing_package": "package [a-zA-Z0-9_\.\$]+ does not exist",
}


# Errors to be found based on regex
regex_errors = {
    "not_visible_package": "package [a-zA-Z0-9_\.]+ is not visible",
    "exception": "^[A-Za-z]+Exception$",
    "special_char_expected": "'?(\(|\)|;|\[|\]|\<|\>)'? expected",
    "non_applicable_method_diff_len": "method .* cannot be applied .* reason: actual and formal argument lists differ in length",
    "non_applicable_method_varargs_mismatch": "method .* cannot be applied .* reason: varargs mismatch",
    "ambiguous_reference": "reference to [A-Za-z]+ is ambiguous",
    "no_suitable_method": "^no suitable method found for",
#     "no_suitable_method_diff_length": "no suitable method found for .* actual and formal argument lists differ in length",
#     "no_suitable_method_varargs_mismatch": "no suitable method found for .* varargs mismatch",
    "non_static_var_from_static_context": "non-static variable .* cannot be referenced from a static context",
    "cannot_be_dereferenced": "<?[A-Za-z]+>? cannot be dereferenced",
    "method_cannot_be_applied_to_given_types": "method .* in class .* cannot be applied to given types",
    "no_suitable_constructor": "^no suitable constructor found for",
    "unexpected_type": "unexpected type(\s)*required:(\s)*([a-zA-Z0-9_]+)(\s)*found:",
    "incomparable_types": "^incomparable types:",
    "deprecated_usage": "has been deprecated and marked for removal$",
    "non_static_method_referenced_from_static_context": "non-static method [a-zA-Z0-9_\.]+\s*\(\s*\)\s*cannot be referenced from a static context",
    "name_clash": "^name clash:",
    "cannot_inherit_from": "^cannot inherit",
    "unclosed_literal": "unclosed [a-zA-Z]+ literal",
    "try_without_catch_finally_declarations": "'try' without 'catch', 'finally' or resource declarations",
    "constructor_cannot_be_applied": "^constructor [a-zA-Z0-9\.\_\$]+ .* cannot be applied to given types",
    "cannot_infer_type_for_local_var": "^cannot infer type for local variable",
    "abstract_class_cannot_be_instantiated": "^[a-zA-Z0-9_\.\$\<\>]+ is abstract; cannot be instantiated",
    "type_not_allowed": "'[a-zA-Z0-9_\.\<\>]+' type not allowed here",
    "class_doesnot_override_abst_mthd": "[a-zA-z0-9\.\$\<\>]+ is not abstract and does not override abstract method",
    "element_has_private_access": "^[a-zA-z0-9\.\$\<\>\(\)\s]+ has private access in",
    "element_has_protected_access": "[a-zA-z0-9\.\$\<\>\(\)\s]+ has protected access in",
    "element_cannot_be_accessed_from_outside_pkg": "cannot be accessed from outside package$",
    "illegal_static_declaration": "^Illegal static declaration in inner class",
    "pkg_deprecated_marked_for_removal": "[a-zA-Z0-9_\.\$\<\>]+ in [a-zA-Z0-9_\.\$\<\>]+ has been deprecated and marked for removal",
    "cannot_inherit_from": "^cannot inherit from final java.lang.Module",


}

# Cell

# Errors to be found based on specific names
# Note just a part of the error description is included but it is searched based on str coincidence

named_errors = {
    "method_doesnot_override_implement_super": "method does not override or implement a method",
    "unexpected_lambda": "lambda expression not expected",
    "expected_structure": "class, interface, or enum expected",
    "illegal_parenthesized_expression": "illegal parenthesized expression",
    "incompatible_types": "incompatible types",
    "for_each_not_applicable": "for-each not applicable to expression type",
    "return_required": "return required",
    #"cannot_infer_type_for_local variable": "cannot infer type for local variable",
    "element_cannot_be_accessed_from_outside_the_pkg": "cannot be accessed from outside package",
    "private_access": "has private access in",
    "unclosed_character_literal": "unclosed character literal",
    "not_a_statement": "not a statement"
}


# Warning (errors) to be found based on names (str coincidence)

warnings = {
    "warn_deprecated_API": "uses or overrides a deprecated API",
    "warn_unsafe_operations": "uses unchecked or unsafe operations",
    "xdiags_warning": "recompile with -Xdiags:verbose to get full output",
    "xlint_warning": "Recompile with -Xlint",
    "non_varargs-warning": "non-varargs call of varargs method with inexact argument type for last parameter"
}

# Cell

name_coincidence_errors = {
    **named_errors,
    **warnings
}

# Cell

def jarWrapper(*args):
    """
    Function for executing jar files from python
    :param args: Arguments to be passed for the executed program
    :returns: Output produced by the executed jar
    """
    process = Popen(['java', '-jar']+list(args), stdout=PIPE, stderr=PIPE)
    ret = []
    while process.poll() is None:
        line = process.stdout.readline()
        if line != '' and line.endswith(b'\n'):
            ret.append(line[:-1])
    stdout, stderr = process.communicate()

    ret += stdout.split(b'\n')
    if stderr != '':
        ret += stderr.split(b'\n')

    if '' in ret:
        ret.remove('')
    return ret

# Cell

def process_chars_for_bpes(code_snippet):
    return code_snippet.replace('\n', '<n>').replace('\t', '<t>').replace('@', '<@>')

# Cell

class JavaErrorChecker():
    def __init__(self, jar_path):
        self.jar_path = jar_path

    def perform_analysis(self, code_df, idx_column, error_column):
        """
        Performs the error analysis and gets the report error report
        :param  code_df: Pandas Dataframe with the required structure containing the code to be analyzed
        :param idx_column: Column name to reference the snippets in the generated report
        :param error_column: Column name to reference the error details in the generated report
        """

        self.__create_aux_dirs()
        code_df = self.__process_df(code_df)
        out_csv_name = "error_analysis_report.csv"
        code_csv_name = "code.csv"
        code_df.to_csv(str(self.resources_path/code_csv_name), index=False)
        args = [self.jar_path, code_csv_name, out_csv_name]

        try:
            jar_result = jarWrapper(*args)
            logging.info(f'jar program produced this output: {jar_result}')
        except Exception as e:
            logging.error(f'An error ocurred when trying to execute the jar program')
            #print(e.message, e.args)

        processed_df =  self.__process_results(out_csv_name, idx_column, error_column)
        self.__remove_aux_files()

        return processed_df


    def __process_results(self, out_name, idx_column, error_column):
        errors_report_df = pd.read_csv(str(self.resources_path/out_name), delimiter = '\t')
        clean_df = self.__get_generic_errors(errors_report_df, fixed_errors, regex_errors, name_coincidence_errors, error_column)
        dimension_based_df = self.__get_error_dims_records(clean_df, idx_column, error_column)
        return dimension_based_df

    def __get_generic_errors(self, df, fixed_errors, regex_errors, named_errors, error_column):
        """
        Performs processing for error names
        :param df: Pandas dataframe containing errors info.
        :param fixed_errors: Dictionary containing the names-regex for more generic error names
        :param regex_errors: Dictionary containing regex defining generic error names
        :param named_errors: Dictionary containing generic error names
        :param error_column: Column name to access to access errors in df
        :returns: Processed dataframe
        """
        logging.info('Processing external report.')
        df_copy = df.copy()

        # Replace most generic errors first
        for k, v in fixed_errors.items():
            df_copy.loc[df_copy[error_column].str.contains(v, case=False, regex=True), error_column] = k

        for k, v in regex_errors.items():
            df_copy.loc[df_copy[error_column].str.contains(v, case=False, regex=True), error_column] = k

        for k, v in named_errors.items():
            df_copy.loc[df_copy[error_column].str.contains(v, case=False, regex=False), error_column] = k

        return df_copy


    def __get_error_dims_records(self, df, idx_column, error_column):
        logging.info('Getting error dimensions.')
        # Group/count errors for each class
        grouped_errors = df.groupby([idx_column, error_column])[error_column].count().reset_index(name='count')

        # Turn errors rows into columns (dimensions for vectors)
        pivot_df = grouped_errors.pivot(index=idx_column, columns=error_column, values='count').reset_index()
        pivot_df = pivot_df.fillna(0)

        return pivot_df

    def __remove_aux_files(self):
        """
        Removes auxiliar - tmp directories/files created for the functioning of the external package
        """
        logging.info('Removing auxiliar directories/files.')
        shutil.rmtree(str(self.base_path))

    def __create_aux_dirs(self):
        logging.info('Creating auxiliar directories.')
        self.out_path = Path(".")
        # Configure directories for jar tool
        self.base_path = self.out_path / "java"
        self.resources_path = self.base_path / "resources"
        self.compiled_path = self.resources_path / "compiled"
        self.base_path.mkdir(exist_ok=True)
        self.resources_path.mkdir(exist_ok=True)
        self.compiled_path.mkdir(exist_ok=True)

    def __process_df(self, df):
        """
        Function to process the df according to the format required by the
        java analyzer
        """
        df = df.copy()

        # Add special tokens expected by the analyzer
        df['code'] = df['code'].apply(lambda method: process_chars_for_bpes(method))

        # Format the dataframe appropriately as the analyzer program expects
        columns = df.columns

        if "idx" not in columns:
            idx_column = [i for i in range(df.shape[0])]
            df['idx'] = idx_column
        if "stop_column" not in columns:
            stop_column = ['*stop*' for _ in range(df.shape[0])]
            df['stop_column'] = stop_column

        df = df[['idx', 'code', 'stop_column']]

        return df

# Cell

selected_errors = ['cannot_find_symbol',
    'illegal_parenthesized_expression',
    'incompatible_types',
    'method_doesnot_override_implement_super',
    'non_applicable_method_diff_len',
    'non_existing_package',
    'warn_deprecated_API',
    'warn_unsafe_operations',
    'xdiags_warning',
    'xlint_warning',
    'method_cannot_be_applied_to_given_types',
    'expected_structure',
    'cannot_be_dereferenced',
    'for_each_not_applicable',
    'deprecated_usage',
    'non_static_var_from_static_context',
    'unexpected_lambda',
    'ambiguous_reference',
    'non_applicable_method_varargs_mismatch',
    'no_suitable_constructor',
    'not_visible_package',
    'no_suitable_method',
    'unexpected_type',
    'incomparable_types',
    'invalid method declaration; return type required',
    'private_access',
    'method reference not expected here',
    'non_varargs-warning'
]

# Cell

def get_error_columns(df_columns: List[str]) -> List[str]:
    """
    Get the appropriate columns according to the selected errors
    and present errors in the provided dataset

    :param df_columns: List containing the columns of a given dataset

    :return: List containing appropriate columns.
    """

    return [e  for e in errors_result.columns if e != 'ID Class']

# Cell

def group_error_df(error_df: pd.DataFrame, selected_errors) -> pd.DataFrame:
    """
    :param error_df: Pandas Dataframe containing the errors for the code snippet
                     records
    :return: Pandas DataFrame containing the grouped errors
    """
    error_df = error_df.copy()

    actual_columns = [e for e in error_df.columns if e != 'ID Class']
    actual_err_set = set(actual_columns)
    sel_error_set = set(selected_errors)

    present_errors = list(actual_err_set & sel_error_set)
    diff = list(actual_err_set - sel_error_set)

    # present_errors = [e for e in selected_errors if e in actual_columns]

    n_diffs = len(diff)

    other_errors = error_df.loc[:, diff]
    error_df = error_df.loc[:, ['ID Class', *present_errors]]

    # Group errors with less frequency -> other (and count them)
    other_errors['other'] = other_errors.sum(axis=1)
    other_errors['n_others'] = (other_errors[diff] > 0).sum(1)

    error_df['other'] = other_errors['other']
    error_df['n_grouped_errors'] = other_errors['n_others']

    return error_df

# Cell

class JavaErrorAnalyzer:
    def __init__(self, jar_path: str):
        """
        :param jar_path:
        """

        self.java_error_checker = JavaErrorChecker(jar_path)

    def get_errors_java_data(self, df: pd.DataFrame,
                             id_column: Optional[str]='ID Class',
                             error_column: Optional[str]=' error message',
                             base_errors:Optional[list]=selected_errors) -> pd.DataFrame:
        """
        Function to perform the process of getting error-related data
        :param df: Pandas DataFrame containing code snippets
        :param jar_path: Path with the corresponding location of the jar pkg (error detection program)
        :param id_column: Idx column name in the generated report
        :param error_column: Column name of the error in the generated report

        :return: Pandas DataFrame containing the grouped errors
        """


        error_report_df = self.java_error_checker.perform_analysis(df, id_column, error_column)

        grouped_df = group_error_df(error_report_df, base_errors)

        return grouped_df

# Cell

def compute_jaccard_similarity(x: np.ndarray, y: np.ndarray) -> float:
    """
    Calculate the jaccard similarity for 2 sets

    :param x: np array containing 1st set
    :param y: np array containing 2nd set

    :return: Float with the resulting jaccard index value.
    """
    x_set = set(x)
    y_set = set(y)

    jacc_idx= len(x_set & y_set) / len(x_set | y_set)

    return jacc_idx

# Cell

def verify_columns(cols1: List[str], cols2: List[str]) -> bool:
    """
    Perform verification for columns prior to comparison

    :return: bool indicating if the column sets match
    """
    if len(cols1) != len(cols2):
        msg = "Columns lengths don't match"
        logging.error(msg)
        return False

    s1 = set(cols1)
    s2 = set(cols2)

    if len(s1-s2) != 0:
        msg = "Columns sets don't match"
        logging.error(msg)
        return False

    return True

# Cell

def compare_jacc_sample_sets(sample_set1: pd.DataFrame, sample_set2: pd.DataFrame):
    """
    Compare 2 sample sets based on error information: Computes jaccard similarity index
    for the vector representing the mean of base errors for the entire set.


    :param sample_set1: DataFrame containing error information for 1st sample set to be compared
    :param sample_set2: DataFrame containing error information for 2nd sample set to be compared
    :return: Float value Jaccard similarity
    """
    columns_s1 = get_error_columns(list(sample_set1.columns))
    columns_s2 = get_error_columns(list(sample_set2.columns))

    if not verify_columns(columns_s1, columns_s2):
        msg = "Data frames cannot be compared, different dimensions provided."
        logger.error(msg)
        raise Exception(msg)

    error_vect_s1 = sample_set1.describe()[columns_s1].loc['mean'].values
    error_vect_s2 = sample_set2.describe()[columns_s2].loc['mean'].values

    jacc_idx = compute_jaccard_similarity(error_vect_s1, error_vect_s2)

    return jacc_idx