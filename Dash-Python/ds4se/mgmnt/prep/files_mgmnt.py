# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/0.2_mgmnt.prep.files_mgmnt.ipynb (unless otherwise specified).

__all__ = ['logger', 'get_file_name', 'get_files_list', 'jsonl_list_to_dataframe', 'jsonl_to_dataframe',
           'csv_to_dataframe', 'load_np_vectors', 'get_vector_paths_4_sample_set']

# Cell

import pandas as pd
import numpy as np

from pathlib import Path, PosixPath
from typing import List

# Cell
#Logging configuration

import logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Cell

def _check_file_existence(file_path: str) -> bool:
    """
    Validates the existence of a file
    """
    path = Path(file_path)
    if not path.exists():
        logging.error('Provided file cannot be found.')
        return False
    return True

def _check_dir_existence(path: PosixPath):
    """
    Validates the existence of a given directory
    """
    if not path.exists():
        msg = "Provided directory cannot be found."
        logging.error(msg)
        raise Exception(msg)


# Cell

def get_file_name(full_dir: str):
    """
    Retrieves the filename of a path
    """
    path = Path(full_dir)
    return Path(path.name).stem

# Cell

def get_files_list(directory: str, file_extension: str) -> List[str]:
    """
    Get a list of files (with a specific extension) within a directory.
    :param directory: Directory to extract list of files
    :param file_extension: File extension of files to include in the list

    :return: List of files within the directoy with the provided extension
    """
    path = Path(directory)
    _check_dir_existence(path)

    return list(path.glob(f'**/*.{file_extension}'))

# Cell

def jsonl_list_to_dataframe(file_list: List[str]) -> pd.DataFrame:
    """Load a list of jsonl.gz files into a pandas DataFrame."""
    return pd.concat([pd.read_json(f,
                                   orient='records',
                                   compression='gzip',
                                   lines=True)
                      for f in file_list], sort=False)

def jsonl_to_dataframe(file_path: str) -> pd.DataFrame:
    """
    Gets a DataFrame from a jsonl file
    :param file_path: Location of the jsonl file
    :return:
    """

    _check_file_existence(file_path)
    return pd.read_json(file_path, orient='records', lines=True)

# Cell

def csv_to_dataframe(file_path: str) -> pd.DataFrame:
    """Gets a DataFrame from a csv file"""

    _check_file_existence(file_path)
    return pd.read_csv(file_path)

# Cell

def load_np_vectors(path: str) -> np.array:
    """
    :param path: Location of the .npy files to be loaded

    :return: Np array corresponding to the loaded vectors
    """
    path = Path(path)
    if not path.exists():
        msg = "Vectors could not be found"
        logging.error(msg)
        raise Exception(msg)
    return np.load(str(path))

# Cell

def get_vector_paths_4_sample_set(set_name: str, base_path: str) -> List[PosixPath]:
    """
    Gets the files for a given directory containing sample set
    :param set_name: Str indicating the name of the directory for a given set of samples
    :param base_path: Str indicating the location directory of samples
    """
    paths = []
    vectors_path = f"{base_path}/{set_name}"
    path = Path(vectors_path)

    # TODO: Validate existence of directory

    # Iterate over all the samples for a set
    for sample_directory in path.iterdir():
        vectors_path = list(sample_directory.rglob('*-ft_vecs.npy'))
        if len(vectors_path) == 0:
            logging.warning(f"Could not load vectors for sample {str(directory)}")
            continue

        paths.append(vectors_path[0])

    return paths